{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nadd suppport for vedv\nplease go to stack overflow for help and support if you open a github issue here is our policy 1 it must be a bug a feature request or a significant problem with the documentation for small docs fixes please send a pr instead 2 the form below must be filled out 3 it shouldnt be a tensorboard issue those go here heres why we have that policy tensorflow developers respond to issues we want to focus on work that benefits the whole community eg fixing bugs and adding features support only helps individuals github also notifies thousands of people when issues are filed we want them to see you communicating an interesting problem rather than being redirected to stack overflow system information have i written custom code as opposed to using a stock example script provided in tensorflow os platform and distribution eg linux ubuntu 1604 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device tensorflow installed from source or binary tensorflow version use command below python version bazel version if compiling from source gcccompiler version if compiling from source cudacudnn version gpu model and memory exact command to reproduce you can collect some of this information using our environment capture script you can obtain the tensorflow version with bash python c import tensorflow as tf tfversionversion describe the problem describe the problem clearly here be sure to convey here why its a bug in tensorflow or a feature request source code logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached try to provide a reproducible test case that is the bare minimum necessary to generate the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncant run bertvocabfromdataset without typeerror tensor is unhashable\nissue type support have you reproduced the bug with tensorflow nightly no source source tensorflow version 213 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior this is the code from you manual i really dont understans that i get this error why is it if i add i get runtimeerror inputdataset attempting to capture an eagertensor without building a function standalone code to reproduce the issue shell data tagspath from import bertvocabfromdataset as bertvocab tokens data the target vocabulary size vocabsize 50000 reserved tokens that must be included in the vocabulary reservedtokenspad unk start end arguments for textberttokenizer arguments for learnparams relevant log output shell typeerror tensor is unhashable instead use tensorref as the key"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nfloat16 mixed precision training\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2130 custom code yes os platform and distribution ubuntu 20045 lts mobile device no response python version python 3109 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory a6000 current behavior enabled float16 training by setting the mixed precision policy but why i still need to manually cast the y tensors to float16 before calculating the loss error when no manual cast the tensor image standalone code to reproduce the issue shell confidential relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nckpt to tflite\nhow can i convert ckpt file to tf lite while ive only ckpt file no metafile present"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nwhen converting tensorflow model to tflite model is there any way to fix the output order during inference using tflite as facing an issue of output order of tflite inference on meraki custom cv\ni took a pretrained model ssd mobilenet 320x320 for object detection from the tensorflow zoo and configuredtuned it according to my data i trained a tensorflow model which detects 2 labels i have used the latest checkpoint to save the model then froze it and finally performed tf lite conversion i did this because i need to upload the tf lite model only to a cisco camera im facing an issue with the output order during tf lite inference as the output arrays get jumbled rearranged i need help on how to convert the tensorflow model to tf lite efficiently my tensorflow version is 210"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ndistributed training with parameter servers example using a single binary\nhello everyone i am sorry if this is a duplicate issue but from my considerable search i could not find a single endtoend distributed parameterserver example to run using tensorflow using the keras api with fit method also for some reason the documentation for parameterserver strategy seems a lot more confusing and difficult to get started with compared to multiworker strategy i have been running training jobs using the estimator api before and now trying to update it to tf2x style distributed training job with parameterserver training strategy using a single binary file for all workers and parameterservers i started with the example in documentation here and modified the code to be used as a single binary code import tensorflowdatasets as tfds import tensorflow as tf import os clusterresolver if in worker ps start a tensorflow server and wait server or grpc starttrue serverjoin else parameterserver strategy globalbatchsize 64 x tfrandomuniform10 10 y tfrandomuniform10 dataset yshuffle10repeat dataset dataset datasetprefetch2 with strategyscope model lossmse stepsperexecution10 workingdir myworkingdir logdir ospathjoinworkingdir log ckptfilepath ospathjoinworkingdir ckpt backupdir ospathjoinworkingdir backup callbacks modelfitdataset epochs5 stepsperepoch20 callbackscallbacks to my understanding all workers and paramterservers will start and wait for chief to assign the tasks chief or coordinator documentation uses them interchangeably but is there any difference between the two will automatically divide the work based on the information it gets from clusterresolver let me know if thats wrong interpretation in any case i would highly appreciate if someone can point out what i am doing wrong in this example because i have not been able to get it to work"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nwhen building from source code i always end up with a python 310 whl file instead of a python38 whl file\nissue type buildinstall have you reproduced the bug with tensorflow nightly no source source tensorflow version 2140 custom code no os platform and distribution linux ubuntu 20046 lts mobile device no response python version 38 bazel version 117 gcccompiler version 940 cudacudnn version 11887 gpu model and memory gtx 1050 ti 4gb current behavior when i try to build the source code from my machine i end up always with a wheel for python 310 although i specified the python path for python38 and i dont even have python310 installed the generated wheel is called can you guide why this is happening and how to solve it standalone code to reproduce the issue shell just trying to build the source code following the steps from this two sites relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nissues running transformer model example with estimator api\nhello everyone i am trying to run an image classification training example with vision transformer from keras examples everything ran perfectly when i ran it as it is but i started facing issues when i switched training from modelfit to ofcourse i made the appropriate changes to first convert model to estimator from what i understand the problem lies with saving and reloading the model which is done by the estimator api the model has custom classes class patcheslayerslayer def initself patchsize kwargs superinitkwargs selfpatchsize patchsize def callself images batchsize tfshapeimages0 patches imagesimages sizes1 selfpatchsize selfpatchsize 1 strides1 selfpatchsize selfpatchsize 1 rates1 1 1 1 paddingvalid patchdims patchesshape1 patches tfreshapepatches batchsize 1 patchdims return patches personal addition def getconfigself baseconfig supergetconfig baseconfigupdate patchsize selfpatchsize return baseconfig class def initself numpatches projectiondim kwargs superinitkwargs selfnumpatches numpatches selfprojection layersembedding inputdimnumpatches def callself patch positions tfrangestart0 limitselfnumpatches delta1 encoded selfprojectionpatch return encoded personal addition def getconfigself baseconfig supergetconfig baseconfigupdate numpatches selfnumpatches projection selfprojection positionembedding return baseconfig from looking at some related issues i found how we need to provide a getconfig method to save and reload the model with custom classes so i made small personal modifications but now its sort of giving me a different issue i am unable to understand error log warningswarn xtrain shape 50000 32 32 3 ytrain shape 50000 1 xtest shape 10000 32 32 3 ytest shape 10000 1 trainpy225 runconfiginit from is deprecated and will be removed in a future version instructions for updating use tfkeras instead userwarning is deprecated and will be removed after 20201011 to update it simply pass a truefalse value to the training argument of the call method of your layer or model warningswarn traceback most recent call last file trainpy line 257 in history file trainpy line 231 in runexperiment modelest modeldir configrunconfig file line 376 in modeltoestimatorv2 return file line 725 in modeltoestimator warmstartpath customobjects file line 457 in savefirstcheckpoint model kerasmodel file line 230 in cloneandbuildmodel clone file line 806 in cloneandbuildmodel clone clonemodelmodel file line 539 in clonemodel return clonefunctionalmodel file line 222 in clonefunctionalmodel modelconfigs createdlayers file line 298 in config file line 1590 in getnetworkconfig layerconfig file line 295 in copylayer layerfnlayer file line 52 in clonelayer return file trainpy line 108 in fromconfig return clsconfig typeerror init missing 1 required positional argument projectiondim i thought it might be because of patchencoder class constructor has custom objects as argument so i tried to do but to no vail in any case i would highly appreciate if someone can guide me as to where i am going wrong in this"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntesla v100 tensorflow cuda support\nissue type support have you reproduced the bug with tensorflow nightly yes source source tensorflow version 24 custom code yes os platform and distribution rhel 79 mobile device no response python version 36 bazel version no response gcccompiler version 43 cudacudnn version 118 10176 gpu model and memory tesla v100 2gb vram current behavior attempting to fetch value instead of handling error internal failed to get device attribute 13 for device 0 cudaerrorunknown unknown error nvidiasmi give the following output nvidiasmi 4505105 driver version 4505105 cuda version 110 nvccv the following output nvcc nvidia r cuda compiler driver copyright c 20052019 nvidia corporation built on frifeb8190817pst2019 cuda compilation tools release 101 v101105 standalone code to reproduce the issue shell doesnt happen with windows or ubuntu systems relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nparse output of\nissue type support have you reproduced the bug with tensorflow nightly no source source tensorflow version v2111 custom code yes os platform and distribution linux ubuntu 2004 mobile device android python version no response bazel version 620 gcccompiler version 12 cudacudnn version no response gpu model and memory no response current behavior im trying to use the model on a c application im able to execute the inference and get the results based on the netron app i see that its output is image but i couldnt find an example code showing how to parse this output i tried to look into and but the output of the model is different from the one provided here do you have any example code available in java python or even better in c to parse this model output standalone code to reproduce the issue shell no example code is available to parse the output of relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nerror installing impoerting tf model into node red\nhello i am getting a tensor flow to install on my node red it seems like there is and install issue and i keep on getting the error pictured below i have also tried import an model from teachable machine too and i get the same error please help capture capture1"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nsupport for empty gpu batches during distributed training\nissue type support have you reproduced the bug with tensorflow nightly no source source tensorflow version 2120 custom code yes os platform and distribution ubuntu 2004 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior when doing distributed training using mirroredstrategy one may encounter empty gpu batches when dropremainderfalse during dataset construction from 44348 it seems it is a longstanding issue for the last few batches of data it is possible that some replica workers receive an empty tensor as input see here for an example either one must set dropremaindertrue or consider not using tffunction because you would have to add a conditional statement in the trainstep function which wont work with tffunction so from the point of efficiency dropremaindertrue seems the only option in some applications or critical experiments one would not like to drop the remainder data for very precise and reproducible quantitative analysis so can there be a support for handling empty gpu batches in distributed mode standalone code to reproduce the issue shell over 3 replicas results in the following output batch 1 replica 1 0 1 replica 2 2 3 replica 3 batch 2 replica 1 4 5 replica 2 6 7 replica 3 without dropremaindertrue this will cause an incompatible shape error when doing a forward pass relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nconvert tftensor into tensorflowtensor\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 213 custom code yes os platform and distribution ubuntu 20 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version 112 gpu model and memory no response current behavior is there any way to convert tftensor from python into tensorflowtensor c standalone code to reproduce the issue shell actually using pybind11 i can get pyobject from tftensor and have no idea how to get tensorflowtensor from pyobject relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to use keras layers to augment both image and label data in image segmentation tasks？\nissue type others have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 26 custom code yes os platform and distribution linux ubuntu 2004 mobile device no response python version python 37 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior how to use tool a to enhance both image and label data in image segmentation tasks i saw an example in the official document of using keras layer for data augmentation which is very useful in the training process of classification models because the data augmentation does not require synchronized operations on labels however in the segmentation task if i embed the data enhancement layer into the model structure i cannot do operations like rotate 、zoom etc on the label and image at the same time because the fit method only feed the original image into the model for inference which results in the label being isolated from the inference process so it is impossible to do synchronize affine transformations with the original image thanks standalone code to reproduce the issue shell i cannot copy my code from the company computer i just want to know how to do efficient data augmentation that can apply gpu acceleration and distribute strategythanks relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nsavedmodel is not deterministic when saved with\nissue type support have you reproduced the bug with tensorflow nightly no source source tensorflow version 292 custom code no os platform and distribution ubuntu 2004 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior i have a model with montecarlo sampling layers at train time it is ok for sampling to be random and i do not set a seed at inference this model must output deterministic results so the sampled values must be reproducible i need to save this model after training using and then load it with when training is complete i save the model like so modelseed 42 savepath saveformattf to load it import tensorflow as tf model for in range10 output modelinputtensor trainingfalse i expect output to be always the same for the same input within one python process and when reloading however it is not this is what my model looks like only the relevant portions class def initself args kwargs selfseed none selfmclayer property def seedself return selfseed seedsetter def seedself value if lgrinfosetting random seed selfseed value tfrandomsetseedvalue else lgrinfotf op determinism not set def callself inputs trainingtrue return selfmclayerinputs seedselfseed internally in i use the seed value like so tfrandomsetseedseed samples distsamplenumsamples seedseed where dist is a distribution from when selfseed none which is the case in training distsample will randomly generate values when selfseed is set then i need distsample to be reproducible the loaded model even with op determinism enabled during saving and loading is not reproducible standalone code to reproduce the issue shell see above relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nerror input 0 of layer batchnormalization is incompatible with the layer expected ndim2 found ndim4\nestoy intentando entrenar un modelo gan utilizando keras en tensorflow pero estoy encontrando el siguiente error input 0 of layer batchnormalization is incompatible with the layer expected ndim2 found ndim4 full shape received none none none 32768 el error ocurre cuando intento entrenar el modelo con el siguiente código python history epochs100 callbackscheckpoint tensorboard ¿alguien podría ayudarme a entender qué está causando este error y cómo puedo solucionarlo gracias"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhi radres2019 thank you for reporting the issue\nhi radres2019 thank you for reporting the issue you are seeing this error because colab has python version 310 tensorflow quantum 072 is compatible with python 37 38 39 and does not support python 310 please refer to the gist where i was able to install tensorflow quantum sucessfully here thank you originally posted by synandi in"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nusing c api and library\nsystem information windows if possible tensorflow lite in play windows google play services version standalone code to reproduce the issue hi i have compiled tflites static library libtensorflowlite a and libtensorflowitecso using cmake according to the official document however when i introduced this library and used c to call it the following error occurred undefined reference to undefined reference to imp do you know what caused it or are there any relevant cases thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nwhat phone support tensorflow lite gpu delegate\nclick to expand issue type support have you reproduced the bug with tf nightly no source binary tensorflow version 2120 custom code no os platform and distribution android 13 mobile device android 13 python version 383 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour i tested multiple mobile phones including xiaomi 12s ultra oneplus 8 honor nova 10 oppo reno 9 using the example android apk at on all of the devices the app tells gpu is not supported but nnapi and cpu is ok anything i can do to enable the gpu delegate on these qualcomm snapdragon devices standalone code to reproduce the issue shell the example android apk at relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nabout using c to call tflite\nsystem information riscv standalone code to reproduce the issue hi if i want to compile tflite into a library and then use c to call it how can i effectively optimize and crop it to make the compiled tflite library file smaller because for our model tflite micro is not supported by many operators"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntensorflowmap hangs randomly when using for numparallelcalls a value 1\nsystem information have i written custom code as opposed to using a stock example script provided in tensorflow yes os platform and distribution eg linux ubuntu 1604 wsl2 on windows tensorflow installed from source or binary binary tensorflow version use command below 2120 python version 3810 cudacudnn version 120 gpu model and memory rtx a5000 24gb describe the problem i am using tensorflow in a docker container on wsl2 for training neural networks but unfortunately everything freezes during the image import if done with the tfmap function with the parameter numparallelcalls set to a value 1 below is a minimal example of the code which causes the console to freeze at a random step and the cpuusage to drop to a minimal level while the ram is still occupied after everything is frozen the docker container is unresponsive and has to be restarted by stopping the process this might even take half a day a few hundred thousand iterations but it allways happens at some point source code logs import tensorflow as tf def return tfioreadfilefilename filenames for i in range 100000 datasettrain datasettrain numparallelcalls 2 datasettrain datasettrainbatch50 for epoch in range1000 for step xbatchtrain in printepoch epoch start train stepstep this issue is similar to others like 32454 but i still cant find a fix bypassing the mapfunction by loading everything at once works definitly during mapping if parallel calls are allowed"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nsame error as 35100 w error occurred when finalizing generatordataset iterator failed precondition python interpreter state is not initialized the process may be terminated node pyfunc\ni am reproducing the code i followed there requirement but when code reached to 44100 epoch i got this error 20230524 064229554799 w error occurred when finalizing generatordataset iterator failed precondition python interpreter state is not initialized the process may be terminated node pyfunc i tried to to update tensorflow but it stop working because of keras version code requirements package version abslpy 140 astor 081 certifi 2022127 charsetnormalizer 310 colorama 046 filelock 3120 fsspec 202310 gast 053 googlepasta 020 grpcio 1513 h5py 380 huggingfacehub 0141 idna 34 importlibmetadata 600 joblib 120 keras 224 kerasapplications 108 kerasbert 0800 kerasembedsim 0100 0160 kerasmultihead 0290 kerasposembd 0130 080 keraspreprocessing 112 kerasselfattention 0510 kerastransformer 0330 markdown 341 markupsafe 212 mock 501 numpy 1216 packaging 231 pip 2231 protobuf 3201 pyyaml 60 regex 202355 requests 2310 scikitlearn 102 scipy 173 setuptools 6563 six 1160 sklearn 00post5 tensorboard 1131 tensorflowestimator 1130 tensorflowgpu 1131 termcolor 220 threadpoolctl 310 tokenizers 0133 torch 1131 tqdm 4650 transformers 4292 typingextensions 450 urllib3 202 werkzeug 223 wheel 0384 wincertstore 02 wrapt 1150 zipp 3150 and runpy code is codingutf8 from dataloader import datagenerator loaddata from model import e2emodel evaluate from utils import extractitems gettokenizer metric import os argparse 1 from keras import backend as k ifkbackend tensorflow import tensorflow as tf from import setsession config tfconfigproto true sess tried these lines too but not useful config sess parser controller defaulttrue typebool helpto train the hbt model python runpy traintrue defaultvkg typestr helpspecify the dataset from args parserparseargs if name main pretrained bert model config bertmodel casedl12h768a12 bertconfigpath pretrainedbertmodels bertmodel bertconfigjson bertvocabpath pretrainedbertmodels bertmodel vocabtxt bertcheckpointpath pretrainedbertmodels bertmodel bertmodelckpt dataset argsdataset trainpath data dataset traintriplesjson devpath data dataset devtriplesjson testpath data dataset 12345 testpath data dataset normal seo epo testpath data dataset testtriplesjson overall test reldictpath data dataset rel2idjson saveweightspath savedweights dataset bestmodelweights lr 1e5 tokenizer traindata devdata testdata id2rel rel2id numrels loaddatatrainpath devpath testpath reldictpath subjectmodel objectmodel hbtmodel bertcheckpointpath lr numrels if argstrain batchsize 6 epoch 100 maxlen 100 steps lentraindata batchsize datamanager tokenizer rel2id numrels maxlen batchsize evaluator evaluatesubjectmodel objectmodel tokenizer id2rel devdata saveweightspath stepsperepochsteps epochsepoch callbacksevaluator else testresultpath results dataset testresultjson isexactmatch true if dataset wikikbp else false if isexactmatch printexact match else printpartial match precision recall f1score metricsubjectmodel objectmodel testdata id2rel tokenizer isexactmatch testresultpath 35100"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow object detection project\nclick to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version tf1x custom code no os platform and distribution macos ventura mobile device macbook air 2020 i3 python version 31011 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour so i am making an object detection projetc for school and i need help whenever i run this code this is the error that pops up please help it is due in a few days i have installed all neccesary modules i think standalone code to reproduce the issue shell usrbinenv python coding utf8 detect objects using your webcam this demo will take you through the steps of running an outofthebox detection model to detect objects in the video stream extracted from your camera create the data directory the snippet shown below will create the data directory where all our data will be stored the code will create a directory structure as shown bellow codeblock bash data └── models where the models folder will will contain the downloaded models import os oschdir detection datadir ospathjoinosgetcwd data modelsdir ospathjoindatadir models for dir in datadir modelsdir if not ospathexistsdir osmkdirdir download the model the code snippet shown below is used to download the object detection model checkpoint file as well as the labels file pbtxt which contains a list of strings used to add the correct label to each detection eg person the particular detection algorithm we will use is the ssd resnet101 v1 fpn 640x640 more models can be found in the tensorflow 2 detection model zoo to use a different model you will need the url name of the specific model this can be done as follows 1 right click on the model name of the model you would like to use 2 click on copy link address to copy the download link of the model 3 paste the link in a text editor of your choice you should observe a link similar to 4 copy the xxxxxxxxx part of the link and use it to replace the value of the modelname variable in the code shown below 5 copy the yyyyyyyy part of the link and use it to replace the value of the modeldate variable in the code shown below for example the download link for the model used below is import tarfile import urllibrequest download and extract model modeldate 20200711 modelname modeltarfilename modelname targz modelsdownloadbase modeldownloadlink modelsdownloadbase modeldate modeltarfilename pathtomodeltar ospathjoinmodelsdir modeltarfilename pathtockpt ospathjoinmodelsdir ospathjoinmodelname checkpoint pathtocfg ospathjoinmodelsdir ospathjoinmodelname pipelineconfig if not printdownloading model this may take a while end pathtomodeltar tarfile tarfileclose printdone download labels file labelfilename mscocolabelmappbtxt labelsdownloadbase pathtolabels ospathjoinmodelsdir ospathjoinmodelname labelfilename if not printdownloading label file end import ssl labelfilename pathtolabels printdone load the model next we load the downloaded model 2 suppress tensorflow logging import tensorflow as tf from objectdetectionutils import labelmaputil from objectdetectionutils import visualizationutils as visutil from objectdetectionutils import visualizationutils as vizutils from import modelbuilder suppress tensorflow logging 2 enable gpu dynamic memory allocation gpus for gpu in gpus true load pipeline config and build a detection model configs modelconfig configsmodel detectionmodel istrainingfalse restore checkpoint ckpt ckpt0expectpartial tffunction def detectfnimage detect objects in image image shapes predictiondict shapes detections shapes return detections predictiondict tfreshapeshapes 1 load label map data for plotting label maps correspond index numbers to category names so that when our convolution network predicts 5 we know that this corresponds to airplane here we use internal utility functions but anything that returns a dictionary mapping integers to appropriate string labels would be fine categoryindex usedisplaynametrue define the video stream we will use opencv to capture the video stream generated by our webcam for more information you can refer to the opencvpython tutorials import cv2 cap cv2videocapture0 putting everything together the code shown below loads an image runs it through the detection model and visualizes the detection results including the keypoints note that this will take a long time several minutes the first time you run this code due to tffunctions tracecompilation on subsequent runs eg on new images things will be faster here are some simple things to try out if you are curious modify some of the input images and see if detection still works some simple things to try out here just uncomment the relevant portions of code include flipping the image horizontally or converting to grayscale note that we still expect the input image to have 3 channels print out and try to match the box locations to the boxes in the image notice that coordinates are given in normalized form ie in the interval 0 1 set minscorethresh to other values between 0 and 1 to allow more detections in or to filter out more detections import numpy as np while true read frame from camera ret imagenp capread expand dimensions since the model expects images to have shape 1 none none 3 imagenpexpanded npexpanddimsimagenp axis0 things to try flip horizontally imagenp npfliplrimagenpcopy convert image to grayscale imagenp nptile npmeanimagenp 2 keepdimstrue 1 1 3astypenpuint8 inputtensor 0 dtypetffloat32 detections predictionsdict shapes detectfninputtensor labelidoffset 1 imagenpcopy categoryindex maxboxestodraw200 minscorethresh30 agnosticmodefalse display output cv2imshowobject detection 800 600 if cv2waitkey25 0xff ordq break caprelease cv2destroyallwindows relevant log output shell traceback most recent call last file line 92 in from objectdetectionutils import labelmaputil file line 21 in from import stringintlabelmappb2 file line 36 in file line 561 in new typeerror descriptors cannot not be created directly if this call came from a pb2py file your generated code is out of date and must be regenerated with protoc 3190 if you cannot immediately regenerate your protos some other possible workarounds are 1 downgrade the protobuf package to 320x or lower 2 set but this will use purepython parsing and will be much slower more information"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntypeerror cannot convert 01 to eagertensor of dtype int64\nclick to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version 2120 custom code yes os platform and distribution googlecolab mobile device no response python version 31011 bazel version colab gcccompiler version colab cudacudnn version colab gpu model and memory colab current behaviour getting this error when i execute the code present in tensowflow website to implement error typeerror cannot convert 01 to eagertensor of dtype int64 python class def initself initiallearningrate initiallearningrate def callself step return step 1 optimizer standalone code to reproduce the issue shell typeerror cannot convert 01 to eagertensor of dtype int64 relevant log output typeerror traceback most recent call last in 7 return step 1 8 9 optimizer 4 frames in initself learningrate momentum nesterov weightdecay clipnorm clipvalue globalclipnorm useema emamomentum jitcompile name kwargs 121 kwargs 122 123 selflearningrate 124 selfmomentum momentum 125 selfnesterov nesterov in learningrate 382 create a variable to hold the current learning rate 383 currentlearningrate tfconverttotensor 384 385 386 tfvariable in callself step 5 6 def callself step 7 return step 1 8 9 optimizer in errorhandlerargs kwargs 151 except exception as e 152 filteredtb 153 raise from none 154 finally 155 del filteredtb in ctx dtype 101 dtype 102 ctxensureinitialized 103 return opseagertensorvalue ctxdevicename dtype 104 105 typeerror cannot convert 01 to eagertensor of dtype int64"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nunable to compile tensorflow c code using cmake\ni followed this steps 1 i cloned the repo 2 cd tensorflow 3 mkdir examples in examples folder i created helloworldcc file and cmakelisttxt this is cmakelisttxt file 380 projectexamples specify the path to the tensorflow source directory add the tensorflow source directory to the cmake module path listappend cmakemodulepath add the tensorflow include directories build the helloworld executable helloworldcc tensorflow after running the command cmake build config release i got this error fatal error c1083 cannot open include file tensorflowccclientcl ientsessionh no such file or directory 2 3 4 5"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nshuffle flag is true in makedataset function\nclick to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version 20 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour just replicating an example of time series forecasting from link tsf there is a function makedataset which uses the function shuffle flag is set to true which is not allowed in time series forecasting standalone code to reproduce the issue shell def makedatasetself data data nparraydata dtypenpfloat32 ds datadata targetsnone sequencestride1 shuffletrue batchsize32 ds dsmapselfsplitwindow return ds makedataset relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nbuilding from source with clang and nvcc\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 211 custom code yes os platform and distribution debian gnulinux 10 mobile device no response python version 39 bazel version no response gcccompiler version gcc9clang12 cudacudnn version 113 gpu model and memory nvidia t4 current behaviour the docs say that tf 211 is supported with gcc 9 but clangllvm builds significantly faster how can i use bazel to at least try to build using clang and nvcc at the same time changing gcchostcompilerpath fails using my own crosstooltop with clang seems to work but im not sure if this ends up building the cuda kernels with clang as well standalone code to reproduce the issue shell from bazelrc build buildcuda repoenv tfneedcuda1 buildcuda buildcuda buildtfgpu actionenv buildtfgpu actionenv pythonlibpathbin buildtfgpu buildtfgpu actionenv buildtfgpu buildtfgpu actionenv tfcudaversion11 buildtfgpu actionenv tfcudnnversion8 buildtfgpu actionenv buildtfgpu actionenv buildtfgpu actionenv buildtfgpu actionenv buildtfgpu actionenv buildtfgpu actionenv buildtfgpu actionenv buildtfgpu actionenv buildtfgpu configcuda relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nissue when importing pix2pix in google colab\nhello i wanted to use pix2pix in google colab and here is the command i used to import it pip install git i also tried pip install q git but for both request i get this error looking in indexes collecting git cloning to running command git clone filterblobnone quiet resolved to commit error × python setuppy egginfo did not run successfully │ exit code 1 ╰─ see above for output note this error originates from a subprocess and is likely not a problem with pip preparing metadata setuppy error error × encountered error while generating package metadata ╰─ see above for output note this is an issue with the package mentioned above not pip hint see above for details could you please repair it best regards ps if there is any way for me to use pix2pix in an alternative way could you please indicate me on how to do it because i did not found an alternative"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ngetting error with using cocossd model with the latest tensorflow\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 450 custom code yes os platform and distribution windows mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour when i try to use the netdetectframe it throws me error typeerror is not a function at backendcpujs991 at enginereadsync enginejs9431 at tensordatasync tensorjs2971 at dinfer even though i am using the latest tensorflow js libraries standalone code to reproduce the issue shell i am trying to use the cocossd model to do object detection in my packagejson i have 222 tensorflowtfjs 450 450 450 for some reasons i want to use the latest tensorflow libraries as my project uses other things also i have the following code const tf const tfcpubackend const tfwebglbackend const cocossd i have also set the tfsetbackendwebgl and tfready before cocossdload but when i try to use the netdetectframe it throws me error typeerror is not a function at backendcpujs991 at enginereadsync enginejs9431 at tensordatasync tensorjs2971 at dinfer even though i am using the latest tensorflow js libraries relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow does average pooling function work in tensorflow\nlet us assume a tensor like this x tfconstant1 2 3 4 5 6 7 8 9 to apply the average pooling function i will do this x tfreshapex 1 3 3 1 avgpool2d 2strides2 2 paddingsame avgpool2dx the result is tftensor shape1 2 2 1 dtypefloat32 numpy array3 45 75 9 dtypefloat32 i can follow the logic above 12454 3 362 45 782 75 91 9 i think the logic is the pooling filter is usually situated inside the tensor to perform the pooling operator but when the entire filter does not situate inside the tensor see the below figure for an example we need to specify the number of elements of the filter that are situated inside the tensor a the following figure illustrates the logic for a 4 by 3 tensor with pooling filter and stride sizes of 2 by 2 and padding the same image however it is not always like this for example suppose the following tensor y tfconstant1 2 3 4 5 6 7 8 9 10 then i do this y tfreshapey 1 2 5 1 avgpool2d 4strides4 4 paddingsame avgpool2dy the result is like this tftensor shape1 1 2 1 dtypefloat32 numpy array45 7 dtypefloat32 if i wanted to follow the logic for the first example i expected the result to be like this 123467898 5 5102 75 i am using tensorflow 280 what mistake am i making"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nxlasharding in new version\nhi what is the replacement for from import xlasharding in tf2120 for example the function is xlashardingsplit"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nwe dont have your exam ready right now\ni had purchased the tensorflow exam and tried to start it but it is showing that we dont have your exam ready right nowbut in the candidate portal it is showing resumeso i am gonna post the screenshot of my problem img width960 altscreenshot 20230428 114949 src"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nunequal strides support recently removed for depthwiseconv2d\nplease go to stack overflow for help and support if you open a github issue here is our policy 1 it must be a bug a feature request or a significant problem with the documentation for small docs fixes please send a pr instead 2 the form below must be filled out 3 it shouldnt be a tensorboard issue those go here heres why we have that policy tensorflow developers respond to issues we want to focus on work that benefits the whole community eg fixing bugs and adding features support only helps individuals github also notifies thousands of people when issues are filed we want them to see you communicating an interesting problem rather than being redirected to stack overflow system information have i written custom code as opposed to using a stock example script provided in tensorflow yes os platform and distribution eg linux ubuntu 1604 ubuntu mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device tensorflow installed from source or binary tensorflow version use command below 29 and 211 python version 38 bazel version if compiling from source gcccompiler version if compiling from source cudacudnn version 112 and 81 gpu model and memory exact command to reproduce import tensorflow as tf import numpy as np layer1 printlayer1npones100 28 28 1 dtypenpfloat32 you can collect some of this information using our environment capture script you can obtain the tensorflow version with bash python c import tensorflow as tf tfversionversion describe the problem describe the problem clearly here be sure to convey here why its a bug in tensorflow or a feature request the command would run without any error when i was using it with tf211 version installed previously on the newly installed tf29 version however the code throws an error as invalidargumenterror exception encountered when calling layer depthwiseconv2d1 type depthwiseconv2d functionnode current implementation only supports equal length strides in the row and column dimensions call arguments received by layer depthwiseconv2d1 type depthwiseconv2d • 28 28 1 dtypefloat32 seeing the documentation the error is expected for version 212 but should work for versions 29 and 211 is it that the implementation existing in the earlier versions has been removed recently for all previous and current versions source code logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached try to provide a reproducible test case that is the bare minimum necessary to generate the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ndata and ml module missing\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source source tensorflow version 2 custom code no os platform and distribution mac mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour a bug happened standalone code to reproduce the issue shell from data import bodypart from ml import movenet relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntraining data format for efficientnet\ni would like to train a efficientnetb7 model from scratch to classify 2d arrays into two 2 classes but it seems like i did not prepare my data in the correct format currently my xtrain is a list of float64 arrays with a 600x600 size my ytrain is a list of integers that are either 0 or 1 of course xtrain and ytrain have the same length this is what i have so far from import dense flatten from import efficientnetb7 from import sequential basemodel weightsnone inputshape6006001 classes2 basemodeltrainable true model sequential modeladdbasemodel modeladdflatten modeladddense1 activationsigmoid metricsaccuracy history modelfitxtrain ytrain batchsize8 epochs100 the last line currently gives me an error valueerror failed to find data adapter that can handle input containing values of types containing values of types what would be the right format for training data any help is appreciated"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nissue with obtaining files from this repo via google colab\nscreenshot 20230414 162503"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ndoes not support graph control flow operations like tfcond or tfwhile at this time use tfgradients instead\nplease go to stack overflow for help and support if you open a github issue here is our policy 1 it must be a bug a feature request or a significant problem with the documentation for small docs fixes please send a pr instead 2 the form below must be filled out 3 it shouldnt be a tensorboard issue those go here heres why we have that policy tensorflow developers respond to issues we want to focus on work that benefits the whole community eg fixing bugs and adding features support only helps individuals github also notifies thousands of people when issues are filed we want them to see you communicating an interesting problem rather than being redirected to stack overflow system information have i written custom code as opposed to using a stock example script provided in tensorflow os platform and distribution eg linux ubuntu 1604 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device tensorflow installed from source or binary tensorflow version use command below python version bazel version if compiling from source gcccompiler version if compiling from source cudacudnn version gpu model and memory exact command to reproduce you can collect some of this information using our environment capture script you can obtain the tensorflow version with bash python c import tensorflow as tf tfversionversion describe the problem describe the problem clearly here be sure to convey here why its a bug in tensorflow or a feature request source code logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached try to provide a reproducible test case that is the bare minimum necessary to generate the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow lite library is crashing in wasm library at 3rd inference\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 270 custom code yes os platform and distribution emscripten ubuntu 1804 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell hello i have c code that i want to deploy as wasm library and this code contains tflite library i have compiled tflite library with xnnpack support using emscripten toolchain quite easy so no issue there i have a leightweight convolutiondense model that runs perfectly on desktop but i am starting having problems in the browser in 99 of cases i have an error on the third inference uncaught runtimeerror memory access out of bounds through some trivial debugging i have found out that the issue comes from interpreterinvoke method does not matter if i put any input or not i just need to call invoke three times and i have a crash first thing first i decided to add more memory to my wasm library by adding this line to cmake setcmakecxxflags cmakecxxflags s totalstack134217728 s totalmemory268435456 setcmakecxxflags cmakecxxflags s totalstack134217728 s totalmemory268435456 128 mb and 256 mb in total for 1 mb model i think this is more than enough and on top of that i am allowing memory growth but unfortunately i have exactly the same issue i am beating on this problem for 2 weeks straight and at this stage i have no clue how to fix it also i have tried to set custom allocation using but in this case i have a crash on the very first inference i guess i was not using it right but unfortunately i couldnt find even one tutorial describing how to apply custom allocation in tflite i said that i have a crash in 99 of cases there was one time when wasm library worked and inference worked as well it happens just randomly once and i couldnt reproduce it anymore standalone code to reproduce the issue shell here is the code that does tflite inference include include tflitemodelh include include include tensorflowliteutilh namespace tracker ifdef emscripten void stream stdstring imgstr streamstr stdvector stdcopyimgstrbegin imgstrend imgmodeldatabegin model imgstrsize else void tflitemodelinitconst stdstring path model endif resolver resolverinterpreter for int i 0 i tensorssize i tflitetensor tensor interpretertensori if tensorallocationtype ktflitearenarw tensorallocationtype int alignedbytes tensorbytes tensorbytes customalloc int result tensorbytes if result 0 customallocdata null stdcout posixmemalign does not workn tflitestatus st customalloc stdcout status st stdendl if tensorbytes 0 stdcout bytes stdendl exit0 void cvmat imginput const stdvector lmsinput float modelin stdmemcpymodelin imginputdata imginputtotal imginputelemsize float lmsin stdmemcpylmsin lmsinputdata sizeoffloat lmsinputsize interpreterinvoke float tflitemodelout return stdvector const tflitetensor outtensor tfliteintarray dims outtensordims stdvector sh for int i 0 i size i shpushbackdimsdatai return sh relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to evaluate a pretrained tf mobilenetv2 savedmodel for accuracy on test dataset\nsystem information have i written custom code as opposed to using a stock example script provided in tensorflow no os platform and distribution eg linux ubuntu 1604 ubuntu 2004 tensorflow installed from source or binary binary tensorflow version use command below211 python version 39 describe the problem how can i use a pretrained savedmodel and find its accuracy on a test dataset i have mobilenetv2 saved model which is sourced from i have an imagenet validation dataset consisting of 50000 images and a labelstxt file consisting of ground truth labels for those 50000 images i also have imagenetlabelstxt sourced from consisting of 1001 imagenet classes how do i preprocess this data so that i can run evaluate function to find testdata loss and accuracy of this pretrained model i am currently using the below script but it doesnt seem to work import tensorflow as tf import tensorflowhub as hub import numpy as np import os m outputshape1001 mbuildnone 224 224 3 batch input shape images classes labels homedocumentsvaltxt with openlabels r as f labelname linestrip for line in freadlines classmap with openclasses r as f classes linestrip for line in f for i classname in enumerateclasses classmapclassname i testlabels for label in labelname if label in classmap else printflabel label not found in classmap imagepaths ospathjoinimages filename for filename in oslistdirimages dataset testlabels def image image channels3 image tfimageresizeimage 224224 image tffloat32 image 2550 return image dataset datasetmaplambda imagepath label label dataset optimizerrmsprop metricsaccuracy loss accuracy mevaluatedataset printloss loss printaccuracy accuracy i get the below error here traceback most recent call last file test1234py line 74 in loss accuracy mevaluatedataset file line 70 in errorhandler raise from none file line 15 in tftestfunction retval agldself aglditerator none fscope valueerror in user code file line 1820 in testfunction return stepfunctionself iterator file line 1804 in stepfunction outputs argsdata file line 1792 in runstep outputs modelteststepdata file line 1758 in teststep selfcomputelossx y ypred sampleweight file line 1082 in computeloss return selfcompiledloss file line 265 in call lossvalue lossobjyt yp sampleweightsw file line 152 in call losses callfnytrue ypred file line 284 in call return agfnytrue ypred selffnkwargs file line 2004 in return file line 5532 in valueerror shapes none 1 and none 1001 are incompatible i assume something is wrong in the way i preprocess my data though but not sure how to go about it some insights would be nice thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ndocs do not mention discontinuation of support for python 37 in tf 2111\nclick to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version tf 2111 custom code no os platform and distribution no response mobile device no response python version 37 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell the release notes for tensorflow 2120 state that support for python 37 has been discontinued however it seems that python 37 support has also been removed from tensorflow 2111 despite this not being mentioned in the release notes or documentation as a result to maintain compatibility we were forced to limit our application to using tensorflow 2110 standalone code to reproduce the issue shell na relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\njvp using becomes none under graph execution\nim new to tensorflow im trying to compute a jacobianvector product using with a train function looks something like the code below the jvp looks fine under eager execution however the jvp becomes a list of nones when activate graph execution using tffunction what could be the issue here tensorflow version tf 260 python version 37 train code shell tffunction def trainself data with tfgradienttape as uppertape loss1 selfloss1data grad1 selfnet1variables with tangentsgrad1 as acc with tfgradienttape as lowertape loss2 selfloss2data grad2 selfnet2variables finalgrad accjvpgrad2 selfnet2variables grad1 and grad2 are correctly computed under both eager mode and graph mode the only problem is with the jvp"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nspam removed\nplease go to stack overflow for help and support if you open a github issue here is our policy 1 it must be a bug a feature request or a significant problem with the documentation for small docs fixes please send a pr instead 2 the form below must be filled out 3 it shouldnt be a tensorboard issue those go here heres why we have that policy tensorflow developers respond to issues we want to focus on work that benefits the whole community eg fixing bugs and adding features support only helps individuals github also notifies thousands of people when issues are filed we want them to see you communicating an interesting problem rather than being redirected to stack overflow system information have i written custom code as opposed to using a stock example script provided in tensorflow os platform and distribution eg linux ubuntu 1604 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device tensorflow installed from source or binary tensorflow version use command below python version bazel version if compiling from source gcccompiler version if compiling from source cudacudnn version gpu model and memory exact command to reproduce you can collect some of this information using our environment capture script you can obtain the tensorflow version with bash python c import tensorflow as tf tfversionversion describe the problem describe the problem clearly here be sure to convey here why its a bug in tensorflow or a feature request source code logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached try to provide a reproducible test case that is the bare minimum necessary to generate the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nbuild tensorflow lite for ios failed\nplease go to stack overflow for help and support if you open a github issue here is our policy 1 bazel build configiosarm64 c opt cxxoptstdc17 ❯ bazel build verbosefailures configiosarm64 c opt info options provided by the client inherited common options isatty1 terminalcolumns170 info reading rc options for build from inherited common options info reading rc options for build from build options define define c opt announcerc definegrpcnoarestrue configshortlogs configv2 info reading rc options for build from build options actionenv actionenv info reading rc options for build from build options info found applicable config definition buildshortlogs in file info found applicable config definition buildv2 in file definetfapiversion2 info found applicable config definition buildiosarm64 in file configios cpuiosarm64 info found applicable config definition buildios in file appleplatformtypeios applebitcodeembedded coptfembedbitcode coptwnoc11narrowing coptw cxxoptstdc17 hostcxxoptstdc17 info build option cxxopt has changed discarding analysis cache error in cctoolchainsuite rule cctoolchainsuite does not contain a toolchain for cpu iosarm64 error analysis of target failed error analysis of target failed build aborted info elapsed time 45455s info 0 processes failed build did not complete successfully 66 packages loaded 1118 targets configured heres why we have that policy tensorflow developers respond to issues we want to focus on work that benefits the whole community eg fixing bugs and adding features support only helps individuals github also notifies thousands of people when issues are filed we want them to see you communicating an interesting problem rather than being redirected to stack overflow system information macosm1max 133 tensorflow292 python 3100 describe the problem describe the problem clearly here be sure to convey here why its a bug in tensorflow or a feature request source code logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached try to provide a reproducible test case that is the bare minimum necessary to generate the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nthreadsafety for tensorflowtensor\nclick to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version 2110 custom code yes os platform and distribution debian gnulinux 10 mobile device no response python version 39 bazel version 610 gcccompiler version llvm 12 cudacudnn version 116 gpu model and memory t4 current behaviour shell are there any methods on tensorflowtensor objects that are threadsafe specifically any of subslice flat unalignedflat shaped standalone code to reproduce the issue shell stdvector output mutex mu bool ready false void eval output tensordatatypedthalf 2 16 one entry per thread nnevaluatorinfer output mulock ready true muunlock void readresultint threadid mulock muunlock can we read tensor result now auto res return res0 relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nif we have any detail information of each ci in tensorflow github\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell hello i have been studying the actions ci of various open source projects on github recently i noticed that tensorflowhas a wellestablished ci so i would like to further understand its composition and structure do you have any relevant materials that i can study and refer to thank you very much standalone code to reproduce the issue shell none relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nplot training and validation losses of object detection model\nhello i am using the following notebook to train my dataset with efficientdetlite0 model i can see for each epoch we get the information of training loss loss and validation loss valloss i would like to plot them like loss modelhistoryloss valloss modelhistoryvalloss pltplotloss labeltraining loss pltplotvalloss labelvalidation loss pltlegendlocupper right pltylabelcross entropy pltylim010 plttitletraining and validation loss pltxlabelepoch pltshow and unfortunately getting the following error attributeerror objectdetector object has no attribute history can you help me to figure out how to plot training and validation losses on the same graph thanks in advance"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntype int32 2 not supportednode add number 0 failed to invoke with status 1node while number 10 failed to invoke with status 1\nsystem information os platform window10 tensorflow installed from source or binary pip tensorflow version or github sha if from source233 board arduino nano 33 ble sense i tried to run tensorflow lite for microcontrollers with arduino nano 33 ble sense the model is my custom lstm and the result type int32 2 not supportednode add number 0 failed to invoke with status 1node while number 10 failed to invoke with status 1invoke failed but it has output values model1 tflite"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to find accuracy of a pretrained tflite model\nsystem information have i written custom code as opposed to using a stock example script provided in tensorflow no os platform and distribution eg linux ubuntu 1604 ubuntu 2004 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device none tensorflow installed from source or binary binary tensorflow version use command below v211 python version 39 describe the problem i have a pretrained tf mobilenetv2 model downloaded from tfhub which i converted to tflite using tflite interpreter converter the original model was trained on imagenet dataset but i want to find out the accuracy of the converted tflite model how do i do that as of now the eval function is specific to models generated from modelmaker what is the best way to find the model accuracy thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to benchmark tflite object detection model\nit seems that only classification models can be benchmarked there is no explanation for how to run benchmarking on tflite object detection models under could anybody point me into the right direction to get the modifications needed to run the tflite benchmark on my custom tflite object detection model after running bash ➜ tensorflow gitmaster adb shell am start s n es args numthreads4 when i check logcat bash ➜ tensorflow gitmaster adb logcat grep inference timings in us i see shell 0315 140051294 12836 12836 i tflite inference timings in us init 36618 first inference 1530248 warmup avg 153025e06 inference avg 149712e06 0315 141343409 13393 13393 i tflite inference timings in us init 33412 first inference 307818 warmup avg 297955 inference avg 333826 basically my model inference fails and it falls back onto the classification model click to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version 2110 custom code no os platform and distribution linux ubuntu 1804 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour standalone code to reproduce the issue shell the app falls back onto the classification model once the object detection one fails 0315 140051294 12836 12836 i tflite inference timings in us init 36618 first inference 1530248 warmup avg 153025e06 inference avg 149712e06 0315 141343409 13393 13393 i tflite inference timings in us init 33412 first inference 307818 warmup avg 297955 inference avg 333826 relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntypeerror got an unexpected keyword argument\nclick to expand issue type support have you reproduced the bug with tf nightly no source binary tensorflow version 2120rc1 custom code no os platform and distribution windows 10 mobile device no response python version 311 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell selfmodel kerassequential file line 205 in methodwrapper result methodself args kwargs file line 70 in errorhandler raise from none file line 285 in call return kwargs typeerror got an unexpected keyword argument standalone code to reproduce the issue shell selfmodel kerassequential keraslayersdense1 inputdimselfdegree keraslayersdense1 lossloss selfmodelsummary relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nresource exhausted error during training\nresource exhausted error during training i would like to train the deep learning task semantic segmentation specifications model with 31 million parameters image size minimum 1024x1024 batch size 256 framework tensorflow keras 27 total image samples 30000 label mask samples 30000 does colab pro plus allow the training for this specification with out oom error issue currently facing is even with 2000 number of images and 512x512 size for batch size 32 results in out of memory error in colab pro subscription"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nunsupported object type numpyndarray on multiinput dataset\nclick to expand issue type support have you reproduced the bug with tf nightly no source binary tensorflow version 2110 custom code yes os platform and distribution kaggle kernel mobile device no response python version 3712 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell im trying to return tuple to a dataset to be used in a multiinput model but its throwing an error saying unsupported object type numpyndarray previosuly i was setting shape with setshape but right now i simply dont know how to set shape for a different input shape standalone code to reproduce the issue shell def readimagepath rel blah blah blah read somehow return image def readimage1path1 filter0 blah blah blah read somehow return image def preprocessx y def funcx y x jsonloadsx ximg1 readimagexpath xrel 3d image ximg2 readimagexpathfork xfilter 2d image with different shape image resizing will lose data y todo yeah ill optimize it never return ximg1 ximg2 y x y tfnumpyfunctionfunc x y tffloat32 tffloat32 xsetshape256 256 3 previously i used to do this ysetshape10 return x y here x is an array of string and those strings are actually jsondictionary def tfdatasetxy batch16 dataset y dataset dataset datasetmappreprocess dataset datasetbatchbatch dataset datasetprefetch16 return dataset relevant log output shell internalerror graph execution error unsupported object type numpyndarray node pyfunc iteratorgetnext here is what im trying to do multi input model with tfdatadataset"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nfailing to run hexagon delegates on android\nclick to expand issue type support have you reproduced the bug with tf nightly no source binary tensorflow version 2100 custom code yes os platform and distribution windows 10 mobile device qcs6125 python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell problem with hexagon delegates the hexagon libs from hexagon delegates page are set into arm64v8a folder cpu architecture 8 adb shell getprop roboardplatform trinket adb shell getprop roproductdevice trinket standalone code to reproduce the issue shell implementation implementation running tensorflow example from quickstart for android relevant log output shell tflite failed to fetch hexagon nn version this might be because youre using incompatible versions of libhexagoninterface and libhexagonnnskel you must use compatible versions refer to tensorflow lite hexagon delegate guide"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow import error\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 210 custom code yes os platform and distribution no response mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i cannot import the tensorflow package in my jupyter notebook i have checked the installations in conda and pip but everything seems to work so whenever i try to import it i get the following error importerror traceback most recent call last file line 62 in from import importerror dll load failed while importing a dynamic link library dll initialization routine failed is it a problem of the environment or a problem with package itself i am starting now to study dl so i would appreciate a lot a quick response thank you standalone code to reproduce the issue shell import tensorflow as tf relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nrunning tensorflow distributed on multiple workers\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 26 custom code yes os platform and distribution linux hpc mobile device no response python version 383 bazel version no response gcccompiler version no response cudacudnn version 1131 gpu model and memory 4 rtx 2080 ti workers each having 8 gpus current behaviour shell i am trying to run tensorflow distributed training code on multiple worker nodes i initially tried it using the mirrored strategy using a single worker with multiple gpus and the code was working fine and the training process was getting distributed among multiple gpus when i have tried it with multiple worker nodes the training process is actually executing seperately on different workers rather than the load getting distributed among the workers my linux systems has 4 worker nodes with each node having 8 2080ti gpus and the gpus are connected through pcie system i also not sure how to configure the tfconfig can anyone help me on this standalone code to reproduce the issue shell if name main get mpi rank from getonehot import getonehot from mpi4py import mpi comm mpicommworld rank commgetrank load in the parameter files from json import load as loadf with openparamsjson r as infile params loadfinfile get data files and prep them for the generator import tensorflow from tensorflow import distribute as d callbacks devices getdevices printdevices settfconfigmpi strat create network from sys import argv resumetraining false printargv if resumelatest in argv resumetraining true with stratscope scheduler if str get the string for the importable function lr paramslearningrate from import use a dummy learning rate paramslearningrate 01 model createmodelparams get the importable function lr lrsplit baseimport importlr0 globals locals lr1 0 lr getattrbaseimport lr1 make a schedule lr callbacksappendlr resume model modelname none if resumetraining initialepoch modelname if modelname is none initialepoch0 model createmodelparams resumetraining false else from import loadmodel model loadmodelmodelname load data from disk import numpy if root in paramskeys root paramsroot else root if filename in paramskeys filename paramsfilename else filename restricted euc1 e1 x1 y1 z1 euc2 e2 x2 y2 z2 euc3 e3 x3 y3 z3 x y getonehotformatroot filename restrictedrestricted params valfilename valx valy getonehotformatroot valfilename restrictedrestricted valx valy none none paramsgbatchsize paramsbatchsize lendevices printxshape xshape printyshape yshape printepochs paramsepochs typeparamsepochs printbatch paramsbatchsize typeparamsbatchsize printgbatch paramsgbatchsize typeparamsgbatchsize load data into a distributed dataset dataset object does nothing in place from tensorflowdata import dataset data y create validation set v paramsvalidation if valx is not none vrecord valxshape0 val valy validation val datatakevrecord else vrecord intxshape0v validation datatakevrecord validation validation validation need to do kfold one day this set should not be distributed vsteps vrecord paramsgbatchsize if vrecord paramsgbatchsize 0 vsteps 1 data data records xshape0 vrecord steps records paramsgbatchsize if records paramsgbatchsize steps 1 printsteps steps note that if we are resuming that the number of remaining epochs has changed the number of epochs steps is the numbers of samples to drop printinitial cardinality datacardinality printinitial v cardinality datacardinality data validation printfinal cardinality datacardinality printfinal v cardinality datacardinality data split into validation and training callbacks callbacks rank resumetraining printcallbacks printfitting model printdata import tensorflow as tf options tfdataoptions traindata valdata history modelfittraindata epochsparamsepochs stepsperepochsteps verbose0 callbackscallbacks printfitting model done if rank 0 modelsavemodelfinal else slurm script binbash sbatch jobnamejob1 job name sbatch mem30000 job memory request sbatch gresgpu4 number of requested gpus sbatch time3230000 time limit dayshrsminsec sbatch constraintrtx2080 specific hardware constraint sbatch errorslurmerr error file name sbatch outputslurmout output file name sbatch nodes2 sbatch ntaskspernode1 sbatch cpuspertask1 sbatch array121 if d modelfinal then scancel slurmarrayjobid else module load anaconda3202007 module load mpirun python u mainpy resumelatest fi relevant log output shell i log each and every epoch in a csv file i see two csv files created and each one has different workers running"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow grad\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source source tensorflow version tf 2x custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell hi if i want to slimming network standalone code to reproduce the issue shell i want to ask how i can get the gradient value of each iteration in the model training process relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow static library of windows missing few files\nplease go to stack overflow for help and support if you open a github issue here is our policy 1 it must be a bug a feature request or a significant problem with the documentation for small docs fixes please send a pr instead 2 the form below must be filled out 3 it shouldnt be a tensorboard issue those go here heres why we have that policy tensorflow developers respond to issues we want to focus on work that benefits the whole community eg fixing bugs and adding features support only helps individuals github also notifies thousands of people when issues are filed we want them to see you communicating an interesting problem rather than being redirected to stack overflow system information have i written custom code as opposed to using a stock example script provided in tensorflow its tensorflow provided code as given in os platform and distribution eg linux ubuntu 1604 windows 10 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device laptop tensorflow installed from source or binary static library from tensorflow version use command below 211 python version na bazel version if compiling from source na gcccompiler version if compiling from source 122 cudacudnn versionna gpu model and memory na exact command to reproduce took static library from tensorflow ebsite from link below have taken windows version of cpu version unzipped and created hellotfc as mentioned in same webpage compiled the hellotfc as below gcc hellotfc i o hellotf got error as in file included from hellotfc2 fatal error tensorflowctfbufferh no such file or directory 23 include tensorflowctfbufferh compilation terminated then took tfbufferh from github repo to see if the error is only dependent on tfbufferh but then got another error dtensorflowlibgcc hellotfc i o hellotf in file included from from from hellotfc2 fatal error no such file or directory 19 include compilation terminated you can collect some of this information using our environment capture script you can obtain the tensorflow version with bash python c import tensorflow as tf tfversionversion describe the problem describe the problem clearly here be sure to convey here why its a bug in tensorflow or a feature request took static library from tensorflow ebsite from link below have taken windows version of cpu version unzipped and created hellotfc as mentioned in same webpage compiled the hellotfc as below gcc hellotfc i o hellotf got error as in file included from hellotfc2 fatal error tensorflowctfbufferh no such file or directory 23 include tensorflowctfbufferh compilation terminated then took tfbufferh from github repo to see if the error is only dependent on tfbufferh but then got another error dtensorflowlibgcc hellotfc i o hellotf in file included from from from hellotfc2 fatal error no such file or directory 19 include compilation terminated source code logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached try to provide a reproducible test case that is the bare minimum necessary to generate the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nwhat is the final training result of asynchronous synchronous parallel distributed training？\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version tf28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell when distributed training adopts asynchronous synchronous parallel the parameters updated by each worker are inconsistent is the final result of distributed training the slowest parameter updated by workers standalone code to reproduce the issue shell when distributed training adopts asynchronous synchronous parallel the parameters updated by each worker are inconsistent is the final result of distributed training the slowest parameter updated by workers relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nwarningabslfound untraced functions such as while saving showing 5 of 6 these functions will not be directly callable after loading\nclick to expand issue type support have you reproduced the bug with tf nightly no source binary tensorflow version 211 custom code yes os platform and distribution ubuntu 22041 lts mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell the warning appears warningabslfound untraced functions such as while saving showing 5 of 6 these functions will not be directly callable after loading can you please explain what is meant by this warning and how to fix it i have the following accompanying questions to it function traces are basically graph representations of functions or something else if these jit traces are not found in a loaded model will they be generated again is model compilation needed for regeneration are these functions needed only for training or also for predictionevaluation i have found in keras docs that i can disable saving the traces with the following note disabling this will decrease serialization time and reduce file size but it requires that all custom layersmodels implement a getconfig method why would the getconfig method be only needed when i disable saving the traces thanks in advance for any explanations given shell reproducer its not my code but the warnings appear eg here relevant log output warningabslfound untraced functions such as while saving showing 5 of 6 these functions will not be directly callable after loading"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to use exported automl tensorflow model for tabular data in python\nclick to expand issue type support have you reproduced the bug with tf nightly no source binary tensorflow version 29 custom code yes os platform and distribution linux ubuntu mobile device no response python version 37 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell hello i followed the instructions from google cloud to export and load a trainen automl model training was done with data from bigquery as we want to integrate this model in our spark flow i need to load it and make predictions on it in python directly i tested the model with the tensorflow serving docker image as described in the documentation this works perfectly fine however when i try to use the model directly i get an erro error dataloss failed skipping unrequested field input must be a string tensor i tried several formats json csv but none of them seemed to be correct can anybody give me a hint on how to convert the tabular data into a string tensor in a way that the model accepts the data and returns a prediction thanks in advance kay standalone code to reproduce the issue shell import struct2tensor import tensorflow as tf import json import requests modelpath predictsample animals 00 apparel 00165423884627339 arts 0000893240417492657 baby 00 business 00 cameras 0000158694043359865 electronics 00 food 64749054130615e05 furniture 00 hardware 0000247099237409669 health 000928790329794604 home 00442892335578687 luggage 365980448833796e05 mature 00 media 070324946112978 office 0000297127488105344 religious 00 software 00 sporting 00 toys 00 vehicles 725524348202571e06 aovbench 598599307847218 aovrep 0 avgprice 12704623853211 bouncerate 8106 brandsearchvolume 0 00 category adult competition 00 cpc 00 crbench 000972125074728272 date 20220801 directshare 4079 displayshare 00 domaincat1 0 domaincat2 0 00 domainsearchvolume 0 ekpsaov 26859908543707 ekpscr 00194748958674429 iibbench 104867824234893 int64field0 1 lineid 1 mailshare 00 maincountry germany maincountryshare 8425 nocat 0224926250022808 organicshare 5766 pageviews 174154466250536 paidsearchshare 00 request to tensorflowserving docker container works perfectly response requestspost jsoninstances predictsample prints predictions 00056517720222473145 printresponsetext model infer no matter what i tried as input here i always get error error consuming error dataloss failed skipping unrequested field to feed model with one string tensor relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntflite minimal example failing on latest tensorflow repo\nwhen i run latest tensorflow lite example minimal and it is failing on linux machine with the below error followed steps mentioned here and ran on x8664 gnulinux 100 linking cxx executable minimal usrbinld in function registercctext0x1cd undefined reference to usrbinld registercctext0x1ed undefined reference to usrbinld registercctext0x207 undefined reference to usrbinld registercctext0x227 undefined reference to usrbinld registercctext0x241 undefined reference to usrbinld registercctext0x25b undefined reference to usrbinld registercctext0x27b undefined reference to usrbinld registercctext0x29b undefined reference to usrbinld registercctext0x2bb undefined reference to usrbinld registercctext0x2db undefined reference to usrbinld registercctext0x2fb undefined reference to usrbinld registercctext0x315 undefined reference to usrbinld registercctext0x335 undefined reference to usrbinld registercctext0x355 undefined reference to usrbinld registercctext0x375 undefined reference to usrbinld registercctext0x395 undefined reference to usrbinld registercctext0x3b5 undefined reference to usrbinld registercctext0x3d5 undefined reference to usrbinld registercctext0x3f5 undefined reference to usrbinld registercctext0x40f undefined reference to usrbinld registercctext0x42f undefined reference to usrbinld registercctext0x449 undefined reference to usrbinld registercctext0x463 undefined reference to usrbinld registercctext0x483 undefined reference to usrbinld registercctext0x4a3 undefined reference to usrbinld registercctext0x4c0 undefined reference to usrbinld registercctext0x4e0 undefined reference to usrbinld registercctext0x500 undefined reference to usrbinld registercctext0x520 undefined reference to usrbinld registercctext0x540 undefined reference to usrbinld registercctext0x55a undefined reference to usrbinld registercctext0x57a undefined reference to usrbinld registercctext0x59a undefined reference to usrbinld registercctext0x5ba undefined reference to usrbinld registercctext0x5da undefined reference to usrbinld registercctext0x5fa undefined reference to usrbinld registercctext0x614 undefined reference to usrbinld registercctext0x634 undefined reference to usrbinld registercctext0x654 undefined reference to usrbinld registercctext0x66e undefined reference to usrbinld registercctext0x68e undefined reference to usrbinld registercctext0x6ae undefined reference to usrbinld registercctext0x6ce undefined reference to usrbinld registercctext0x6ee undefined reference to usrbinld registercctext0x70e undefined reference to usrbinld registercctext0x72e undefined reference to usrbinld registercctext0x74e undefined reference to usrbinld registercctext0x76e undefined reference to usrbinld registercctext0x78e undefined reference to usrbinld registercctext0x7ae undefined reference to usrbinld registercctext0x7ce undefined reference to usrbinld registercctext0x7e8 undefined reference to usrbinld registercctext0x808 undefined reference to usrbinld registercctext0x822 undefined reference to usrbinld registercctext0x842 undefined reference to usrbinld registercctext0x862 undefined reference to usrbinld registercctext0x882 undefined reference to usrbinld registercctext0x89c undefined reference to usrbinld registercctext0x8bc undefined reference to usrbinld registercctext0x8dc undefined reference to usrbinld registercctext0x8fc undefined reference to usrbinld registercctext0x91c undefined reference to usrbinld registercctext0x93c undefined reference to usrbinld registercctext0x95c undefined reference to usrbinld registercctext0x97c undefined reference to usrbinld registercctext0x99c undefined reference to usrbinld registercctext0x9b6 undefined reference to usrbinld registercctext0x9d0 undefined reference to usrbinld registercctext0x9ea undefined reference to usrbinld registercctext0xa04 undefined reference to usrbinld registercctext0xa24 undefined reference to usrbinld registercctext0xa3e undefined reference to usrbinld registercctext0xa5e undefined reference to usrbinld registercctext0xa78 undefined reference to usrbinld registercctext0xa92 undefined reference to usrbinld registercctext0xab2 undefined reference to usrbinld registercctext0xad2 undefined reference to usrbinld registercctext0xaf2 undefined reference to usrbinld registercctext0xb12 undefined reference to usrbinld registercctext0xb32 undefined reference to usrbinld registercctext0xb52 undefined reference to usrbinld registercctext0xb6c undefined reference to usrbinld registercctext0xb86 undefined reference to usrbinld registercctext0xba0 undefined reference to usrbinld registercctext0xbc0 undefined reference to usrbinld registercctext0xbe0 undefined reference to usrbinld registercctext0xc00 undefined reference to usrbinld registercctext0xc1a undefined reference to usrbinld registercctext0xc3a undefined reference to usrbinld registercctext0xc54 undefined reference to usrbinld registercctext0xc6e undefined reference to usrbinld registercctext0xc88 undefined reference to usrbinld registercctext0xca8 undefined reference to usrbinld registercctext0xcc8 undefined reference to usrbinld registercctext0xce2 undefined reference to usrbinld registercctext0xcfc undefined reference to usrbinld registercctext0xd16 undefined reference to usrbinld registercctext0xd30 undefined reference to usrbinld registercctext0xd50 undefined reference to usrbinld registercctext0xd70 undefined reference to usrbinld registercctext0xd8a undefined reference to usrbinld registercctext0xda4 undefined reference to usrbinld registercctext0xdbe undefined reference to usrbinld registercctext0xdd8 undefined reference to usrbinld registercctext0xdf8 undefined reference to usrbinld registercctext0xe18 undefined reference to usrbinld registercctext0xe38 undefined reference to usrbinld registercctext0xe58 undefined reference to usrbinld registercctext0xe72 undefined reference to usrbinld registercctext0xe92 undefined reference to usrbinld registercctext0xeac undefined reference to usrbinld registercctext0xecc undefined reference to usrbinld registercctext0xeec undefined reference to usrbinld registercctext0xf06 undefined reference to usrbinld registercctext0xf20 undefined reference to usrbinld registercctext0xf3a undefined reference to usrbinld registercctext0xf5a undefined reference to usrbinld registercctext0xf74 undefined reference to usrbinld registercctext0xf8e undefined reference to usrbinld registercctext0xfa8 undefined reference to usrbinld registercctext0xfc2 undefined reference to usrbinld registercctext0xfdc undefined reference to usrbinld registercctext0xff6 undefined reference to usrbinld registercctext0x1010 undefined reference to usrbinld registercctext0x102a undefined reference to usrbinld registercctext0x104a undefined reference to usrbinld registercctext0x1064 undefined reference to usrbinld registercctext0x1084 undefined reference to usrbinld registercctext0x109e undefined reference to usrbinld registercctext0x10b8 undefined reference to usrbinld registercctext0x10d2 undefined reference to usrbinld registercctext0x10ec undefined reference to usrbinld registercctext0x1106 undefined reference to usrbinld registercctext0x1120 undefined reference to usrbinld registercctext0x113a undefined reference to usrbinld registercctext0x1154 undefined reference to usrbinld registercctext0x116e undefined reference to usrbinld registercctext0x1188 undefined reference to usrbinld registercctext0x11a2 undefined reference to usrbinld registercctext0x11bc undefined reference to usrbinld registercctext0x11d6 undefined reference to usrbinld registercctext0x11f0 undefined reference to usrbinld registercctext0x120a undefined reference to usrbinld registercctext0x1224 undefined reference to usrbinld registercctext0x123e undefined reference to usrbinld registercctext0x1258 undefined reference to usrbinld registercctext0x1272 undefined reference to usrbinld registercctext0x1292 undefined reference to usrbinld registercctext0x12ac undefined reference to usrbinld registercctext0x12c6 undefined reference to usrbinld registercctext0x12e0 undefined reference to usrbinld registercctext0x12fa undefined reference to usrbinld registercctext0x1314 undefined reference to usrbinld registercctext0x132e undefined reference to usrbinld registercctext0x134e undefined reference to usrbinld registercctext0x136a undefined reference to usrbinld registercctext0x1386 undefined reference to usrbinld registercctext0x13a2 undefined reference to usrbinld in function undefined reference to usrbinld undefined reference to collect2 error ld returned 1 exit status gmake2 minimal error 1 gmake1 error 2 gmake makefile136 all error 2"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\non mtk platforms tflite calls the gpu with clgetplatformids return 1001\nsystem information android device information use adb shell getprop robuildfingerprint if possible tensorflow lite in play services sdk version found in buildgradle 29 google play services version settings apps google play services app details standalone code to reproduce the issue on mtk platforms code if ktfliteok logedelegate init failed exit1 get clgetplatformids returned 1001 or clgetplatformids returned 30 any other info logs this mtk platform has a gpu device"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to create tfkeraslayersinput without batchsize dimension\nclick to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version 291 custom code no os platform and distribution centos7 mobile device no response python version 3814 bazel version 50 gcccompiler version 102 cudacudnn version 114 gpu model and memory a30 current behaviour one input of my model has nothing to do with batchsize for example its shape is 123 how to avoid automatically adding 1 dimension when creating tfkeraslayersinput if i manually slice it the slice operator will be introduced resulting in a decrease in inference performance standalone code to reproduce the issue shell import tensorflow as tf x xshape none 32 64 x x0 xshape 32 64"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ngraph execution error\nim facing an issue that says graph execution error tried to solve it but couldnt"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to invoke h5 model instead of tflite model for pose classification\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 27 custom code yes os platform and distribution ubuntu 2004 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell a bug happened standalone code to reproduce the issue shell i need to implement poseclassifierh5 model instead of poseclassifiertflite relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\npass additional parameters to tfcustomgradient\nissue type support have you reproduced the bug with tf nightly no source source tensorflow version 280 current behaviour currently we can define a custom gradient using tfcustomgradient following what im looking for is to be able to pass to this function additional information in my case the loss of my network for example its stupid but its to give an idea to take the incoming gradient and multiply it by loss that has generated that gradient"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncant convert custom model to tflite with model config and weights file being separate\nhi i am trying to convert a custom model to tflite with these steps creates a custom model that i have previously defined resnet50 as a backbone pretrained weights transformer encoder mlp head model createmodelclasses5 the best weights file obtained after my custom model training converter tfmodel converterconvert with tflitemodel tflite wb as f fwritetfmodel i do not get any output on this no errors as well the question is is it possible to convert my custom model with creating the model without saving it and then loading the weights the way i have done is there any other way how to make my model smaller after training"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nerror in importing tensor flow\nclick to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version tf 49 custom code no os platform and distribution windows mobile device no response python version 388 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i have installed tensorflow using below command pip install tensorflow pip install keras then i tried to import and throwing error attributeerror module numpy has no attribute typedict current numpy version numpy1241 numpy121 standalone code to reproduce the issue shell i have installed tensorflow using below command pip install tensorflow pip install keras then i tried to import and throwing error attributeerror module numpy has no attribute typedict current numpy version numpy1241 numpy121 relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nmissing fp16 ops when converting from tf to tflite\nsystem information os platform and distribution eg linux ubuntu 1604 ubuntu 2004 tensorflow installed from source or binary pip install tensorflow version or github sha if from source 211 provide the text output from tfliteconvert fullerrortxt error failed while converting main some ops are not supported by the native tflite runtime you can enable tf kernels fallback using tf select see instructions tf select ops addv2 cast concatv2 conv2d elu gatherv2 max minimum mul pad realdiv relu sqrt sum transpose standalone code to reproduce the issue converter tflitemodel converterconvert"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow data working on databricks\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version tf28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i am unable to display the output of output on databricks where as the same is working on local system is it because that facets are not supported on databricks please provide a solution on how i can use modules of tensorflow data validation library on databricks standalone code to reproduce the issue shell link relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nmodel save issues with custom optimizer dpkerassgdoptimizer\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version tf28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell problem a keras sequential model was compiled using dpkerassgd optimizer and saved but when the saved model is loaded it throws the below error unknown optimizer dpoptimizerclass please ensure you are using a and that this object is included in the scope see for details expected behaviour since the model was already compiled using the optimizer it should run perfectly fine when fitted with the data whereas the same works when the optimizer is replaced please provide a solution on how to save the model with this custom optimizer standalone code to reproduce the issue shell building the model model tfkerassequential activationrelu activationrelu activationrelu tfkeraslayersdense1 activationsigmoid compiling the model modelcompile metrics saving the model modelsavemymodel loading the model throws the error relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to get label of detection after tensorflowtfjstflite predict returns result from a custom tflite model in reactjs web app\nclick to expand issue type support have you reproduced the bug with tf nightly yes source binary tensorflow version tfjs370 custom code no os platform and distribution windows 10 mobile device windows laptop python version 27 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i am using import as tflite from tensorflowtfjstflite and have successfully loaded a custom tflite model tflitemodel await as well as gotten a prediction var outputtensor await the code works well when i only have 1 label to detect initially now i need to detect multiple labels i created a new custom model and tested that it is able to detect multiple labels in an android project eg i can get labels l1 and l2 can i detect multi labels using the code above after i load in the new model if not what changes do i have to make to detect multi labels and know which label i am detecting eg obtain the name of the label standalone code to reproduce the issue shell see above not a bug issue relevant log output shell instance of result outputtensors value outputtensor kept false isdisposedinternal false shape 1 25 dtype float32 size 25 strides 25 dataid id 364 id 364 ranktype 2 kept false isdisposedinternal false shape 1 25 4 dtype float32 size 100 strides 100 4 dataid id 365 id 365 ranktype 3 kept false isdisposedinternal false shape 1 dtype float32 size 1 strides dataid id 366 id 366 ranktype 1 kept false isdisposedinternal false shape 1 25 dtype float32 size 25 strides 25 dataid id 367 id 367 ranktype 2"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nerror while evaluating tflite model with bazel runeval\nhi i managed to train a ssdmobilenetv1 using modelmaintf2py after that i managed to export with changing the maxdetections paramenter to 33 and then i successfully exported a tflite model i tried then to run some inference with the new tflite model and it worked as expected i decided then to try to evaluate the tflite model using this guide but when i run this command bazel run c opt debugmodetrue output shows odd results like this object 0 score 33 classid 1 bounding box normalized top 0999825 normalized bottom 0999262 normalized left 0999445 normalized right 0999066 object 1 score 0 classid 1 bounding box normalized top 0998896 normalized bottom 0997808 normalized left 0998822 normalized right 0996969 object 2 score 0780337 classid 1 bounding box normalized top 0996294 normalized bottom 0988497 normalized left 0994716 normalized right 0985629 object 3 score 0479028 classid 1 bounding box normalized top 0972919 normalized bottom 00584207 normalized left 00640493 normalized right 00434026 object 4 score 0 classid 1 bounding box normalized top 00374295 normalized bottom 00290796 normalized left 00313877 normalized right 00227272 object 5 score 0 classid 1 bounding box normalized top 00221782 normalized bottom 00208216 normalized left 00213712 normalized right 00207996 object 6 score 0 classid 1 bounding box normalized top 00199532 normalized bottom 00192215 normalized left 00193954 normalized right 00187497 object 7 score 0 classid 1 bounding box normalized top 00186509 normalized bottom 00180727 normalized left 00181409 normalized right 00176707 object 8 score 0 classid 1 bounding box normalized top 00176005 normalized bottom 202493 normalized left 00637459 normalized right 0325256 this is for the first image of the folder i used one thing i noted is that the first score of the first object is always 33 that is the parameter i changed when i exported the trained model with is there a way to fix this so i can evaluate my tflite model thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nserializedpb\nplease go to stack overflow for help and support if you open a github issue here is our policy 1 it must be a bug a feature request or a significant problem with the documentation for small docs fixes please send a pr instead 2 the form below must be filled out 3 it shouldnt be a tensorboard issue those go here heres why we have that policy tensorflow developers respond to issues we want to focus on work that benefits the whole community eg fixing bugs and adding features support only helps individuals github also notifies thousands of people when issues are filed we want them to see you communicating an interesting problem rather than being redirected to stack overflow system information have i written custom code as opposed to using a stock example script provided in tensorflow os platform and distribution eg linux ubuntu 1604 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device tensorflow installed from source or binary tensorflow version use command below python version bazel version if compiling from source gcccompiler version if compiling from source cudacudnn version gpu model and memory exact command to reproduce you can collect some of this information using our environment capture script you can obtain the tensorflow version with bash python c import tensorflow as tf tfversionversion describe the problem describe the problem clearly here be sure to convey here why its a bug in tensorflow or a feature request source code logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached try to provide a reproducible test case that is the bare minimum necessary to generate the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to design tfkeras callback to save model predictions for each batch and each epoch\nclick to expand issue type bug have you reproduced the bug with tf nightly no source source tensorflow version 211 custom code yes os platform and distribution ubuntu 2204 mobile device no response python version 37 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i want to create a tfkeras callback to save model predictions for each batch and each epoch during the training using the training data sets to a numpy array i have tried the following callback however it gives error like attributeerror predictioncallback object has no attribute xtrain standalone code to reproduce the issue shell class def onepochendself epoch logs ypred printprediction at epoch formatypred epoch epoch cnnmodelfitxtrain verbose1 relevant log output shell attributeerror predictioncallback object has no attribute xtrain i also tried tensorflow create keras callback to save model predictions and targets for each batch during training stack overflow but not get success yethope experts will help methanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncannot import name buildinfo from\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 2110 custom code yes os platform and distribution windows 11 22h2 mobile device no response python version 3106 bazel version no gcccompiler version no response cudacudnn version no response gpu model and memory mx150 2gb vram current behaviour shell cannot import name buildinfo from standalone code to reproduce the issue shell cannot import name buildinfo from import tensorflow as tf from objectdetectionutils import configutil from import pipelinepb2 from googleprotobuf import textformat relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ni want to reduce the app size with\n1 system information ios tflite model cocoapods pod tensorflowliteobjc 270 pod 001nightly20210521 2 code and question with parsing linkmap file i found the take 74 mb which is too bigger when converting the tflite model my model just use three tensorflow flextensorliststack who can tell me some ways to reduce the size of app with"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\na bug in tensorflow\nsu standalone code to reproduce the issue relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\n404\nclick to expand issue type support source binary tensorflow version 28 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell this file can download at is 404 standalone code to reproduce the issue shell this file can download at is 404 relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nerror could not find a version that satisfies the requirement tensorflow1152\ni use google colab and was wondering if anyone can solve this problem if you want to fix my notebook i will leave a link down below thanks if you solve it"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nerror tfconv2d op is neither a custom op nor a flex op\n1 system information os platform and distribution eg linux ubuntu 1604 linux ubuntu 2004 tensorflow installation pip package or built from source pip package tensorflow library version if pip package or github sha if built from source v210 2 code code for conversion converter tflitemodel converterconvert save the model with openfnametflite wb as f fwritetflitemodel code for the model latent keraslayersinputnh nw 4 decoder decoder decoder decoderlatent class def initself superinit x 1 018215 x paddedconv2d4 1 paddedconv2d512 3 padding1 resnetblock512 512 attentionblock512 resnetblock512 512 resnetblock512 512 resnetblock512 512 resnetblock512 512 2 paddedconv2d512 3 padding1 resnetblock512 512 resnetblock512 512 resnetblock512 512 2 paddedconv2d512 3 padding1 resnetblock512 256 resnetblock256 256 resnetblock256 256 2 paddedconv2d256 3 padding1 resnetblock256 128 resnetblock128 128 resnetblock128 128 paddedconv2d3 3 padding1 3 failure after conversion conversion fails 5 optional any other info logs errorlog some ops are not supported by the native tflite runtime you can enable tf kernels fallback using tf select see instructions tf select ops conv2d details tfconv2dtensor tensor tensor dataformat nhwc device dilations 1 1 1 1 explicitpaddings padding valid strides 1 1 1 1 usecudnnongpu true tfconv2dtensor tensor tensor dataformat nhwc device dilations 1 1 1 1 explicitpaddings padding valid strides 1 1 1 1 usecudnnongpu true tfconv2dtensor tensor tensor dataformat nhwc device dilations 1 1 1 1 explicitpaddings padding valid strides 1 1 1 1 usecudnnongpu true tfconv2dtensor tensor tensor dataformat nhwc device dilations 1 1 1 1 explicitpaddings padding valid strides 1 1 1 1 usecudnnongpu true tfconv2dtensor tensor tensor dataformat nhwc device dilations 1 1 1 1 explicitpaddings padding valid strides 1 1 1 1 usecudnnongpu true tfconv2dtensor tensor tensor dataformat nhwc device dilations 1 1 1 1 explicitpaddings padding valid strides 1 1 1 1 usecudnnongpu true tfconv2dtensor tensor tensor dataformat nhwc device dilations 1 1 1 1 explicitpaddings padding valid strides 1 1 1 1 usecudnnongpu true according to the error message i suspect that it can not recognize the input shape but as you can see on the above code input is specified for the functional api for decoder model fyi the inference code is called with predictonbatch method i found out other model with predictonbatch is converted successfully but that model doesnt contain conv2d block inside can using predictonbatch together with conv2d be a problem im sure conv2d is on the allowlist for tflite operators any suggestions for this problem thank you"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ninit got an unexpected keyword argument reduction\nclick to expand issue type support source source tensorflow version tf 270 custom code yes os platform and distribution windows 10 mobile device no response python version 383 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell compile a model with does not raise error the training process seems also good however if we save the model and try to reload it it does not work now i know we could not use tfkeraslosses in metrics we must use some functions in tfkerasmetrics or some customized metrics but the error message init got an unexpected keyword argument reduction gives no information why not raise an error during the training or even during the compiling that would be much more friendly for new comers standalone code to reproduce the issue shell import numpy as np from import dense dropout import tensorflow as tf inputlength 2 latentdim 512 outputlength 2 model tfkerassequential denselatentdim activationrelu dropoutrate05 denseunitslatentdim activationrelu xtrain nponesshape150000 2 ytrain nponesshape150000 2 history modelfitxtrain ytrain epochs2 batchsize128 pretrained relevant log output shell traceback most recent call last file dvscodem2smcdebugpy line 26 in pretrained file line 67 in errorhandler raise from none file line 784 in fromconfig return clsconfig typeerror init got an unexpected keyword argument reduction"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntfcustomgradient with multiple input and output\nsystem information have i written custom code as opposed to using a stock example script provided in tensorflow os platform and distribution eg linux ubuntu 1604 ubuntu 2004 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device tensorflow installed from source or binary tensorflow version use command below 292 python version 39 bazel version if compiling from source gcccompiler version if compiling from source cudacudnn version gpu model and memory exact command to reproduce describe the problem i have a function with 4 inputs x1 x2 x3 x4 and 2 outputs y1 y2 using tensorflow i would like to specify the gradients since i perform some nonautodiff operations inside the function i need to specify the derivatives of the outputs with respect to the inputs we can see these derivatives as a jacobian of size 24 regarding this i have 8 derivatives dy1dx1 dy1dx2 dy1dx3 dy1dx4 dy2dx1 dy2dx2 dy2dx3 and dy2dx4 however the grad function used in this tfcustomgradient needs to have the same length as the inputs this is 4 so i do not know how tensorflow handles with the introduction of the 8 derivatives using just 4 elements i tried to include them as lists but it gives the error here is a general code to reproduce the error import tensorflow as tf tfcustomgradient def barx1 x2 x3 x4 def graddy1 dy2 dy1dx1 x22 x33 x44 360000 dy1dx2 x1 2x2 x33 x44 480000 dy1dx3 x1 x22 3x32 x44 540000 dy1dx4 x1 x22 x33 4x43 576000 dy2dx1 x22 x33 x44 698 dy2dx2 x1 2x2 x33 x44 697 dy2dx3 x1 x22 3x32 x44 684 dy2dx4 x1 x22 x33 4x43 575 return dy1dx1 dy2dx1 dy1dx2 dy2dx2 dy1dx3 dy2dx3 dy1dx4 dy2dx4 y1 x1 x22 x33 x44 y2 x1 x22 x33 x44 return y1 y2 grad x1 tfconstant20 dtypetffloat32 x2 tfconstant30 dtypetffloat32 x3 tfconstant40 dtypetffloat32 x4 tfconstant50 dtypetffloat32 with as tape tapewatchx1 tapewatchx2 tapewatchx3 tapewatchx4 z barx1 x2 x3 x4 printtapegradientz x1 dy1dx1 dy2dx1 printtapegradientz x2 dy1dx2 dy2dx2 printtapegradientz x3 dy1dx3 dy2dx3 printtapegradientz x4 dy1dx4 dy2dx4 the error says customgradient function expected to return 4 gradients but returned 8 instead i expect someway to specify the correspondent 8 derivatives thank you in advance"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nstrange c macro generated by\n1 system information although i believe the system setup does not matter in this issue here goes windows 10 and ubuntu 2210 python 37 python 38 python 310 tensorflow lite 210 and 211 pip package 2 code generates the following strange c macro we need to keep the data array aligned on some architectures ifdef hasattribute define haveattributex hasattributex else define haveattributex 0 endif if haveattributealigned definedgnuc definedclang define dataalignattribute attributealigned4 else define dataalignattribute endif the strange part is definedgnuc definedclang if the code is compiled with the gnu c compiler then of course it is not compiled with the clang compiler the definedclang seems redundant and if its not redundant can someone explain it to me"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to reduce power consumption for gpu delegate on android\nclick to expand issue type performance source source tensorflow version 210 or 211 custom code yes os platform and distribution android mobile device android python version 37 bazel version no gcccompiler version no cudacudnn version no response gpu model and memory no response current behaviour shell here it is not a bug i want to reduce power consumption for gpu delegate on androidbecause i find the execution of tflite model using gpu occupys many power（ma） i use opencl backend do you have some optimization method in order to reduce power of model thank you very much standalone code to reproduce the issue shell my configuration is following gpuoptions relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to release memory when i want to change model with tfsavedmodelload already\nclick to expand issue type support source source tensorflow version tf 211 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i use tfsavedmodelload to load a trained model i want to change another model when it done but the memory is still high how to release the memory i have test and gccollect all of these didnt work standalone code to reproduce the issue shell model gccollect relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to calculate the models flops when i use tensorflow\nclick to expand issue type support source source tensorflow version tf 28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i dont find a good way to calculate the models flops by tensorflow standalone code to reproduce the issue shell i dont find a good way to calculate the models flops by tensorflow relevant log output shell i dont find a good way to calculate the models flops by tensorflow"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ndeploy yolo5 model into tensorflow lite object detection android\nhello tensorflow team i checked your real time object detection app which works good with the initial models mobilenet v1 efficientnet lite0 efficientnet lite1 efficientnet lite2 but i receive errors when i try to add other model for example yolo5s model trained on coco dataset which converted from pt format to tflite with exportpy script below you can find converted models for yolo5s fp16 and int8 options i already checked they are working fine with detectpy is it possible to deployintegrate yolo5 model into your real time object detection app if yes can you please check if you can deploy into app one of those two models fp16 or int8 i shared with you above in case if it works for you can you share your experience what did you exactly modify in initial tensorflow lite object detection app scripts thank you in advance"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nwhich encoding can i use to parse tensorflowstatspb\nissue type others source binary tensorflow version tf 28 custom code yes os platform and distribution ubuntu 1604 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour i get a tensorflowstatspb file by tfprofiler code like this loss i want to read tensorflowstatspb in my python code but i dont know which encoding this file use the file content is ä°\u0001 zb91\bź zba1\bź zbi1\bź zbać i9×łp ia×łp ii×łp iaiś\u000fâ­¤i veđç\u0001\u0007unknown iůţbyč\u0001\u0007unknown b\b \u0012\u0004host\u001a"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to convert model with multiple input\n1 system information os platform and distribution eg window 10 tensorflow installation pip package tensorflow library tensorflow 291 2 code provide code to help us reproduce your issues using one of the following options im use code as below what should i change to make convertion success import numpy as np import tensorflow as tf from tensorflow import keras how to write function def for in range20 data1 nprandomrand1 3 16 16astypenpfloat32 data2 nprandomrand1 3 16 16astypenpfloat32 yield data1 data2 build model kinput1 kerasinputshape16 16 3 batchsize1 nameinput1 kinput2 kerasinputshape16 16 3 batchsize1 nameinput2 conv1 keraslayersconv2d16 3 2kinput1 conv2 keraslayersconv2d16 3 2kinput2 out conv1 conv2 kerasmodel kinput2 outputsout kerasmodeltrainable false kerasmodelsummary convert converter tfuint8 or tfint8 tfuint8 or tfint8 tflitemodel converterconvert with openmodeltflite wb as fp fpwritetflitemodel 3 failure after conversion if the conversion is successful but the generated model is wrong then state what is wrong model produces wrong results andor has lesser accuracy model produces correct results but it is slower than expected 4 optional rnn conversion support if converting tf rnn to tflite fused rnn ops please prefix rnn in the title 5 optional any other info logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached error info valueerror the inferenceinputtype and inferenceoutputtype must be tffloat32"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntflite model with a conv2dtranspose layer is fail to run on mobile gpu\n1 system information os platform and distribution eg linux ubuntu 1604 conversion env centos7 test env galaxy s10 tensorflow installation pip package or built from source pip install tensorflow library version if pip package or github sha if built from source 2100 2 code provide code to help us reproduce your issues using one of the following options def getmodel inputs tfkerasinputshape64 64 3 x keraslayersconv2d16 3 activationrelu nameconv1inputs x keraslayersconv2d16 3 activationrelu nameconv2x x 3 strides2 activationrelu namedeconv1x x 3 strides2 activationrelu namedeconv2x outputs x model outputsoutputs namecustom x tfones5 64 64 3 y modelx printxshape printyshape return model def tflitesavedir converter tffloat32 tflitemodel converterconvert with opentflitesavedir wb as f fwritetflitemodel if namemain model getmodel currentpath savedir custom1 savedir tflitesavedir mymodeltflite convertmodelsavedir tflitesavedir 3 failure after conversion tf lite conversion and run on the mobile phone with cpu is ok but when running with gpu an error occurs i tested the model in adb shell image"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nadd support for 3rd part object storage s3 in docker image\nclick to expand issue type support source binary tensorflow version 26 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell when using tensorflow docker image to run tensorboard kubeflow uses this method out of the box the image only supports gcsfilesystem and to support for 3rd party object storage eg s3 due to the dependency on tensorflowio the ask is to make tensorflowio as required pip dependency while docker build happens that way lot of customizations could be avoided and the support is out of the box standalone code to reproduce the issue shell when using the below sample spec simplified to make the reproducibility easy spec affinity containers args awsregionuseast1 s3endpoint awssecretaccesskey someawssecret logdirs3logspath bindall command binsh c image imagepullpolicy ifnotpresent name tensorboard ports containerport 6006 protocol tcp resources devterminationlog file workingdir dnspolicy clusterfirst imagepullsecrets name regcred restartpolicy always schedulername defaultscheduler securitycontext 30 relevant log output shell when the above spec is deployed we will run into the following error error unsupported filename scheme s3 supported schemes ram file gs for additional filesystem support consider instal │ │ ling tensorflow io via pip install tensorflowio"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nattributeerror object has no attribute uniqueid\nclick to expand issue type bug source source tensorflow version 210 custom code yes os platform and distribution debian64 unix mobile device no response python version 3104 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell hello to everyone i need to training an actor network for a reinforcement learning algorithm but in time i am trying to predict continuous actions i have a problem with the function zip grads2 std also this one gives me the same error zip grads1 grads2 std please note that with the following function all goes well lossactions varlist std tape tapeactions the problem seems to be caused by the external variable std that it is not internal to the model did i make some mistakes is there a way to clipbynorm the std variables gradients best regards samir standalone code to reproduce the issue shell one tfones dtype float std tfvariable one dtype float name std sample selfreplaysample with tfgradienttape persistent false as tapeactions tapeactionsreset actionslocal selfactormodel sample 0 tfpdist loc actionslocal scale std newprobs tfpdistlogprob sample 1 newprobs tfmathreducesum newprobs axis 1 newprobs tfmathexp newprobs ratio newprobs sample 3 0 ratio tfmathreducemin tfconverttotensor ratio sample 4 tfclipbyvalue ratio clipvaluemin 1 01 clipvaluemax 1 01 sample 4 axis 0 lossactions tfmathreducemean ratio grads tapeactionsgradient lossactions std grads1 tfclipbynorm t w clipnorm 075 for w in grads 0 grads2 tfclipbynorm t w clipnorm 075 for w in grads 1 zip grads1 zip grads2 std relevant log output shell deprecationwarning the imp module is deprecated in favour of importlib and slated for removal in python 312 see the modules documentation for alternative uses import fnmatch glob traceback errno sys atexit locale imp stat traceback most recent call last file line 43 in file line 295 in crossentropyloss selfplayep ie trainmode true file line 78 in playep print selftrainingforelite realstepstotrain print file line 169 in trainingforelite selftraining realstepstotrain file line 272 in training zip grads2 std file line 695 in applygradients file line 959 in createallweights file line 126 in createslots selfaddslotvar m file line 1017 in addslot varkey varkeyvar file line 1650 in varkey return varuniqueid file line 446 in getattr selfgetattributename attributeerror object has no attribute uniqueid"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow much fps in ios swift\nclick to expand issue type support source source tensorflow version pod tensorflowliteswift 001nightly subspecs coreml metal custom code yes os platform and distribution macos mobile device iphone x python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell can i increase number of frames per second standalone code to reproduce the issue shell how much fps in ios swift relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow lite quantization debugger issue\n1 system information os platform and distribution eg linux ubuntu 1604ubuntu 18043 tensorflow library version if pip package or github sha if built from 2 code def denseblockinputs filters y y batchnormalizationy return y def model inputs inputshape 112 112 3 x denseblockx 1 inputsize111256 outputsize1111 return modelinputs x 3 conversion is successfulbut the predicted value of int8 tflite has a large error value with the pb weights file if the conversion is successful but the generated model is wrong then state what is wrong model produces wrong results and accuracy drop 715 5 optional any other info logs question1 my weights pb file is successfully quantized into an int8 tflite model when doing the rmsescale value of the last layerconv2d is 2 which is far more than 0289 but the rmsescale values ​​in other layers are all it is around 0289 and if i change the output of the last layer to more nodes the value of rmsescale of the last layer will be closer to 0289 does anyone know what could be causing this to happen thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nfrom kerasmodels import loadmodel raises no module named tensorflowcompat error\nclick to expand issue type support source binary tensorflow version 211 custom code no os platform and distribution windoes 11 mobile device no response python version 379 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell when doing kerasmodels import loadmodel an error saying no module named tensorflowcompat appears standalone code to reproduce the issue shell just open python 37 and type kerasmodels import loadmodel relevant log output shell traceback most recent call last file cusersnoah ryucodingaiteachable machineguesser3py line 1 in from kerasmodels import loadmodel tensorflow is needed for keras to work file cusersnoah line 21 in from keras import models file cusersnoah line 18 in from import functional file cusersnoah line 24 in import tensorflowcompatv2 as tf modulenotfounderror no module named tensorflowcompat"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nthere is no operator to calculate the matrixs inverse using tflite\nand tflinalgsvd is not supported in tflite batchmatrixinverse is not available in graphdef version 1205 hence， how to calculate the matrixs inverse using tflite i need some op to calculate the matrixs inverse best wishes"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ndifference between and\nclick to expand issue type support source source tensorflow version 26 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell this is not a bug report just a question now im learning the source code of tensorflow and i cant understand the difference between these two and can anyone explain this for me thanks standalone code to reproduce the issue shell none relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nold versions of tflite native benchmark binaries\nhi is it possible to download old versions of tflite native benchmark binaries i can find here only the nightly version"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nrunning tensorflow on sharc processors\nare there any information on the possibility to compile tensorflow lite c targeting sharc processor from analog devices"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nimplement llama 2 using tensorflow\nissue type feature request have you reproduced the bug with tensorflow nightly no source source tensorflow version tf 28 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior standalone code to reproduce the issue shell relevant log output shell"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nwill there a mlp model in the future version\nissue type feature request have you reproduced the bug with tensorflow nightly no source source tensorflow version 2130 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior when building deep learning models like multilayer perceptrons mlps code reusability and conciseness are crucial factors currently using tfkerassequential in tensorflow allows for convenient creation of sequential models however manually adding common operations such as batch normalization or dropout to each layer can lead to code redundancy and an increased burden in terms of coding and maintenance therefore proposing the addition of a feature in tensorflow to directly create mlps with batch normalization and dropout is highly beneficial here are several reasons why this feature would be advantageous for tensorflow users 1 simplified code users wont need to manually add batch normalization and dropout operations to each layer resulting in cleaner more readable and maintainable code 2 reduced error rate manual copypasting of code is errorprone especially as model complexity increases automating the integration of batch normalization and dropout operations can reduce issues arising from code errors 3 increased productivity developers can build and iterate on models more swiftly focusing on design and parameter tuning rather than rewriting the same code segments for every new model 4 education and learning for newcomers to tensorflow this feature can provide a quicker onboarding process lowering the learning curve and enabling them to grasp and apply deep learning concepts faster certainly heres the additional information i also believe that pytorch has implemented mlp functionality quite effectively an example of this can be found in the following url pytorch mlp pytorchs approach to creating mlps provides a good reference for how tensorflow could potentially integrate similar features standalone code to reproduce the issue origin python model tfkerassequential tfkeraslayersrelu tfkeraslayersdense64 tfkeraslayersrelu tfkeraslayersdense32 tfkeraslayersrelu tfkeraslayersdense10 with mlp model python model tfkerasmlp hiddenchannels128 64 32 10 dropout02 relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\npybind11proto from python to c\nblaziusmaximus thanks for the explanation ive been exploring how to update the importgraphdef codepath to use pybind11protobuf and i could use your help with the following similar to how pybind11protobuf allows us to pass protos directly from c to python is there a way to pass a graphdef proto from python to c without performing serialization this would be needed to invoke the from pywrap session in c originally posted by othakkar in"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nfeature the heaviside step function as a activation function\nsome of the implementations like single layer perceptron needs discrete outputs like 0 or 1 adding this could make the model building ease"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nfloat8 support for array ops\nissue type feature request have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2120 custom code no os platform and distribution mobile device no response python version 396 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior please add fp8 datatype support for array ops like reshape transpose gatherv2 expanddims squeeze concatv2 split pack unpack and stridedslice standalone code to reproduce the issue shell import tensorflow as tf from import dtypes a tfconstant12345678 23456789 34567891 45678912 56789123 67891234 dtypedtypesfloat16 printa afp8 tfcasta dtypesfloat8e4m3fn printafp8 b afp812 b tftransposeafp8 1 0 relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nissue still tittle\nissue type documentation feature request have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior what you see what im see standalone code to reproduce the issue shell us see you relevant log output shell productive projects"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nthe tf keras models loadmodel used for loading ml model is not able to load model\nclick to expand issue type feature request have you reproduced the bug with tf nightly yes source source tensorflow version tf 28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour hi i am trying to load my deep learning model using tensorflow keras models loadmodel when i run it for first time it got loaded but from next time it is not loading like it is in this function for more than 30 min i store my model in h5 format model size is approx 13 mb at the time of saving deep learning i use modelsave i am using a machine with 128 gb ram i am using multiprocessing with no of worker 16 sometime it worked and sometime is got stucked standalone code to reproduce the issue shell relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntreats label as binary\nclick to expand issue type documentation feature request have you reproduced the bug with tf nightly yes source binary tensorflow version 2140dev20230611 custom code yes os platform and distribution linux mobile device na python version 3113 bazel version na gcccompiler version na cudacudnn version no response gpu model and memory no response current behaviour is returning precision assuming the label is binary it looks so to me see in 4 m mupdatestate0 1 2 3 0 1 2 2 mresultnumpy out4 10 in 5 import tensorflow as tf in 6 m mupdatestate0 1 2 3 0 1 2 2 mresultnumpy out6 10 in 7 tfversion out7 2140dev20230611 in 8 m mupdatestate0 5 3 3 0 1 2 2 mresultnumpy out8 10 above shouldnt be 10 if labels are treated as non binary it appears to me that 0s are treated as 0 while non zeros are treated as 1 but nowhere in the doc mentions this behavior i cant find categorical precision or similar either please update doc to explain this behavior standalone code to reproduce the issue shell see above relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncould not interpret loss function ndcg lambda weight v2\na erro happened could not interpret loss function ndcg lambda weight v2 modelcompile optimizeroptimizer modelfittraindataset epochs20 some error happened in modefit valueerror could not interpret loss function identifier"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ngpu delegate dynamic tensor input shape feature request\nclick to expand issue type feature request have you reproduced the bug with tf nightly yes source source tensorflow version tf 2120 custom code yes os platform and distribution android mobile device android python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour hello im writing you to ask are there plans to implement dynamic input shape in gpu delegate in near future right now dynamic input shape working fine on cpu but on gpu delegate im getting the issue internal error error applying delegate this is very important feature if this feature already exist and it is possible somehow to rung with dynamic shape will be good to have some information in documentation standalone code to reproduce the issue shell private fun context interpreter val tfliteoptions interpreter options if delegate null 1 else 4 val interpreter tfliteoptions intarrayof1 modelheight modelwidth 3 true return interpreter relevant log output shell internal error error applying delegate method"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nadd docs reference to latest numpy version for tfexperimentalnumpy functions\nclick to expand issue type documentation feature request have you reproduced the bug with tf nightly no source binary tensorflow version 2120 custom code no os platform and distribution linux ubuntu 1804 mobile device no response python version 310 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour as the tf version requirements for running the latest version we need the latest version of numpy and all tfexperimentalnumpy functions point to the numpy v116 i am thinking if we can update the referencing docs link thanks standalone code to reproduce the issue shell check this relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nnetworklevel control of precision fp32 in training fp16 in inference\nclick to expand issue type feature request have you reproduced the bug with tf nightly yes source binary tensorflow version tf 212 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour a very common use case is that we train and export the model in fp32 then use fp16 mode in inference but it seems xla doesnt support this it would be good if xla can support networklevel control of precision like tensorrt standalone code to reproduce the issue shell na relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to write custom xla op for tensorflow\nclick to expand issue type documentation feature request have you reproduced the bug with tf nightly yes source binary tensorflow version 2120 custom code yes os platform and distribution linux mobile device no response python version 310 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour hi i have custom tensorflow ops implemented in c using this guide which are invoked during training they work fine as long as xla is not used however im unable to get them working and even a dummy custom xla op the test op i have written is mentioned below and compiled by following the guide linked above the compilation succeeds but i get following runtime error when the module with custom op is imported nonokstatus lookupstatus status notfound op type not registered xlatestop in binary running on make sure the op and kernel are registered in the binary running in this process im not able to find any more info how to resolve this issue standalone code to reproduce the issue shell c xla op implementation include include include include include include include include include include include include void testopcudastreamt stream void buffers const char opaque sizet opaquelen stdcout executing testopn class xlatestop public xlaopkernel public explicit ctx xlaopkernelctx void ctx override xlaxlabuilder const builder ctxbuilder xlaxlaop input ctxinput0 use output aliasing to reuse input buffer for output stdpair xlashapeindex 0 xlashapeindex xlashape outputshape xlaxlaop outputop xlacustomcall builder testop input outputshape opaque hassideeffectfalse literalnullptr ctxsetoutput0 outputop xlatestop cuda relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nneed add perl to supported api languages\nthis page lists all the languages with support for the tensorflow api thanks to an official grant from the perl foundation we have recently released a perl api how do we go about getting perl added to the list"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nmake time seriesfromarray more intuitive to use\nclick to expand issue type feature request have you reproduced the bug with tf nightly no source source tensorflow version 2100 tensorflowmacos custom code yes os platform and distribution macos 1321 mobile device no response python version 3108 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour timeseriesgenerator is deprecated and tensorflow docs encourage the use of time seriesfromarray instead however this is not intuitive to use requiring far more boilerplate code to achieve the same effect in addition the results are not as expected i spent hours debugging my code to realise time seriesfromarray is not behaving as expected using the code below i would expect there to be 6 different inputs and outputs however there are only 3 running the same code with timeseriesgenerator without the 4 and 4 indexing produces the expected 6 inputs and outputs standalone code to reproduce the issue shell x npzeros10 3 y nparray1 2 3 4 5 6 7 8 9 10 test y4 sequencelength4 batchsize2000 relevant log output shell array0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 array5 6 7 code for timeseriesgenerator expected output python test y length4 test0 expected output shell array0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 array 5 6 7 8 9 10"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to build with xnnpack\nclick to expand issue type feature request have you reproduced the bug with tf nightly yes source source tensorflow version tf 2100 custom code yes os platform and distribution ubuntu 2004 mobile device qualcomm python version 38 bazel version 511 gcccompiler version 930 cudacudnn version no response gpu model and memory no response current behaviour shell i want to build without xnnpack or with xnnpackqs8 diabled how to achieve that standalone code to reproduce the issue shell i tried with and define but it seems that they didnt work relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nfreeze zero weights during training\nclick to expand issue type feature request have you reproduced the bug with tf nightly yes source source tensorflow version 211 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell is there any way to freeze zero weights during model retraining this is different than freezing a layer which is already available in tf this is relevant to model pruning for example i want to retrain only nonzero weights of a pruned model is it possible to use tfindexedslices efficiently for this standalone code to reproduce the issue shell i think we can achieve this if theres any feature in tf to calculate grads only for nonzero weights i couldnt find any method to achieve this tffunction def trainstepinputs targets with tfgradienttape as tape predictions modelinputs trainingtrue lossvalue lossfntargets predictions grads return lossvalue relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncast int32 to bfloat16 does not run on a100 gpu\nclick to expand issue type feature request have you reproduced the bug with tf nightly yes source source tensorflow version tensorflow version 2130dev20230215 custom code yes os platform and distribution ubuntu 2004 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version 11886 gpu model and memory single a100 80g current behaviour shell when using tfcast to cast tfint32 tensor to tfbfloat16 tensor op run on gpu when i convert int32bfloat16 it run on cpu when i convert int32float32bfloat16 it run on gpu is it expected standalone code to reproduce the issue shell import tensorflow as tf from tensorflowkeras import mixedprecision policy printpolicyname class def buildself inputshape selfkernel selfaddweightkernel inputshape1 10 def callself inputs out tflinalgmatmulinputs selfkernel out2 tfones10 10 dtypetfint32 out2 tfcastout2 tffloat32 namecastout21 out2 tfcastout2 outdtype namecastout22 out3 out out2 return out3 layer toylayer y layertfones10 10 relevant log output shell 20230217 162634748024 i this tensorflow binary is optimized to use available cpu instructions in performancecritical operations to enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler flags 20230217 162635370677 w tftrt warning could not find tensorrt mixedbfloat16 20230217 162636876507 i created device with 78915 mb memory device 0 name nvidia a100 80gb pcie pci bus id 000100000 compute capability 80 input arg 20230217 162636886233 i input arg eagerconst eagerconst 20230217 162636886254 i eagerconst eagerconst outputretval retval 20230217 162636886267 i outputretval retval 20230217 162636889118 i executing op eagerconst in device input arg 20230217 162637293473 i input arg eagerconst eagerconst 20230217 162637293513 i eagerconst eagerconst outputretval retval 20230217 162637293521 i outputretval retval 20230217 162637294777 i executing op eagerconst in device dims devicearg 20230217 162637295227 i dims devicearg value arg 20230217 162637295238 i value arg fill fill 20230217 162637295250 i fill fill outputretval retval 20230217 162637295257 i outputretval retval 20230217 162637295729 i executing op fill in device 20230217 162637297303 i executing op eagerconst in device 20230217 162637297667 i executing op eagerconst in device 20230217 162637297928 i executing op eagerconst in device 20230217 162637298227 i executing op eagerconst in device seed arg 20230217 162637298533 i seed arg 20230217 162637298547 i keyretval retval 20230217 162637298561 i keyretval retval counterretval retval 20230217 162637298573 i counterretval retval 20230217 162637299212 i executing op in device 20230217 162637300704 i executing op eagerconst in device shape devicearg 20230217 162637300963 i shape devicearg key arg 20230217 162637300974 i key arg counter arg 20230217 162637300979 i counter arg alg devicearg 20230217 162637300993 i alg devicearg 20230217 162637300999 i outputretval retval 20230217 162637301008 i outputretval retval 20230217 162637301526 i executing op in device x arg 20230217 162637302304 i x arg y arg 20230217 162637302316 i y arg sub sub 20230217 162637302332 i sub sub zretval retval 20230217 162637302338 i zretval retval 20230217 162637302706 i executing op sub in device x arg 20230217 162637303361 i x arg y arg 20230217 162637303372 i y arg mul mul 20230217 162637303379 i mul mul zretval retval 20230217 162637303391 i zretval retval 20230217 162637303748 i executing op mul in device x arg 20230217 162637304205 i x arg y arg 20230217 162637304216 i y arg addv2 addv2 20230217 162637304223 i addv2 addv2 zretval retval 20230217 162637304229 i zretval retval 20230217 162637304663 i executing op addv2 in device resourceretval retval 20230217 162637305249 i resourceretval retval varhandleop varhandleop 20230217 162637305263 i varhandleop varhandleop 20230217 162637305637 i executing op varhandleop in device resource arg 20230217 162637306104 i resource arg value arg 20230217 162637306122 i value arg assignvariableop assignvariableop 20230217 162637306139 i assignvariableop assignvariableop 20230217 162637306554 i executing op assignvariableop in device x arg 20230217 162637307498 i x arg cast cast 20230217 162637307523 i cast cast yretval retval 20230217 162637307532 i yretval retval 20230217 162637307943 i executing op cast in device resource arg 20230217 162637308714 i resource arg readvariableop readvariableop 20230217 162637308734 i readvariableop readvariableop valueretval retval 20230217 162637308743 i valueretval retval 20230217 162637309154 i executing op readvariableop in device 20230217 162637309366 i executing op cast in device a arg 20230217 162637309693 i a arg b arg 20230217 162637309710 i b arg matmul matmul 20230217 162637309727 i matmul matmul productretval retval 20230217 162637309738 i productretval retval 20230217 162637310165 i executing op matmul in device 20230217 162637897703 i executing op eagerconst in device 20230217 162637897841 i executing op eagerconst in device dims arg 20230217 162637898261 i dims arg value arg 20230217 162637898272 i value arg fill fill 20230217 162637898280 i fill fill outputretval retval 20230217 162637898285 i outputretval retval 20230217 162637898934 i executing op fill in device x devicearg 20230217 162637899509 i x devicearg cast cast 20230217 162637899523 i cast cast yretval retval 20230217 162637899530 i yretval retval 20230217 162637899935 i executing op cast in device x arg 20230217 162637900335 i x arg y arg 20230217 162637900348 i y arg mul mul 20230217 162637900361 i mul mul zretval retval 20230217 162637900369 i zretval retval 20230217 162637901006 i executing op mul in device"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nfeature request more descriptive getweights method\nissue type feature request tensorflow version tf 2110 os platform and distribution windows 11 python version 3109 hello currently i can get the weights of each layer of a keras model by calling tensorflows getweights method additionally this method returns the bias of the layer if the usebias term is true there is no mention of the order in which weights and biases are returned in tensorflow or keras documentation when the method returns two or more numpy arrays how can we determine what these layers represent it would be awesome if the getweights method could also indicate whether a particular numpy array is a weights array bias array etc standalone code to reproduce the issue shell import tensorflow as tf def getmodel mnistmodel tfkerassequential 28 activationrelu activationrelu tfkeraslayersdense10 return mnistmodel def for index layer in enumeratemodellayers statedict"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nproto file missing in nightly wheels\nhave you reproduced the bug with tf nightly yes tensorflow version tf 212 current behaviour i work on the tensorflowdirectml plugin and we use the proto files included in the tf wheel to generate pbccpbh files needed by the plugin one of the files needed is the file which has not been included in the nightly wheels so far would it be possible to make sure that its included for tf 212"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to change specific body line colour eg hipkneeankle line in swift\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source source tensorflow version pod tensorflowliteswift 001nightly subspecs coreml metal custom code yes os platform and distribution macos mobile device iphone x python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell unable to change specific body line colour eg hipkneeankle line in swift standalone code to reproduce the issue shell how to change specific body line colour eg hipkneeankle line in swift relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nnot working\nclick to expand issue type bug have you reproduced the bug with tf nightly no source source tensorflow version tf 210 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell to clone a model using to keep ema weights standalone code to reproduce the issue shell when cloning a model that inherits from tfkerasmodelsmodel cant use relevant log output shell valueerror traceback most recent call last input in 20 in 1 gan 5 define losses 6 generatorloss discriminatorloss getlossnsl input in 19 in adatganinitself generator discriminator 4 superadatgan selfinit 5 selfgenerator generator 6 selfemagenerator 7 selfdiscriminator discriminator 8 selfnoisedim noisedim file in clonemodelmodel inputtensors clonefunction 501 return clonesequentialmodel 502 model layerfnclonefunction 503 504 else 505 return clonefunctionalmodel 506 model layerfnclonefunction 507 file in inputtensors layerfn 167 raise valueerror 168 expected model argument 169 to be a functional model instance 170 fgot a sequential instance instead model 171 172 if not modelisgraphnetwork 173 raise valueerror 174 expected model argument 175 to be a functional model instance 176 fbut got a subclassed model instead model 177 179 newinputlayers cache for created layers 180 if inputtensors is not none 181 make sure that all input tensors come from a keras layer valueerror expected model argument to be a functional model instance but got a subclassed model instead"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to train with mobilenet models using modelspecget\nhello i am using this tutorial to train my dataset for the object detection and efficientdetlite 04 models are working fine i found a documentation for modelspecget and it seems you can train only with efficientdetlite models is there any way to train the model with ssdmobilenetv2 or ssdmobilenetv1 models and what i should write inside of modelspecget look forward to hearing from you"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nrequest some way to initialise a dynamicallysized state variable in tflite\nsystem information os platform and distribution eg linux ubuntu 1604 all tensorflow installed from source or binary binary tensorflow version or github sha if from source 291 provide the text output from tfliteconvert unable to lift tensor because it depends transitively on placeholder via at least one path eg zeros fill shape shape arr placeholder standalone code to reproduce the issue i want to define a stateful graph where the shape of the state variable is defined when model is loaded not when its saved as a simple example lets say i just want to compute a temporal difference ie a graph that returns the difference between the input in two consecutive calls the following should pass func runtimeshape 60 80 rng ims for in range3 assert npallclosefuncims0 ims0 assert npallclosefuncims1 ims1ims0 assert npallclosefuncims2 ims2ims1 however as far as i know there is not way i can save a model or define some function loadtflitemodelfunc for loading it that would make this work for any runtimeshape because variables in the graph can only be saved with a predetermined size a full standalone notebook demonstrating the issue is here request is for tflite to be able to initialise statevariables where the shape of the initialised variable can depend on the inputshape see also"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nsupport for keepdims and padding in tfbooleanmask or tfraggedbooleanmask\nclick to expand issue type feature request source source tensorflow version tf 28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour given two example tensors input and mask input tfrandomnormal235 input tftensor shape2 3 5 dtypefloat32 numpy array 11260294 005932725 085893923 15332409 06681451 08833729 08421117 060990584 008593109 05969471 020015325 09459327 10818844 17254639 051545954 036073774 024315724 15217028 15075827 005745999 02570101 15501927 017113225 016063859 095638955 048955616 011943919 03523262 010750653 11027677 dtypefloat32 mask tfconstant010101 mask tftensor shape2 3 dtypeint32 numpy array0 1 0 1 0 1 dtypeint32 i need to mask out input according to mask where values are 0 however since the number of masked out elements for each example in the batch input might be different to keep the output a valid tensor the output should be maskedinput tftensor shape2 3 5 dtypefloat32 numpy array 08833729 08421117 060990584 008593109 05969471 0 0 0 0 0 0 0 0 0 0 036073774 024315724 15217028 15075827 005745999 048955616 011943919 03523262 010750653 11027677 0 0 0 0 0 dtypefloat32 ie in the output the masked input keeps only elements where mask is 1 and with zeropadding at the end to ensure that the output is a valid tensor ive searched around and tried using 1 tfgather however still cant figure out how to proceed 2 tfbooleanmask however it doesnt support masking but just drops the first zeroth dimension as shown below tfbooleanmaskinput mask tftensor shape3 5 dtypefloat32 numpy array 08833729 08421117 060990584 008593109 05969471 036073774 024315724 15217028 15075827 005745999 048955616 011943919 03523262 010750653 11027677 dtypefloat32 3 tfraggedbooleanmask this is by far the closest one to what i want it keeps the dimension however still doesnt support masking so the result is a ragged tensor similar issues are mentioned in github in short tensor 1 2 3 4 5 6 7 8 9 mask nparraytrue false true false false true true true true booleanmasktensor mask keepdimsfalse 1 3 6 7 8 9 booleanmasktensor mask keepdimstrue padval0 1 3 0 6 0 0 7 8 9 standalone code to reproduce the issue as mentioned above relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow lite image classification add a new model\nhello i tested your tensorflow lite image classification android app and it works perfect with these models mobilenet v1 efficientnet lite0 efficientnet lite1 efficientnet lite2 which are downloading automatically by the downloadgradle file then i wanted to add my own classification model which has different labels compared to models mentioned above i placed my model in assets folder appsrcmainassets and then did some modification in file val modelname when currentmodel modelmymodel mymodeltflite modelmobilenetv1 mobilenetv1tflite else mymodeltflite companion object const val delegatecpu 0 const val delegategpu 1 const val delegatennapi 2 const val modelmymodel 0 const val modelmobilenetv1 1 private const val tag while i build and launch the app i received the following error launching app on xiaomi install successfully finished in 6 s 117 ms adb shell am start n a c connected to process 15146 on device xiaomi can you please let me know how to fix the issue and do i need to do other modification in scripts to make it work with my model look forward to hearing from you and thank you in advance"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nexpecting the same names when converting to tflite model\nhello i have created very simple model and i want to export it to tflite model to benchmark it on android device and run simple inferences this is code to create model python import tensorflow as tf import numpy as np from tensorflow import keras from tensorflowkeras import layers input0 kerasinputshape64 nameinput0 input1 kerasinputshape16 nameinput1 input2 kerasinputshape16 nameinput2 layer0 layersdense3 activationrelu namelayer0input0 layer1 layersdense5 activationrelu namelayer1input1 layer2 layersdense7 activationrelu namelayer2input2 x0 layer1 layer2 x1 layer1 layer2 output0 layersdense3 nameoutput0x0 output1 layersdense7 nameoutput1x1 model kerasmodel inputsinput0 input1 input2 outputsoutput0 output1 lossmeansquarederror converter tflitemodel converterconvert with openmodeltflite wb as f fwritetflitemodel environment google colab i expect that tflite model would have input0 input1 input2 input names and output0 output1 output names but real names are"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow lite ios interpreter production logs\nclick to expand issue type feature request source source tensorflow version 2100 custom code no os platform and distribution ios mobile device ios python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell the log outputs of the interpreter cannot be disabled for production use but we would need that see would be nice if you could introduce another option for the interpreter where you could set log outputs enableddisabled or even with loglevels standalone code to reproduce the issue shell interpretermodelpath path options options relevant log output shell initialized tensorflow lite runtime"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nfeature request tensorflow lite implement mechanism to load flex ops in c for android\nsystem information have i written custom code no os platform and distribution macos monterey 126 tensorflow installed from source tensorflow version 2100 python version 3108 bazel version 511 gcccompiler version apple clang 1400 clang1400029202 cudacudnn version not using cuda gpu model and memory not using gpu acceleration exact command to reproduce feature request no describe the problem this is a feature request in tensorflow lite 27 and higher if a model contains flex ops you must go through java to load the flex library see and flexdelegatejava we develop a crossplatform app where most of the ml inference logic runs in a separate c library we test that library separately from the rest of the app using gtest without going through the android runtime for our purposes it would be much more convenient if we could load the flex library directly in c as a tentative implementation we could move the logic in to c so that we could automatically load flex ops when creating models from the c api with tflitemodelcreate the existing java classes could be kept as shallow wrappers to the underlying c implementation java and c entry points could be toggled at build time through a flag is this something that you would consider implementing and if not would you accept prs that go in that direction"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntfidentity docs missing instructions gpu to cpu\nissue type documentation feature request source binary tensorflow version 2100 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour the docs do not describe how cpu should be accomplished standalone code to reproduce the issue shell import tensorflow as tf tfconstant1cpu relevant log output shell eagertensorbasecpu from is deprecated and will be removed in a future version instructions for updating use tfidentity instead"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ndocument behavior of with returnstatetrue\nclick to expand issue type documentation feature request source source tensorflow version 210 custom code no it is unclear from the documentation how a layer will behave if returnstate is true ie in what order the hiddencell states will be returned and what if any interaction there is with mergemode per the source code any states of forward layer are returned after the outputs followed by any states of the backward layer this should be documented if selfreturnstate states y1 yrev1 y y0 yrev yrev0 if selfreturnstate if selfmergemode is none return output states return output states return output"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to enable gspmd\nclick to expand issue type support source binary tensorflow version tf 27 custom code no os platform and distribution linux mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell we are trying to utilize gspmd on a server with 8 gpus we find the uttest cases as follows to dump the irs we enable the environment variables as tfxlaautojit2 mytensorflowprogram but only 4 irs are saved none of them is related to spmd pass it seems that our current run does not enable gspmd functionality at all is there any tutorial or instructions for us to follow to enable gspmd on multiple gpus standalone code to reproduce the issue shell from import xlasharding from tensorflowpythonops import arrayops from tensorflowpythonops import mathops from import testutil from import dtypes from import ops import numpy as np from import deffunction class def testdotsplitself deffunctionfunction def splithelpertensor devicemesh nparray0 1 2 3 4 5 6 7 splittensor devicemesh 0 1 opstensor splitsharding splitshape expectedshape 2 4 splitshape ytensor arrayopsones8 8 dtypedtypesfloat32 ysplit devicemesh 0 1 result ysplit devicemesh nparray0 1 2 3 4 5 6 7 result devicemesh 0 1 result mathopssqrtresult result devicemesh 1 0 return result intensor 2 npsqrt2 arrayopsones8 8 dtypedtypesfloat32 result splithelper arrayopsones8 8 dtypedtypesfloat32 result if name main xlasharding xlashardingtest relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nsupport for c builder 112\nclick to expand issue type others source binary tensorflow version tf 28 custom code no os platform and distribution windows 11 x64 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell is there anyway to support c builder 112 current static libs are in a format not supported by c builder static libs are only in coff format so they cant be linked with in c builder they need to be in omf format for c builder to link the static libs the only way i can solve this is to do a loadlibrary in code and get proc address of each function standalone code to reproduce the issue shell no able to link static libs only in msvc not c builder relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nleakyrelu in tensorflow lite with the hexagon delegate not supported\nwhen using a tflite model 8bits quantized via tensorflow lite conversion framework that includes the activation function leakyrelu the hexagon delegate from tensorflow framework cannot perform the dnn inference on the whole graph but rather it falls back to the cpuxnnpack delegate this is due to the fact that leakyrelu operation is not supported by the hexagon delegate confirmed in tensorflow doc when using relu activation function and relu6 as well we can see below that the tf hexagon delegate can process the whole dnn graph unfortunately the qualitative results i get are much worse hence the need of having leaky relu implemented in the hexagon delegate we can easily reproduce this behavior by using tensorflow benchmark tool see below could we consider to implement leaky relu in tensorflow lite dsp delegate system information os platform and distribution android 10 ndk r21e tensorflow installed from source or binary from source using the release tag 291 tensorflow version or github sha if from source 291 provide the text output from tfliteconvert warningabslfound untraced functions such as while saving showing 5 of 23 these functions will not be directly callable after loading userwarning statistics for quantized inputs were expected but not specified continuing anyway for quantized inputs were expected but not 20221013 181316990773 w ignored outputformat 20221013 181316991046 w ignored 20221013 181316998334 i reading savedmodel from 20221013 181317027069 i reading meta graph with tags serve 20221013 181317027795 i reading savedmodel debug info if present from 20221013 181317269741 i mlir v1 optimization pass is not enabled 20221013 181317291178 i restoring savedmodel bundle 20221013 181318176412 i running initialization op on savedmodel bundle at path 20221013 181318475762 i savedmodel load for tags serve status success ok took 1477588 microseconds 20221013 181319015757 i disabling mlir crash reproducer set env var to enable found 7390 files belonging to 1 classes fullyquantize 0 inferencetype 6 inputinferencetype 9 outputinferencetype 9 process finished with exit code 0 standalone code to reproduce the issue here is a colab link with the code used to generate the model that include leaky relu op quantize and save the model in int8 ops colab code link link to the quantized model the tool below from tensorflow allow to run any model when running the model above it fails because leakyrelu is not supported link to tensorflow benchmark tflite benchmark command line tfbenchmark usehexagontrue when performing the inference on dsp using tensorflow lite benchmark tool for android we get the following error message tfbenchmark usehexagontrue starting log parameter values verbosely 0 graph require full delegation 1 use hexagon 1 hexagon lib path datalocaltmp loaded model info initialized tensorflow lite runtime loaded libcdsprpcso hexagon delegate created info delegate 6 nodes delegated out of 12 nodes with 5 partitions verbose replacing 6 nodes with delegate node yielding 6 partitions disallowed cpu fallback detected benchmarking failed if i disable the usage of the dsp then it works properly tflite benchmark command line tfbenchmark logs tfbenchmark starting log parameter values verbosely 0 graph loaded model info initialized tensorflow lite runtime the input model file size mb 0038384 initialized session in 057ms running benchmark for at least 1 iterations and at least 05 seconds but terminate if exceeding 150 seconds count1141 first4613 curr428 min427 max4613 avg438004 std125 running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds count2311 first433 curr428 min427 max627 avg432374 std14 inference timings in us init 570 first inference 4613 warmup avg 438004 inference avg 432374 note as the benchmark tool itself affects memory footprint the following is only approximate to the actual memory footprint of the model at runtime take the information at your discretion memory footprint delta from the start of the tool mb init0 overall309766 if i replace leakyrelu by relu then it works properly here is a colab link with the code used to generate the model that include relu op quantize and save the model in int8 ops colab code link link to the quantized model myquantmodelreluzip tflite benchmark command line tfbenchmark usehexagontrue logs tfbenchmark usehexagontrue starting log parameter values verbosely 0 graph require full delegation 1 use hexagon 1 hexagon lib path datalocaltmp loaded model info initialized tensorflow lite runtime loaded libcdsprpcso hexagon delegate created info delegate 8 nodes delegated out of 8 nodes with 1 partitions verbose replacing 8 nodes with delegate node yielding 1 partitions explicitly applied hexagon delegate and the model graph will be completely executed by the delegate the input model file size mb 00374 initialized session in 17422ms running benchmark for at least 1 iterations and at least 05 seconds but terminate if exceeding 150 seconds count918 first796 curr537 min324 max3378 avg540937 std180 running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds count1754 first701 curr537 min443 max2552 avg565409 std136 inference timings in us init 174220 first inference 796 warmup avg 540937 inference avg 565409 note as the benchmark tool itself affects memory footprint the following is only approximate to the actual memory footprint of the model at runtime take the information at your discretion memory footprint delta from the start of the tool mb init348047 overall348047"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nmaking tensorflowtile similar to numpytile and torchtile\nclick to expand issue type feature request source source tensorflow version 291 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell running this code tftiletfones321 will currently give an error for tensorflow since the dimension length of the input and the multiples is different numpy and pytorch handle this by modifying the dimension of the multiples or the input argument i believe it would be nice if tensorflow did this too standalone code to reproduce the issue shell import tensorflow as tf tftiletfones321 relevant log output shell tensors devicename opname expected multiples argument to be a vector of length 1 but got length 2 optile"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nsupporting int32 value type in textfileinitializer\nclick to expand issue type feature request source source tensorflow version tf 29 custom code no os platform and distribution linux mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell in textfileinitializer we have a validation to check whether the valuedtype is of type tfint64 wondering why do we have such constraints the context is that we are trying to initialize a vocabulary lookup table in the tensorflow model and would like to save memory for the hashtable both the key and value type can be of int32 type but seems that the value type is restricted to int64 standalone code to reproduce the issue shell initializer vocabfile keydtypetfint64 keyindex0 valuedtypetfint32 valueindex1 delimiter relevant log output shell 0 vocabtable numoovbuckets1 0 file line 1235 in init 0 dtypesint64 0typeerror invalid value dtype expected but got"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to build tensorflow from source with clang\nclick to expand issue type buildinstall source source tensorflow version v2100 custom code no os platform and distribution ubuntu 2004 mobile device no response python version 38 bazel version 511 gcccompiler version clang 14 cudacudnn version no response gpu model and memory no response current behaviour shell i am trying to build tensorflow with clang and add options for generating coverage information however it fails with clang build standalone code to reproduce the issue shell bazel build verbosefailures repoenvccclang coptfcoveragemapping removing coptfcoveragemapping also fails relevant log output shell error compiling failed undeclared inclusions in rule this rule is missing dependency declarations for the following files included by target failed to build info elapsed time 138453s critical path 6333s info 7649 processes 4288 internal 3361 local failed build did not complete successfull"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nadan optimizer\nclick to expand issue type feature request source binary tensorflow version tf 291 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell adan seems to be a superior optimizer compared to adam and its variants can we introduce this in tfkeras optimizers please find a few references below adan paper pytorch implementation blog article standalone code to reproduce the issue shell na relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ngpu detection src location\nclick to expand issue type others source source tensorflow version 2 custom code no os platform and distribution ubuntu 2004 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version 117 gpu model and memory tesla v100 current behaviour shell hello im a student researcher and i am only posting this as i got no response on the tensorflow google group please direct me to next place to the answer im trying to develop a feature where if tensorflow does not detect a local gpu i direct the binary to my custom application a gpu virtualization framework for it to talk to a remote gpu execute the calls i want to know in the large codebase of tensorflow where should i start looking for this i need source file where it decides no gpu so use cpu or something similar standalone code to reproduce the issue shell na relevant log output shell na"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncrash with segmentation fault\nclick to expand issue type bug source binary tensorflow version 2110dev20220916 custom code no os platform and distribution ubuntu 18044 lts x8664 mobile device no response python version 376 bazel version no response gcccompiler version no response cudacudnn version na gpu model and memory no response current behaviour shell crash with segmentation fault when maxtotalsize is given a large value standalone code to reproduce the issue shell import numpy as np import tensorflow as tf scoresnpones221 boxesnpones2214 relevant log output shell 20220919 205642880536 w could not load dynamic library libcudaso1 dlerror libcudaso1 cannot open shared object file no such file or directory 20220919 205642880586 w failed call to cuinit unknown error 303 20220919 205642880661 i no nvidia gpu device is present devnvidia0 does not exist 20220919 205642881322 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 avx512f fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20220919 205642924370 w detected a large value for maxtotalsize this may cause oom error maxtotalsize 1916847725 segmentation fault core dumped"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ninclude name parameter in function to give a new name to the clone\nclick to expand issue type feature request source source tensorflow version 282 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell when using the function it assigns the same name as previousmodel to the created clone i want to assign a new name to the created clone this can probably be done by passing a name parameter to the clonemodel function standalone code to reproduce the issue shell prem1 tfkerassequential sentenceencoderlayer namepretrainedm1 prem2 in the summary the name of prem2 is printed as pretrainedm1 ie same as prem1 printprem2summary relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nfeature balanced accuracy\nclick to expand issue type feature request source binary tensorflow version tf 2100rc3 custom code no os platform and distribution debian 11 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version 112 gpu model and memory no response current behaviour i suggest adding balanced accuracy as additional keras metrics it is useful for training with an imbalanced validation dataset note i see various suggestions on stackoverflow 1 2 standalone code to reproduce the issue shell import tensorflow as tf metrics relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntfimagerot90 should add a note for the case k0\nclick to expand issue type documentation feature request source source tensorflow version tf28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell the documentation only describes how the code runs when k0 and dont mention k0 the code shows that when k0 the image will be rotated clockwise i think a note should be added to explain what happens when k0 standalone code to reproduce the issue shell import tensorflow as tf results try arg0 2 1 minval256 maxval257 dtypetfint64 dtypetfint32 k 1 resultsres tfimagerot90arg0kk except exception as e resultserr errorstre printresults relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntfpad fails when executing in\nclick to expand issue type bug source binary tensorflow version tf 291 custom code yes os platform and distribution linux ubuntu 2004 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell tfpad fails when executing in and throws typeerror however if we run tfpad outside of forwardaccumulator with the same input it will pass standalone code to reproduce the issue shell import tensorflow as tf inputtensor tfrandomuniform3 1 1 1 minval20 maxval30 dtypetffloat32 paddings tfrandomuniform4 2 minval0 maxval5 dtypetfint64 mode constant constantvalues 0 result tfpadinputtensor paddings modemode printresultshape pass tangent tfreshapetfonehot1 tfsizeinputtensor with tangent as acc result tfpadinputtensor paddings modemode fail relevant log output shell 8 3 8 4 typeerror input y of sub op has type int64 that does not match type int32 of argument x"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nwhen will tensorflow support fp8\nclick to expand issue type feature request source binary tensorflow version tf29 custom code no os platform and distribution linux ubuntu 2004 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell pytorch added fp8 support will tf add fp8 support sometime for both e4m3 and e5m2 standalone code to reproduce the issue shell no source code just a feature request question relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nplease publish official wheels for apple silicon\nclick to expand issue type buildinstall source binary tensorflow version 291 custom code no os platform and distribution macos 12 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour users of macs with apple silicon m1 m2 etc cannot pip install tensorflow because wheels for the architecture are not published on pypi the current state of this august 2022 is that these wheels are published under a different package name tensorflowmacos which is released separately by apple this makes it more complicated to install software that uses tensorflow on macos eg a requirementstxt file might have to look something like tensorflow sysplatform darwin or platformmachine arm64 tensorflowmacos sysplatform darwin and platformmachine arm64 apples repository tensorflowmacos is archived which makes it unclear where users should get support is it here moreover at the time of writing tensorflowmacos is version 392 which is one bugfix release ahead of the latest official tensorflow so comparing version numbers across the two is difficult and it leaves many other unanswered questions are these being tested in ci how soon after an upstream release will tensorflowmacos get an update finally both tensorflow and tensorflowmacos support intelbased macs which is another potential point of confusion—which is preferred cc kulinseth jhavukainen standalone code to reproduce the issue shell venv arch arm64 venv python3 m pip install tensorflow error could not find a version that satisfies the requirement tensorflow from versions none error no matching distribution found for tensorflow"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to fix the undefined reference problem for the tf lite a suggestion\nwhen cmakeliststxt is used to build a shared library of tf lite it is impossible to link with it because of the undefined reference problem those undefined reference objects reside on the tensorflow main branch but the following macro populatetfsourcevars has never populated a single line of main tensorflow code for the tf lite build yet the main code is referenced by it no wonder we see the undefine reference i did try to use populatetfsourcevars to bring those missing objects to tf lite unfortunately however the references will quickly escalate to reference a lot of main tensorflow stuff that defeats the very motivation of having a lite version of tensorflow doesnt it can you please make tf lite stop referencing those objects because they dont seem to be important if you do think they are important can you make a light version of them just for tf lite the problem usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nis possible to measure height of person using tensorflow pose estimation\nclick to expand issue type feature request source source tensorflow version pod tensorflowliteswift 001nightly subspecs coreml metal custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i want to performe vertical jump test want to measure distance between floor to ankle standalone code to reproduce the issue shell i want to performe vertical jump test want to measure distance between floor to ankle relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nrsqrt doesnt support for\nsystem information os platform and distribution eg linux ubuntu 1604 tensorflow installed from source or binary tensorflow version or github sha if from source provide the text output from tfliteconvert copy and paste here standalone code to reproduce the issue provide a reproducible test case that is the bare minimum necessary to generate the problem if possible please share a link to colabjupyterany notebook also please include a link to a graphdef or the model if possible any other info logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nare there ondevice training with tensorflow lite in arduino ides\nclick to expand issue type feature request source source tensorflow version tf28 custom code no os platform and distribution windows mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell is there a way to perform ondevice training with tensorflow lite in arduino ide i see an option for java and c with android but cant find the c doc seems like c aint supported too standalone code to reproduce the issue shell no code relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nfeature request gelu activation with the hexagon delegate\nsystem information os platform and distribution eg linux ubuntu 1604 ubuntu 2004 tensorflow installed from source or binary binary tensorflow version or github sha if from source 291 i think id be able to implement this myself but wanted to see if there was any interest in including this upstream most of this im writing out to make sure my own understanding is correct the problem id like to add support for the gelu op to the hexagon delegate the motivation for this is mostly for use with distilbert which uses this activation function in its feedforward network layers also used by bert gpt3 roberta etc adding this as a supported op for the hexagon delegate would avoid creating a graph between dspcpu each time the gelu activation function is used how id implement this gelu in tf lite is implemented as a lookup table when there are integer inputs here and here this same approach could be used for the hexagon delegate as it has int8uint8 data types and also supports lookup tables id plan to do this by adding a new op builder in the delegate populating a lookup table for each node as is currently done for the cpu version of the op and then using the gather8 nnlib library function to do the lookup possible workaround a workaround i thought of im going to try removing the pattern matching for approximate gelu in mlir and then using the approximate version of gelu so that using tanh and not erf this will probably be slower but should let me keep execution on the dsp since this will then be tanh addition multiplication ops instead of gelu they should all be runnable by the dsp"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntfio incompatible with aws s3 filepaths\nclick to expand issue type bug source binary tensorflow version 291 custom code no os platform and distribution rhel mobile device no response python version 3712 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour apparently from the aws logs it seems the headers are obtained but the response body is empty im using tfds however its accessing via etils the tf backend to create a stream for the s3 object hence why its reproducible from a tf method this was the full error from tfds for those interested to verify that it does indeed call tfio as a backend to execute the request traceback most recent call last file scriptskecamtesterpy line 47 in tfrecords of bdd100k dataset long only delayed by 60 frames for each tuple file line 80 in writemetadata f for f in datadiriterdir if file line 80 in f for f in datadiriterdir if file line 126 in iterdir for f in file line 191 in listdir return selfgfilelistdirpath file line 769 in listdirectoryv2 messagecould not find directory formatpath could not find directory standalone code to reproduce the issue shell import tensorflow as tf insert any s3 filepath tfiogfilelistdirs3 relevant log output shell traceback most recent call last file line 1 in file line 769 in listdirectoryv2 messagecould not find directory formatpath could not find directory s3"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncmake has no key to disable the build of python wrapper when building tf lite from source using xcode or android studio\nclick to expand issue type feature request source source tensorflow version tf29 custom code no os platform and distribution linux ubuntu 18 or macos mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell cmake has no key to disable the build of python wrapper when building tf lite from source using xcode or android studio current cmake in with the a non optional python wrapper which triggers errors when using tensorflow as a submodule in an xcode or android studio project python interpreter wrapper shared excludefromall to remove lib prefix properties prefix public tfliteincludedirs tensorflowlite cmakedllibs public private i would expect a cmake key to enable or disable the python wrapper eg iftfliteenablepywrap endif standalone code to reproduce the issue shell cmake has no key to disable the build of python wrapper when building tf lite from source using xcode or android studio relevant log output shell cannot find pythonh"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncustom op written in c api errors when requesting gpudevice stream\nclick to expand issue type documentation feature request source binary tensorflow version 28 custom code yes os platform and distribution linux mobile device 07010841551 python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell hi there i was trying to write a custom op using the tensorflow c api and in the cuda version i was facing errors while requesting for the gpudevice stream my questions are 1is there any way to convert spstreamreturned by to cudastream 2what is the equivalent of eigendevicestream c for the c api 3where is the implementation of tfopkernelcontext thanks yoga standalone code to reproduce the issue shell c code cudastreamt equivalent c code cudastreamt thestream relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nreproducible sparsedense matrix multiplication\nclick to expand issue type feature request source binary tensorflow version v29018gd8ce9f9c301 291 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell there is currently no deterministic sparsedense matrix multiplication implementation on the gpu i would like to have one standalone code to reproduce the issue shell import tensorflow as tf m tfsparsetensor indices0 0 0 1 valuesnparray1 2 dtypenpfloat32 denseshape3 2 v tfconstant1 1 dtypetffloat32 v relevant log output shell unimplementederror a deterministic gpu implementation of is not currently available"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow gpu delegate limit resources feature request\nhello sometimes when im running the tflite model on gpu delegate it use almost all gpu resources while execution and this behaviour freeze ui because of lack resources if it possible will be good to have some initial option with percentage of gpu use os android for example 08 this feature will provide more control over resources"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nis it possible to sync tensorflow streamexecutors cuda stream with cuda stream outside\nin tensorflow streams including cuda streams are handled by streamexecuter now i make some modification to tensorflow and create an independent cuda stream outside streamexecuter i was wondering is it possible to sync the independent cuda stream with the streams that wrap a cuda stream in streamexecuter i really appreciate if someone has advices"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncustom op written in c api compilation issue\nclick to expand issue type documentation feature request source binary tensorflow version 28 custom code yes os platform and distribution linux mobile device 07010841551 python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell hi there is there any example where custom op written using c api was compiled successfully and executed after tfloadlibrary i have referred the entire kernelsh opsh and capih files of the official github tf repo but i am not able to figure it out could someone give the command to execute a c api custom op file along with the code thanks yoga standalone code to reproduce the issue shell include tensorflowckernelsh include tensorflowcopsh include tensorflowctftensorh include include include include include shape inference void ctxtfstatus status tfshapehandle handle tfnewshapehandle 0 handle status 0 handle status tfok typedef struct basic tftensor input tftensor output basic static void context basic k basic calloc1 sizeofbasic tfstatus status tfnewstatus initialize the fields of k as needed tfok tfdeletestatusstatus return void k static void basiccomputevoid k tfopkernelcontext ctx compute the result tftensor inputtensornull tfstatus status tfnewstatus tfgetinputctx 0 inputtensor status tfsetoutputctx 0 inputtensor status tfok tfdeletestatusstatus static void basicdeletevoid kernel delete staticcastkernel op and kernel registration void initplugin tfstatus status tfnewstatus opbuilder tozero int32 zeroed int32 status tfok tfdeletestatusstatus tfstatus status1 tfnewstatus auto builder tensorflowdevicecpu basiccreate basiccompute basicdelete builder status1 asserttfok tfgetcodestatus1 tfattributeunused static bool if registerbasickernel return true relevant log output shell module has no attribute basic"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nadd tfcomplex to tflite ops support padding and slicing of complex tensors\nclick to expand issue type feature request source binary tensorflow version 291 custom code no os platform and distribution linux ubuntu 2004 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell it would be great if we could get support in tflite for the tfcomplex op as well as support for slicing and padding complex numbers this is very important for audio use cases as it often involves running stfts and working with complex numbers heres the error i currently get when i try to convert my model some ops are not supported by the native tflite runtime you can enable tf kernels fallback using tf select see instructions tf select ops complex pad stridedslice details tfcomplextensor tensor tensor device tfpadtensor tensor tensor device tfstridedslicetensor tensor tensor tensor tensor beginmask 15 i64 ellipsismask 0 i64 endmask 11 i64 newaxismask 0 i64 shrinkaxismask 0 i64 standalone code to reproduce the issue shell na relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nf1 score metric\nissue type feature request tensorflow version 291 current behaviour no f1 score metric its a holistic measure for classification standalone code to reproduce the issue"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nis it possible to change colour of specific keypoint in ios\nclick to expand issue type feature request source source tensorflow version pod tensorflowliteswift 001nightly subspecs coreml metal custom code yes os platform and distribution macos mobile device iphone x python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i want to change colour of specific body landmarks is it possible to achieve in ios using swift standalone code to reproduce the issue shell multicolor on overlay image relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nbuilding tflite compiling out pthread\nclick to expand issue type buildinstall source source tensorflow version tf29 custom code no os platform and distribution linux ubuntu 16042 lts mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i am trying to build tflite example minimal for a device which does not support posix thread i know one can disabled multithreading by setting numthreads 1 in the interpreter but what i am trying to get is disabling pthread fully during compilation is there a way to achieve this thanks standalone code to reproduce the issue shell you can run the test relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to display custom label with angles in ios\nclick to expand issue type feature request source source tensorflow version pod tensorflowliteswift 001nightly subspecs coreml metal custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell how to display degree of angle on every keypoint standalone code to reproduce the issue shell below code for to create degree of angle i used func angle firstlandmark cgpoint midlandmark cgpoint lastlandmark cgpoint cgfloat let radians cgfloat atan2lastlandmarky midlandmarky lastlandmarkx midlandmarkx atan2firstlandmarky midlandmarky firstlandmarkx midlandmarkx var degrees radians 1800 pi var degrees radians pi 180 pi degrees absdegrees angle should never be negative if degrees 1800 degrees 3600 degrees always get the acute representation of the angle let roundedvalue1 rounddegrees return roundedvalue1 relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to calculate 45 degree standing position of body from camera in swift pose estimation\nclick to expand issue type feature request source source tensorflow version pod tensorflowliteswift 001nightly subspecs coreml metal custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell how to calculate 45 degree standing position of body from camera in swift standalone code to reproduce the issue shell how to calculate 45 degree standing position of body from camera in swift using the body keypoints pose estimation relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nis it possible to calculate body degree angle using pose estimation\nclick to expand issue type feature request source source tensorflow version pod tensorflowliteswift 001nightly subspecs coreml metal custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell how to calculate degree of angles using body keypoints pose angle ie 45 degree 90 degree standalone code to reproduce the issue shell i want to detect human body pose angle is it possible relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nrestore non max suppression nms support for tensorflow lite gpu delegate\nclick to expand issue type feature request source binary tensorflow version 290 custom code yes os platform and distribution google colab mobile device no response python version 3713 google colab bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell tldr please restore support for nonmaxsuppression for tensorflow lite gpu delegate it was supported before tf 23 and is not supported now background back in tensorflow version 23 one could take and run object detection model eg from tensorflow object detection api and run it fully on the tflite with gpu via delegate right now it is impossible operations that were previously supported like nonmaxsuppression are now unsupported by dropping support to these operations users are forcedlocked to use older tensorflow version please bring back support for nonmaxsuppression as it was previously supported standalone code to reproduce the issue shell colab link lets verify support with tflites authoring tool import tensorflow as tf tftensorspecshape1 100 4 dtypetffloat32 boxes tftensorspecshape1 100 1 dtypetffloat32 scores def nmsboxes scores return boxes scores maxoutputsize15 verify this works boxes tfonesshape1 100 4 scores tfonesshape1 100 1 numvalid nmsboxes scores verify crashes tflite gpu delegate authoring tool targetspec tflitetargetspec gpu functotest nms raiseexceptiontrue functotestboxes scores relevant log output shell the log output is rather long and covers multiple sub ops im only pasting the lower part during handling of the above exception another exception occurred compatibilityerror traceback most recent call last in decodeerrorself err 244 245 if selfraiseexception and selflogmessages 246 raise at reprselffunc 247 248 def logself message compatibilityerror at"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntflite dynamic batch size with gpu delegate\nclick to expand issue type feature request source source tensorflow version 2100dev20220427 custom code yes os platform and distribution linux ubuntu 1804 mobile device linux ubuntu 1804 python version 310 bazel version 511 gcccompiler version 750 cudacudnn version cuda 116 gpu model and memory nvidia geforce gtx 1650 4bg current behaviour considering these two assertions please tell me if they are wrong it is not possible to use dynamicsized tensors with the gpu delegate nor is it possible to use a batch size greater than one with the gpu delegate edit it seems that when i saw the bug with batch size greater than one the gpu delegate switched to opengl instead of opencl i do not know the reason and now that it is working with opencl after rebooting the computer the inference can run on the gpu with any batch size thus it would still mean that this feature should be available with opengl however it would very convenient to be able to modify the batch size before creating the network on the gpu or if requested by the user to recreate the network at any time with a different batch size this would allow to convert and store a single model with dynamicsized tensors the size of which would actually be known ie batch size would be set before making use of the network then it would be possible to perform ondevice training on the gpu with a batch of inputs once issue 56151 is solved standalone code to reproduce the issue try running this ondevice training tutorial with both flex and gpu delegates using the experimental c api relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nbuildrelease python 310 tfliteruntime wheels to pypi\nclick to expand issue type buildinstall source binary tensorflow version 290 custom code no os platform and distribution linux macos mobile device no response python version 310 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour tensorflow 290 was released with python 310 support we would like to support python 310 in production but in order to do this we need all of the following packages to support python 310 tensorflow tensorflowmacos for arm macos tfliteruntime for stripped down production on linux neither tensorflowmacos or tfliteruntime have 290 releases on pypi yet standalone code to reproduce the issue create a python 310 virtual environment on linux bash venv python m pip install tfliteruntime create a python 310 virtual environment on macos arm bash venv python m pip install tensorflowmacos relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\n3d ssim\nhi is it possible to add 3d ssim batched into tensorflow we need this feature for 3d inference currently tfimagessim only accepts batched 2d input if not is there any internal beta version of 3d ssim for tryout thanks"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nonly support constant weightdecay\nclick to expand issue type feature request source source tensorflow version 28 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell only supports constant weight decay but usually we want the weightdecay value to decay with learning rate schedule standalone code to reproduce the issue shell the legacy tfaoptimizersadamw supports callable weightdecay which is much better relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to resize downsample 5d samples in tensorflow\nissue type feature request source binary tensorflow version tf 28 custom code yes os platform and distribution windows 10 python version 39 note reposting from here its closed in keras and recommended to post it on the tensorflow side because this functionality is not precisely available in tensorflow it may need to write lowlevel ops in tf for best performance current behaviour currently for 5d data batchsize h w depth channel the or upsampling3d can be used to upsampling purpose for example i can do python a tfonesshape1 100 100 64 1 a depthfactor2 heightfactor2 widthfactor2 shape tensorshape1 200 200 128 1 these factor values above should be an integer and are coded here in that case how can we downsample the input sample for example python a tfonesshape1 100 100 64 1 a depthfactor05 heightfactor05 widthfactor05 shape typeerror float object cannot be interpreted as an integer expected tensorshape1 50 50 32 1 here another scenario where the factor needed to be fractional candidate solutions scipyndimagezoom in pytorch didnt test others such downsampling feature needs to be implemented in lowlevel in the depth part of volumetric data it might be hard to decide the appropriate strategy to drop the slices depending on the domain for example in medical data if we drop the slice blindly we might lose information fyi in ctmri images most of the information appears mainly in the middle range currently a workaround for medical data ctmri were following input data 1 50 50 20 4 desired output 1 25 25 10 4 python a tfonesshape1 50 50 20 4 ashape tensorshape1 50 50 20 4 a2 tfreshapea 1 50 50 204 a2shape tensorshape1 50 50 80 a3 tfimageresizea2 25 25 a3shape tensorshape1 25 25 80 a4 tfreshapea3 1 25 25 20 4 a4shape tensorshape1 25 25 20 4 here picking some middle slices assuming that by this we may get relevant slices how convenient is this may not general a5 a4 515 a5shape tensorshape1 25 25 10 4"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntflite tensor name converted by 270 is much longer than 1140\nsystem information os platform and distribution linux ubuntu 1804 mobile device no tensorflow installed from source or binary binary pip install tensorflow270 tensorflow version 270 python version 3813 bazel version if compiling from source none gcccompiler version if compiling from source none cudacudnn version none gpu model and memory none exact command to reproduce none describe the problem using tensorflow 1140 convert pb model to tflite as follows python import tensorflow as tf graphdeffile pathtomobilenetv1pb inputarrays input outputarrays inputshapes input 1 224 224 3 convert inputarrays outputarrays inputshapes tflitemodel convertconvert with wb as f fwritetflitemodel after update tensorflow to 270 and modify scripts as follows python import tensorflow as tf graphdeffile pathtomobilenetv1pb inputarrays input outputarrays inputshapes input 1 224 224 3 convert inputarrays outputarrays inputshapes tflitemodel convertconvert with wb as f fwritetflitemodel i found tensor name in is much longer than such a long name caused a lot of trouble when comparing the tflite model with the original model however i also noticed that there will be a new attributes in tfliteconverter python convert inputarrays outputarrays inputshapes false tflitemodel convertconvert but the log as follows warning me that old converter is deprecated shell warningabslplease consider switching to the new converter by setting the old converter toco is deprecated is is possible to add an attribute in the new version so that the model conversion name can remain unchanged and the tensor of folder const can be removed"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nreplacing add layer with linear combination of learnable weights\nclick to expand issue type feature request the add layer can be expressed as a linear combination of inputs where each coefficient value is 1 i was trying to make a custom layer that performs the same as add except uses trainable coefficients as we assume a coefficient of 1 is optimal unfortunately i was unable to do so on my own specifically the gradients i do not think this would be too hard to implement as all the code is kind of already there just need to calculate gradients and then update source source tensorflow version 27 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell the add layer can be expressed as a linear combination of inputs where each coefficient value is 1 i was trying to make a custom layer that performs the same as add except uses trainable coefficients as we assume a coefficient of 1 is optimal unfortunately i was unable to do so on my own specifically the gradients i do not think this would be too hard to implement as all the code is kind of already there just need to calculate gradients and then update standlone code to reproduce the issue shell x relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nrequest for feature gather and matmul\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate system information tensorflow version you are using 271 are you willing to contribute it yesno yes describe the feature and the current behaviorstate this function can realize that the corresponding weight is taken from the matrix b according to the index given by the matrix c and then multiplied by the matrix a a batch h b num h d c batch out batch d batch num python for i j in enumeratec outi matmulai bj currently this function can be implemented by tfgather then tfmatmul however it will waste a lot of gpu memory due to the need to define an intermediate variable w python w tfgatherb c out tfmatmula w it can also be implemented by one hot matmul however the time complexity of the calculation will be very high python tmp tfonehotc depthnum out tfenisumbhbnnhdbd a tmp b will this change the current api how no who will benefit with this feature this function can be applied to the moe model to achieve the assignment of experts strictly according to the probability of the router avoids the limitations of the expert capacity currently required any other info no"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nrfe tensorflowaarch64260 build\nsystem information tensorflow version you are using 260 are you willing to contribute it yesno yes describe the feature and the current behaviorstate brainchip akida akd1000 snn neuromorphic metatf sdk support 260 on x8664 they claim support for aarch64 but when creating a virtualenv it fails on aarch64 due to lacking tensorflowaarc64260 build will this change the current api how na who will benefit with this feature customer of brainchip akida who run on arm64 platforms any other info"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ndefault value for areas outside the input\nrunning by the same padding leads to zeros for areas outside the input there is no way to change the default value and it is best to have this as another parameter for this function this background label should be always zero otherwise this function mess up the labels"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\npfortfvectorizemap improve feedbackhints messages when it fallbacktowhileloop\nsystem information tensorflow version you are using are you willing to contribute it yesno probably if i can talk with a codeowner of this namepace describe the feature and the current behaviorstate as we are adding a root cause message on the cause we are going internally to rely on fallbacktowhileloop it would be nice to have a more clear feedback string to the user on what kind of action is required eg refactoring his function open a new ticket with a code gist on tf github etc see more at cc wangpengmit will this change the current api how no who will benefit with this feature developers that partially fail to fully tfvectorizemap their functions any other info"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nlist of tf ops that tfvectorizedmap supports\nwhere can i get this information which tf operation is a vectorized operation and which one is not"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ngeneralise xlamap to functions over arbitrary shapes\nsystem information tensorflow version you are using 28 are you willing to contribute it yesno no describe the feature and the current behaviorstate currently xlamap only allow functions from shape to id like to use functions with arbitrary shapes for example apply a function with shapes 2 3 5 to a tensor 100 4 2 3 to get a 100 4 5 ive not yet thought about how it would work when mapping multiple input tensors at once will this change the current api how it would extend xlamap either internally or as an overload its possible additional information would need to be passed to a more general implementation of map in which an overload may be preferable to maintain backwards compatibility who will benefit with this feature anyone using xla whod like to apply a function over sections of a tensor it would effectively be an alternative to some portion of broadcasting allowing people to use functions that dont allow leading dimensions to tensors with leading dimensions it is particularly useful for me as im working with dependent types and adding leading dimensions is nontrivial and verbose in type signatures any other info it is already possible to do this by indexing into the tensor and iteratively applying the function to the contents then concatenating the results but i expect this is significantly slower than could be achieved within xla i have considered using xlawhile for this but i still expect the slicing and concatenation would still come with a significant performance cost"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nplease publish tensorflowliteobjc 28\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate system information tensorflow version you are using android 28 ios 27 are you willing to contribute it yesno no describe the feature and the current behaviorstate will this change the current api how who will benefit with this feature any other info"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncapturetpuprofile on cloud tpu vm\nhello it seems that capturetpuprofile only works for legacy tpu devices but not for cloud tpu vm i was wondering if and when we can expect to have support for cloud tpu vm at the moment its is impossible to monitor jaxflax tpu workloads as tensorboard instrumentation does not exhibit the right metrics eg utilization of tpu matrix units other related thread for legacy tpu devices thanks"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nxla tfbincount support\nsystem information tensorflow version you are using master are you willing to contribute it yesno only if we have a clear path and a reviewer on how to contribute this describe the feature and the current behaviorstate tfbincount isnt supported by xla will this change the current api how no who will benefit with this feature speedup functionsloops that rely on tfbincount any other info how to reproduce it python import tensorflow as tf def return tfmathbincountvalues values tfconstant11232445 0 2 2 1 2 1 python invalidargumenterror detected unsupported operations when trying to compile graph on xlacpujit bincount no registered bincount opkernel for xlacpujit devices compatible with node node bincountbincountnode bincountbincount the op is created at without this we had problems to compile intermediate ms coco recall function in kerascv extra please also note that the cpugpu tf2xla supported ops tables are probably outdated 2018 cc jokereph lukewood"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nwith device annotations\nsystem information tensorflow version you are using 28 are you willing to contribute it yesno yes describe the feature and the current behaviorstate feature request adding option to tfgradients in 1x to tfgradienttape in 2x this feature requestissue was 1st mentioned in almost two years ago by olesalscheider allow me to quickly review the op in which the current behavior still hold in tf 28 is described currently gradienttapegradient is executed on the device of the scope it is called in have a look at the following code with tfgradienttape as tape with tfdevicegpu1 x f1input with tfdevicegpu2 x f2x with tfdevicegpu0 g tapegradientx fvars here all gradient calculations will be carried out by gpu0 and all variables needed for the gradient calculation will also be allocated on gpu0 this is a problem if these temporary variables are too large to fit into the vram of gpu0 please provide a way to execute the backward functions on the device of the corresponding forward function and allocate temporary variables for gradient calculation there this allows to split a large model and distribute it among as many gpus as necessary also olesalscheider provided a pr to achieved such feature and it get merged at the beginning but shortly get rollbacked due to certain performance issues i opened another pr to fit the current master tf28 and build and test it it looks to me the gradient can now be split correctly according to the device annotation will this change the current api how it will allow tfgradienttape to do gradient in the device of the corresponding forward function hence it would be possible to split the training of large models into as many possible gpus as necessary who will benefit with this feature anyone who wants to train large models that do not fit into the vram of a single gpu any other info it looks to me that the original post has gone silence so i raise the issue again here to draw more attentions it is a very import feature for peoples working in large image segmentation tasks some times the input tensor is so large and the model can not even be fitted into a single a100 card moreover i noticed that in the discussion flow in the original post that there are some other work around like split into different tapes i tried but with no luck all gradient calculation still be allocated on gpu0 and moreover splitting tape would be very different for model like unet which has a lot of skipconnections last but not the least i know for a fact that there is the mashtensorflow which propose to do such job but a native tensorflow support would be also very useful for people work on large models"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nruntimeerror exportingimporting meta graphs is not supported when eager execution is enabled no graph exists when eager execution is enabled\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate 20220211 110530792376 i successfully opened dynamic library libcudartso101 traceback most recent call last file 01genquadproposalspy line 82 in file line 92 in restorecnnsess saver meta importscopecornerdet file line 1460 in importmetagraph return file line 1472 in raise meta graphs is not supported when runtimeerror exportingimporting meta graphs is not supported when eager execution is enabled no graph exists when eager execution is enabled system information tensorflow version you are using tensorboard 280 061 tensorboardpluginwit 181 tensorflow 231 tensorflowestimator 230 tensorflowhub 0120 0240 tensorflowjs 3130 cuda 101 cudnn 76 python 38 are you willing to contribute it yesno yes describe the feature and the current behaviorstate will this change the current api how who will benefit with this feature any other info"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\noption to avoid caching with bijectors\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate system information tensorflow version you are using 270 are you willing to contribute it yesno yes describe the feature and the current behaviorstate the current behaviour for is to cache the input to be used if the inverse function is called i would very much like a keyword being able to turn this caching off to ensure the inverse function of the bijector is always called whilst setting the property of isinjective can accomplish this you lose other features will this change the current api how yes a keyword in the definition of the bijector class who will benefit with this feature anyone who wishes to have bijectors where the inverse function is always called rather than the input thats been cached any other info"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ngradient for tfsparsereducemax\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate describe the feature and the current behaviorstate tfsparsereducemax do not define grad so it cannot be used in training step will this change the current api how wont change current api just add grad in tfsparsereducemax who will benefit with this feature people using sparsereducemax in training if they have huge sparse matrix and cannot turn to dense array any other info i am working with pointnetlike model and it will take a huge sparse matrix if i turn this sparse matrix to dense it will take 60g memory so i need do global maxpooling using tf sparse reducemax unfortunately it cannot be used in training right now thanks"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\niterating over tftensor is not allowed\nplease make sure that this is a bug as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagbugtemplate system information have i written custom code as opposed to using a stock example script provided in tensorflow yes os platform and distribution eg linux ubuntu 1604 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on mobile device tensorflow installed from source or binary tensorflow version use command below 23 python version38 bazel version if compiling from source gcccompiler version if compiling from source cudacudnn version gpu model and memory you can collect some of this information using our environment capture script you can also obtain the tensorflow version with 1 tf 10 python c import tensorflow as tf printtfgitversion tfversion 2 tf 20 python c import tensorflow as tf tfversionversion describe the current behavior i have a dictionary that i build by accessing only the channel dimensions of an output layer of a convolutional neural network it has a shape 10024246 therefore keys of this dictionary are tuples of tensor shape 6 i want to map these keys to the input of the next layer using the tfmapfn however i am incapable of doing it because the keys of my dictionary are of type tensor and i cannot iterate over them looking for some help thank you describe the expected behavior contributing do you want to contribute a pr yesno briefly describe your candidate solutionif contributing standalone code to reproduce the issue provide a reproducible test case that is the bare minimum necessary to generate the problem if possible please share a link to colabjupyterany notebook other info logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncount number of leaves in the ensemble gradient boostedtree\nthis is an issue related to the performance of system information tensorflow version you are using 270 are you willing to contribute it yesno yes describe the feature and the current behaviorstate is there any method that returns the number of entire leaves in the built ensemble if the feature already exists would you please introduce it a bit more here if not could we develop it will this change the current api how no who will benefit with this feature users of the tensorflow"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nnormalization should be done using moving averages\nurls with the issue description of issue what needs changing hello this is a small feature request in the time series tutorial at the normalization section in the 3rd paragraph there is a remark saying and that this normalization should be done using moving averages i am very curious on how a moving average would be used here should a simple moving average for the whole dataset be computed and then on that new datasetma just use the normalization technique that is described in the tutorial the feature i am requesting is something like a remark on how this would be done or maybe a pointer to different tutorial if one exists or some further referencesresearch users could look into"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nusing scipy fsolve or other solvers eg gekko in combination with backpropagation models\ni was wondering if there was any progress or existing methodologies to use existing solvers such as gekko to findupdate certain values in your network eg when using pinn networks on a electrical circuit one might use a variable resistance dependent on one of your network input parameters when this dependency is given by an explicit equation it would be nice to given the inputs be able to use existing solvers as scipys fsolve to get this value and use it further on in the network from my experience in order to be able to use solvers tensors should be converted to numpy elements and used in combination with tfnumpyfunction this way i can use solvers as such however it breaks the chain of gradients and tf can no longer find gradients for certain values and thus no longer train the network system information tensorflow 230 but using some tf1 functionalities from tfcompatv1 no possibility to share existing code but see below for small hypothetical case example start of code from scipyoptimize import fsolve class def initself superppinlayer selfinitkwargs def callself input nn args nnoutput nninput this is a nn already initialized somewhere else with trainable parameters output selffnnoutput input return output the output is then used later on to compare with labeled data as loss function for training def fself nnoutput input r0 input0 r1 input1 v0 input2 def r2eqr2 r0 r1 return npexpr2r1 r1r2 r02 r2 fsolver2eq 0 argsr0 r1 return v0r0 r2 thanks in advance cedric"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntflite optional debug tools can only support log in desktop computer\nhi tensorflowers the in minimalcc can only be used on computer system with desktop because it use printf style to output info in optionaldebugtoolscc not the tflitelog in minimallogging the better way supporting more systems besides why not use something like stdstringstream to format info that seems more general"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ni have made wrapper of tensor\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate system information tensorflow version you are using are you willing to contribute it yesno latest github release describe the feature and the current behaviorstate graph will this change the current api how nope who will benefit with this feature everyone any other info i have started wrapper of tensorflow using cppflow i need some help with graph it is unclear how it works in c api i am thinking of wrapping c api it works for all swig languages the question is does capi suppot the graph enough to use it or should i wrap the c api"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntfdatadataset gather element\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate system information tensorflow version you are using tensorflow 27 are you willing to contribute it yesno no describe the feature and the current behaviorstate i want to do something like tfgather on tfdatadataset for example dataset b c d e f g h i choicedataset define a dataset containing 0 1 2 0 1 2 i want it to output a dataset having a b c a b c this is somewhat similar to choosefromdatasets but that method choose from multiple datasets not element in the dataset will this change the current api how add new method to tfdatadataset who will benefit with this feature tensorflow dataset user any other info i am not sure if there is a workaround please correct me if i am wrong"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nrequest for randomillumination layer in keras\nsomething like this already is possible with imagedatagenerator but with corners in it only applies brightness scale what is needed is a full keras layer that randomize illumination differences spatially across the image or even a single scaling factor to the whole image i think more ideas can be added to something like this if it was implemented properly"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nrelease tensorflowmacos wheel compatible with python 39 and x86\ncurrently in version 270 of tensorflowmacos there are only 3 wheels released in pip 2 for arm64 supporting python 3839 and 1 for x86 only supporting python 38 it would be great to have also a wheel for python 39 for the x86 architecture the same thing also applies for tensorflowmetal system information tensorflow version you are using 270 describe the feature and the current behaviorstate see above will this change the current api how no who will benefit with this feature every intel mac user with python 39 any other info"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nthrows error when checking type of raggedtensor\nplease make sure that this is a bug as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagbugtemplate system information have i written custom code as opposed to using a stock example script provided in tensorflow yes os platform and distribution eg linux ubuntu 1604 ubuntu 18046 lts mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device na tensorflow installed from source or binary binary tensorflow version use command below 270 python version 390 bazel version if compiling from source na gcccompiler version if compiling from source na cudacudnn version na gpu model and memory na you can collect some of this information using our environment capture script you can also obtain the tensorflow version with 1 tf 10 python c import tensorflow as tf printtfgitversion tfversion 2 tf 20 python c import tensorflow as tf tfversionversion describe the current behavior when calling on a raggedtensor a valueerror typeerror object of type raggedtensor has no len is thrown describe the expected behavior the assertion check should pass if the ragged tensor is the correct type or fail otherwise contributing do you want to contribute a pr yesno no briefly describe your candidate solutionif contributing na standalone code to reproduce the issue provide a reproducible test case that is the bare minimum necessary to generate the problem if possible please share a link to colabjupyterany notebook python import tensorflow as tf a tfraggedconstant1 2 1 tftypetfint32 should pass valueerror typeerror object of type raggedtensor has no len other info logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached workaround import tensorflow as tf a tfraggedconstant1 2 1 assert adtype tfint32"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nsupport partial parameter warmstart from pretrained checkpoints in tensorflow v2 nonestimator mode\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate system information tensorflow version you are using tensorflow 2x are you willing to contribute it yesno no describe the feature and the current behaviorstate warmstarting from an existing checkpoint is an important feature for all kinds of model training thats well supported under tfestimator framework the latter unfortunately seems relegated to second class status in tensorflow 2x since its not eager at least not natively the closest way to achieve warmstart in tf2x seems to be via tftraincheckpoint a more directly approach than that is if implemented well so far however i see that it supports loading all the parameters in a checkpoint altogether but not loading only some of the parameters will this change the current api how possibly maybe provide a kwarg in checkpoint initializer called parameterlist who will benefit with this feature anyone who wants to reuse a pretrained model but not all of its parameters any other info there is a lot of emphasis on eagerness efficiency in tensorflow v2 but in my opinion not sufficient focus on flexibility and directness of usage so far warmstarting is one example update my colleague found an unofficial implementation of flexible warmstart from a checkpoint in the tf2 version of bert here i would recommend adding some official examples along similar lines"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nnew dtype bcomplex32\nsystem information tensorflow version you are using 27 are you willing to contribute it yesno probably yes describe the feature and the current behaviorstate add bcomplex32 dtype currently only a real like in math real field version is supported bfloat16 will this change the current api how each function that supports the dtype paramter should also support the new bcomplex32 who will benefit with this feature anyone who uses the complex plane and wants a speedup for further calculations on supported hardware such as gpus with compatibility level of 7 and above for example while using fft any other info"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncan i repeat a 1d tensor in segment form\naccording to the doc tf has tfsegmentxxx and tfrepeat but can i repeat a 1d tensor in segment form example segment 0 0 0 1 1 value 0 1 2 3 4 1 if repeatcnt 2 2 2 1 1 with tfrepeat i can easily repeat value to 0 0 1 1 2 2 3 4 2 but i want a segment repeat which means segment0 repeat 2 times segment1 repeat 1 time that is to say if repeatcntnew 2 1 and i want to repeat value to 0 1 2 0 1 2 3 4 i mean repeat blocks in a vector 0 1 2 2 3 4 1 are there any tf func or api can help thanks"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nlstm expansion\nsystem information tensorflow version you are using 13 are you willing to contribute it yesno maybe describe the feature and the current behaviorstate simple lstms have limitations it cannot extract some features ie some mathematical operands conditional logic etc i dont think the lstm advancements cover this this paper kind of shows what logic needs to be part of lstm out of the box can we improve the lstm to include ability to figure out some basic logic like mathematical operands and conditional logic will this change the current api how shouldnt who will benefit with this feature everyone any other info lstm is brokened at the moment pretty rudimentary"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nkeyerror min\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version tf 213 custom code yes os platform and distribution mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version 122 gpu model and memory no response current behavior traceback most recent call last file o2kpy line 11 in kmodel onnxtokerasonnxmodel input1 namepolicyrenumerate verbosetrue file line 175 in onnxtokeras file line 31 in convertclip if paramsmin 0 keyerror min standalone code to reproduce the issue shell from onnx2keras import onnxtokeras import keras import onnx import sys syspathappendrootmr onnxmodel onnxinputs onnxmodelgraphinput print printonnxinputs onnxmodel onnxloadvgg11onnx kmodel onnxtokerasonnxmodel input1 namepolicyrenumerate verbosetrue ssdbmv1torchh5 overwritetrue saveformath5 onnx file can be downloaded at relevant log output shell traceback most recent call last file o2kpy line 11 in kmodel onnxtokerasonnxmodel input1 namepolicyrenumerate verbosetrue file line 175 in onnxtokeras file line 31 in convertclip if paramsmin 0 keyerror min"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nattributeerror number of inputs is not equal 1 for unsqueeze layer\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version tf 213 custom code yes os platform and distribution mobile device no response python version 3817 bazel version no response gcccompiler version no response cudacudnn version 122 gpu model and memory no response current behavior traceback most recent call last file o2kpy line 11 in kmodel onnxtokerasonnxmodel onnxunsqueeze0 namepolicyrenumerate verbosetrue file line 175 in onnxtokeras file line 210 in convertunsqueeze raise attributeerrornumber of inputs is not equal 1 for unsqueeze layer attributeerror number of inputs is not equal 1 for unsqueeze layer standalone code to reproduce the issue shell please run the below codes to reproduce from onnx2keras import onnxtokeras import keras import onnx import sys syspathappendrootmr onnxmodel onnxinputs onnxmodelgraphinput print printonnxinputs onnxmodel onnxloadvgg11onnx kmodel onnxtokerasonnxmodel onnxunsqueeze0 namepolicyrenumerate verbosetrue textcnntorchh5 overwritetrue saveformath5 onnx file can be downloaded at relevant log output shell traceback most recent call last file o2kpy line 11 in kmodel onnxtokerasonnxmodel onnxunsqueeze0 namepolicyrenumerate verbosetrue file line 175 in onnxtokeras file line 210 in convertunsqueeze raise attributeerrornumber of inputs is not equal 1 for unsqueeze layer attributeerror number of inputs is not equal 1 for unsqueeze layer"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nvalueerror exception encountered when calling layer 13 type lambda\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 213 custom code yes os platform and distribution mobile device no response python version 3817 bazel version no response gcccompiler version no response cudacudnn version 122 gpu model and memory no response current behavior html xmlns link idmainfile relmainfile link relfilelist table page margin75in 7in 75in 7in msoheadermargin3in msofootermargin3in font5 colorwindowtext fontsize90pt fontweight400 fontstylenormal textdecorationnone fontfamily等线 msofontcharset134 tr msoheightsourceauto col msowidthsourceauto br td paddingtop1px paddingright1px paddingleft1px msoignorepadding colorblack fontsize110pt fontweight400 fontstylenormal textdecorationnone fontfamily等线 msofontcharset134 textaligngeneral verticalalignmiddle bordernone msopatternauto msoprotectionlocked visible whitespacenowrap msorotate0 xl65 textaligncenter xl66 textaligncenter whitespacenormal ruby rubyalignleft rt colorwindowtext fontsize90pt fontweight400 fontstylenormal textdecorationnone fontfamily等线 msofontcharset134 msochartypenone displaynone valueerror exception encountered when calling layer 13 type lambda dimensions must be equal but are 204 and 206 for node 13add placeholder1 with input shapes 64204204 64206206 call arguments received by layer 13 type lambda • 64 204 204 dtypefloat32 tftensorshapenone 64 206 206 dtypefloat32 • masknone • trainingnone standalone code to reproduce the issue shell just run the following code to reproduce from onnx2keras import onnxtokeras import keras import onnx import sys syspathappendrootmr onnxmodel onnxinputs onnxmodelgraphinput print printonnxinputs onnxmodel onnxloadvgg11onnx kmodel onnxtokerasonnxmodel x namepolicyrenumerate verbosetrue overwritetrue saveformath5 the onnx file can be downloaded at relevant log output shell traceback most recent call last file o2kpy line 11 in kmodel onnxtokerasonnxmodel x namepolicyrenumerate verbosetrue file line 175 in onnxtokeras file line 83 in layersnodename lambdalayerinput0 input1 file line 70 in errorhandler raise from none file line 76 in targetlayer layer tfadd valueerror exception encountered when calling layer layer12 type lambda dimensions must be equal but are 204 and 206 for node layer12add placeholder1 with input shapes 64204204 64206206 call arguments received by layer layer12 type lambda • 64 204 204 dtypefloat32 tftensorshapenone 64 206 206 dtypefloat32 • masknone • trainingnone"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntraining vanilla transformer on tpu gives internalerror\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version 2130 custom code yes os platform and distribution linux ubuntu 22042 google colab mobile device colab python version 31012 bazel version colab gcccompiler version colab cudacudnn version colab gpu model and memory colab current behavior training transformer model on tpu gives internal error i have some idea on the error that theres a incompatible tensor ops thats causing the problem but i cant pinpoint it i had already done a bigger model which is using pretrained embeddings and it went off without a hitch i tried to replicate the same but with different tfds dataset if this is already solved please direct me to the relevant links standalone code to reproduce the issue this is the notebook this notebook worked fine thankyou in advance i will respond asap relevant log output shell internalerror traceback most recent call last in 1 modelfit 2 trainds 3 4 epochsepochs 5 1 frames in errorhandlerargs kwargs 68 to get the full stack trace call 69 70 raise from none 71 finally 72 del filteredtb in capturebyvalueself graph tensor name 120 graphconst 121 if graphconst is none 122 graphconst pylint 123 if graphconst is none 124 some eager tensors eg parallel tensors are not convertible to internalerror failed to connect to all addresses last error unknown ipv412700135437 failed to connect to remote host connection refused additional grpc error information from remote target unknownfailed to connect to all addresses last error unknown ipv412700135437 failed to connect to remote host connection refused grpcstatus14 executing noncommunication op originally returned unavailableerror and was replaced by internalerror to avoid invoking tf network error handling logic"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nbody function of whileloop cannot access the external variable after compilation\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2150dev20230914 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior the body function of whileloop cannot access the external variable after compilation it will raise the error unboundlocalerror local variable x referenced before assignment however if i run the model without the the model can be executed without any error standalone code to reproduce the issue shell class modeltfkerasmodel def initself supermodel selfinit comment this line it will succeed def callself x def condi return i 10 def bodyi y y tfmathaddy 20 x tfmathmultiplyx 20 return tfmathsubtracti 1 y x i tfconstant10 y tfconstant10 finaly tfwhileloopcond body i y yshape return finaly m model inputshape 12 x tfconstant45 shapeinputshape y mx relevant log output shell unboundlocalerror exception encountered when calling layer model28 type model in user code file line 16 in body x tfmathmultiplyx 20 unboundlocalerror local variable x referenced before assignment call arguments received by layer model28 type model • xtftensorshape1 2 dtypefloat32"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncould not find matching concrete function to call loaded from the savedmodel\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf210 custom code yes os platform and distribution win10 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior how to match data of signature standalone code to reproduce the issue shell saveformattf signaturesnone localmodel ylocalpred ymodelpred modelpredictxtest printylocalpred ymodelpred ymodelpred userinputs nameinputs0 nameinputs1 nameinputs2 useroutputs relevant log output shell could not find matching concrete function to call loaded from the savedmodel got positional arguments 1 total keyword arguments expected these arguments to match one of the following 1 options option 1 positional arguments 1 total tensorspecshapenone 5 dtypetffloat32 nameinputs0 tensorspecshapenone 10 dtypetfint32 nameinputs1 tensorspecshapenone 3 5 dtypetfint32 nameinputs2 keyword arguments"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nvalueerror unable to create dataset name already exists\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior epoch 110 11 eta 0s loss 68405 accuracy 03250 valueerror traceback most recent call last in 1 epochsepochs checkpointcall plotlosses 2 frames in makenewdsetparent shape dtype data name chunks compression shuffle fletcher32 maxshape compressionopts fillvalue scaleoffset tracktimes external trackorder dcpl dapl efileprefix virtualprefix allowunknownfilter rdccnslots rdccnbytes rdccw0 161 sid h5screatesimpleshape maxshape 162 163 dsetid h5dcreateparentid name tid sid dcpldcpl dapldapl 164 165 if data is not none and not isinstancedata empty h5pyobjectspyx in h5pyobjectspyx in h5pyh5dpyx in h5pyh5dcreate valueerror unable to create dataset name already exists i want to save each epoch as a checkpoint two weeks back back without any any error each checkpoint will save as a checkpoint but suddenly now getting error standalone code to reproduce the issue shell import matplotlibpyplot as plt from import callback import os checkpointdir modelcheckpointsm1 if not from import earlystopping earlystop patience3 set up the model checkpoint callback checkpointcall monitorvalloss savebestonlytrue saveweightsonlyfalse modemin savefreqepoch epochsepochs checkpointcall relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nbazel test failed with some ctest\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf212 custom code yes os platform and distribution centos76 mobile device no response python version 39 bazel version 530 gcccompiler version 931 cudacudnn version no response gpu model and memory no response current behavior after compiling tensorflow based on the source code bazel test is executed for unit testing some test items are passed but there are many failures and the reasons for the error are as follows so i want to know if im executing the statement incorrectly how should i set it up bazel test c opt configcuda output information exec pagerusrbinless 0 exit 1 executing tests from image image standalone code to reproduce the issue shell bazel test c opt configcuda relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nunable to open file truncated file eof 2568306 sblockbaseaddr 0 storedeof 9406464\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version 2130 custom code no os platform and distribution mac os 1351 mobile device no response python version 3113 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior oserror traceback most recent call last cell in15 line 3 1 create the base model from the pretrained model mobilenet v2 2 imgshape imgsize 3 3 basemodel 4 includetopfalse 5 weightsimagenet file in alpha includetop weights inputtensor pooling classes classifieractivation kwargs 477 weightpath baseweightpath modelname 478 weightspath datautilsgetfile 479 modelname weightpath cachesubdirmodels 480 481 482 elif weights is not none 483 file in kwargs 67 filteredtb 68 to get the full stack trace call 69 70 raise from none 71 finally 72 del filteredtb file h5pyobjectspyx55 in file h5pyh5fpyx106 in h5pyh5fopen oserror unable to open file truncated file eof 2568306 sblockbaseaddr 0 storedeof 9406464 standalone code to reproduce the issue shell create the base model from the pretrained model mobilenet v2 imgshape imgsize 3 basemodel includetopfalse weightsimagenet relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nxla compiled tfwhere with known output shape error setshape tfconcat tfstack\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 213 custom code no os platform and distribution google colab mobile device no response python version 31012 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior output of tfwhere when used inside tffunction with jitcompiletrue can sometimes be used correctly as with sum and sometimes raises shape mismatch error as with concatenation this error is present even if output shape is set manually with setshape the code below runs without jitcompile or with sum instead of tfconcat and only fails if concatenating inside a compiled function note autoclustering solves the issue on the toy example but not on the codebase i am working on standalone code to reproduce the issue colab python import tensorflow as tf def funx y x tfwherex 1 printfshape before unknown xshape 2 printfshape after known xshape return tfconcatxy axis1 concatentation fails return x y sum would succeed x tfconstant00110 01010 10001 10100 01100 dtypetfint32 y 2 dtypetfint64 axis1 funx y tffunctionfunxy tffunctionfun jitcompiletruexy fails as described above relevant log output shell shape before unknown none 2 shape after known 10 2 invalidargumenterror cannot concatenate arrays that differ in dimensions other than the one being concatenated dimension 0 in both shapes must be equal s64252 vs s64101"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nwill there a mlp model in the future version\nissue type feature request have you reproduced the bug with tensorflow nightly no source source tensorflow version 2130 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior when building deep learning models like multilayer perceptrons mlps code reusability and conciseness are crucial factors currently using tfkerassequential in tensorflow allows for convenient creation of sequential models however manually adding common operations such as batch normalization or dropout to each layer can lead to code redundancy and an increased burden in terms of coding and maintenance therefore proposing the addition of a feature in tensorflow to directly create mlps with batch normalization and dropout is highly beneficial here are several reasons why this feature would be advantageous for tensorflow users 1 simplified code users wont need to manually add batch normalization and dropout operations to each layer resulting in cleaner more readable and maintainable code 2 reduced error rate manual copypasting of code is errorprone especially as model complexity increases automating the integration of batch normalization and dropout operations can reduce issues arising from code errors 3 increased productivity developers can build and iterate on models more swiftly focusing on design and parameter tuning rather than rewriting the same code segments for every new model 4 education and learning for newcomers to tensorflow this feature can provide a quicker onboarding process lowering the learning curve and enabling them to grasp and apply deep learning concepts faster certainly heres the additional information i also believe that pytorch has implemented mlp functionality quite effectively an example of this can be found in the following url pytorch mlp pytorchs approach to creating mlps provides a good reference for how tensorflow could potentially integrate similar features standalone code to reproduce the issue shell origin model tfkerassequential tfkeraslayersrelu tfkeraslayersdense64 tfkeraslayersrelu tfkeraslayersdense32 tfkeraslayersrelu tfkeraslayersdense10 with mlp model python model tfkerasmlp hiddenchannels128 64 32 10 dropout02 relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nextensions eglquerydevicesext and not available\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 1131 custom code yes os platform and distribution unbuntu 22 mobile device no response python version python 27 bazel version no response gcccompiler version 940 cudacudnn version 10 gpu model and memory gtx 1060 current behavior hi i got this error when i run dirt model with my tensorflowgpu 1131 20230825 152337711796 f extensions eglquerydevicesext and not available standalone code to reproduce the issue shell import numpy as np import tensorflow as tf import dirt canvaswidth canvasheight 128 128 centrex centrey 32 64 squaresize 16 def getnondirtpixels xs ys tfrangecanvasheight xs tfcastxs tffloat32 05 ys tfcastys tffloat32 05 xinrange tflessequaltfabsxs centrex squaresize 2 yinrange tflessequaltfabsys centrey squaresize 2 return yinrange tffloat32 def getdirtpixels build square in screen space squarevertices tfconstant0 0 0 1 1 1 1 0 dtypetffloat32 squaresize squaresize 2 squarevertices centrex centrey transform to homogeneous coordinates in clip space squarevertices squarevertices 2 canvaswidth canvasheight 1 squarevertices tfzeros4 1 tfones4 1 axis1 return dirtrasterise faces0 1 2 0 2 3 vertexcolorstfones4 1 canvaswidth 1 heightcanvasheight widthcanvaswidth channels1 0 def main if in tfversion and inttfversionsplit0 2 session tfsession with sessionasdefault nondirtpixels getnondirtpixelseval dirtpixels getdirtpixelseval else nondirtpixels dirtpixels getdirtpixelsnumpy if npallnondirtpixels dirtpixels printsuccessful all pixels agree else printfailed pixels dirtpixels if name main main relevant log output shell 20230825 152337181664 i your cpu supports instructions that this tensorflow binary was not compiled to use sse41 sse42 avx avx2 fma 20230825 152337186756 i cpu frequency 2496000000 hz 20230825 152337189184 i xla service 0x24d6bf0 executing computations on platform host devices20230825 152337189205 i streamexecutor device 0 20230825 152337478413 e could not open file to read numa node your kernel may have been built without numa support 20230825 152337478518 i xla service 0x233ae60 executing computations on platform cuda devices20230825 152337478540 i streamexecutor device 0 nvidia geforce gtx 1060 6gb compute capability 61 20230825 152337478666 i found device 0 with properties name nvidia geforce gtx 1060 6gb major 6 minor 1 memoryclockrateghz 17085 pcibusid 000001000 totalmemory 600gib freememory 509gib 20230825 152337478681 i adding visible gpu devices 0 20230825 152337478801 i device interconnect streamexecutor with strength 1 edge matrix 20230825 152337478813 i 0 20230825 152337478817 i 0 n 20230825 152337478968 i could not identify numa node of platform gpu id 0 defaulting to 0 your kernel may not have been built with numa support 20230825 152337479033 i created tensorflow device with 4913 mb memory physical gpu device 0 name nvidia geforce gtx 1060 6gb pci bus id 000001000 compute capability 61 20230825 152337711796 f extensions eglquerydevicesext and not available aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nbatch matmul imprecision\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 213 2140dev20230706 custom code yes os platform and distribution linux ubuntu 2004 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version mamba list grep cu cudanvcc 122128 0 nvidia cudatoolkit 1180 h4ba93d112 condaforge nvidiacublascu11 202248 pypi0 pypi nvidiacublascu117 1110125 pypi0 pypi nvidiacudanvrtccu11 202248 pypi0 pypi nvidiacudanvrtccu117 11750 pypi0 pypi nvidiacudnncu11 89425 pypi0 pypi gpu model and memory nvidia geforce rtx 3060 12 gb driver version 5206105 current behavior im trying to do a batch matrix multiply ie ive got a bunch of m x n matrices all in one tensor and i want to do a matrix multiply of each of them with some other matrix however im getting slightly different results than i get from numpy and previous tensorflow versions this script passed for me in 29 one interesting thing is that the value 25 the second dimension of x is significant if i reduce this to 16 or below it passes also if i change the second dimension of c from 2 to 1 it also passes standalone code to reproduce the issue python import numpy as np import tensorflow as tf printffile tffile printfgit version tfversiongitversion printfversion tfversion rng nprandomrandomstate0 x rnguniform1 1 size1 25 5astypenpfloat32 c rnguniform1 1 size5 2astypenpfloat32 y x c x2 nptilex 2 1 1 y2 x2 c for y2i in y2 ysqueeze0 tols dictatol1e7 rtol1e5 z tfmatmulx cnumpy z tfeinsumtqqrtr x c y tols z2 tfmatmulx2 cnumpy z2 tfeinsumtqqrtr x2 c y2 tols relevant log output shell file git version version 2140dev20230706 traceback most recent call last file testbatchpy line 26 in y2 file line 1592 in assertallclose actual desired errmsgstrerrmsg file line 75 in inner return funcargs kwds file line 862 in assertarraycompare raise assertionerrormsg assertionerror not equal to tolerance rtol1e07 atol0 mismatched elements 100 100 100 max absolute difference 000046098 max relative difference 001047752 x array0187503 0005696 0255552 084404 0268836 1250793 y array0187499 0005691 0255404 0844322 0268935 1251033"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntf quantizer breaks pip package\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version git head custom code no os platform and distribution ubuntu 2004 mobile device na python version 3916 bazel version 610 gcccompiler version 1606 cudacudnn version na gpu model and memory na current behavior the commit added to the pip package but the build fails to set the rpath for in the new so leading to a failure in auditwheel when attempting to repair to make it manylinux2014 compatible standalone code to reproduce the issue shell python3 m auditwheel repair plat manylinux2014aarch64 wheeldir whl relevant log output shell python3 m auditwheel repair plat manylinux2014aarch64 wheeldir whl traceback most recent call last file line 198 in runmoduleasmain file line 88 in runcode file line 6 in sysexitmain file line 59 in main rval argsfuncargs p file line 173 in execute outwheel repairwheel file line 80 in repairwheel raise valueerror valueerror cannot repair wheel because required library could not be located also ldd linuxvdsoso1 0x0000ffffb8af9000 0x0000ffffb6800000 not found libdlso2 0x0000ffffb8923000 libpthreadso0 0x0000ffffb88f2000 libmso6 0x0000ffffb8847000 libstdcso6 0x0000ffffb661b000 libgccsso1 0x0000ffffb8823000 libcso6 0x0000ffffb64a8000 libldlinuxaarch64so1 0x0000ffffb8ac9000 librtso1 0x0000ffffb8809000 compare with ldd linuxvdsoso1 0x0000ffffa40a2000 0x0000ffffa1e00000 0x0000ffffa1c0a000 libdlso2 0x0000ffffa3ee5000 libmso6 0x0000ffffa3e3a000 libpthreadso0 0x0000ffffa3e09000 libstdcso6 0x0000ffffa1a25000 libgccsso1 0x0000ffffa3de5000 libcso6 0x0000ffffa18b2000 libldlinuxaarch64so1 0x0000ffffa4072000 librtso1 0x0000ffffa3dcd000 libtensorflowccso2 0x0000ffff8be00000 libmldtypessoso 0x0000ffffa3d99000 libompso5 0x0000ffff8bcc0000"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nfile line 915 in invoke runtimeerror tdimsdatad t0dimsdatad 1 2node number 304 concatenation failed to prepare\n1 system information image os platform and distribution linux ubuntu 2004 tensorflow installation 291nv229 2 code import numpy as np import tensorflow as tf def main load the tflite model and allocate tensors interpreter return get input and output tensors inputdetails outputdetails test the model on random input data inputshape inputdetails0shape inputdata dtypenpfloat32 inputdata signatures printsignatures interpreterinvoke return the function gettensor returns a copy of the tensor data use tensor in order to get a pointer to the tensor outputdata printoutputdata if name main main how to get the model i used a library here to get a unet with efficientnetb0 as encoder so you can try to use my script to get the model backbone efficientnetb0 batchsize 1 classes background target others lr 00001 epochs 10 preprocessinput define network parameters nclasses 1 if lenclasses 1 else lenclasses 1 case for binary and multiclass segmentation activation sigmoid if nclasses 1 else softmax create model model smunetbackbone classesnclasses activationactivation"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncheck failed when running\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior specific input combination is caused check failure standalone code to reproduce the issue shell import tensorflow as tf import numpy as np from tensorflowpythonops import gennnops try try with tfdevicecpu arg0tensor tfrandomuniform2 3 3 1 dtypetffloat32 arg0 tfidentityarg0tensor arg1tensor tfrandomuniform2 2 2 1 dtypetffloat32 arg1 tfidentityarg1tensor arg2tensor tfrandomuniform2 2 2 1 minval256 maxval257 dtypetfint64 arg2 tfidentityarg2tensor ksize0 1 ksize1 2 ksize2 2 ksize3 1 ksize strides0 1 strides1 1 strides2 1 strides3 1 strides padding valid includebatchinindex false out except exception as e printerrorstre try with tfdevicegpu0 arg0 tfidentityarg0tensor arg0 tfcastarg0 tffloat32 arg1 tfidentityarg1tensor arg1 tfcastarg1 tffloat32 arg2 tfidentityarg2tensor arg2 tfcastarg2 tfint64 ksize strides except exception as e printerrorstre except exception as e printerrorstre relevant log output shell 20230821 003614553160 f check failed gradoutindex outputstart gradoutindex outputend invalid output gradient index 77 0 18 aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncannot build tensorflow from source\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version latest custom code yes os platform and distribution debian 12 mobile device no response python version python 38 bazel version latest gcccompiler version clang 16 cudacudnn version dont have gpu model and memory dont have current behavior i tried several times still same error searched on google found nothing standalone code to reproduce the issue shell i follow the guide from tensorflowcom but still faced this error please help relevant log output shell myenv bazel build j 2 configopt verbosefailures info options provided by the client inherited common options isatty1 terminalcolumns189 info reading rc options for build from inherited common options info reading rc options for build from build options define define c opt announcerc definegrpcnoarestrue configshortlogs configv2 info reading rc options for build from build options actionenv actionenv actionenv info found applicable config definition buildshortlogs in file info found applicable config definition buildv2 in file definetfapiversion2 info found applicable config definition buildopt in file coptwnosigncompare info found applicable config definition buildlinux in file hostcoptw coptwnoall coptwnoextra coptwnodeprecated coptwnoarraybounds coptwunusedresult coptwswitch coptwerrorswitch defineprefixusr cxxoptstdc17 hostcxxoptstdc17 configdynamickernels info found applicable config definition builddynamickernels in file info analyzed target 648 packages loaded 42257 targets configured info found 1 target info deleting stale sandbox base error compiling failed killed clang failed error executing command from target cd exec env pwdprocselfcwd tf2behavior1 usrlibllvm16binclang ufortifysource fstackprotector wall wthreadsafety wselfassign wnofreenonheapobject fcolordiagnostics fnoomitframepointer g0 o2 dfortifysource1 dndebug ffunctionsections fdatasections stdc0x md mf fpic dllvmonunix1 dhavebacktrace1 dbacktraceheader dltdlshlibextso dllvmpluginextso dllvmenablethreads1 dhavelibpthread1 dhavepthreadh1 dhaveregisterframe1 dhavesetenvr1 dhavestrerrorr1 dhavesysexitsh1 dhaveunistdh1 dgnusource dhavelinkh1 dhavemallinfo1 dhavesbrk1 dllvmnativearchx86 dllvmversionmajor18 dllvmversionminor0 dllvmversionpatch0 dstdclimitmacros dstdcconstantmacros dstdcformatmacros dblake3useneon0 dblake3noavx2 dblake3noavx512 dblake3nosse2 dblake3nosse41 deigenmpl2only dhavesysuioh dtfusesnappy iquote iquote bazeloutk8optbin iquote iquote iquote externalllvmproject iquote iquote externalnsync iquote iquote iquote iquote externalgif iquote iquote externallibjpegturbo iquote iquote iquote iquote iquote iquote externalfft2d iquote iquote externalhighwayhash iquote iquote externalzlib iquote iquote externaleigenarchive iquote iquote externalmldtypes iquote iquote iquote iquote externalsnappy iquote isystem isystem isystem isystem isystem externalnsyncpublic isystem isystem isystem isystem externalgif isystem isystem isystem isystem externalzlib isystem isystem isystem isystem externaleigenarchive isystem isystem externalmldtypes isystem isystem isystem wnoall wnoextra wnodeprecated wnoignoredattributes wnoarraybounds wunusedresult werrorunusedresult wswitch werrorswitch wnosigncompare stdc17 nocanonicalprefixes ddateredacted dtimestampredacted dtimeredacted c o configuration execution platform in file included from in file included from in file included from in file included from warning parsetype overrides a member function but is not marked override mlirtype parser const note overridden virtual function is here virtual type parser const in file included from in file included from in file included from in file included from warning printtype overrides a member function but is not marked override void printtypemlirtype type printer const note overridden virtual function is here virtual void printtypetype dialectasmprinter const target failed to build info elapsed time 3990011s critical path 34316s info 991 processes 3 internal 988 local failed build did not complete successfully"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\noffset 0x2f3000signal 11 sigsegv code 2 segvaccerr fault addr 0xa59fdbc0\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version custom code yes os platform and distribution andorid 13 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior our process comvttvaipq use tensorflowlite cause process crash build fingerprint revision 1234 abi arm timestamp 20230506 1436470800 pid 14794 tid 28796 name tfservicet comvttvaipq uid 1000 signal 11 sigsegv code 2 segvaccerr fault addr 0xa59fdbc0 r0 00000004 r1 00000020 r2 00000300 r3 a59fdbc0 r4 31a05640 r5 000002f0 r6 31a05740 r7 a59fe4c0 r8 31a056c0 r9 a5674220 r10 a59fe1c0 r11 31a055c0 ip a59fdec0 sp 84db73e8 lr 832ded97 pc 832f08ac backtrace 00 pc 000258ac offset 0x2f3000 standalone code to reproduce the issue shell the google server background statistics process crash information unable to clarify the steps to reproduce the problem relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\noverflow bug when running tfimageresize\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large elements in the input list standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try arg0tensor tfconstant1000000 shape577 700 3 1 dtypetffloat64 arg0 tfidentityarg0tensor arg10 1610637938 arg11 1250999896764 arg1 arg10arg11 out except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 929338090226 with 1164413628 result 1 opresizebilinear name"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\noverflow when running tfcompatv1linalgdiag\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large elements in the input list standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try diagonal0000 1111 diagonal0001 1112 diagonal000 diagonal0010 1121 diagonal0011 1122 diagonal001 diagonal00 diagonal0100 1211 diagonal0101 1212 diagonal010 diagonal0110 1221 diagonal0111 1222 diagonal011 diagonal01 diagonal0 diagonal00diagonal01 diagonal1000 2111 diagonal1001 2112 diagonal100 diagonal1010 2121 diagonal1011 2122 diagonal101 diagonal10 diagonal1100 2211 diagonal1101 2212 diagonal110 diagonal1110 2221 diagonal1111 2222 diagonal111 diagonal11 diagonal1 diagonal10diagonal11 diagonal diagonal0diagonal1 name diagpart k 1610637938 paddingvalue 0 align rightleft out except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 12885103520 with 1610637940 result 1 opmatrixdiagv3"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\noverflow when running tfcompatv1tile\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large elements in the input list standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try inputtensor tfrandomuniform370 1 1024 dtypetffloat32 input multiples0 125091515651 multiples1 125091515651 multiples2 125091515651 multiples nametensor tfrandomuniform dtypetfint32 maxval66860669291904 name tfidentitynametensor name tfvariablename out except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 46283860790870 with 125091515651 result 1 node tile optile"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\noverflow bug when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large list element standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try imagestensor tfconstant256 shape16 4 5 1 dtypetffloat16 images size0 1250999896764 size1 1610637938 size size0size1 aligncorners false halfpixelcenters false name none out except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 18630618048 with 1610637938 result 1"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\noverflow bug when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large list element standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try padding00 125091515651 padding01 false padding0 padding00padding01 padding10 125091515651 padding11 125091515651 padding1 padding10padding11 padding padding0padding1 argclass arginput0tensor tfrandomuniform3 300 300 192 dtypetffloat32 arginput0 arginput arginput0 out argclassarginput except exception as e printerrorstre relevant log output shell functionnode encountered overflow when multiplying 2501999793529 with 2501999793530 result 1n t node pad oppadn n call arguments received by layer zeropadding2d type zeropadding2dn • inputstftensorshape1 1 2 2 dtypefloat32n"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\noverflow bug when running tflinalgdiag on colab\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large integer list element standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try diagonal0000 1111 diagonal0001 1112 diagonal000 diagonal0010 1121 diagonal0011 1122 diagonal001 diagonal00 diagonal0100 1211 diagonal0101 1212 diagonal010 diagonal0110 1221 diagonal0111 1222 diagonal011 diagonal01 diagonal0 diagonal00diagonal01 diagonal1000 2111 diagonal1001 2112 diagonal100 diagonal1010 2121 diagonal1011 2122 diagonal101 diagonal10 diagonal1100 2211 diagonal1101 2212 diagonal110 diagonal1110 2221 diagonal1111 2222 diagonal111 diagonal11 diagonal1 diagonal10diagonal11 diagonal diagonal0diagonal1 name none k 92233720368 paddingvalue 0 align rightleft out except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 16315257232 with 2039407154 result 1 opmatrixdiagv3"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\noverflow bug when running tfclipbyvalue on colab\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large tensor standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try arg0tensor tfrandomuniform2 472 496 4 1 1024 dtypetffloat64 arg0 tfidentityarg0tensor arg1 0 arg2 false out except exception as e printerrorstre relevant log output shell 215514592 notebookapp searching rootjupyter rootlocaletcjupyter usretcjupyter usrlocaletcjupyter etcjupyter for config 215514592 notebookapp looking for jupyterconfig in 215514594 notebookapp looking for jupyterconfig in 215514601 notebookapp looking for jupyterconfig in 215514602 notebookapp looking for jupyterconfig in 215514602 notebookapp looking for jupyterconfig in 215514604 notebookapp looking for in 215514604 notebookapp loaded config file 215514605 notebookapp looking for in 215514597 notebookapp searching rootjupyter rootlocaletcjupyter usretcjupyter usrlocaletcjupyter etcjupyter for config 215514609 notebookapp loaded config file 215514610 notebookapp looking for in 215514610 notebookapp looking for in 215514610 notebookapp looking for in 215514612 notebookapp loaded config file 215514597 notebookapp looking for jupyterconfig in 215514597 notebookapp looking for jupyterconfig in 215514598 notebookapp looking for jupyterconfig in 215514598 notebookapp looking for jupyterconfig in 215514598 notebookapp looking for jupyterconfig in 215514599 notebookapp looking for in 215514600 notebookapp loaded config file 215514601 notebookapp looking for in 215514603 notebookapp loaded config file 215514603 notebookapp looking for in 215514603 notebookapp looking for in 215514603 notebookapp looking for in 215514606 notebookapp loaded config file notebook server cookie secret to of metrics is off since other authentication is serverextension notebook server cookie secret to of metrics is off since other authentication is serverextension notebooks from local directory notebooks from local directory notebook 655 is running controlc to stop this server and shut down all kernels twice to skip notebook 655 is running controlc to stop this server and shut down all kernels twice to skip started name events for closed stream 215556928312 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 215558601992 w tftrt warning could not find 215604276761 w oprequires failed at tileopscc193 invalidargument encountered overflow when multiplying 500366062604 with 125091515651 result exception was never wrapper done defined at most recent call file line 1087 in await stream is handling of the above exception another exception most recent call file line 232 in result file line 1089 in raise events for closed stream 231717631931 w allocation of 19327655268 exceeds 10 of free system restarting kernel 15 keep random 231954827450 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 231958360271 w tftrt warning could not find 232003457377 w allocation of 15342764032 exceeds 10 of free system restarting kernel 15 keep random"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\noverflow when running tfrawopspadv2\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to the large list of element standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try inputtensor tfrandomuniform16 4 4 512 dtypetffloat32 input paddings00 125091515651 paddings01 125091515651 paddings0 paddings00paddings01 paddings10 125091515651 paddings11 125091515651 paddings1 paddings10paddings11 paddings20 125091515651 paddings21 125091515651 paddings2 paddings20paddings21 paddings30 125091515651 paddings31 125091515651 paddings3 paddings30paddings31 paddings constantvalues 0 name none out except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 250183031318 with 250183031306 result 1 node padv2 oppadv2"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\noverflow when running on colab\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large list element standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try arg0000 10 arg0001 20 arg0002 30 arg000 arg0010 40 arg0011 50 arg0012 60 arg001 arg00 arg000arg001 arg0100 70 arg0101 80 arg0102 90 arg010 arg0110 100 arg0111 110 arg0112 120 arg011 arg01 arg010arg011 arg0 arg00arg01 arg1 1 arg2 1 arg3 4 arg4 1676240524292489355 out except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 6704962097169957420 with 3 result 1 node pad oppad name"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\noverflow when running\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large list elements standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try padding00 125091515651 padding01 false padding0 padding00padding01 padding10 125091515651 padding11 125091515651 padding1 padding10padding11 padding padding0padding1 argclass arginput0tensor tfrandomuniform3 300 300 192 dtypetffloat32 arginput0 arginput arginput0 out argclassarginput except exception as e printerrorstre relevant log output shell errorexception encountered when calling layer zeropadding2d type zeropadding2d functionnode encountered overflow when multiplying 375274547853 with 250183031602 result 1 node pad oppad call arguments received by layer zeropadding2d type zeropadding2d • inputstftensorshape3 300 300 192 dtypefloat32"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\noverflow bug when running tfpad on colab\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large input tensor standalone code to reproduce the issue shell import tensorflow as tf import numpy as np try try with tfdevicecpu arg0tensor tfrandomuniform12 2 256 513 dtypetffloat32 arg0 tfidentityarg0tensor arg1tensor tfrandomuniform4 2 dtypetfint32 maxval54676034958255 arg1 tfidentityarg1tensor out tfpadarg0arg1 except exception as e printerrorstre try with tfdevicegpu0 arg0 tfidentityarg0tensor arg0 tfcastarg0 tffloat32 arg1 tfidentityarg1tensor arg1 tfcastarg1 tfint32 tfpadarg0arg1 except exception as e printerrorstre except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 2206572623628733836 with 75929941 result 1 oppad name errorfunctionnode encountered overflow when multiplying 2206572623628733836 with 75929941 result 1 oppad name"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncannot type i accept to extract from hexagonnnskel\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version hexagonnnskelv12001 custom code no os platform and distribution android mobile device android python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior same as here running the instantly prints license extraction aborted extractsh5 read p no coprocess aborting extraction done without giving time to write i accept neither does accept option work standalone code to reproduce the issue shell adb push datalocaltmp adb shell cd datalocaltmp chmod x accept relevant log output shell limited or its designated affiliate licensee shall be solely responsible to obtain such separate license from apical limited the provision or license of a pkla product kit to licensee does not convey any license or other right under any patents of qualcomm incorporated or snaptrack inc type i accept if you agree to the terms of the license you didnt accept the license extraction aborted extractsh5 read p no coprocess aborting extraction done hnnthdatalocaltmp"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncrash when running on colab\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large elements in input lists standalone code to reproduce the issue shell results dict import tensorflow as tf import os import numpy as np try poolsize0 1e38 poolsize1 1048576 poolsize poolsize0poolsize1 strides0 2 strides1 2 strides strides0strides1 padding same dataformat none argclass arginput0tensor tfrandomuniform3 74 74 256 dtypetffloat32 arginput0 arginput arginput0 out argclassarginput except exception as e printerrorstre printresults relevant log output shell 142443837 notebookapp searching rootjupyter rootlocaletcjupyter usretcjupyter usrlocaletcjupyter etcjupyter for config 142443838 notebookapp looking for jupyterconfig in 142443840 notebookapp looking for jupyterconfig in 142443842 notebookapp looking for jupyterconfig in 142443842 notebookapp looking for jupyterconfig in 142443842 notebookapp looking for jupyterconfig in 142443843 notebookapp looking for in 142443847 notebookapp loaded config file 142443847 notebookapp looking for in 142443849 notebookapp loaded config file 142443849 notebookapp looking for in 142443849 notebookapp looking for in 142443849 notebookapp looking for in 142443857 notebookapp loaded config file 142444049 notebookapp searching rootjupyter rootlocaletcjupyter usretcjupyter usrlocaletcjupyter etcjupyter for config 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444059 notebookapp looking for in 142444059 notebookapp loaded config file 142444060 notebookapp looking for in 142444060 notebookapp loaded config file 142444060 notebookapp looking for in 142444060 notebookapp looking for in 142444060 notebookapp looking for in 142444061 notebookapp loaded config file notebook server cookie secret to of metrics is off since other authentication is serverextension notebook server cookie secret to of metrics is off since other authentication is serverextension notebooks from local directory notebook 648 is running controlc to stop this server and shut down all kernels twice to skip notebooks from local directory notebook 648 is running controlc to stop this server and shut down all kernels twice to skip started name 142629531813 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 142632617224 w tftrt warning could not find 142636113889 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636787982 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636788362 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636803571 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636803974 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636804329 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000011 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000338 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000550 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000771 w overriding origvalue setting because the environment variable is set original config value was 142640000816 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 142640077428 w allocation of 6093750902 exceeds 10 of free system 142642860963 f check failed size 0 0 vs restarting kernel 15 keep random 142736094812 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 142737142240 w tftrt warning could not find 142741764145 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741816688 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741826117 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741831423 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741832476 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741833383 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743665264 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743667057 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743668052 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743668828 w overriding origvalue setting because the environment variable is set original config value was 142743669432 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 142743701398 w allocation of 6093750902 exceeds 10 of free system 142748308263 f check failed size 0 0 vs restarting kernel 15 keep random 143109645133 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143110714033 w tftrt warning could not find 143112844776 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112892144 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112894009 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112896074 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112897012 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112897897 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114331805 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114332225 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114332548 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114332751 w overriding origvalue setting because the environment variable is set original config value was 143114332800 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 143118149537 i loaded cudnn version 143118151181 f check failed handleget cudnnmaxpoolingmode propagatenans cudnnpropagatenan cudnnnotpropagatenan nd shapedata paddingdata stridesdata cudnnstatussuccess 3 vs restarting kernel 15 keep random 143258023248 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143300925573 w tftrt warning could not find 143422817441 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422920819 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422921484 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422923040 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422923548 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422924029 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424323413 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424324064 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424324360 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424324522 w overriding origvalue setting because the environment variable is set original config value was 143424324601 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 143429102979 i loaded cudnn version 143429104423 f check failed handleget cudnnmaxpoolingmode propagatenans cudnnpropagatenan cudnnnotpropagatenan nd shapedata paddingdata stridesdata cudnnstatussuccess 3 vs restarting kernel 15 keep random 143439499788 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143441797362 w tftrt warning could not find restarted 143459388548 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143501250311 w tftrt warning could not find 143606143899 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606181829 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606182572 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606184389 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606184737 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606185055 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607232416 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607232868 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607233157 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607233367 w overriding origvalue setting because the environment variable is set original config value was 143607233419 i created device with 13692 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 143607261994 w oprequires failed at matrixdiagopcc273 invalidargument encountered overflow when multiplying 12884901888 with 1610612736 result 143657056526 w allocation of 6093750902 exceeds 10 of free system 143703543980 w oprequires failed at matrixdiagopcc273 invalidargument encountered overflow when multiplying 3046875451 with 3046875451 result 143704268280 w allocation of 6093750784 exceeds 10 of free system 143708172313 w oprequires failed at matrixdiagopcc273 invalidargument encountered overflow when multiplying 3046875392 with 3046875392 result 143816953443 i loaded cudnn version 143816953795 f check failed handleget cudnnmaxpoolingmode propagatenans cudnnpropagatenan cudnnnotpropagatenan nd shapedata paddingdata stridesdata cudnnstatussuccess 3 vs restarting kernel 15 keep random 144146795637 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 144147897333 w tftrt warning could not find 144150174067 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 144150217161 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 144150217535 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 145315973272 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 145315977064 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 145315977438 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 145317404160 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 145317405355 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 145317406091 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 145317406821 w overriding origvalue setting because the environment variable is set original config value was 145317407403 i created device with 13692 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 145317447492 w oprequires failed at matrixdiagopcc273 invalidargument encountered overflow when multiplying 9984734776 with 1248091847 result 145600832626 i loaded cudnn version 145600832804 f check failed handleget cudnnmaxpoolingmode propagatenans cudnnpropagatenan cudnnnotpropagatenan nd shapedata paddingdata stridesdata cudnnstatussuccess 3 vs restarting kernel 15 keep random"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncrash when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution prettynameubuntu 22042 lts nameubuntu versionid2204 version22042 lts jammy jellyfish versioncodenamejammy idubuntu idlikedebian homeurl supporturl bugreporturl privacypolicyurl ubuntucodenamejammy mobile device no response python version 31012 main jun 11 2023 052628 bazel version no response gcccompiler version gcc 1140 cudacudnn version nvcc nvidia r cuda compiler driver copyright c 20052022 nvidia corporation built on cuda compilation tools release 118 v11889 build gpu model and memory t4 current behavior due to the large list of elements standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try arg00 1e20 arg01 true arg0 arg00arg01 strides0 2 strides1 2 strides strides0strides1 argclass arginput0tensor tfrandomuniform2 17 17 768 dtypetffloat32 arginput0 arginput arginput0 out argclassarginput except exception as e printerrorstre relevant log output shell 142443837 notebookapp searching rootjupyter rootlocaletcjupyter usretcjupyter usrlocaletcjupyter etcjupyter for config 142443838 notebookapp looking for jupyterconfig in 142443840 notebookapp looking for jupyterconfig in 142443842 notebookapp looking for jupyterconfig in 142443842 notebookapp looking for jupyterconfig in 142443842 notebookapp looking for jupyterconfig in 142443843 notebookapp looking for in 142443847 notebookapp loaded config file 142443847 notebookapp looking for in 142443849 notebookapp loaded config file 142443849 notebookapp looking for in 142443849 notebookapp looking for in 142443849 notebookapp looking for in 142443857 notebookapp loaded config file 142444049 notebookapp searching rootjupyter rootlocaletcjupyter usretcjupyter usrlocaletcjupyter etcjupyter for config 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444059 notebookapp looking for in 142444059 notebookapp loaded config file 142444060 notebookapp looking for in 142444060 notebookapp loaded config file 142444060 notebookapp looking for in 142444060 notebookapp looking for in 142444060 notebookapp looking for in 142444061 notebookapp loaded config file notebook server cookie secret to of metrics is off since other authentication is serverextension notebook server cookie secret to of metrics is off since other authentication is serverextension notebooks from local directory notebook 648 is running controlc to stop this server and shut down all kernels twice to skip notebooks from local directory notebook 648 is running controlc to stop this server and shut down all kernels twice to skip started name 142629531813 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 142632617224 w tftrt warning could not find 142636113889 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636787982 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636788362 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636803571 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636803974 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636804329 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000011 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000338 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000550 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000771 w overriding origvalue setting because the environment variable is set original config value was 142640000816 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 142640077428 w allocation of 6093750902 exceeds 10 of free system 142642860963 f check failed size 0 0 vs restarting kernel 15 keep random 142736094812 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 142737142240 w tftrt warning could not find 142741764145 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741816688 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741826117 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741831423 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741832476 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741833383 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743665264 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743667057 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743668052 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743668828 w overriding origvalue setting because the environment variable is set original config value was 142743669432 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 142743701398 w allocation of 6093750902 exceeds 10 of free system 142748308263 f check failed size 0 0 vs restarting kernel 15 keep random 143109645133 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143110714033 w tftrt warning could not find 143112844776 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112892144 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112894009 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112896074 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112897012 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112897897 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114331805 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114332225 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114332548 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114332751 w overriding origvalue setting because the environment variable is set original config value was 143114332800 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 143118149537 i loaded cudnn version 143118151181 f check failed handleget cudnnmaxpoolingmode propagatenans cudnnpropagatenan cudnnnotpropagatenan nd shapedata paddingdata stridesdata cudnnstatussuccess 3 vs restarting kernel 15 keep random 143258023248 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143300925573 w tftrt warning could not find 143422817441 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422920819 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422921484 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422923040 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422923548 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422924029 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424323413 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424324064 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424324360 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424324522 w overriding origvalue setting because the environment variable is set original config value was 143424324601 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 143429102979 i loaded cudnn version 143429104423 f check failed handleget cudnnmaxpoolingmode propagatenans cudnnpropagatenan cudnnnotpropagatenan nd shapedata paddingdata stridesdata cudnnstatussuccess 3 vs restarting kernel 15 keep random 143439499788 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143441797362 w tftrt warning could not find restarted 143459388548 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143501250311 w tftrt warning could not find 143606143899 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606181829 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606182572 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606184389 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606184737 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606185055 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607232416 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607232868 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607233157 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607233367 w overriding origvalue setting because the environment variable is set original config value was 143607233419 i created device with 13692 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 143607261994 w oprequires failed at matrixdiagopcc273 invalidargument encountered overflow when multiplying 12884901888 with 1610612736 result 143657056526 w allocation of 6093750902 exceeds 10 of free system 143703543980 w oprequires failed at matrixdiagopcc273 invalidargument encountered overflow when multiplying 3046875451 with 3046875451 result 143704268280 w allocation of 6093750784 exceeds 10 of free system 143708172313 w oprequires failed at matrixdiagopcc273 invalidargument encountered overflow when multiplying 3046875392 with 3046875392 result 143816953443 i loaded cudnn version 143816953795 f check failed handleget cudnnmaxpoolingmode propagatenans cudnnpropagatenan cudnnnotpropagatenan nd shapedata paddingdata stridesdata cudnnstatussuccess 3 vs restarting kernel 15 keep random"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ninteger overflow when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution prettynameubuntu 22042 lts nameubuntu versionid2204 version22042 lts jammy jellyfish versioncodenamejammy idubuntu idlikedebian homeurl supporturl bugreporturl privacypolicyurl ubuntucodenamejammy mobile device no response python version 31012 main jun 11 2023 052628 bazel version no response gcccompiler version gcc 1140 cudacudnn version cudatoolkit1180nvcc nvidia r cuda compiler driver copyright c 20052022 nvidia corporation built on cuda compilation tools release 118 v11889 build gpu model and memory t4 current behavior due to large integer variable standalone code to reproduce the issue shell results dict import tensorflow as tf import numpy as np try try with tfdevicecpu ntensor 3046875451 n tfidentityntensor dtype tfuint16 out except exception as e printerrorstre try with tfdevicegpu0 n tfidentityntensor n tfcastn tfcomplex64 dtype tfuint16 except exception as e printerrorstre except exception as e printerrorstre printresults relevant log output shell errorfunctionnode encountered overflow when multiplying 3046875451 with 3046875451 result 9163294059803098215 opmatrixdiagv3 name diag complexwarning casting complex values to real discards the imaginary part return intselfnumpy errorfunctionnode encountered overflow when multiplying 3046875392 with 3046875392 result 9163294419334397952 opmatrixdiagv3 name diag"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncould not find a version that satisfies the requirement from versions none\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version fail custom code yes os platform and distribution no response mobile device no response python version 3912 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior i try to pip intsall tensorflowfederated it fail so i build it on source i pip install requirement requirementstxt then happened this error can i know how to solve this problem standalone code to reproduce the issue shell relevant log output shell error could not find a version that satisfies the requirement from versions none error no matching distribution found for"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntrain simple audio recognition tinyml\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2120 custom code yes os platform and distribution windows 11 mobile device no response python version 31012 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior issue report error in training audio recognition model description i am trying to train a simple audio recognition model as described in the book tinyml i am using google colab to train the model however i encountered errors during both the installation of dependencies and the training process error during install dependencies when attempting to install dependencies using the command pip uninstall y tensorflow tensorflowestimator tensorboard pip install q i encountered the following error error could not find a version that satisfies the requirement from versions 2120 error no matching distribution found for error during training modulenotfounderror error to begin training upon running the training script with tensorflow in the begin training section i received the following error traceback most recent call last file line 81 in import inputdata file line 35 in from import audioops as contribaudio modulenotfounderror no module named tensorflowcontrib observations i suspect that these errors are occurring because the code provided in the book is intended for tensorflow 115 while i am using tensorflow 2120 since tensorflow 115 is no longer supported not sure how i can resolve this please help me to fix this issue standalone code to reproduce the issue shell relevant log output shell error could not find a version that satisfies the requirement from versions 2120 error no matching distribution found for traceback most recent call last file line 81 in import inputdata file line 35 in from import audioops as contribaudio modulenotfounderror no module named tensorflowcontrib"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncrash when running\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2100 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to feeding large integer value standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import nnops try arg0tensor tfrandomuniform5 20 20 3 dtypetffloat64 arg0 tfidentityarg0tensor arg10 1 arg11 130 arg12 15 arg13 1 arg1 arg10arg11arg12arg13 seed 125091515651 seed2 1 deterministic true out except exception as e printerrorstre relevant log output shell 20230814 220506501205 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230814 220507064824 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507082027 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507082168 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507082457 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 220507083701 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507083818 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507083916 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507144960 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507145099 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507145198 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507145279 i created device with 4205 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 fractionalmaxpool from is deprecated and will be removed in a future version instructions for updating seed2 and deterministic args are deprecated use fractionalmaxpoolv2 segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncrash when running\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2100 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior probably due to an invalid string argument standalone code to reproduce the issue shell import tensorflow as tf import numpy as np from import context try try with tfdevicecpu arg0 out except exception as e printerrorstre try with tfdevicegpu0 except exception as e printerrorstre except exception as e printerrorstre relevant log output shell 0230814 214355028346 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355045718 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355045863 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355046195 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 214355047241 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355047355 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355047452 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355101589 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355101732 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355101832 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355101916 i created device with 4018 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nabort when running\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to large input tensor standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import genctcops try arg0tensor shape2 2 3 dtypetffloat32 arg0 tfidentityarg0tensor arg1tensor shape4 2 dtypetfint64 arg1 tfidentityarg1tensor arg2tensor tfrandomuniform4 minval256 maxval257 dtypetfint32 arg2 tfidentityarg2tensor arg3tensor tfrandomuniform2 minval256 maxval257 dtypetfint32 arg3 tfidentityarg3tensor false ctcmergerepeated true false out except exception as e printerrorstre relevant log output shell 20230814 213656173477 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656190838 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656190979 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656191266 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 213656191900 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656192006 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656192110 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656252143 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656252287 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656252387 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656252470 i created device with 4025 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 20230814 213656314614 i loaded cudnn version 8600 20230814 213656327748 f check failed handleget cudnnstatussuccess 3 vs 0 aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nabort when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2100 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to feeding invalid list element standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import nnops try arg0tensor tfrandomuniform2 5 6 4 3 dtypetffloat32 arg0 tfidentityarg0tensor arg1tensor tfrandomuniform3 3 3 2 3 dtypetffloat32 arg1 tfidentityarg1tensor arg20 2 arg21 11 arg22 13 arg23 9 arg24 false arg2 strides0 1 strides1 2 strides2 2 strides3 2 strides4 1 strides padding valid out except exception as e printerrorstre relevant log output shell 20230814 213234731642 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234748917 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234749058 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234749350 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 213234750631 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234750742 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234750840 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234804553 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234804756 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234804893 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234804979 i created device with 4009 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 20230814 213234866964 i loaded cudnn version 8600 20230814 213234880076 f check failed handleget cudnnstatussuccess 3 vs 0 aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ninternal assertion failure when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to feeding nan input standalone code to reproduce the issue shell import tensorflow as tf import numpy as np from import remote try try with tfdevicecpu arg0 nan out except exception as e printerrorstre try with tfdevicegpu0 except exception as e printerrorstre except exception as e printerrorstre relevant log output shell 20230814 194647563173 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647580413 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647580559 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647580847 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 194647582229 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647582354 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647582453 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647643352 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647643499 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647643600 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647643684 i created device with 4110 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 20230814 194647645827 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647645936 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647646029 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647646141 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647646236 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647646304 i created device with 4110 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 20230814 194647654175 e invalidargument could not interpret nan as a hostport pair e0814 194647654333018 18949 completionqueuecc244 assertion failed queuenumitems 0 aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncrash when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2100 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to mismatch between input tensors standalone code to reproduce the issue shell import tensorflow as tf import numpy as np from tensorflowpythonops import genarrayops try try with tfdevicecpu arg0tensor tfrandomuniform2 3 dtypetffloat32 arg0 tfidentityarg0tensor arg1tensor tfrandomuniform2 dtypetffloat32 arg1 tfidentityarg1tensor arg2 tfint32 arg3 false out except exception as e printerrorstre try with tfdevicegpu0 arg0 tfidentityarg0tensor arg0 tfcastarg0 tffloat32 arg1 tfidentityarg1tensor arg1 tfcastarg1 tffloat32 arg2 tfint32 except exception as e printerrorstre except exception as e printerrorstre relevant log output shell 20230814 193709497421 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709514487 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709514629 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709514917 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 193709515817 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709515932 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709516035 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709573389 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709573531 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709573629 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709573710 i created device with 4043 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 free invalid pointer aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncrash when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to the large integer value standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import genlistops try elementshapetensor tfrandomuniform0 minval256 maxval257 dtypetfint32 elementshape numelements 1250999896764 elementdtype tffloat64 out except exception as e printerrorstre relevant log output shell 20230814 191202093783 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202111206 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202111351 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202111663 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 191202113096 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202113270 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202113369 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202167538 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202167673 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202167772 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202167855 i created device with 4163 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nabort when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2100 custom code no os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to empty input value standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import mathops try arg0 10 arg1 50 arg2 dtype none out except exception as e printerrorstre relevant log output shell 20230814 185753081061 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753098644 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753098788 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753099088 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 185753099985 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753100112 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753100209 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753168279 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753168422 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753168524 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753168607 i created device with 3574 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 20230814 185753212928 f check failed 1 numelements 1 vs 0must have a one element tensor aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncrash when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2100 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to feeding none value standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from import context try arg0 none out except exception as e printerrorstre relevant log output shell 20230814 180938431471 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230814 180939008742 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939026368 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939026511 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939026801 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 180939027611 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939027718 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939027812 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939086029 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939086174 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939086268 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939086349 i created device with 4023 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nsegmentation fault when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2110 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to large input tensor standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import nnops try arg0tensor tfrandomuniform5 20 20 3 dtypetffloat64 arg0 tfidentityarg0tensor arg10 40 arg11 15 arg12 15 arg13 1 arg1 arg10arg11arg12arg13 seed 1 seed2 1 deterministic true out except exception as e printerrorstre relevant log output shell 20230814 163531365070 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230814 163531920926 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163531937761 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163531937904 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163531938205 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 163531939360 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163531939470 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163531939568 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163532006452 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163532006593 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163532006693 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163532006775 i created device with 4461 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 fractionalmaxpool from is deprecated and will be removed in a future version instructions for updating seed2 and deterministic args are deprecated use fractionalmaxpoolv2 segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nunicodedecodeerror when loading model from a path with chinese characters\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 2130 custom code yes os platform and distribution windows 11 22h2 mobile device no response python version 311 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior current behavior when i attempt to use to load a saved model from a folder path that contains chinese characters tensorflow throws a unicodedecodeerror this suggests that tensorflow may not be parsing chinese characters correctly in the folder path expected behavior i expect to be able to load the model correctly from any folder path regardless of whether it contains chinese characters or not if there are limitations on the folder name it should be clearly documented or provide a more descriptive error message standalone code to reproduce the issue shell import tensorflow as tf create a simple model model inputshape1 lossmse modelsave模型 模型 is chinese for model now try to load the saved model loadedmodel relevant log output shell traceback most recent call last unicodedecodeerror utf8 codec cant decode byte 0xa1 in position 27 invalid start byte"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nsegmentation fault when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2110 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to feeding none value standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from import importer try arg00 a arg0 arg00 arg1 none arg2 none out except exception as e printerrorstre relevant log output shell 0230813 021014149106 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nabort when running\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2110 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to a negative large integer the behavior is bizarre it would be best if you ran multiple times to see the abort standalone code to reproduce the issue shell import tensorflow as tf import numpy as np from tensorflowpythonops import genmathops try try with tfdevicecpu splitstensor tfconstant1000000 shape129 1 1 dtypetffloat16 splits valuestensor shape3456 values weightstensor shape128 27 weights size 3046875451 out except exception as e printerrorstre try with tfdevicegpu0 splits splits tfcastsplits tffloat16 values values tfcastvalues tfuint64 weights weights tfcastweights tfint16 except exception as e printerrorstre except exception as e printerrorstre relevant log output shell 20230813 015836322308 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230813 015837120869 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837139665 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837139841 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837140154 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230813 015837140677 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837140794 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837140896 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837187990 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837188156 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837188267 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837188356 i created device with 152 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 errorcant convert negative int to unsigned 20230813 015837207611 i failed to allocate 15281m 160235520 bytes from device cudaerroroutofmemory out of memory 20230813 015837207886 i failed to allocate 13753m 144211968 bytes from device cudaerroroutofmemory out of memory 20230813 015837208138 i failed to allocate 12378m 129790976 bytes from device cudaerroroutofmemory out of memory 20230813 015837213816 f check failed pyerroccurred aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nabort when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2110 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to very large integer argument standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import genarrayops try arg0tensor tfrandomuniform3 2 3 4 dtypetffloat32 arg0 tfidentityarg0tensor arg1 2147483647 arg2 nhwc out except exception as e printerrorstre relevant log output shell 0230813 002353644564 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230813 002354491071 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354510564 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354510736 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354511051 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230813 002354511595 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354511717 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354511830 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354572398 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354572634 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354572791 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354572916 i created device with 153 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 20230813 002354594062 i failed to allocate 15388m 161349632 bytes from device cudaerroroutofmemory out of memory 20230813 002354594484 i failed to allocate 13849m 145214720 bytes from device cudaerroroutofmemory out of memory 20230813 002354600623 f nonokstatus initdimsdimsizes status invalidargument expected a nonnegative size got 2 aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nsegmentation fault when running\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior when numelements is very large standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import listops try elementshape0 1 elementshape elementshape0 numelements 1250999896764 elementdtype tffloat32 out except exception as e printerrorstre relevant log output shell 20230812 230556608429 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230812 230557434965 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557454466 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557454644 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557454958 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230812 230557455499 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557455620 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557455724 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557504359 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557504534 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557504649 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557504741 i created device with 151 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 20230812 230557518166 i failed to allocate 15144m 158793728 bytes from device cudaerroroutofmemory out of memory segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncheck failure when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2110 custom code no os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior the following input combination causes check failure standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import nnops try arg0tensor tfrandomuniform2 5 6 4 3 dtypetffloat32 arg0 tfidentityarg0tensor arg1tensor tfrandomuniform3 3 3 2 3 dtypetffloat32 arg1 tfidentityarg1tensor arg20 2 arg21 11 arg22 13 arg23 9 arg24 false arg2 arg30 1 arg31 2 arg32 2 arg33 2 arg34 1 arg3 padding valid dataformat ndhwc dilations none out except exception as e printerrorstre relevant log output shell 20230806 065826108204 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230806 065826851251 w could not load dynamic library libnvinferso7 dlerror libnvinferso7 cannot open shared object file no such file or directory ldlibrarypath 20230806 065826851492 w could not load dynamic library libnvinferpluginso7 dlerror libnvinferpluginso7 cannot open shared object file no such file or directory ldlibrarypath 20230806 065826851500 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230806 065827585126 w could not load dynamic library libnvinferso7 dlerror libnvinferso7 cannot open shared object file no such file or directory ldlibrarypath 20230806 065827585372 w could not load dynamic library libnvinferpluginso7 dlerror libnvinferpluginso7 cannot open shared object file no such file or directory ldlibrarypath 20230806 065827585380 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230806 065912781705 f check failed handleget cudnnstatussuccess 3 vs 0"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nsegmentation fault when running\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior probably due to invalid string argument standalone code to reproduce the issue shell import tensorflow as tf import numpy as np from import context try try with tfdevicecpu arg0 out except exception as e printerrorstre try with tfdevicegpu0 except exception as e printerrorstre except exception as e printerrorstre relevant log output shell cudnnlib 20230812 152722605920 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230812 152723511442 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723533020 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723533197 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723533535 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230812 152723534136 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723534277 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723534432 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723605501 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723605704 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723605831 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723605930 i created device with 77 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntypeerror unable to serialize 640 to json unrecognized type\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version 213 custom code no os platform and distribution windows 11 mobile device no response python version 3113 bazel version na gcccompiler version na cudacudnn version not using gpu gpu model and memory na current behavior i have been receiving this message when trying to save a variety of tensorflow models since version 211 i have reported it before it appears to be produced by the lack of an ability by tensorfow to serialize the model representations it maintains in memory typeerror unable to serialize 640 to json unrecognized type see the debugger output below for details can i change anything in my models to dodge this logic is there another model saving function i can try standalone code to reproduce the issue shell please email me for code relevant log output shell traceback most recent call last file line 132 in saveformattf file line 149 in savemodel return file line 70 in errorhandler raise from none file line 200 in encode chunks selfiterencodeo oneshottrue file line 258 in iterencode return iterencodeo 0 typeerror unable to serialize 640 to json unrecognized type"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nalpha does not work\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version tf 213 custom code yes os platform and distribution linux ubuntu 2004 mobile device no response python version 31012 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior computes the loss without using the alpha import tensorflow as tf ytruelist 0 1 0 0 logitslist 16 051 294 18 gamma 2 focalfunc1 alpha025 fromlogitstrue focalloss1 focalfunc1ytruelist logitslist focalfunc2 alpha10 fromlogitstrue focalloss2 focalfunc2ytruelist logitslist focalfunc3 alpha100 fromlogitstrue focalloss3 focalfunc3ytruelist logitslist printfocalloss1 printfocalloss2 printfocalloss3 the results are tftensor06932789 shape dtypefloat32 tftensor06932789 shape dtypefloat32 tftensor06932789 shape dtypefloat32 focalloss1 in the codes should be 051168 standalone code to reproduce the issue shell in above relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nnotimplementederror while converting a tensorflow model to coreml using coremltools\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior i am facing a notimplementederror while trying to convert movinets model to coreml the model is saved in savedmodel format and i am using a tensorflow version equal to 2130 and a version of core ml tools equal to 630 and a 3106 python i dont understand the origin of operation and its meaning any idea whats could be going on here are the steps to reproduce the error 1 download a savedmodel from the following link 2 convert the model using shell import coremltools as ct coremlmodel ctconvertsaveddir converttomlprogram where saveddir is the path to the downloaded model relevant log output shell notimplementederror conversion for tf op not implemented name op input image input unknown input unknown0 input unknown1 input unknown2 input unknown3 input unknown4 input unknown5 input unknown6 input unknown7 input unknown8 input unknown9 input unknown10 input unknown11 input unknown12 input unknown13 input unknown14 input unknown15 input unknown597 input unknown598 input unknown599 attr key tin value list type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat attr key tout value list type dtfloat attr key xlamustcompile value b true attr key collectivemanagerids value list attr key value b true attr key value list i 1 i 2 i 3 i 4 i 5 i 6 i 7 i 8 i 9 i 10 i 11 i 12 i 13 i 14 i 15 i 597 i 598 i 599 i 600 i 601 attr key config value s attr key configproto value s attr key executortype value s attr key f value func name"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow inference error\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 28 custom code yes os platform and distribution linux centos mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior my model can train normally but there was an error when inference after the training was completedthe model structure code is as follows conv1 bn1 out1 prelusharedaxes12bn1 out2 tfreshapeout1 dp1 lstmout2 dpo1 dense32dp1 dpo2 lso1 lstmdpo2 dpo3 dense2lso1 the error is as follows execution error scale must have the same number of elements as the channels of x got 32 and 2 node may i ask what caused this and if it can be resolved standalone code to reproduce the issue shell no relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nhow to get detailed information about the issue\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2121 custom code no os platform and distribution linux ubuntu 1804 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version cuda 118 cudnn 892 gpu model and memory nvidia a10 current behavior im getting following error while compiling the model with xla oprequires failed at xlaopscc347 invalidargument trying to access resource located in device from device this issue is documented as xla limitation here which seems reasonable but the error message doesnt specify where this issue is coming from is there any way to get more details on which variable is creating this issue standalone code to reproduce the issue shell na relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nattempting to use uninitialized value\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 28 custom code yes os platform and distribution linux ubuntu 2004 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior i have trained the carcacontext and attributeaware sequential recommendation via crossattention on video games dataset i saved the session after 1 epoch and try to restore the session since all the architecture was written using the concepts of the session i saved the session using tftrainsaver save method sessionsaver sessionoutputpath epochsstrepoch if not make directory if not exists sessionsaversavesess printfinfo save the model after epochs epoch then i restored session using saver carcamodelmeta saverrestoresess i have tried to perform prediction on new dataset using restored session sess but i have encountered attempting to use uninitialized value error the full error is traceback most recent call last file line 1356 in docall return fnargs file line 1341 in runfn options feeddict fetchlist targetlist runmetadata file line 1429 in calltfsessionrun runmetadata attempting to use uninitialized value node during handling of the above exception another exception occurred traceback most recent call last file carcatrainpy line 1441 in usernum itemnum args itemfeatures userfeatures cxtdict file carcatrainpy line 1317 in predictions modelpredictsess nponesargsmaxlenu seq itemidx seqcxt testitemscxt file carcatrainpy line 976 in predict selftestuser u selfinputseq seq selftestitem itemidx selfistraining false selfseqcxtseqcxt file line 950 in run runmetadataptr file line 1173 in run feeddicttensor options runmetadata file line 1350 in dorun runmetadata file line 1370 in docall raise typeenodedef op message attempting to use uninitialized value node defined at carcatrainpy670 original stack trace for file carcatrainpy line 1441 in usernum itemnum args itemfeatures userfeatures cxtdict file carcatrainpy line 1266 in model modelusernum itemnum args itemfeatures userfeatures cxtsize cxtsize useres true file carcatrainpy line 768 in init file carcatrainpy line 670 in feedforward outputs tflayersconv1dparams file line 324 in newfunc return funcargs kwargs file line 218 in conv1d return layerapplyinputs file line 1479 in apply return selfcallinputs args kwargs file line 537 in call outputs superlayer selfcallinputs args kwargs file line 591 in call selfmaybebuildinputs file line 1881 in maybebuild selfbuildinputshapes file line 165 in build dtypeselfdtype file line 450 in addweight kwargs file line 384 in addweight file line 663 in kwargsforgetter file line 1496 in getvariable file line 1239 in getvariable file line 562 in getvariable file line 514 in truegetter file line 929 in getsinglevariable file line 259 in call return kwargs file line 220 in variablev1call shapeshape file line 198 in previousgetter lambda kwargs kwargs file line 2511 in shapeshape file line 263 in call return clscallargs kwargs file line 1568 in init shapeshape file line 1755 in initfromargs selfsnapshot nameread file line 180 in wrapper return targetargs kwargs file line 86 in identity ret namename file line 4253 in identity identity inputinput namename file line 788 in applyophelper opdefopdef file line 507 in newfunc return funcargs kwargs file line 3616 in createop opdefopdef file line 2005 in init selftraceback tfstackextractstack i have also checked the variables in both the stored session and the session just after training both outputs seem similar i was stuck on this issue for a few days and also tested saving the model using and restoring the model using but not solved the issuecurrentlyi am using tensorflow 114 standalone code to reproduce the issue shell sessionsaver sessionoutputpath epochsstrepoch if not make directory if not exists sessionsaversavesess printfinfo save the model after epochs epoch saver carcamodelmeta saverrestoresess relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nfails\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version git head custom code no os platform and distribution ubuntu 2004 mobile device na python version 3917 bazel version 610 gcccompiler version 1021 cudacudnn version na gpu model and memory na current behavior unit test fails since commit standalone code to reproduce the issue shell bazel test testenvtf2behavior1 definetfapiversion2 jobs75 buildtestsonly relevant log output shell test output for testing 1 tests 1 workers fail mlir tests optimizemlir 1 of 1 test mlir tests optimizemlir failed script run at line 2 tfloptimize run at line 4 checkprefixfold run at line 7 tfllegalizetf tfloptimize checkprefixfusing run at line 9 tfllegalizetf checkprefixnofusing exit code 1 command output stderr error check expected string not found in input check tflbatchmatmularg0 arg1 154253 note scanning from here funcfunc tensor arg1 tensor tensor 15497 note possible intended match here 2 tflbatchmatmularg1 1 adjx true adjy false false tensor tensor tensor input file check file dumpinputhelp explains the following input dump input was 1537 3 tfltranspose2 0 tensor tensor tensor 1538 4 tflgathernd3 1 tensor tensor tensor 1539 5 tflreshape4 cst tensor tensor tensor 1540 return 5 tensor 1541 1542 funcfunc tensor arg1 tensor tensor check36220 x error no match found 1543 cst arithconstant dense tensor check36220 1544 cst0 arithconstant dense tensor check36220 1545 cst1 arithconstant dense tensor check36220 1546 cst2 arithconstant dense tensor check36220 1547 0 tfltransposearg0 cst2 tensor tensor tensor check36220 1548 1 tflreshape0 cst1 tensor tensor tensor check36220 1549 2 tflbatchmatmularg1 1 adjx true adjy false false tensor tensor tensor check36220 check36221 possible intended match 1550 3 tflreshape2 cst0 tensor tensor tensor check36220 1551 4 tfltranspose3 cst tensor tensor tensor check36220 1552 return 4 tensor check36220 1553 check36220 1554 funcfunc tensor arg1 tensor arg2 none tensor check36220 failed tests 1 mlir tests optimizemlir testing time 053s failed 1"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncould not load dynamic library cudart64110dll dlerror cudart64110dll not found\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 2100 custom code yes os platform and distribution windows 11 mobile device na python version 310microsoft store bazel version no response gcccompiler version no response cudacudnn version cuda 112 gpu model and memory rtx 3070 ti 8gb current behavior i installed cuda 112 as recommended for tf 2100 heres the install screenshot at first i thought it was a path issue but after restarting my pc i was able to access exe files in that folder image if the files are in path why cant tensorflow find them many people say to use miniconda so i did but i got the same result other resolved issues were resolved as the ops were using the wrong version of cuda i checked on the website and i can confirm that my version is the required one standalone code to reproduce the issue shell import tensorflow as tf relevant log output shell 20230731 185625098058 w could not load dynamic library cudart64110dll dlerror cudart64110dll not found 20230731 185625098226 i ignore above cudart dlerror if you do not have a gpu set up on your machine 20230731 185626164080 w could not load dynamic library cudart64110dll dlerror cudart64110dll not found 20230731 185626164320 w could not load dynamic library cublas6411dll dlerror cublas6411dll not found 20230731 185626164540 w could not load dynamic library cublaslt6411dll dlerror cublaslt6411dll not found 20230731 185626164818 w could not load dynamic library cufft6410dll dlerror cufft6410dll not found 20230731 185626368828 w could not load dynamic library cusparse6411dll dlerror cusparse6411dll not found 20230731 185626369092 w could not load dynamic library cudnn648dll dlerror cudnn648dll not found"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\njava cant parse savedmodelpb as binary proto jdk 17\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 1150 custom code yes os platform and distribution rhel 8 version 875 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior has following files 1 assetsvocabtxt 2 savedmodelpb 3 4 i am using java binding code to run the inference libraries i am using are orgtensorflow tensorflow 1150 orgtensorflow libtensorflow 1150 orgtensorflow proto 1150 orgtensorflow libtensorflowjni 1150 tensorflow version 1150 jdk oracle open jdk version 1705 os rhel 8 version 875 describe the current behavior cant parse savedmodelpb as binary proto at method at at at at describe the expected behavior in jdk 11 the code runs while in jdk 17 its throws error the model file is not corrupted same model path file is able to run successfully in jdk 11 standalone code to reproduce the issue shell code import import orgjunittest import import orgtensorflowsession import javaioioexception import import javaniofilepaths public class testclass test public void tfpredictor throws ioexception urisyntaxexception savedmodelbundle b savedmodelbundleload serve session sess bsession"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nissue\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 29 custom code yes os platform and distribution linux ubuntu mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior xyz standalone code to reproduce the issue shell xyz relevant log output shell jkjnk"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nint8 tflite model allocatetensors silently stop python process\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 281 2130 2140dev20230706 custom code yes os platform and distribution windows 11 windows 10 wsl with ubuntu 2004 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior i have converted a resnet18 model from onnx to tflite onnx tf tflite onnx to tf conversion is done by this repo tflite is converted to int8 precision using posttraining integer quantization link netron can display the converted int8 model correctly onnx model tflite model link tflite int8 model link but when i try to do inference calling the method allocatetensors stop the python process without showing any errorwarning if the tflite model is converted with fp32 this issue doesnt happen i have no idea how do to fix this issue or is there any workaround thanks standalone code to reproduce the issue shell tf to tflite conversion import tensorflow as tf import numpy as np savedmodeldir resnet18 tflitemodelpath savedmodeldir tflite converter def for in range100 data nprandomrand1 3 224 224 yield dataastypenpfloat32 tfint8 tfint8 tflitemodel converterconvert save the model with opentflitemodelpath wb as f fwritetflitemodel inference time import tensorflow as tf interpreter printbefore printafter this line not displayed relevant log output shell inference time output tf 2140dev20230706 from is deprecated and will be removed after 20190101 instructions for updating the tensorflow distributions library has moved to tensorflow probability you should update all references to use tfpdistributions instead of tfdistributions registerklinit from is deprecated and will be removed after 20190101 instructions for updating the tensorflow distributions library has moved to tensorflow probability you should update all references to use tfpdistributions instead of tfdistributions before info created tensorflow lite xnnpack delegate for cpu"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ninvalid work group size\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version tf 2100 custom code yes os platform and distribution ubuntu 2004 mobile device qualcomm sm6225 python version 38 bazel version 511 gcccompiler version 940 cudacudnn version no gpu model and memory qualcomm adrenotm qualcomm opencl c 20 adrenotm 610 current behavior use tflite to invoke mobilnetv2 or any model with op softmax on mobile device will encounter an error tflitegpudelegate invoke failed to invalid work group size more details if inferenceforcefp16 is false no error occured if work group size is smaller than 256 no error occured standalone code to reproduce the issue shell same code as tflite invoke on android phone will reproduce this issue relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nrng generators make python abort in python311 and tf212 condaforge\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2121 custom code yes os platform and distribution macos 1341c mobile device no response python version 311 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior unable to make random number generators this happens with condaforge python 3113 tensorflow2121 it works fine with pip python 3113 tensorflow 2120 standalone code to reproduce the issue shell import tensorflow as tf g gnormalshape3 relevant log output shell assertion failed f nullptr dynamiccastf nullptr function downcast file line 58 1 18173 abort python"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncannot find explicitly assigned device for op\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 284 custom code no os platform and distribution ubuntu1804 mobile device no response python version no response bazel version 520 gcccompiler version gcc1130 cudacudnn version none gpu model and memory none current behavior model trained use gpu but infer machine dont have gpu device so will meet cannot find assigend device at model load stage here is log e20230724 130227982717 35915 tfmodelcorecc80 failed to load model in cannot assign a device for operation node was explicitly assigned to devicegpu0 but available devices are make sure the device specification refers to a valid device the requested device appears to be a gpu but cuda is not enabled standalone code to reproduce the issue shell no code relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nlstm loss does not work tpu with bfloat16\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2120 custom code yes os platform and distribution google colab tpu mobile device no response python version 310 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior lstm on tpu works in float32 gives error message in bfloat16 value passed to parameter input has datatype bfloat16 not in list of allowed values float16 float32 float64 standalone code to reproduce the issue shell colab code in this gist run with tpu relevant log output shell typeerror traceback most recent call last in 1 with strategyscope 2 model buildmodel 3 4 modelcompile 5 3 frames in attrdef paramname 54 allowedvalues for x in allowedlist 55 if dtype not in allowedlist 56 raise typeerror 57 fvalue passed to parameter paramname has datatype 58 not in list of allowed values typeerror exception encountered when calling layer lstm4 type lstm value passed to parameter input has datatype bfloat16 not in list of allowed values float16 float32 float64 call arguments received by layer lstm4 type lstm • none 128 dtypebfloat16 • masknone • trainingnone • initialstatenone"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nassertionerror tried to export a function which references an untracked resource tensorflow objectseg tfvariable\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 210 custom code yes os platform and distribution no response mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior as you can see in the code below the operation of multiplying attn by temperature at mdta is being performed and the temperature is defined by tfvariable the model using the attention module below runs normally until trainingmodelfit but an assertionerror occurs when saving the model i would appreciate it if you could tell me how to make the temperature variable trackable standalone code to reproduce the issue shell import tensorflowcompatv2 as tf import tensorflow as tf import keras from keras import backend from kerasapplications import imagenetutils from kerasengine import training from keraslayers import versionawarelayers from kerasutils import datautils from kerasutils import layerutils from keraslayers import layer activation relu concatenate conv2d add dense maxpool2d avgpool2d flatten multiply softmax from keraslayers import dropout dense input batchnormalization depthwiseconv2d zeropadding2d layernormalization from tensorflowkeras import backend as k from kerasmodels import model import tensorflowkeras 정상적으로 작동 temperature제외 isort off from import tflogging as logging from import kerasexport baseweightpath kerasexport def mobilenet inputshapenone alpha10 depthmultiplier1 dropout1e3 includetoptrue weightsimagenet inputtensornone poolingnone classes1000 kwargs global layers if layers in kwargs layers kwargspoplayers else layers versionawarelayers if kwargs raise valueerrorfunknown arguments kwargs if not weights in imagenet none or raise valueerror the weights argument should be either none random initialization imagenet pretraining on imagenet or the path to the weights file to be loaded freceived weightsweights if weights imagenet and includetop and classes 1000 raise valueerror if using weights as imagenet with includetop as true classes should be 1000 freceived classesclasses determine proper input shape and default size if inputshape is none defaultsize 224 else if channelsfirst rows inputshape1 cols inputshape2 else rows inputshape0 cols inputshape1 if rows cols and rows in 128 160 192 224 defaultsize rows else defaultsize 224 inputshape inputshape minsize32 weightsweights if channelslast rowaxis colaxis 0 1 else rowaxis colaxis 1 2 rows inputshaperowaxis cols inputshapecolaxis if weights imagenet if depthmultiplier 1 raise valueerror if imagenet weights are being loaded depth multiplier must be 1 freceived if alpha not in 025 050 075 10 raise valueerror if imagenet weights are being loaded alpha can be one of 025 050 075 or 10 only freceived alphaalpha if rows cols or rows not in 128 160 192 224 rows 224 loggingwarning inputshape is undefined or nonsquare or rows is not in 128 160 192 224 weights for input shape 224 224 will be loaded as the default if inputtensor is none imginput inputshapeinputshape else if not imginput shapeinputshape else imginput inputtensor numheads 4 expansionfactor 3 x convblockimginput 32 alpha strides2 2 x transformerblockx numheads expansionfactor x depthwiseconvblockx 64 alpha depthmultiplier blockid1 x transformerblockx numheads expansionfactor x depthwiseconvblock x 128 alpha depthmultiplier strides2 2 blockid2 x transformerblockx numheads expansionfactor x depthwiseconvblockx 128 alpha depthmultiplier blockid3 x transformerblockx numheads expansionfactor x depthwiseconvblock x 256 alpha depthmultiplier strides2 2 blockid4 x transformerblockx numheads expansionfactor x depthwiseconvblockx 256 alpha depthmultiplier blockid5 x transformerblockx numheads expansionfactor x depthwiseconvblock x 512 alpha depthmultiplier strides2 2 blockid6 x transformerblockx numheads expansionfactor x depthwiseconvblockx 512 alpha depthmultiplier blockid7 x transformerblockx numheads expansionfactor x depthwiseconvblockx 512 alpha depthmultiplier blockid8 x transformerblockx numheads expansionfactor x depthwiseconvblockx 512 alpha depthmultiplier blockid9 x transformerblockx numheads expansionfactor x depthwiseconvblockx 512 alpha depthmultiplier blockid10 x transformerblockx numheads expansionfactor x depthwiseconvblockx 512 alpha depthmultiplier blockid11 x transformerblockx numheads expansionfactor x depthwiseconvblock x 1024 alpha depthmultiplier strides2 2 blockid12 x transformerblockx numheads expansionfactor x depthwiseconvblockx 1024 alpha depthmultiplier blockid13 x transformerblockx numheads expansionfactor if includetop x x layersdropoutdropout namedropoutx x layersconv2dclasses 1 1 paddingsame nameconvpredsx x layersreshapeclasses namereshape2x weights x layersactivation namepredictions x else if pooling avg x elif pooling max x globalmaxpooling2dx ensure that the model takes into account any potential predecessors of inputtensor if inputtensor is not none inputs else inputs imginput create model model trainingmodelinputs x namemobilenet02fs alpha rows load weights if weights imagenet if alpha 10 alphatext 10 elif alpha 075 alphatext 75 elif alpha 050 alphatext 50 else alphatext 25 if includetop modelname mobilenetsdtfh5 alphatext rows weightpath baseweightpath modelname weightspath datautilsgetfile modelname weightpath cachesubdirmodels else modelname mobilenetsdtfnotoph5 alphatext rows weightpath baseweightpath modelname weightspath datautilsgetfile modelname weightpath cachesubdirmodels bynametrue elif weights is not none bynametrue return model class mdtakeraslayerslayer important the channels must be zero when divided by numheads def initself numheads supermdta selfinit selfnumheads numheads selftemperature tfvariable1 for in rangeselfnumheads shapenone selfnumheads 1 1 trainabletrue def buildself inputs n h w c n h w c output of mdta feature should be added to input feature x b h w c inputsshape layers qkv conv2dfiltersc3 kernelsize1 usebiasfalse qkvconv conv2dc3 kernelsize3 paddingsame groupsc3 usebiasfalse projectout conv2dfiltersc kernelsize1 usebiasfalse temperature tfvariable1 for in rangeselfnumheads shapenone selfnumheads 1 1 trainabletrue forward q k v numorsizesplits3 axis1 divide the of channels into heads learn separate attention map q tfreshapeq 1 selfnumheads cselfnumheads h w n numheads cnumheads hw k tfreshapek 1 selfnumheads cselfnumheads h w v tfreshapev 1 selfnumheads cselfnumheads h w q k tfnnl2normalizeq axis1 tfnnl2normalizek axis1 cxc attention map instead of hwxhw when numheads1 attn tfmatmulq k transposebtrue attn multiplyattn temperature attn softmaxaxis1attn out tfmatmulattn v shape tfshapeoutk for k in range4 batch numheads cnumheads hw out tfreshapeout shape0 h w shape1shape2 out projectoutout attnv n numheads cnumheads hw return out def callself inputs return selfbuildinputs class gdfnkeraslayerslayer def initself supergdfn selfinit selfexpansionfactor 2 def buildself inputs n h w c n h w c with expansionfactorr output of gdfn feature should be added to input feature x b h w c inputsshape hiddenchannels intc selfexpansionfactor channel expansion layers projectin conv2dhiddenchannels 2 kernelsize1 usebiasfalse conv conv2dhiddenchannels 2 kernelsize3 paddingsame groupshiddenchannels 2 usebiasfalse projectout conv2dc kernelsize1 usebiasfalse forward x projectininputs n h w 2cr x convx n h w 2cr x1 x2 tfsplitx numorsizesplits2 axis1 n h w cr n h w cr gating the elementwise product of 2 parallel paths of linear transformation layers out relux1 x2 n h w cr out projectoutout n h w cr return out def callself inputs return selfbuildinputs def numheads expansionfactor n h w c n h w c shape tfshapeinputsk for k in range4 b h w c inputsshape0 inputsshape1 inputsshape2 inputsshape3 assert c numheads 0 norm1 layernormalization default axis1 attn mdtanumheads norm2 layernormalization ffn gdfn add mdta output feature inputsnorm1 norm1tfreshapeinputs 1 hw c inputsnorm1 tfreshapeinputsnorm1 1 h w c inputs inputs attninputsnorm1 add gdfn output feature inputsnorm2 norm2tfreshapeinputs 1 hw c inputsnorm2 tfreshapeinputsnorm2 1 h w c x inputs ffninputsnorm2 return x def convblockinputs filters alpha kernel3 3 strides1 1 channelaxis 1 if channelsfirst else 1 filters intfilters alpha x conv2d filters kernel paddingsame usebiasfalse stridesstrides nameconv1 inputs x nameconv1bnx return relu60 nameconv1relux def depthwiseconvblock inputs pointwiseconvfilters alpha depthmultiplier1 strides1 1 blockid1 channelaxis 1 if channelsfirst else 1 pointwiseconvfilters alpha if strides 1 1 x inputs else x zeropadding2d 0 1 0 1 nameconvpadd blockid inputs x depthwiseconv2d 3 3 paddingsame if strides 1 1 else valid stridesstrides usebiasfalse nameconvdwd blockid x x batchnormalization axischannelaxis nameconvdwdbn blockid x x relu60 nameconvdwdrelu blockidx x conv2d pointwiseconvfilters 1 1 paddingsame usebiasfalse strides1 1 nameconvpwd blockid x x batchnormalization axischannelaxis nameconvpwdbn blockid x return relu60 nameconvpwdrelu blockidx def dropoutrate numclass if inputshape224 224 3 weights imagenet else weights none basemodel includetopfalse inputshapeinputshape basemodeltrainable true x basemodeloutput headlayer activationrelu activationsoftmax predictions headlayerx this is the model we will train model outputspredictions printmodel return model inputshape 768 768 3 x inputinputshape model 03 6 out modelx savepath dmodelmdtah5 metricsacc modelsavesavepath relevant log output in the vscodeterminal shell assertionerror tried to export a function which references an untracked resource tensorflow objects eg tfvariable captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly see the information below function name captured tensor trackable referencing this tensor internal tensor tensor181720 shape dtyperesource during handling of the above exception another exception occurred in the jupyternoetebook shell valueerror traceback most recent call last in 1 metricsacc 2 in errorhandlerargs kwargs 68 to get the full stack trace call 69 70 raise from none 71 finally 72 del filteredtb in encodeself o 197 exceptions arent as detailed the list call should be roughly 198 equivalent to the pysequencefast that join would do 199 chunks selfiterencodeo oneshottrue 200 if not isinstancechunks list tuple 201 chunks listchunks in iterencodeself o oneshot 255 selfkeyseparator selfitemseparator selfsortkeys 256 selfskipkeys oneshot 257 return iterencodeo 0 258 259 def default encoder indent floatstr valueerror unable to serialize 4 1 1 dtypetffloat32 trainabletrue aliasidnone to json because the typespec class has not been registered"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncould not load dynamic library libcublasltso12 dlerror libcublasltso12 cannot open shared object file no such file or directory\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code no os platform and distribution linux ubuntu 2310 mobile device no response python version 311 bazel version no response gcccompiler version no response cudacudnn version 11801893281cuda121 gpu model and memory nvidia geforce gtx 960m 4096mib current behavior running the mobilenet from keras included by tensorflow leads to the following error could not load library libcublasltso12 error libcublasltso12 cannot open shared object file no such file or directory abgebrochen speicherabzug geschrieben standalone code to reproduce the issue shell python c from import mobilenet import numpy as np m mobilenet relevant log output shell could not load library libcublasltso12 error libcublasltso12 cannot open shared object file no such file or directory abgebrochen speicherabzug geschrieben"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow distributed training works for at most 2 gpus\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2120 custom code yes os platform and distribution linux ubuntu 2204 mobile device no response python version 3916 bazel version no response gcccompiler version no response cudacudnn version cuda 118 cudnn 860163 gpu model and memory no response current behavior i have 8 nvidia h100s on this system below is the output of nvidiasmi image the following code works as intended if gpus includes at most 2 gpus image in the relevant log output section i have the error log from running the code with 3 gpus in the gpus list please let me know if you need any additional information standalone code to reproduce the issue shell import tensorflow as tf gpus gpu0 gpu1 gpu2 strategy with strategyscope model inputshape1 modelcompilelossmse optimizersgd dataset 1repeat100batch16 modelfitdataset relevant log output shell 20230717 232831469519 i onednn custom operations are on you may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders to turn them off set the environment variable tfenableonednnopts0 20230717 232831516738 i this tensorflow binary is optimized to use available cpu instructions in performancecritical operations to enable the following instructions avx2 avx512f avx512vnni avx512bf16 avxvnni amxtile amxint8 amxbf16 fma in other operations rebuild tensorflow with the appropriate compiler flags 20230717 232831972313 w tftrt warning could not find tensorrt 20230717 232835178825 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232835181183 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232835183528 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232835185905 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232835188234 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232835190559 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232835192895 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232835195198 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836609484 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836610685 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836611908 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836613166 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836614370 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836615584 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836616799 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836617975 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836680264 i created device with 78938 mb memory device 0 name nvidia h100 80gb hbm3 pci bus id 000019000 compute capability 90 20230717 232836682112 i created device with 78938 mb memory device 1 name nvidia h100 80gb hbm3 pci bus id 00003b000 compute capability 90 20230717 232836683772 i created device with 78938 mb memory device 2 name nvidia h100 80gb hbm3 pci bus id 00004c000 compute capability 90 20230717 232836685499 i created device with 78938 mb memory device 3 name nvidia h100 80gb hbm3 pci bus id 00005d000 compute capability 90 20230717 232836687179 i created device with 78938 mb memory device 4 name nvidia h100 80gb hbm3 pci bus id 00009b000 compute capability 90 20230717 232836688884 i created device with 78938 mb memory device 5 name nvidia h100 80gb hbm3 pci bus id 0000bb000 compute capability 90 20230717 232836690581 i created device with 78938 mb memory device 6 name nvidia h100 80gb hbm3 pci bus id 0000cb000 compute capability 90 20230717 232836692292 i created device with 78938 mb memory device 7 name nvidia h100 80gb hbm3 pci bus id 0000db000 compute capability 90 20230717 232839806560 i devicecpu0 debug info executor start aborting this does not indicate an error and you can ignore this message invalidargument you must feed a value for placeholder tensor placeholder1 with dtype float and shape 1 node placeholder1 20230717 232839806723 i devicecpu0 debug info executor start aborting this does not indicate an error and you can ignore this message invalidargument you must feed a value for placeholder tensor placeholder0 with dtype float and shape 1 node placeholder0 20230717 232839807452 w auto sharding policy will apply data sharding policy as it failed to apply file sharding policy because of the following reason found an unshardable source dataset name tensordataset2 op tensordataset input placeholder0 input placeholder1 attr key toutputtypes value list type dtfloat type dtfloat attr key cardinality value i 1 attr key metadata value s n017tensordataset0 attr key outputshapes value list shape dim size 1 shape dim size 1 experimentaltype typeid tftproduct args typeid tftdataset args typeid tftproduct args typeid tfttensor args typeid tftfloat args typeid tfttensor args typeid tftfloat 20230717 232839823305 i devicecpu0 debug info executor start aborting this does not indicate an error and you can ignore this message invalidargument you must feed a value for placeholder tensor placeholder1 with dtype float and shape 1 node placeholder1 20230717 232839823469 i devicecpu0 debug info executor start aborting this does not indicate an error and you can ignore this message invalidargument you must feed a value for placeholder tensor placeholder1 with dtype float and shape 1 node placeholder1 20230717 232840010671 i devicecpu0 debug info executor start aborting this does not indicate an error and you can ignore this message invalidargument you must feed a value for placeholder tensor placeholder1 with dtype float and shape 1 node placeholder1 20230717 232840010843 i devicecpu0 debug info executor start aborting this does not indicate an error and you can ignore this message invalidargument you must feed a value for placeholder tensor placeholder0 with dtype float and shape 1 node placeholder0 20230717 232848599915 i xla service 0x7fe600008ff0 initialized for platform cuda this does not guarantee that xla will be used devices 20230717 232848599956 i streamexecutor device 0 nvidia h100 80gb hbm3 compute capability 90 20230717 232848599964 i streamexecutor device 1 nvidia h100 80gb hbm3 compute capability 90 20230717 232848599971 i streamexecutor device 2 nvidia h100 80gb hbm3 compute capability 90 20230717 232848599977 i streamexecutor device 3 nvidia h100 80gb hbm3 compute capability 90 20230717 232848599983 i streamexecutor device 4 nvidia h100 80gb hbm3 compute capability 90 20230717 232848599988 i streamexecutor device 5 nvidia h100 80gb hbm3 compute capability 90 20230717 232848599994 i streamexecutor device 6 nvidia h100 80gb hbm3 compute capability 90 20230717 232848600003 i streamexecutor device 7 nvidia h100 80gb hbm3 compute capability 90 20230717 232848636269 e could not create cudnn handle 20230717 232848636335 e possibly insufficient driver version 535543 20230717 232848649063 e could not create cudnn handle 20230717 232848649131 e possibly insufficient driver version 535543 20230717 232848711026 i loaded cudnn version 8600 20230717 232848712282 e internal retcheck failure dnn nullptr begin stack trace const xlaautotuneresults const const const stduniqueptr xlabackend const bool const absllts20220623span const const absllts20220623span const const const const const const stdvector const const tslmutex const const const stdvector const const xlalocalexecutable stdfunction stdfunction const end stack trace 20230717 232848712483 w oprequires failed at xlaopscc362 internal retcheck failure dnn nullptr 20230717 232848712506 i debug info executor start aborting this does not indicate an error and you can ignore this message internal retcheck failure dnn nullptr node 20230717 232848727426 e internal retcheck failure dnn nullptr begin stack trace const xlaautotuneresults const const const stduniqueptr xlabackend const bool const absllts20220623span const const absllts20220623span const const const const const const stdvector const const tslmutex const const const stdvector const const xlalocalexecutable stdfunction stdfunction const end stack trace 20230717 232848727590 w oprequires failed at xlaopscc362 internal retcheck failure dnn nullptr 20230717 232848727609 i debug info executor start aborting this does not indicate an error and you can ignore this message internal retcheck failure dnn nullptr node 20230717 232848728128 e could not create cudnn handle 20230717 232848728185 e possibly insufficient driver version 535543 20230717 232848740946 w falling back to the cuda driver for ptx compilation ptxas does not support cc 90 20230717 232848740965 w used ptxas at ptxas 20230717 232848742906 e could not create cudnn handle 20230717 232848742961 e possibly insufficient driver version 535543 20230717 232848770994 i compiled cluster using xla this line is logged at most once for the lifetime of the process 20230717 232848806579 e internal retcheck failure dnn nullptr begin stack trace const xlaautotuneresults const const const stduniqueptr xlabackend const bool const absllts20220623span const const absllts20220623span const const const const const const stdvector const const tslmutex const const const stdvector const const xlalocalexecutable stdfunction stdfunction const end stack trace 20230717 232848806809 w oprequires failed at xlaopscc362 internal retcheck failure dnn nullptr 20230717 232848818268 e internal retcheck failure dnn nullptr begin stack trace const xlaautotuneresults const const const stduniqueptr xlabackend const bool const absllts20220623span const const absllts20220623span const const const const const const stdvector const const tslmutex const const const stdvector const const xlalocalexecutable stdfunction stdfunction const end stack trace 20230717 232848818437 w oprequires failed at xlaopscc362 internal retcheck failure dnn nullptr 20230717 232848858099 i debug info executor start aborting this does not indicate an error and you can ignore this message internal retcheck failure dnn nullptr node traceback most recent call last file line 8 in modelfitdataset file line 70 in errorhandler raise from none file line 52 in quickexecute tensors devicename opname graph execution error detected at node defined at most recent call last file line 8 in modelfitdataset file line 65 in errorhandler return fnargs kwargs file line 1685 in fit tmplogs file line 1284 in trainfunction return stepfunctionself iterator file line 1268 in stepfunction outputs argsdata file line 1250 in file line 1245 in applygradtoupdatevar return var idselfvarkeyvar node detected at node defined at most recent call last file line 8 in modelfitdataset file line 65 in errorhandler return fnargs kwargs file line 1685 in fit tmplogs file line 1284 in trainfunction return stepfunctionself iterator file line 1268 in stepfunction outputs argsdata file line 1250 in file line 1245 in applygradtoupdatevar return var idselfvarkeyvar node detected at node defined at most recent call last file line 8 in modelfitdataset file line 65 in errorhandler return fnargs kwargs file line 1685 in fit tmplogs file line 1284 in trainfunction return stepfunctionself iterator file line 1268 in stepfunction outputs argsdata file line 1250 in file line 1245 in applygradtoupdatevar return var idselfvarkeyvar node 3 root errors found 0 internal retcheck failure dnn nullptr node 1 internal retcheck failure dnn nullptr node 2 internal retcheck failure dnn nullptr node 0 successful operations 0 derived errors ignored"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nthe return value when layernormalization takes zero vectors as input\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version tf2120 custom code yes os platform and distribution macos mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior output tftensor 0 0 0 0 0 0 0 0 0 0 0 0 shape3 4 dtypefloat32 tftensor nan nan nan nan nan nan nan nan nan nan nan nan shape3 4 dtypefloat32 tftensor 0 0 0 0 0 0 0 0 0 0 0 0 shape3 4 dtypefloat32 document epsilon is used to avoid division by zero errors but when layernormalization takes a zero vector as input it returns nan and batchnormalization returns 0 （psepsilon is documented as a small floatingpoint numberin our experiments we found that epsilon works with larger floatingpoint numbersis this a bit vague） standalone code to reproduce the issue shell standalone code import tensorflow as tf data tfzerosshape3 4 printdata layer1 epsilon0 output1 layer1data printoutput1 layer2 epsilon0 output2 layer2data printoutput2 relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntfmathreducesums name property doesnt change in modelcompile\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version tf 213 custom code no os platform and distribution linux ubuntu 18046 lts mobile device no response python version 310 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior out 05 tffloat32 axis1 keepdimstrue namefinal model outputsposition out modelsummary tfmathreducesum tfoplambda none 1 0 tfcast00 standalone code to reproduce the issue shell input layersinputshape3 position layersdense5 sigmoid namepositioninput out 05 tffloat32 axis1 keepdimstrue namefinal model outputsposition out modelsummary relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ncant save compiled model as tf\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2130 custom code yes os platform and distribution mac mini m1 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory m1 gpu and 8gb ram current behavior cant save compile model as a tf file standalone code to reproduce the issue shell import tensorflow as tf class def initself dmodel f05 warmupsteps4000 superinit selfdmodel dmodel selfdmodel tfcastselfdmodel tffloat32 selfwarmupsteps warmupsteps selff f def callself step step tfcaststep dtypetffloat32 arg1 tfmathrsqrtstep arg2 step selfwarmupsteps 15 return selff tfmathminimumarg1 arg2 def getconfigself config dmodel selfdmodel warmupsteps selfwarmupsteps f selff return config model tfkerassequential tfkeraslayersdense10 learningrate customschedule1024 optimizer beta109 beta2098 epsilon1e5 modelcompile optimizeroptimizer lossmse metricsaccuracy modelsavemodeltf relevant log output shell traceback most recent call last file line 40 in modelsavemodeltf file line 70 in errorhandler raise from none file line 199 in encode chunks selfiterencodeo oneshottrue file line 257 in iterencode return iterencodeo 0 typeerror unable to serialize 10240 to json unrecognized type"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nsegmentation fault\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior python trainpy x datatrain2xnpy y datatrain2ynpy standalone code to reproduce the issue shell segmentation fault but i use tensorflow2120 this problem does not occur relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nthe required input dimension and type changed after conversion of sac algorithm\n1 system information os platform and distribution linux ubuntu 2204 tensorflow installation pip package tensorflow library tensorflow 2121 2 code most of them i followed the sac minitaur tutorial here but with some modification to fit with my environment also with additional function to convert to tflite 3 failure after conversion the observation spec reduced and changed from shape 5 float32 to shape1 int32 in this conversion observation spec dtypedtypefloat32 nameobservation minimum00 maximum10 reward spec arrayspecshape dtypedtypefloat32 namereward action spec dtypedtypefloat32 nameaction time step timestep discount array1 dtypefloat32 observation array009387773 045744053 08837498 084389937 05 dtypefloat32 reward array0 dtypefloat32 steptype array0 dtypeint32 step 0 averagereturn 0000758 averageepisodelength 120449997 step 100 loss 029556670784950256 step 200 loss 042344561219215393 step 300 loss 04886786639690399 step 400 loss 05600587129592896 step 500 loss 06421032547950745 step 600 loss 07184216380119324 step 700 loss 0785315752029419 step 800 loss 08600273728370667 step 900 loss 09031595587730408 step 1000 averagereturn 1299191 averageepisodelength 115500000 step 1000 loss 0990966796875 policy saved at convert to tflite input shape arg0discount tensorspecshapenone dtypetffloat32 name0discount arg0observation tensorspecshapenone 5 dtypetffloat32 name0observation arg0reward tensorspecshapenone dtypetffloat32 name0reward arg0steptype tensorspecshapenone dtypetfint32 name0steptype info created tensorflow lite xnnpack delegate for cpu input details name action0steptype0 index 0 shape array1 dtypeint32 shapesignature array1 dtypeint32 dtype quantization 00 0 scales array dtypefloat32 zeropoints array dtypeint32 quantizeddimension 0 sparsityparameters name action0discount0 index 1 shape array1 dtypeint32 shapesignature array1 dtypeint32 dtype quantization 00 0 scales array dtypefloat32 zeropoints array dtypeint32 quantizeddimension 0 sparsityparameters name action0observation0 index 2 shape array1 5 dtypeint32 shapesignature array1 5 dtypeint32 dtype quantization 00 0 scales array dtypefloat32 zeropoints array dtypeint32 quantizeddimension 0 sparsityparameters name action0reward0 index 3 shape array1 dtypeint32 shapesignature array1 dtypeint32 dtype quantization 00 0 scales array dtypefloat32 zeropoints array dtypeint32 quantizeddimension 0 sparsityparameters output details name index 92 shape array1 1 dtypeint32 shapesignature array1 1 dtypeint32 dtype quantization 00 0 scales array dtypefloat32 zeropoints array dtypeint32 quantizeddimension 0 sparsityparameters input data 0 input shape 1 output data 06 the converted model has less dimension input and different input type required"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nattributeerror module tensorflowdatasets has no attribute load\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version 2100 os platform and distribution windows 11 mobile device no response python version 31012 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior i cannot access ucf101 and download tensorflow 210 python 31112 tensorflowdatasets 492 standalone code to reproduce the issue shell import tensorflowdatasets ucf101 relevant log output shell attributeerror module tensorflowdatasets has no attribute load"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntfdata train model worse than numpy data\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version tf 210 custom code yes os platform and distribution linux ubuntu 2204 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version 120 gpu model and memory no response current behavior 1 used tfdata train model best val loss is 014 and the code is image traindataset1 traindataset2 traindataset traindataset2 testdataset1 testdataset2 testdataset testdataset2 batchsize 256 shufflebuffersize 1000 traindataset testdataset model modelinputs inputs outputs s2s modelcompileloss mse optimizeradam metricsmape earlystopping patience4 modelfittraindataset epochs20 batchsize256 validationdata testdataset 2 used numpy array train model best val loss is 010 the code is image model modelinputs inputs outputs s2s modelcompileloss mse optimizeradam metricsmape earlystopping patience4 nparrayytrain epochs20 batchsize256 validationdata nparrayytest 3 val loss worse more standalone code to reproduce the issue shell tfdata bugs at version 210 relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nexample code has memory leak\nissue type documentation bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 265 custom code yes os platform and distribution linux centos 76 mobile device linux centos 76 python version 37 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior in the demo code tensor outputtensor was allocated but the memory was not free include using namespace tensorflow class zerooutop public opkernel public explicit context opkernelcontext void context override grab the input tensor const tensor inputtensor contextinput0 auto input inputtensorflat create an output tensor tensor outputtensor null oprequiresokcontext inputtensorshape outputtensor auto outputflat outputtensorflat set all but the first element of the output tensor to 0 const int n inputsize for int i 1 i n i outputflati 0 preserve the first input value if possible if n 0 outputflat0 input0 standalone code to reproduce the issue shell repeatedly call the zerooutop youll see the memory continue to increase relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntfimageadjustgamma outputs incorrect error message for string input\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2120 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior when giving tfimageadjustgamma a string inputs it outputs misleading error messages valueerror failed to convert a numpy array to a tensor unsupported object type float standalone code to reproduce the issue shell import tensorflow as tf t tfconstant dtypetfstring i tfimageadjustgammat gamma01 relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nis not an attribute of inputlib enginedataadapterpy\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version 213 custom code no os platform and distribution no response mobile device no response python version 3109 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior im new to machine learning and i was setting up this network with just one layer with only one neuron inside it just to see how it works setting up went fine the error occured when i asked it to predict im not sure what exactly happend but apparently a non existent attribute was passed to isinstance in the file line 1699 ive replaced by the wrong one by the one suggested and worked as expected standalone code to reproduce the issue shell import numpy as np import tensorflow as tf from import dense input from import sequential from import sigmoid import logging xtrain nparray0 1 2 3 4 5 ytrain nparray0 0 0 1 1 1 model sequential inputshape1 dense1 activationsigmoid name l1 modelsummary setting the weights and bias of the neuron logisticlayer modelgetlayerl1 setw nparray2 setb nparray45 setb performance test a1 this line caused the error printa1 alog setb printalog relevant log output shell line 1699 in isdistributeddataset return isinstanceds attributeerror module has no attribute did you mean"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nmy customized op gives incorrect outputs on gpus since tfnightly 2130dev20230413\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 213 custom code yes os platform and distribution fedora 36 mobile device no response python version 3114 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior i have a complex program based on tensorflow with several customized ops these ops were created following yesterday tf 2130 was released but after i upgraded to 2130 i found that one of my customized op gives incorrect results on gpus and still has the correct outputs on cpus then i tested many tfnightly versions and found that tfnightly 2130dev20230412 works but tfnightly 2130dev20230413 fails so the situation is shown in the following table version cpu gpu tensorflow 2120 correct correct tensorflow 2130 correct incorrect tfnightly 2130dev20230412 correct correct tfnightly 2130dev20230413 correct incorrect id like to know what changed between april 12th and 13th related to the customized ops this can be a breaking change to downstream applications or an internal bug thanks here is a quick link for commits between april 12th and 13th standalone code to reproduce the issue shell indeed the reason is still unclear to me so it is hard to create a minimal example the code of our customized ops is relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\npython 370 is incompitable with tensorflow 2110\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version 2110 custom code yes os platform and distribution windows 10 educion mobile device no response python version 370 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior image python 370 throws an exception that it cannot import ordereddict from typings the fix was downgrading from tensorflow 2110 to tensorflow 2100 orderd dict is supported starting from python 372 by default pip installs 2110 for python 370 which is not supported the doc states that 370 is supported standalone code to reproduce the issue shell 1 install python 370 2 pip install tensorflow2110 3 inside python shell type import tensorflow as tf 4 exception will rise relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntfdata dataset warning when caching validation set you should use instead\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version tf 290 custom code yes os platform and distribution ubuntu 2204 lts mobile device no response python version 395 bazel version no response gcccompiler version no response cudacudnn version gpu model and memory nvidia a100sxm480gb current behavior whenever i use the cache function on my tfdata validation dataset i get the warning below when i use the cache only and without the validation set no warning appears standalone code to reproduce the issue shell dataset tftensorspecshapes0 dtypetffloat32 tftensorspecshapes1 dtypetffloat32 valdataset tftensorspecshapes0 dtypetffloat32 tftensorspecshapes1 dtypetffloat32 dataset valdataset strategy with strategyscope m unet28builds0 epochsargsep stepsperepoch spevalidationsteps relevant log output shell 20230703 134714532355 w the calling iterator did not fully read the dataset being cached in order to avoid unexpected truncation of the dataset the partially cached contents of the dataset will be discarded this can happen if you have an input pipeline similar to you should use instead"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nnot correct result from tfsplit\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version tf 2829210 custom code no os platform and distribution both on mac and on ubuntu mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior tryng to split a four axes tensor i got some unexpected zeros in the splitted tensors this behaviour is not presented in the tf 212 is an old bug standalone code to reproduce the issue shell import tensorflow as tf vectfones176831400 printsplitted zeros have occured in the tensor relevant log output shell no"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ninclude includefloat8h from mldtypes is missing\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source source tensorflow version 2140 custom code yes os platform and distribution mobile device no python version 38 bazel version na gcccompiler version nr cudacudnn version nr gpu model and memory nr current behaviour create a testcc include compile it with flags provided by tensorflow getcompileflags dglibcxxusecxx11abi1 stdc17 getlinkflags g wlrorigin wlrpathorigin stdc17 dndebug shared testcc o tmptestso fpic dglibcxxusecxx11abi1 stdc17 iusrinclude iusrlocalcudainclude o2 the result is in file included from from from from from from from from from fatal error includefloat8h no such file or directory 19 include includefloat8h from mldtypes it is probably caused by this pr either should have include from mldtypes or getcompileflags should include standalone code to reproduce the issue shell as above relevant log output shell as above"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nmodel running on cpu when using nnapi even with false\nclick to expand issue type bug have you reproduced the bug with tf nightly no source binary tensorflow version tensorflowlite 2120 custom code yes os platform and distribution no response mobile device google pixel 7 python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour i am running the openai whisper tiny model on android using the tensorflow lite nnapi delegate it seems to be running on the cpu instead of the hardware accelerator on the google pixel 7 even though false is set standalone code to reproduce the issue shell false relevant log output shell w access denied finding property romediatekplatform w access denied finding property rochipname w access denied finding property rohardwarechipname i created tensorflow lite xnnpack delegate for cpu"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nnoclassdeffounderror not found\nclick to expand issue type bug have you reproduced the bug with tf nightly false source source tensorflow version tf212 custom code yes os platform and distribution android 12 mobile device android 12 python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour the gpu is not being used correctly standalone code to reproduce the issue shell implementation implementation interpreteroptions options new interpreteroptions gpudelegate file file new interpreter interpreter new interpreterfile options relevant log output shell eandroidruntime fatal exception main process pid 13553 failed resolution of at at at at at at at at at at at at at at method at at caused by didnt find class on path dexpathlistzip file systemlib64 systemsystemextlib64 at at at at at at at at at at at at at at at at at method at at"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntf213 breaks\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source pypi tensorflow version tf2130rc2 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour when building tf addons for tf213 were noticing that our ability to register custom keras objects as serializable has been broken class def initself units kwargs superinitunits kwargs standalone code to reproduce the issue shell here it is shown as working in tf212 here it breaks in tf213 relevant log output shell valueerror unknown layer mydense please ensure you are using a and that this object is included in the scope see for details"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nerror to run tf\nclick to expand issue type bug have you reproduced the bug with tf nightly no source source tensorflow version 210 custom code yes os platform and distribution windowsx 11 mobile device no response python version 3109 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour when i try to run tensorflow import him i get this error image standalone code to reproduce the issue shell import tensorflow as tf relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nxla unit tests fail to build on gcc\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source source tensorflow version git head custom code no os platform and distribution ubuntu 2004 mobile device na python version 3813 bazel version 610 gcccompiler version 1021 cudacudnn version na gpu model and memory na current behaviour 3 unit tests fail to build and one fails with error standalone code to reproduce the issue shell bazel test relevant log output shell error compiling failed exit 1 gcc failed error executing command from target cd exec env cachebuster20220325 pwdprocselfcwd tf2behavior1 dt10usrbingcc md mf deigenmpl2only dhavesysuioh dtfusesnappy iquote iquote iquote externaleigenarchive iquote iquote iquote iquote externalnsync iquote iquote iquote iquote iquote iquote externalsnappy iquote iquote iquote iquote iquote iquote iquote iquote iquote iquote externalzlib iquote iquote externalbazeltools iquote isystem externaleigenarchive isystem isystem externalnsyncpublic isystem isystem isystem isystem isystem isystem isystem isystem isystem isystem isystem isystem isystem isystem externalzlib isystem ddateredacted dtimestampredacted dtimeredacted fpie ufortifysource dfortifysource1 fstackprotector wall fnoomitframepointer nocanonicalprefixes dndebug g0 o2 ffunctionsections fdatasections wnoall wnoextra wnodeprecated wnoignoredattributes wnoarraybounds wunusedresult werrorunusedresult wswitch werrorswitch mtunegeneric marcharmv8a o3 stdc17 sysrootdt10 c o configuration execution platform in member function virtual void error call of overloaded tileassignment is ambiguous 3488 tileassignment 2 in file included from from from from from note candidate 173 explicit dims note candidate 172 explicit iota iotastdmoveiota and more"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntf lite converter produces outputs in an incorrect order when multiple outputs are present\n1 system information os platform and distribution eg linux ubuntu 1604 linux ubuntu 2004 tensorflow installation pip package or built from source pip tensorflow library version if pip package or github sha if built from source 2140dev20230622 2 code this is the minimized code to reproduce the issue python import tensorflow as tf import numpy as np x1 tfconstant1 shape11 class modeltfkerasmodel def initself supermodel selfinit def callself x1 x2 tfeye1 x3 tfeye2 x4 tfeye1 return x2 x3 x4 m model expectedvalue mx1 converter tflitemodel converterconvert def inputdata interpreter inputdetails outputdetails for i in rangeleninputdata inputdatai interpreterinvoke outputdata for i in return outputdata actualvalue outputs printfexpected output1 expectedvalue0numpy printflite output1 actualvalue0 print printfexpected output2 expectedvalue1numpy printflite output2 actualvalue1 print printfexpected output3 expectedvalue2numpy printflite output3 actualvalue2 wrong order output ir 3 failure after conversion output incorrect order expected output1 1 lite output1 1 expected output2 1 0 0 1 lite output2 1 expected output3 1 lite output3 1 0 0 1 lite ir subgraph0 maint0 t1 t1 t2 tensors of subgraph0 shapesignature1 1 typefloat32 t1partitionedcall0 shape1 1 typefloat32 ro 4 bytes buffer 2 data1 t2partitionedcall1 shape2 2 typefloat32 ro 16 bytes buffer 3 data1 0 0 1 tf lite converter produces wrong outputs in the lite ir the ouput should be t1 t2 t1 instead of t1 t1 t2"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nfloat8 both e4m3fn and e5m2 missing from numbertype\nissue type bug have you reproduced the bug with tf nightly no source binary tensorflow version 2120 custom code yes os platform and distribution mobile device no response python version 396 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour fp8 datatypes are missing from knumbertypes in and also missing from tfcallfloattypesm in this causes simple ops like slice transpose split etc to raise notfounderror standalone code to reproduce the issue python import tensorflow as tf from import dtypes a tfconstant12345678 23456789 34567891 45678912 56789123 67891234 dtypedtypesfloat16 printa afp8 tfcasta dtypesfloat8e4m3fn printafp8 b afp812 b tftransposeafp8 1 0 relevant log output could not find device for node node stridedslice tdtfloat8e4m3fn beginmask0 ellipsismask0 endmask0 newaxismask0 shrinkaxismask0 all kernels registered for op stridedslice devicexlacpujit index in dtint32 dtint16 dtint64 t in dtfloat dtdouble dtint32 dtuint8 dtint16 930109355527764061 dthalf dtuint32 dtuint64 dtfloat8e5m2 dtfloat8e4m3fn devicecpu t in dtuint64 devicecpu t in dtint64 devicecpu t in dtuint32 devicecpu t in dtuint16 devicecpu t in dtint16 devicecpu t in dtuint8 devicecpu t in dtint8 devicecpu t in dtint32 devicecpu t in dthalf devicecpu t in dtbfloat16 devicecpu t in dtfloat devicecpu t in dtdouble devicecpu t in dtcomplex64 devicecpu t in dtcomplex128 devicecpu t in dtbool devicecpu t in dtstring devicecpu t in dtresource devicecpu t in dtvariant devicecpu t in dtqint8 devicecpu t in dtquint8 devicecpu t in dtqint32 devicedefault t in dtint32 opstridedslice name stridedslice could not find device for node node transpose tpermdtint32 all kernels registered for op transpose devicexlacpujit tperm in dtint32 dtint64 t in dtfloat dtdouble dtint32 dtuint8 dtint16 930109355527764061 dthalf dtuint32 dtuint64 dtfloat8e5m2 dtfloat8e4m3fn devicecpu t in dtuint64 devicecpu t in dtint64 devicecpu t in dtuint32 devicecpu t in dtuint16 devicecpu t in dtint16 devicecpu t in dtuint8 devicecpu t in dtint8 devicecpu t in dtint32 devicecpu t in dthalf devicecpu t in dtbfloat16 devicecpu t in dtfloat devicecpu t in dtdouble devicecpu t in dtcomplex64 devicecpu t in dtcomplex128 devicecpu t in dtbool devicecpu t in dtstring devicecpu t in dtresource devicecpu t in dtvariant optranspose"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nandroid gpu delegate failed to build program executable\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source source tensorflow version 210 or 211 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour a bug happened i test gpu delegate on oppo r9 will reture error value error failed to build program executable build program failure3526 error opencl extension clkhr3dimagewrites is not supported pragma opencl extension clkhr3dimagewrites enable error compiler frontend failed error code 58 error falling back to opengl error tflitegpudelegate init openglbased api disabled error tflitegpudelegate prepare delegate is not initialized error node number 100 tflitegpudelegatev2 failed to prepare error restored original execution plan after delegate application failure tflite gpu delegate create failed2 standalone code to reproduce the issue shell oppo r9 is produced in 2016 year relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ngetfile raises exception if the contentlength is unknown\nclick to expand issue type bug have you reproduced the bug with tf nightly no source binary tensorflow version 2110 custom code no os platform and distribution ubuntu 22042 lts mobile device no response python version 3106 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour calling getfile on a url that doesnt indicate the contentlength causes an exception standalone code to reproduce the issue shell import tensorflow as tf origin printp relevant log output shell downloading data from 8192unknown 0s 0ussteptraceback most recent call last file homekentenvmlsrcf3py line 3 in file line 300 in getfile urlretrieveorigin fpath dlprogbar file line 86 in urlretrieve for chunk in chunkreadresponse reporthookreporthook file line 78 in chunkread reporthookcount chunksize totalsize file line 294 in call file line 252 in update bar 7dunknown current typeerror d format a real number is required not nonetype"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nsome parameters are missing type descriptions\nclick to expand issue type documentation bug have you reproduced the bug with tf nightly yes source source tensorflow version tf 2120 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour html xmlns link idmainfile relmainfile link relfilelist table page margin75in 7in 75in 7in msoheadermargin3in msofootermargin3in font5 colorwindowtext fontsize90pt fontweight400 fontstylenormal textdecorationnone fontfamily等线 msofontcharset134 tr msoheightsourceauto col msowidthsourceauto br td paddingtop1px paddingright1px paddingleft1px msoignorepadding colorblack fontsize110pt fontweight400 fontstylenormal textdecorationnone fontfamily等线 msofontcharset134 textaligngeneral verticalalignbottom bordernone msopatternauto msoprotectionlocked visible whitespacenowrap msorotate0 ruby rubyalignleft rt colorwindowtext fontsize90pt fontweight400 fontstylenormal textdecorationnone fontfamily等线 msofontcharset134 msochartypenone displaynone api lack of type desciption params tfsparsebincount values tfkeraslayersinput tensor inputtensor tfmathaddn inputs inputtensor tfdevice devicename identifier metrics tfexpanddims input inputtensor tfsignalframe signal ytrue 、 ypred ytrue 、 ypred ytrue 、 ypred tfkeraslosseslogcosh ytrue 、 ypred inputtensor ytrue 、 ypred expectedcardinality ytrue 、 ypred tflossessquaredhinge ytrue 、 ypred x、y、sampleweight x tfnndepthtospace input tfgathernd params tfzeroslike input inputtensor metrics tfstack values tfensureshape x tfroll input x tflinalgsetdiag input、diagonal、k tfmathbincount arr、weights tfconcat values inputtensor ytrue 、 ypred tfrandomcategorical logits x x tfpad tensor gain inputtensor tfrepeat input image tfsplit value y tfscatternd updates input bands、rhs tfoneslike input tfnestflatten structure x input image devices tfsize input tfimageresize images tftile input inputtensor ytrue 、 ypred gain image tfraggedrange starts、limits、deltas tfreshape tensor tflosseslogcosh ytrue 、 ypred inputtensor tfnnmoments x inputtensor image ytrue 、 ypred controlinputs images tfimagergbtoyiq images inputtensor tfraggedbooleanmask data、mask tfimagerandomhue image tfimageadjustgamma image tfistensor x gain tfmathpolyval coeffs、x tfioserializetensor tensor image tfonehot indices tflinalgdiagpart input、paddingvalue、 image tfbooleanmask tensor、mask tftranspose a tfimageflipupdown image ytrue 、 ypred tfbroadcastto input value ytrue 、 ypred image image x inputtensor tfidentity input tfgather params inputtensor tfkeraslayersmasking maskvalue ytrue 、 ypred tflinalgbandpart input ytrue 、 ypred image tfimagetranspose image tfstopgradient input tfstringsbytessplit input ytrue 、 ypred image inputtensor ytrue 、 ypred tfnnembeddinglookup params tfmathreducevariance inputtensor data tfnnl2normalize x ytrue 、 ypred inputtensor identifier gain tfdivide x、y tfmathtopk input ytrue 、 ypred image ytrue 、 ypred inputtensor tfclipbyvalue t tftypespecfromvalue value ytrue 、 ypred tensor、indices tfequal x、y images image tfimagergbtohsv images tfconverttotensor value ytrue 、 ypred x tfslice input tfimageadjusthue image tfmathargmax input tfreversesequence input ytrue 、 ypred ytrue 、 ypred tfsqueeze input tfmathequal x、y tfmathdivide x、y tfunstack value inputtensor inputtensor x inputtensor x ytrue 、 ypred ytrue 、 ypred ytrue 、 ypred ytrue 、 ypred ytrue 、 ypred inputtensor x tfimageflipleftright image inputtensor tfmathreducemin inputtensor inputtensor tfmathnotequal x、y tfimagerot90 image inputtensor image inputtensor inputtensor ytrue 、 ypred tfsparsecross inputs ytrue 、 ypred image standalone code to reproduce the issue shell many parameters are not for any type of value so the allowed types should be clearly marked in the document relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntensorboard histogram onehot operation causing resourceexhauseerror oom\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source source tensorflow version 28 custom code yes os platform and distribution linux ubuntu 2004 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour im trying to train a vgg16 model im using a sample dataset of 4000 300x300 images in 14 classes and running my code on a google vm using an nvidia l4 gpu with 20gb of memory i am running python 37 tf version 211 and cuda version 121 my data is stored in gcs when i run the model with the following tensorboard callback tensorboardcallback histogramfreq1 i get this error at the end of the first epoch 20230614 195121248476 w allocator mklcpu ran out of memory trying to allocate 2297gib rounded to 24662507520requested by op onehot if the cause is memory fragmentation maybe the environment variable will improve the situation functionnode oom when allocating tensor with shape10276044830 and type double on by allocator mklcpu oponehot the error traces back to the tensorboard histogram object traceback most recent call last in 1 fit model 2 history modelfittrainds validationdatavalds epochs5 in errorhandlerargs kwargs 68 to get the full stack trace call 69 70 raise from none 71 finally 72 del filteredtb in histogramname data step buckets description 198 tensorlazytensor 199 stepstep 200 201 202 in callself 64 elif selftensor is none 65 selftensor 66 selftensor selftensorcallable 67 return selftensor 68 in lazytensor 192 193 def lazytensor 194 return bucketsdata buckets 195 196 return tfsummarywrite in bucketsdata bucketcount 291 292 293 return tfcondisempty whenempty whennonempty in whennonempty 288 289 return tfcond 290 hassinglevalue whensinglevalue whenmultiplevalues 291 292 in whenmultiplevalues 257 see for details 258 onehots tfonehot 259 clampedindices depthbucketcount dtypetffloat64 260 261 bucketcounts tfcast functionnode oom when allocating tensor with shape10276044830 and type double on by allocator mklcpu oponehot interestingly it seems to be calling tfonehot and blowing up the gpu memory with a massive tensor regardless of whether i train the model with integer labels and spare categorical cross entropy or if i train it with one hot labels and cross entropy i dont really understand what the tensor contains because its dimensions neither relate to the number of training examples or classes that i am using standalone code to reproduce the issue shell tensorboardcallback histogramfreq1 i get this error at the end of the first epoch 20230614 195121248476 w allocator mklcpu ran out of memory trying to allocate 2297gib rounded to 24662507520requested by op onehot if the cause is memory fragmentation maybe the environment variable will improve the situation functionnode oom when allocating tensor with shape10276044830 and type double on by allocator mklcpu oponehot relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntftestgpudevicename leads to soft lockup and unusable system\nclick to expand issue type bug have you reproduced the bug with tf nightly no source binary tensorflow version 2120 custom code yes os platform and distribution linux ubuntu 2004 mobile device no response python version 3816 conda 114 bazel version no response gcccompiler version no response cudacudnn version 114 gpu model and memory nvidia t4 current behaviour we found that running tftestgpudevicename leads to a soft lockup and an unresponsive system i apologise in advance i dont know much about tensorflow but several of my coworkers do and im in charge of maintaining infrastructure we have a virtual server for computeintensive tasks where we train models and work with large datasets yesterday at about 7 local time i found that i couldnt ssh into the server so i had to wait for it to forcibly restart the server at around 13 local time the server was back up and i looked through the kernel logs to find that there was a soft lockup kernel bug this means that the server was still running but some process wasnt releasing the cpu for more than 20 seconds which meant that no other process could fulfill its tasks not even half an hour later and the server locked up again i got a message from a coworker who suspected that they were at fault for the server locking up because they started running a very computeintensive python script on the server last night they opened a python shell and typed in these two lines and watched the server lock up in real time py import tensorflow as tf printdefault gpu i provided the relevant log output below it required another hard reset from it to get the server back into a working state after the server restarted again i had another look at the kernel logs and found that the reported errors were the same which means i have reason to believe that running tftestgpudevicename consistently leads to a soft lockup on our infrastructure as mentioned previously we run our computations on a virtual server the hypervisor is vmware were running on a nvidia t4 gpu with nvidia drivers in version 4706301 these drivers were provided to us by it installing another version for some reason isnt possible and i prefer not to mess with that the coworker installed tensorflow in a conda environment using pip since were running on a virtual server we depend on it in case things go very wrong this means our means of reproducing this issue are somewhat limited if the server locks up we have to wait up to a couple hours for our service desk to escalate this issue enough so that it restarts the server we cannot afford downtimes like these since we rely on the server for our computations im happy to provide any logs from previous runs but if possible i would like to not share them on github in their entirety since they might contain confidential info standalone code to reproduce the issue shell import tensorflow as tf printdefault gpu device relevant log output shell output from running the function in a python shell python3 python 3816 default mar 2 2023 032146 gcc 1120 anaconda inc on linux type help copyright credits or license for more information import tensorflow as tf 20230615 133449940226 i could not find cuda drivers on your machine gpu will not be used 20230615 133450367115 i could not find cuda drivers on your machine gpu will not be used 20230615 133450368678 i this tensorflow binary is optimized to use available cpu instructions in performancecritical operations to enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler flags 20230615 133452102738 w tftrt warning could not find tensorrt printdefault gpu 20230615 133505586532 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 20230615 133505587485 w cannot dlopen some gpu libraries please make sure the missing libraries mentioned above are installed properly if you would like to use gpu follow the guide at for how to download and setup the required libraries for your platform skipping registering gpu devices message from syslogds050009088 at jun 15 133532 kernel 176957689 watchdog bug soft lockup cpu6 stuck for 22s python34167 output from journalctl jun 15 133505 s050009088 kernel nvidiauvm loaded the uvm driver major device number 238 jun 15 133505 s050009088 kernel cut here jun 15 133505 s050009088 kernel trying to vfree nonexistent vm area 00000000f9521180 jun 15 133505 s050009088 kernel warning cpu 6 pid 4167 at mmvmallocc2245 vunmap0x1ff0x210 jun 15 133505 s050009088 kernel modules linked in nvidiauvmoe veth xtnat xttcpudp xtconntrack xtmasquerade nfconntracknetlink nfnetlink xfrmuser xfrmalgo iptablenat nfnat nfconntrack nfdefragipv6 nfdefragipv4 xtaddrtype iptablefilter bpfilter brnetfilter bridge stp llc aufs overlay vsock dmmultipath scsidhrdac scsidhemc scsidhalua binfmtmisc nvidiadrmpoe nvidiamodesetpoe intelraplmsr nvidiapoe vmwballoon intelraplcommon inputleds intelpowerclamp joydev rapl serioraw vmwvmci machid schfqcodel msr ramoops reedsolomon efipstore iptables xtables autofs4 btrfs zstdcompress raid10 raid456 asyncraid6recov asyncmemcpy asyncpq asyncxor asynctx xor raid6pq libcrc32c raid1 raid0 multipath linear vmwgfx crct10difpclmul crc32pclmul ttm ghashclmulniintel drmkmshelper syscopyarea aesniintel sysfillrect cryptosimd sysimgblt mptspi cryptd fbsysfops gluehelper psmouse mptscsih drm mptbase ahci i2cpiix4 vmxnet3 scsitransportspi jun 15 133505 s050009088 kernel libahci pataacpi jun 15 133505 s050009088 kernel cpu 6 pid 4167 comm python3 tainted p oe 540150generic 167ubuntu jun 15 133505 s050009088 kernel hardware name vmware inc vmware virtual platform440bx desktop reference platform bios 600 11122020 jun 15 133505 s050009088 kernel rip 0010vunmap0x1ff0x210 jun 15 133505 s050009088 kernel code ff e8 d5 fc ff ff eb bf 48 89 fe 48 c7 c7 a0 6d b8 8e e8 36 ba 82 00 0f 0b eb b4 4c 89 ee 48 c7 c7 c8 6d b8 8e e8 23 ba 82 00 0b eb a1 66 66 2e 0f 1f 84 00 00 00 00 00 66 90 0f 1f 44 00 00 jun 15 133505 s050009088 kernel rsp 0018ffffab66c32b7c00 eflags 00010286 jun 15 133505 s050009088 kernel rax 0000000000000000 rbx 0000000000000001 rcx 0000000000000006 jun 15 133505 s050009088 kernel rdx 0000000000000007 rsi 0000000000000096 rdi ffff8ce3bfb9c8c0 jun 15 133505 s050009088 kernel rbp ffffab66c32b7c28 r08 00000000000006d2 r09 286565726676206f jun 15 133505 s050009088 kernel r10 286565726676206f r11 6978656e6f6e2029 r12 0000000000000000 jun 15 133505 s050009088 kernel r13 ffff8ce22c348000 r14 ffff8ce22c349000 r15 0000000000000027 jun 15 133505 s050009088 kernel fs 00007fbf935e31800000 jun 15 133505 s050009088 kernel cs 0010 ds 0000 es 0000 cr0 0000000080050033 jun 15 133505 s050009088 kernel cr2 000000000435c3d0 cr3 0000001e50400001 cr4 00000000003606e0 jun 15 133505 s050009088 kernel call trace jun 15 133505 s050009088 kernel vfree0x220x60 jun 15 133505 s050009088 kernel vfree0x2c0x40 jun 15 133505 s050009088 kernel osfreemem0x1b0x30 nvidia jun 15 133505 s050009088 kernel nvidia jun 15 133505 s050009088 kernel nv000647rm0xdc0x160 nvidia jun 15 133505 s050009088 kernel warning kernel stack frame pointer at 0000000068b18731 in python34167 has bad value 00000000f3874266 jun 15 133505 s050009088 kernel unwind stack type0 mask0x2 graphidx0 jun 15 133505 s050009088 kernel 00000000c0e190e6 ffffab66c32b7c40 0xffffab66c32b7c40 jun 15 133505 s050009088 kernel 0000000074c2bd79 ffffffff8da6e972 vfree0x220x60 jun 15 133505 s050009088 kernel 00000000ea3bef41 0000000000000200 0x200 jun 15 133505 s050009088 kernel 00000000d32e6150 ffffab66c32b7c58 0xffffab66c32b7c58 jun 15 133505 s050009088 kernel 00000000e4c2b257 ffffffff8da6e9dc vfree0x2c0x40 jun 15 133505 s050009088 kernel 000000008b622c26 ffff8ce22c348000 0xffff8ce22c348000 jun 15 133505 s050009088 kernel 00000000b443bda0 ffffab66c32b7c68 0xffffab66c32b7c68 jun 15 133505 s050009088 kernel 0000000004f89fc7 ffffffffc068ccdb osfreemem0x1b0x30 nvidia jun 15 133505 s050009088 kernel 0000000058382150 ffffab66c32b7c98 0xffffab66c32b7c98 jun 15 133505 s050009088 kernel 000000007fb1b873 ffffffffc068edfc nvidia jun 15 133505 s050009088 kernel 00000000629b0f28 ffff8ce395ff60c8 0xffff8ce395ff60c8 jun 15 133505 s050009088 kernel 000000003a4ac7ef 0000010004400000 0x10004400000 jun 15 133505 s050009088 kernel 000000005e9a76c9 0000000000000200 0x200 jun 15 133505 s050009088 kernel 000000005fe4a88b 00000000aa000000 0xaa000000 jun 15 133505 s050009088 kernel 0000000068b18731 ffff8ce3b3e92fb0 0xffff8ce3b3e92fb0 jun 15 133505 s050009088 kernel 00000000bd345bcf ffffffffc101e8dc nv000647rm0xdc0x160 nvidia jun 15 133505 s050009088 kernel 0000000089f90db7 ffff8ce395ff60c8 0xffff8ce395ff60c8 jun 15 133505 s050009088 kernel 00000000c99c1977 ffff8ce39726c0c0 0xffff8ce39726c0c0 jun 15 133505 s050009088 kernel 000000009060a662 0000000000000008 0x8 jun 15 133505 s050009088 kernel 0000000043ee1352 ffffffffc101f3a3 nv000723rm0xa430xa90 nvidia jun 15 133505 s050009088 kernel 0000000064b64c73 0000000000000000 jun 15 133505 s050009088 kernel 0000000030c878cd ffff8ce3b35bc000 0xffff8ce3b35bc000 jun 15 133505 s050009088 kernel 00000000e60fac70 ffffffffc101f316 nv000723rm0x9b60xa90 nvidia jun 15 133505 s050009088 kernel 0000000065747b0c ffff8ce3b3e90000 0xffff8ce3b3e90000 jun 15 133505 s050009088 kernel 0000000063da2df1 ffff8ce3a658b800 0xffff8ce3a658b800 jun 15 133505 s050009088 kernel 0000000008c0ac4e ffffab66c32b7e48 0xffffab66c32b7e48 jun 15 133505 s050009088 kernel 0000000057ee515b ffff8ce3b35b9400 0xffff8ce3b35b9400 jun 15 133505 s050009088 kernel 000000006c5468b7 0000000000000027 0x27 jun 15 133505 s050009088 kernel 0000000065281df3 ffffffffc1025204 rmioctl0x540xb0 nvidia jun 15 133505 s050009088 kernel 00000000b419e233 000000388da5fdb5 0x388da5fdb5 jun 15 133505 s050009088 kernel 000000006f1b29a3 ffff8ce39726c0c0 0xffff8ce39726c0c0 jun 15 133505 s050009088 kernel 00000000465f1196 8000000000000027 0x8000000000000027 jun 15 133505 s050009088 kernel 0000000024eadd83 0000000000001047 0x1047 jun 15 133505 s050009088 kernel 00000000e74dc1ab 00000000000007e9 0x7e9 jun 15 133505 s050009088 kernel 00000000f6d262ce 003d08dcf6746300 0x3d08dcf6746300 jun 15 133505 s050009088 kernel 00000000400760c5 003d08dde4df8b00 0x3d08dde4df8b00 jun 15 133505 s050009088 kernel 00000000c7874ca7 003d08e3f2980f00 0x3d08e3f2980f00 jun 15 133505 s050009088 kernel 00000000946d2608 003d08dd6da9f700 0x3d08dd6da9f700 jun 15 133505 s050009088 kernel 000000007a9cecb7 0000000000000000 jun 15 133505 s050009088 kernel 000000000e6b2400 0000000000000200 0x200 jun 15 133505 s050009088 kernel 0000000022df682d 0000002000000006 0x2000000006 jun 15 133505 s050009088 kernel 0000000005972aee 0000000000001047 0x1047 jun 15 133505 s050009088 kernel 00000000f3ab8670 0000000000000000 jun 15 133505 s050009088 kernel 0000000043395ee6 0000000000000001 0x1 jun 15 133505 s050009088 kernel 0000000090b81e91 0000000000000000 jun 15 133505 s050009088 kernel 00000000ce75a231 ffff8ce39726c0c0 0xffff8ce39726c0c0 jun 15 133505 s050009088 kernel 00000000336aa9c4 0000000000000038 0x38 jun 15 133505 s050009088 kernel 0000000016e174a9 ffff8ce3b35b9400 0xffff8ce3b35b9400 jun 15 133505 s050009088 kernel 00000000c453e6ee ffff8ce3a658b800 0xffff8ce3a658b800 jun 15 133505 s050009088 kernel 00000000ca8fc06a 0000000000000000 jun 15 133505 s050009088 kernel 0000000027388a61 ffffffffc068268f nvidia jun 15 133505 s050009088 kernel 000000001f100b3c ffff8ce3b3e90000 0xffff8ce3b3e90000 jun 15 133505 s050009088 kernel 00000000d70e2948 00007ffd116cef60 0x7ffd116cef60 jun 15 133505 s050009088 kernel 000000009e15ae1f ffff8ce3b35b9498 0xffff8ce3b35b9498 jun 15 133505 s050009088 kernel 000000002d53d487 00007ffd00000027 0x7ffd00000027 jun 15 133505 s050009088 kernel 000000002ea37e99 0000000000000000 jun 15 133505 s050009088 kernel 00000000723c86e7 0000000000000003 0x3 jun 15 133505 s050009088 kernel 000000004b070af4 3c5520dc9b31e900 0x3c5520dc9b31e900 jun 15 133505 s050009088 kernel 00000000260adce7 ffff8ce3a37b1e01 0xffff8ce3a37b1e01 jun 15 133505 s050009088 kernel 00000000f3ab64dd ffff8ce3a37b1e00 0xffff8ce3a37b1e00 jun 15 133505 s050009088 kernel 000000009250db0d ffff8ce3a46feaa0 0xffff8ce3a46feaa0 jun 15 133505 s050009088 kernel 000000001a439626 00007ffd116cef60 0x7ffd116cef60 jun 15 133505 s050009088 kernel 00000000d28c869f ffff8ce3a37b1e00 0xffff8ce3a37b1e00 jun 15 133505 s050009088 kernel 00000000264cc6e1 ffffab66c32b7e58 0xffffab66c32b7e58 jun 15 133505 s050009088 kernel 00000000c9cdb9ef ffffffffc069191b nvidia jun 15 133505 s050009088 kernel 00000000dc15a7de ffffab66c32b7ed8 0xffffab66c32b7ed8 jun 15 133505 s050009088 kernel 000000009b8c3053 ffffffff8dae8e77 dovfsioctl0x4070x670 jun 15 133505 s050009088 kernel 00000000f2d02675 0000010004400000 0x10004400000 jun 15 133505 s050009088 kernel 00000000c52e1241 0000000000000000 jun 15 133505 s050009088 kernel 0000000027ba7e88 ffffab66c32b7e78 0xffffab66c32b7e78 jun 15 133505 s050009088 kernel 00000000aaf3e429 ffffab66c32b7e78 0xffffab66c32b7e78 jun 15 133505 s050009088 kernel 00000000fd0b1f6d 3c5520dc9b31e900 0x3c5520dc9b31e900 jun 15 133505 s050009088 kernel 0000000051d890d1 0000000000000031 0x31 jun 15 133505 s050009088 kernel 000000001e5b54d6 0000000000200000 0x200000 jun 15 133505 s050009088 kernel 00000000bf7d038a 0000000000000000 jun 15 133505 s050009088 kernel 00000000a021b6f5 3c5520dc9b31e900 0x3c5520dc9b31e900 jun 15 133505 s050009088 kernel 00000000382d5bbd ffff8ce3a37b1e01 0xffff8ce3a37b1e01 jun 15 133505 s050009088 kernel 000000005691996c 0000000000000006 0x6 jun 15 133505 s050009088 kernel 000000002b0a9fae 00000000c0384627 0xc0384627 jun 15 133505 s050009088 kernel 00000000ed0791ed 00007ffd116cef60 0x7ffd116cef60 jun 15 133505 s050009088 kernel 00000000944e63ee ffff8ce3a37b1e00 0xffff8ce3a37b1e00 jun 15 133505 s050009088 kernel 00000000b8133399 ffffab66c32b7f18 0xffffab66c32b7f18 jun 15 133505 s050009088 kernel 000000006b019d54 ffffffff8dae9147 ksysioctl0x670x90 jun 15 133505 s050009088 kernel 0000000025959ce7 3c5520dc9b31e900 0x3c5520dc9b31e900 jun 15 133505 s050009088 kernel 0000000019e92101 0000000000000000 jun 15 133505 s050009088 kernel 000000002801fc84 ffffab66c32b7f58 0xffffab66c32b7f58 jun 15 133505 s050009088 kernel 0000000060185eb1 0000000000000000 jun 15 133505 s050009088 kernel 000000007c1db1b7 ffffab66c32b7f28 0xffffab66c32b7f28 jun 15 133505 s050009088 kernel 0000000084b8d84e ffffffff8dae918a x64sysioctl0x1a0x20 jun 15 133505 s050009088 kernel 000000009b8e8f5f ffffab66c32b7f48 0xffffab66c32b7f48 jun 15 133505 s050009088 kernel 00000000f2da7b14 ffffffff8d804fd7 dosyscall640x570x190 jun 15 133505 s050009088 kernel 00000000942f1f70 0000000000000000 jun 15 133505 s050009088 kernel 00000000f56a3750 ffffffff8e4000a4 jun 15 133505 s050009088 kernel 0000000018f467fe 00007ffd116ceed0 0x7ffd116ceed0 jun 15 133505 s050009088 kernel 00000000831b89bf 00000000648af769 0x648af769 jun 15 133505 s050009088 kernel 000000000597aba6 00007ffd116cef88 0x7ffd116cef88 jun 15 133505 s050009088 kernel 00000000a139f77e 0000000000000006 0x6 jun 15 133505 s050009088 kernel 000000006612db4e 00000000c0384627 0xc0384627 jun 15 133505 s050009088 kernel 00000000ab55bfe9 00007ffd116cef60 0x7ffd116cef60 jun 15 133505 s050009088 kernel 000000000b644430 0000000000000246 0x246 jun 15 133505 s050009088 kernel 00000000d2d8779b 0000000000000000 jun 15 133505 s050009088 kernel 00000000725ab6b6 00007ffd116cef88 0x7ffd116cef88 jun 15 133505 s050009088 kernel 000000000399d500 00007ffd116cef60 0x7ffd116cef60 jun 15 133505 s050009088 kernel 00000000c0a877c1 ffffffffffffffda 0xffffffffffffffda jun 15 133505 s050009088 kernel 00000000fb645881 00007fbf936f83ab 0x7fbf936f83ab jun 15 133505 s050009088 kernel 00000000f6cd2602 00007ffd116cef60 0x7ffd116cef60 jun 15 133505 s050009088 kernel 000000006fc36d91 00000000c0384627 0xc0384627 jun 15 133505 s050009088 kernel 00000000e5058b78 0000000000000006 0x6 jun 15 133505 s050009088 kernel 000000002777ac42 0000000000000010 0x10 jun 15 133505 s050009088 kernel 00000000d68cb82a 00007fbf936f83ab 0x7fbf936f83ab jun 15 133505 s050009088 kernel 0000000077e7b064 0000000000000033 0x33 jun 15 133505 s050009088 kernel 0000000037ef3830 0000000000000246 0x246 jun 15 133505 s050009088 kernel 00000000fcba1669 00007ffd116ceec8 0x7ffd116ceec8 jun 15 133505 s050009088 kernel 00000000ea0caaa1 000000000000002b 0x2b jun 15 133505 s050009088 kernel nv000723rm0xa430xa90 nvidia jun 15 133505 s050009088 kernel nv000723rm0x9b60xa90 nvidia jun 15 133505 s050009088 kernel rmioctl0x540xb0 nvidia jun 15 133505 s050009088 kernel nvidia jun 15 133505 s050009088 kernel nvidia jun 15 133505 s050009088 kernel dovfsioctl0x4070x670 jun 15 133505 s050009088 kernel ksysioctl0x670x90 jun 15 133505 s050009088 kernel x64sysioctl0x1a0x20 jun 15 133505 s050009088 kernel dosyscall640x570x190 jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel end trace be1a4a9ea080b7b8 the following logs are then repeatedly printed leading to the soft lockup jun 15 133505 s050009088 kernel bug bad page state in process python3 pfn1e301a6 jun 15 133505 s050009088 kernel pageffffd052f8c06980 refcount0 mapcount0 index0x1 jun 15 133505 s050009088 kernel shmemaops namedevzero jun 15 133505 s050009088 kernel flags 0x17ffffc0000000 jun 15 133505 s050009088 kernel raw 0017ffffc0000000 dead000000000100 dead000000000122 ffff8ce230f6e0d8 jun 15 133505 s050009088 kernel raw 0000000000000001 0000000000000000 00000000ffffffff 0000000000000000 jun 15 133505 s050009088 kernel page dumped because nonnull mapping jun 15 133505 s050009088 kernel modules linked in nvidiauvmoe veth xtnat xttcpudp xtconntrack xtmasquerade nfconntracknetlink nfnetlink xfrmuser xfrmalgo iptablenat nfnat nfconntrack nfdefragipv6 nfdefragipv4 xtaddrtype iptablefilter bpfilter brnetfilter bridge stp llc aufs overlay vsock dmmultipath scsidhrdac scsidhemc scsidhalua binfmtmisc nvidiadrmpoe nvidiamodesetpoe intelraplmsr nvidiapoe vmwballoon intelraplcommon inputleds intelpowerclamp joydev rapl serioraw vmwvmci machid schfqcodel msr ramoops reedsolomon efipstore iptables xtables autofs4 btrfs zstdcompress raid10 raid456 asyncraid6recov asyncmemcpy asyncpq asyncxor asynctx xor raid6pq libcrc32c raid1 raid0 multipath linear vmwgfx crct10difpclmul crc32pclmul ttm ghashclmulniintel drmkmshelper syscopyarea aesniintel sysfillrect cryptosimd sysimgblt mptspi cryptd fbsysfops gluehelper psmouse mptscsih drm mptbase ahci i2cpiix4 vmxnet3 scsitransportspi jun 15 133505 s050009088 kernel libahci pataacpi jun 15 133505 s050009088 kernel cpu 6 pid 4167 comm python3 tainted p w oe 540150generic 167ubuntu jun 15 133505 s050009088 kernel hardware name vmware inc vmware virtual platform440bx desktop reference platform bios 600 11122020 jun 15 133505 s050009088 kernel call trace jun 15 133505 s050009088 kernel dumpstack0x6d0x8b jun 15 133505 s050009088 kernel badpagecold0x800xb1 jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel tlbflushmmu0x3a0x140 jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel warn0x9d0xe0 jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel unmapvmas0x790xf0 jun 15 133505 s050009088 kernel unmapregion0xbc0x160 jun 15 133505 s050009088 kernel domunmap0x2aa0x500 jun 15 133505 s050009088 kernel mmapregion0x2480x650 jun 15 133505 s050009088 kernel dommap0x3b40x5c0 jun 15 133505 s050009088 kernel vmmmappgoff0xcb0x120 jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel fput0x130x20 jun 15 133505 s050009088 kernel ksysioctl0x770x90 jun 15 133505 s050009088 kernel x64sysmmap0x330x40 jun 15 133505 s050009088 kernel dosyscall640x570x190 jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel rip 00330x7fbf936fc8e6 jun 15 133505 s050009088 kernel code 00 00 00 00 f3 0f 1e fa 41 f7 c1 ff 0f 00 00 75 2b 55 48 89 fd 53 89 cb 48 85 ff 74 37 41 89 da 48 89 ef b8 09 00 00 00 0f 05 3d 00 f0 ff ff 77 62 5b 5d c3 0f 1f 80 00 00 00 00 48 8b 05 71 jun 15 133505 s050009088 kernel rsp 002b00007ffd116cf078 eflags 00000206 origrax 0000000000000009 jun 15 133505 s050009088 kernel rax ffffffffffffffda rbx 0000000000000032 rcx 00007fbf936fc8e6 jun 15 133505 s050009088 kernel rdx 0000000000000000 rsi 0000000000200000 rdi 0000010004400000 jun 15 133505 s050009088 kernel rbp 0000010004400000 r08 00000000ffffffff r09 0000000000000000 jun 15 133505 s050009088 kernel r10 0000000000000032 r11 0000000000000206 r12 00000000044be5e0 jun 15 133505 s050009088 kernel r13 0000000000000001 r14 00000000047d97c0 r15 000000000430b450 eventually the watchdog reports the soft lockup checking the pid against the one from the process that ran tftestgpudevicename shows that it mustve caused this lockup jun 15 134645 s050009088 kernel watchdog bug soft lockup cpu6 stuck for 22s python34167"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\ntfdatadatasetmap does not support randomization\nclick to expand issue type bug have you reproduced the bug with tf nightly didnt try source binary tensorflow version tf 2110 custom code yes os platform and distribution macos python version python 38 it seems like tfdatadatasetmap does not support randomization from numpy for the sample code it gives constant output from the randint function call but if you switch the function from numpyrandomrandint to tfrandomuniform toggle the comment then you get good randomization behavior i am wondering if this is expected standalone code to reproduce the issue shell a key i value nprandomrandom for i in range5 dictoflist orientlist keys dictoflistkeys dataset tfdatadatasetzip tuple for key in keys dataset datasetmaplambda x key xi for i key in enumeratekeys for i in range2 for b in dataset printbefore map i b def testfunctionx fkey low0 high100 xf tfrandomuniformshape minval1 maxval5 dtypetfint32 this is randomized xf highhigh this is not randomized return x dataset for i in range2 for b in dataset printafter map i b relevant log output shell before map 0 key value before map 0 key value before map 0 key value before map 0 key value before map 0 key value before map 1 key value before map 1 key value before map 1 key value before map 1 key value before map 1 key value after map 0 key value after map 0 key value after map 0 key value after map 0 key value after map 0 key value after map 1 key value after map 1 key value after map 1 key value after map 1 key value after map 1 key value"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nfunctional bug：could not interpret serialized activation function\nclick to expand issue type bug have you reproduced the bug with tf nightly no source source tensorflow version tf2120 custom code yes os platform and distribution macos mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour output could not interpret serialized activation function tensorconv1abiasadd0 shapenone 224 224 64 dtypefloat32 document activation activation function to use if you dont specify anything no activation is applied see kerasactivations standalone code to reproduce the issue py x kernelsize3 strides1 paddingsame py x kernelsize3 strides1 activationserialize paddingsame relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Issue Report Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\nimage segmenter tflitesuuport attributeerror type object segmentationoptions has no attribute outputtype\nclick to expand issue type documentation bug have you reproduced the bug with tf nightly yes source source tensorflow version tflitesupport 010a1 custom code no os platform and distribution macos ventura 134 mobile device no response python version 387 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour the syntax provided for using image segmenter did not execute in python environment possible fix the line segmentationoptions should have been segmentationoptions standalone code to reproduce the issue shell relevant log output shell traceback most recent call last file imagesegmenterpy line 8 in segmentationoptions attributeerror type object segmentationoptions has no attribute outputtype"}, {"role": "assistant", "content": "bug"}]}
