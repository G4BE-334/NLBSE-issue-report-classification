{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue Report Classification: Few Shot Learning\n",
    "\n",
    "### NLBSE 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas emoji openai tiktoken sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the requisite libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "\n",
    "# Loading data from CSV files\n",
    "test_data = pd.read_csv(\"./data/issues/issues_test.csv\")\n",
    "train_data = pd.read_csv(\"./data/issues/issues_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>created_at</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook/react</td>\n",
       "      <td>2023-08-02 02:26:00</td>\n",
       "      <td>bug</td>\n",
       "      <td>Bug: [18.3.0-canary] renderToString hoists som...</td>\n",
       "      <td>&lt;!--\\r\\n  Please provide a clear and concise d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook/react</td>\n",
       "      <td>2023-07-17 22:43:05</td>\n",
       "      <td>bug</td>\n",
       "      <td>[DevTools Bug]: Chrome extension gets disconne...</td>\n",
       "      <td>### Website or app\\r\\n\\r\\nhttps://react.dev/\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook/react</td>\n",
       "      <td>2023-07-13 19:01:47</td>\n",
       "      <td>bug</td>\n",
       "      <td>[DevTools Bug]: Deprecated __REACT_DEVTOOLS_GL...</td>\n",
       "      <td>### Website or app\\n\\nN/A\\n\\n### Repro steps\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook/react</td>\n",
       "      <td>2023-06-07 17:26:43</td>\n",
       "      <td>bug</td>\n",
       "      <td>[DevTools Bug]: React devtools stuck at Loadin...</td>\n",
       "      <td>### Website or app\\n\\ncorporate project (priva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook/react</td>\n",
       "      <td>2023-05-31 15:17:41</td>\n",
       "      <td>bug</td>\n",
       "      <td>Bug: Radio button onChange not called in curre...</td>\n",
       "      <td>&lt;!--\\r\\n  Please provide a clear and concise d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>opencv/opencv</td>\n",
       "      <td>2022-01-22 11:52:21</td>\n",
       "      <td>feature</td>\n",
       "      <td>Task: GCC 12 support</td>\n",
       "      <td>Support compilation with GCC 12 and fix tests\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>opencv/opencv</td>\n",
       "      <td>2022-01-16 19:27:55</td>\n",
       "      <td>feature</td>\n",
       "      <td>AudioIO: add dnn speech recognition sample on C++</td>\n",
       "      <td>### Pull Request Readiness Checklist\\r\\n\\r\\nSe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>opencv/opencv</td>\n",
       "      <td>2022-01-14 22:05:58</td>\n",
       "      <td>feature</td>\n",
       "      <td>Use modern OpenVINO package interface</td>\n",
       "      <td>* new cmake options: `WITH_OPENVINO`, `OPENCV_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>opencv/opencv</td>\n",
       "      <td>2022-01-12 09:14:41</td>\n",
       "      <td>feature</td>\n",
       "      <td>TiffEncoder write support more depth type</td>\n",
       "      <td>**Merge with extra**: https://github.com/openc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>opencv/opencv</td>\n",
       "      <td>2022-01-06 11:01:32</td>\n",
       "      <td>feature</td>\n",
       "      <td>tiff need check TIFFTAG_SAMPLEFORMAT, should n...</td>\n",
       "      <td>### Pull Request Readiness Checklist\\r\\n\\r\\nSe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                repo           created_at    label  \\\n",
       "0     facebook/react  2023-08-02 02:26:00      bug   \n",
       "1     facebook/react  2023-07-17 22:43:05      bug   \n",
       "2     facebook/react  2023-07-13 19:01:47      bug   \n",
       "3     facebook/react  2023-06-07 17:26:43      bug   \n",
       "4     facebook/react  2023-05-31 15:17:41      bug   \n",
       "...              ...                  ...      ...   \n",
       "1495   opencv/opencv  2022-01-22 11:52:21  feature   \n",
       "1496   opencv/opencv  2022-01-16 19:27:55  feature   \n",
       "1497   opencv/opencv  2022-01-14 22:05:58  feature   \n",
       "1498   opencv/opencv  2022-01-12 09:14:41  feature   \n",
       "1499   opencv/opencv  2022-01-06 11:01:32  feature   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Bug: [18.3.0-canary] renderToString hoists som...   \n",
       "1     [DevTools Bug]: Chrome extension gets disconne...   \n",
       "2     [DevTools Bug]: Deprecated __REACT_DEVTOOLS_GL...   \n",
       "3     [DevTools Bug]: React devtools stuck at Loadin...   \n",
       "4     Bug: Radio button onChange not called in curre...   \n",
       "...                                                 ...   \n",
       "1495                               Task: GCC 12 support   \n",
       "1496  AudioIO: add dnn speech recognition sample on C++   \n",
       "1497              Use modern OpenVINO package interface   \n",
       "1498          TiffEncoder write support more depth type   \n",
       "1499  tiff need check TIFFTAG_SAMPLEFORMAT, should n...   \n",
       "\n",
       "                                                   body  \n",
       "0     <!--\\r\\n  Please provide a clear and concise d...  \n",
       "1     ### Website or app\\r\\n\\r\\nhttps://react.dev/\\r...  \n",
       "2     ### Website or app\\n\\nN/A\\n\\n### Repro steps\\n...  \n",
       "3     ### Website or app\\n\\ncorporate project (priva...  \n",
       "4     <!--\\r\\n  Please provide a clear and concise d...  \n",
       "...                                                 ...  \n",
       "1495  Support compilation with GCC 12 and fix tests\\...  \n",
       "1496  ### Pull Request Readiness Checklist\\r\\n\\r\\nSe...  \n",
       "1497  * new cmake options: `WITH_OPENVINO`, `OPENCV_...  \n",
       "1498  **Merge with extra**: https://github.com/openc...  \n",
       "1499  ### Pull Request Readiness Checklist\\r\\n\\r\\nSe...  \n",
       "\n",
       "[1500 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>created_at</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook/react</td>\n",
       "      <td>2023-08-26 06:33:37</td>\n",
       "      <td>bug</td>\n",
       "      <td>[DevTools Bug] Cannot add node \"1\" because a n...</td>\n",
       "      <td>### Website or app\\n\\nPrivate repo cannot give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook/react</td>\n",
       "      <td>2023-07-28 05:16:12</td>\n",
       "      <td>bug</td>\n",
       "      <td>[DevTools Bug]: Devtools extension build faili...</td>\n",
       "      <td>### Website or app\\n\\nN/A\\n\\n### Repro steps\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook/react</td>\n",
       "      <td>2023-07-13 21:58:31</td>\n",
       "      <td>bug</td>\n",
       "      <td>[DevTools Bug]: Deprecated __REACT_DEVTOOLS_GL...</td>\n",
       "      <td>### Website or app\\n\\nhttps://github.com/open-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook/react</td>\n",
       "      <td>2023-06-14 02:31:20</td>\n",
       "      <td>bug</td>\n",
       "      <td>[DevTools Bug] Cannot remove node \"0\" because ...</td>\n",
       "      <td>### Website or app\\n\\nlocal\\n\\n### Repro steps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook/react</td>\n",
       "      <td>2023-06-03 11:29:44</td>\n",
       "      <td>bug</td>\n",
       "      <td>[DevTools Bug] Cannot remove node \"103\" becaus...</td>\n",
       "      <td>### Website or app\\n\\nlocalhost\\n\\n### Repro s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>opencv/opencv</td>\n",
       "      <td>2022-01-24 10:48:13</td>\n",
       "      <td>feature</td>\n",
       "      <td>core: FP denormals support</td>\n",
       "      <td>relates #21046\\r\\n\\r\\n- support x86 SSE FTZ+DA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>opencv/opencv</td>\n",
       "      <td>2022-01-20 12:40:55</td>\n",
       "      <td>feature</td>\n",
       "      <td>feature: submodule or a class scope for export...</td>\n",
       "      <td>All classes are registered in the scope that c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>opencv/opencv</td>\n",
       "      <td>2022-01-15 02:39:22</td>\n",
       "      <td>feature</td>\n",
       "      <td>Reading BigTiff images</td>\n",
       "      <td>**Merge with extra: https://github.com/opencv/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>opencv/opencv</td>\n",
       "      <td>2022-01-14 15:37:53</td>\n",
       "      <td>feature</td>\n",
       "      <td>Add general broadcasting layer</td>\n",
       "      <td>Performance details(broadcasting 1x1 to 16x204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>opencv/opencv</td>\n",
       "      <td>2022-01-11 16:30:53</td>\n",
       "      <td>feature</td>\n",
       "      <td>Adapt remote inference to operate with NV12 blobs</td>\n",
       "      <td>### Pull Request Readiness Checklist\\r\\n\\r\\nSe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                repo           created_at    label  \\\n",
       "0     facebook/react  2023-08-26 06:33:37      bug   \n",
       "1     facebook/react  2023-07-28 05:16:12      bug   \n",
       "2     facebook/react  2023-07-13 21:58:31      bug   \n",
       "3     facebook/react  2023-06-14 02:31:20      bug   \n",
       "4     facebook/react  2023-06-03 11:29:44      bug   \n",
       "...              ...                  ...      ...   \n",
       "1495   opencv/opencv  2022-01-24 10:48:13  feature   \n",
       "1496   opencv/opencv  2022-01-20 12:40:55  feature   \n",
       "1497   opencv/opencv  2022-01-15 02:39:22  feature   \n",
       "1498   opencv/opencv  2022-01-14 15:37:53  feature   \n",
       "1499   opencv/opencv  2022-01-11 16:30:53  feature   \n",
       "\n",
       "                                                  title  \\\n",
       "0     [DevTools Bug] Cannot add node \"1\" because a n...   \n",
       "1     [DevTools Bug]: Devtools extension build faili...   \n",
       "2     [DevTools Bug]: Deprecated __REACT_DEVTOOLS_GL...   \n",
       "3     [DevTools Bug] Cannot remove node \"0\" because ...   \n",
       "4     [DevTools Bug] Cannot remove node \"103\" becaus...   \n",
       "...                                                 ...   \n",
       "1495                         core: FP denormals support   \n",
       "1496  feature: submodule or a class scope for export...   \n",
       "1497                             Reading BigTiff images   \n",
       "1498                     Add general broadcasting layer   \n",
       "1499  Adapt remote inference to operate with NV12 blobs   \n",
       "\n",
       "                                                   body  \n",
       "0     ### Website or app\\n\\nPrivate repo cannot give...  \n",
       "1     ### Website or app\\n\\nN/A\\n\\n### Repro steps\\n...  \n",
       "2     ### Website or app\\n\\nhttps://github.com/open-...  \n",
       "3     ### Website or app\\n\\nlocal\\n\\n### Repro steps...  \n",
       "4     ### Website or app\\n\\nlocalhost\\n\\n### Repro s...  \n",
       "...                                                 ...  \n",
       "1495  relates #21046\\r\\n\\r\\n- support x86 SSE FTZ+DA...  \n",
       "1496  All classes are registered in the scope that c...  \n",
       "1497  **Merge with extra: https://github.com/opencv/...  \n",
       "1498  Performance details(broadcasting 1x1 to 16x204...  \n",
       "1499  ### Pull Request Readiness Checklist\\r\\n\\r\\nSe...  \n",
       "\n",
       "[1500 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "### Data Cleaning: Method 1  \n",
    "Within this notebook, we employ two distinct data cleaning methodologies. This tailored approach is followed given variations among the repositories, each showing a more favorable outcome in response to one or the other cleaning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned 2998 times.\n",
      "Returned original text 2 times.\n",
      "Cleaned 5998 times.\n",
      "Returned original text 2 times.\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters for text cleaning\n",
    "cleaned_count = 0\n",
    "original_count = 0\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    global cleaned_count, original_count\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        original_count += 1\n",
    "        return text\n",
    "\n",
    "    # Remove double quotation marks\n",
    "    text = text.replace('\"', '')\n",
    "\n",
    "    # Remove text starting with \"DevTools\" and ending with \"(automated)\"\n",
    "    text = re.sub(r'DevTools.*?\\(automated\\)', '', text)\n",
    "\n",
    "    # Lowercasing should be one of the first steps to ensure uniformity\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove emojis\n",
    "    text = emoji.demojize(text)\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", '', text)\n",
    "\n",
    "    # Remove '#' characters\n",
    "    text = text.replace(\"#\", \"\")\n",
    "\n",
    "    # Remove consecutive whitespaces and replace with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    # Remove words that are over 20 characters\n",
    "    words = [word for word in words if len(word) <= 20]\n",
    "\n",
    "    # Join the remaining words back into cleaned text\n",
    "    cleaned_text = ' '.join(words)\n",
    "\n",
    "    cleaned_count += 1\n",
    "    return cleaned_text\n",
    "\n",
    "test_data['body'] = test_data['body'].apply(clean_text)\n",
    "test_data['title'] = test_data['title'].apply(clean_text)\n",
    "\n",
    "\n",
    "print(f\"Cleaned {cleaned_count} times.\")\n",
    "print(f\"Returned original text {original_count} times.\")\n",
    "\n",
    "train_data['body'] = train_data['body'].apply(clean_text)\n",
    "train_data['title'] = train_data['title'].apply(clean_text)\n",
    "\n",
    "\n",
    "print(f\"Cleaned {cleaned_count} times.\")\n",
    "print(f\"Returned original text {original_count} times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Division  \n",
    "\n",
    "Subsequently, we partitioned our dataset into five smaller dataframes, ensuring an exclusive handling of each project. This segregation was executed on both the training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    train_facebook = train_data[: 300]\n",
    "    train_tensorflow = train_data[300: 600]\n",
    "    train_microsoft = train_data[600: 900]\n",
    "    train_bitcoin = train_data[900: 1200]\n",
    "    train_opencv= train_data[1200: 1500]\n",
    "    facebook = test_data[: 300]\n",
    "    tensorflow = test_data[300: 600]\n",
    "    microsoft = test_data[600: 900]\n",
    "    bitcoin = test_data[900: 1200]\n",
    "    opencv= test_data[1200: 1500]\n",
    "    return train_facebook, train_tensorflow, train_microsoft, train_bitcoin, train_opencv, facebook, tensorflow, microsoft, bitcoin, opencv\n",
    "\n",
    "train_data_facebook, train_data_tensorflow, train_data_microsoft, train_data_bitcoin, train_data_opencv, test_data_facebook, test_data_tensorflow, test_data_microsoft, test_data_bitcoin, test_data_opencv = split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning  \n",
    "We fine-tuned ChatGPT-3.5-Turbo using the training data, aiming to achieve superior performance compared to the standard approach of invoking the OpenAI API GPT-4 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoking the API\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = 'open-ai-api-key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation  \n",
    "Prior to beginning the fine-tuning process, our initial step involves transforming our dataframe into a JSON line file format. This formatted file will serve as the prompt input for the fine-tuning process. Each prompt will encapsulate the title and body details of every pull request. Our anticipated outcome from the fine-tuned model will be the corresponding label for each PR, distinguishing between bug reports, questions, or feature requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "max_content_tokens = 3999\n",
    "\n",
    "# Function to truncate the message and avoid passing the limit of 4k tokens per gpt-3.5 fine-tuned model limitations\n",
    "def truncate_message(message, max_length):\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "        tokens = encoding.encode(message)\n",
    "        if len(tokens) > max_length:\n",
    "            truncated_tokens = tokens[:max_length]\n",
    "            message = encoding.decode(truncated_tokens)\n",
    "        return message\n",
    "\n",
    "def create_conversational_data(train_data, conversational_data):\n",
    "\n",
    "    # Open the file in write mode\n",
    "    with open(conversational_data, 'w', encoding='utf-8') as f:\n",
    "        # Iterate over the rows in the DataFrame\n",
    "        for index, row in train_data.iterrows():\n",
    "            # Create the user message by formatting the prompt with the title and body\n",
    "            user_message = f\"Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\\n{row['title']}\\n{row['body']}\"\n",
    "            \n",
    "            # Truncate the prompt if necessary\n",
    "            user_message = truncate_message(user_message, max_content_tokens)\n",
    "\n",
    "            # Create the assistant message by taking the label\n",
    "            assistant_message = row['label']\n",
    "            \n",
    "            # Construct the conversation object\n",
    "            conversation_object = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"GitHub Issue Report Classifier\"},\n",
    "                    {\"role\": \"user\", \"content\": user_message},\n",
    "                    {\"role\": \"assistant\", \"content\": assistant_message}\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            # Write the conversation object to one line in the file\n",
    "            f.write(json.dumps(conversation_object, ensure_ascii=False) + '\\n')\n",
    "    return conversational_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training file  \n",
    "With our JSON line file generated, it now serves as the foundational conversation input for our fine-tuned model. We're prepared to upload this training file to the OpenAI API to initiate the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_file(conversational_data):  \n",
    "  ## Uplopading a training file\n",
    "  training_file = client.files.create(\n",
    "    file=open(conversational_data, \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    "  )\n",
    "  return training_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation  \n",
    "At last, the stage is set to create the model, designated with the suffix 'repo-prissueclassifier.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fine_tuned_model(model_training_file, model_sufix):\n",
    "  ## Creating a fine-tuned model\n",
    "  fine_tuning_job = client.fine_tuning.jobs.create(\n",
    "    training_file=model_training_file.id, \n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    suffix= model_sufix\n",
    "  )\n",
    "  return fine_tuning_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tuning_and_training(train_data, conversational_data, model_sufix):\n",
    "    model_conversational_data = create_conversational_data(train_data, conversational_data)\n",
    "    trained_file = create_training_file(model_conversational_data)\n",
    "    fine_tuned_model = create_fine_tuned_model(trained_file, model_sufix)\n",
    "    return fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook repository dataset fine-tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_ft_job_file = fine_tuning_and_training(train_data_facebook, 'data/conversationaldata/conversational_data_facebook.jsonl', \"fb-issueclassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-0613:northern-arizona-university-nau:fb-issueclassifier:8wuvNgeu\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the state of a fine-tune\n",
    "facebook_ft_model = client.fine_tuning.jobs.retrieve(facebook_ft_job_file.id).fine_tuned_model\n",
    "print(facebook_ft_model) # This fine-tuning job took around 40 min to be completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait Before Continuing\n",
    "\n",
    "For each repository (facebook, tensorflow, microsoft, bitcoin, opencv) please wait until the fine tuning job is done. You can ensure that by checking when the code snippet above does not return \"None\". You could also run the snippet below to track the progress of your fine-tuning job by checking the latest events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can track the progress of your fine-tuning job by listing the lastest events. On our models it took about 3 hours to fine-tune each model\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=facebook_ft_job_file.id, limit=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow repository dataset fine-tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow_ft_job_file = fine_tuning_and_training(train_data_tensorflow, 'data/conversationaldata/conversational_data_tensorflow.jsonl', \"tf-issueclassifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-0613:northern-arizona-university-nau:tf-issueclassifier:8wviPsLJ\n"
     ]
    }
   ],
   "source": [
    "tensorflow_ft_model = client.fine_tuning.jobs.retrieve(tensorflow_ft_job_file.id).fine_tuned_model # This fine-tuning job took around 35 min to be completed\n",
    "print(tensorflow_ft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microsoft repository dataset fine-tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "microsoft_ft_job_file = fine_tuning_and_training(train_data_microsoft, 'data/conversationaldata/conversational_data_microsoft.jsonl', \"ms-issueclassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-0613:northern-arizona-university-nau:ms-issueclassifier:8wwuk30C\n"
     ]
    }
   ],
   "source": [
    "microsoft_ft_model = client.fine_tuning.jobs.retrieve(microsoft_ft_job_file.id).fine_tuned_model # This fine-tuning job took around 45 min to be completed\n",
    "print(microsoft_ft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitcoin repository dataset fine-tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_ft_job_file = fine_tuning_and_training(train_data_bitcoin, 'data/conversationaldata/conversational_data_bitcoin.jsonl', \"bc-issueclassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-0613:northern-arizona-university-nau:bc-issueclassifier:8wxVmc7I\n"
     ]
    }
   ],
   "source": [
    "bitcoin_ft_model = client.fine_tuning.jobs.retrieve(bitcoin_ft_job_file.id).fine_tuned_model # This fine-tuning job took around 35 min to be completed\n",
    "print(bitcoin_ft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV repository dataset fine-tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencv_ft_job_file = fine_tuning_and_training(train_data_opencv, 'data/conversationaldata/conversational_data_opencv.jsonl', \"oc-issueclassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-0613:northern-arizona-university-nau:oc-issueclassifier:8wyNcwmv\n"
     ]
    }
   ],
   "source": [
    "opencv_ft_model = client.fine_tuning.jobs.retrieve(opencv_ft_job_file.id).fine_tuned_model\n",
    "print(opencv_ft_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning results  \n",
    "The successful fine-tuning of all models was completed using the default of 3 epochs. The process spanned approximately 5 hours; however, variations in processing time might occur due to queue dynamics at any given moment.\n",
    "\n",
    "**Please remember to wait until the respective fine-tuning model job is completed for each repository before trying to evaluate the model in the steps below**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing Fine-tuned model  \n",
    "Next, another API from OpenAI is used to invoke the fine-tuned model and assess its performance on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import concurrent.futures\n",
    "import tiktoken\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "# Replace 'open-ai-key' with your actual OpenAI API key\n",
    "openai.api_key = 'open-ai-api-key'\n",
    "\n",
    "# max_token here should be one since 'bug', 'feature', and 'question' are one token long. This might change for future versions of the model and api but you can check the value on the\n",
    "def query_chatgpt(prompt, model, temperature=0.0,  max_tokens=1, max_retries=5):\n",
    "    \"\"\"\n",
    "    Function to query ChatGPT-4 with a given prompt, with retries for timeouts.\n",
    "\n",
    "    :param prompt: Prompt string to send to ChatGPT-2.5\n",
    "    :param model: The model to use, default is ChatGPT-3.5\n",
    "    :param max_tokens: Maximum number of tokens to generate\n",
    "    :param max_retries: Maximum number of retries for timeout\n",
    "    :return: Response from ChatGPT-3.5 or None if all retries fail\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    max_content_tokens = 3999\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "    # Function to truncate the message and avoid passing the limit of 4k tokens per gpt-3.5 fine-tuned model limitations\n",
    "    def truncate_message(message, max_length):\n",
    "        tokens = encoding.encode(message)\n",
    "        if len(tokens) > max_length:\n",
    "            truncated_tokens = tokens[:max_length]\n",
    "            message = encoding.decode(truncated_tokens)\n",
    "        return message\n",
    "\n",
    "    # Truncate the prompt if necessary\n",
    "    prompt = truncate_message(prompt, max_content_tokens)\n",
    "\n",
    "    while attempt < max_retries:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            future = executor.submit(\n",
    "                openai.chat.completions.create,\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"system\", \"content\": \"GitHub Issue Report Classifier\"}, {\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature\n",
    "            )\n",
    "            try:\n",
    "                response = future.result(timeout=5)  # 5 seconds timeout\n",
    "                return response.choices[0].message.content\n",
    "            except concurrent.futures.TimeoutError:\n",
    "                print(f\"Attempt {attempt + 1}/{max_retries} - Request timed out. Retrying...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {attempt + 1}/{max_retries} - An error occurred: {e}\")\n",
    "            finally:\n",
    "                attempt += 1\n",
    "\n",
    "    print(\"Failed to get a response after several retries.\")\n",
    "    return None\n",
    "    \n",
    "labels = ['feature', 'bug', 'question']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing\n",
    "The function defined above is being called, passing the specific model for each repository and testing it with the testing dataset. It's essential to note the setup of a timer to comply with the \"token per minute\" limitations on the API. Additionally, the results of each iteration are printed for tracking and improvement purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_data, ft_model):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    iterations = len(test_data)\n",
    "\n",
    "    # Now let's loop through the test data and classify the GitHub issues\n",
    "    for i in range(iterations):\n",
    "        correct_label = test_data.iloc[i]['label'].lower()\n",
    "        description = f\"{test_data.iloc[i]['title']} \\n {test_data.iloc[i]['body']}\"\n",
    "        print(f\"Correct GitHub Issue type: {correct_label}\")\n",
    "        \n",
    "        prompt = f\"Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\\n{description}\"\n",
    "        response = query_chatgpt(prompt, ft_model)\n",
    "        \n",
    "        if response is None:\n",
    "            print(\"Failed to get a response after several retries. Skipping this item.\")\n",
    "            continue  # Skip this iteration and move to the next one\n",
    "        \n",
    "        # Clean the response to keep only letters (and optionally numbers)\n",
    "        predicted_label = re.sub(r'[^A-Za-z]+', '', response).lower().strip()\n",
    "        print(f\"Predicted GitHub Issue type: {predicted_label}\")\n",
    "        \n",
    "        # Append to lists for evaluation\n",
    "        y_true.append(correct_label)\n",
    "        y_pred.append(predicted_label)\n",
    "        time.sleep(6)  # Wait for 6 seconds before retrying since there is a token per minute limit\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "# See output on outputs/cell51output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the results  \n",
    "Once all testing data undergoes evaluation using the corresponding fine-tuned models, we'll leverage the two arrays generated—representing the true labels and predicted labels—to conduct result assessments.\n",
    "\n",
    "For tracking purposes, a CSV file has been generated for each result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, cm_sheet):\n",
    "    # Calculate weighted average F1-score, precision, and recall\n",
    "    f1 = f1_score(y_true, y_pred, labels=labels, average='weighted')\n",
    "    precision = precision_score(y_true, y_pred, labels=labels, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, labels=labels, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "\n",
    "    # Calculate TP, FP, FN, TN\n",
    "    results_fb = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        results_fb[label] = {'TP': cm[i, i]}\n",
    "        results_fb[label]['FP'] = cm[:, i].sum() - cm[i, i]\n",
    "        results_fb[label]['FN'] = cm[i, :].sum() - cm[i, i]\n",
    "        results_fb[label]['TN'] = cm.sum() - (results_fb[label]['TP'] + results_fb[label]['FP'] + results_fb[label]['FN'])\n",
    "\n",
    "    # Print results_fb\n",
    "    for label, metrics in results_fb.items():\n",
    "        print(f\"{label}: {metrics}\")\n",
    "\n",
    "    # Save results_fb to CSV\n",
    "    results_fb_df = pd.DataFrame(results_fb).T\n",
    "    results_fb_df['F1-score'] = f1\n",
    "    results_fb_df['Recall'] = recall\n",
    "    results_fb_df['Precision'] = precision\n",
    "\n",
    "    results_fb_df.to_csv(cm_sheet, index=False)\n",
    "\n",
    "    print(f\"Precision = {precision}\")\n",
    "    print(f\"Recall = {recall}\")\n",
    "    print(f\"F1-score = {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the metrics  \n",
    "Below, the metrics for each label are presented to facilitate a more precise evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating_metrics(y_true, y_pred):\n",
    "    # Create a classification report\n",
    "    report = classification_report(y_true, y_pred, labels=['bug', 'feature', 'question'], target_names=['bug', 'feature', 'question'], zero_division=0, output_dict=True)\n",
    "\n",
    "    # Convert the report to a DataFrame\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "    # Print the classification report\n",
    "    print(report_df)\n",
    "    return report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook Repo Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_facebook, y_pred_facebook = test_model(test_data_facebook, facebook_ft_model) ## See results in outputs/cell48output.txt\n",
    "## This specific model testing took 30 minutes to be completed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait for model testing to be over before proceeding. This can take up to 3 hours. You will need is over because when it stops printing predicted vs actual values. This can take up to 2 hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: {'TP': 91, 'FP': 18, 'FN': 9, 'TN': 182}\n",
      "bug: {'TP': 94, 'FP': 25, 'FN': 6, 'TN': 175}\n",
      "question: {'TP': 66, 'FP': 6, 'FN': 34, 'TN': 194}\n",
      "Precision = 0.8471483394581074\n",
      "Recall = 0.8366666666666667\n",
      "F1-score = 0.8322342487262593\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_true_facebook, y_pred_facebook, 'metrics/confusion_matrix_fb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score     support\n",
      "bug            0.789916  0.940000  0.858447  100.000000\n",
      "feature        0.834862  0.910000  0.870813  100.000000\n",
      "question       0.916667  0.660000  0.767442  100.000000\n",
      "accuracy       0.836667  0.836667  0.836667    0.836667\n",
      "macro avg      0.847148  0.836667  0.832234  300.000000\n",
      "weighted avg   0.847148  0.836667  0.832234  300.000000\n"
     ]
    }
   ],
   "source": [
    "facebook_complete_metrics = evaluating_metrics(y_true_facebook, y_pred_facebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Repo Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_tensorflow, y_pred_tensorflow = test_model(test_data_tensorflow, tensorflow_ft_model) ## See results in outputs/cell53output.txt\n",
    "## This specific model testing took 32 minutes to be completed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait for model testing to be over before proceeding. This can take up to 3 hours. You will need is over because when it stops printing predicted vs actual values. This can take up to 2 hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: {'TP': 77, 'FP': 1, 'FN': 23, 'TN': 199}\n",
      "bug: {'TP': 87, 'FP': 8, 'FN': 13, 'TN': 192}\n",
      "question: {'TP': 94, 'FP': 33, 'FN': 6, 'TN': 167}\n",
      "Precision = 0.8810421470595527\n",
      "Recall = 0.86\n",
      "F1-score = 0.8618900214108847\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_true_tensorflow, y_pred_tensorflow, 'metrics/confusion_matrix_tf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1-score: 86.19%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "bug            0.915789    0.87  0.892308   100.00\n",
      "feature        0.987179    0.77  0.865169   100.00\n",
      "question       0.740157    0.94  0.828194   100.00\n",
      "accuracy       0.860000    0.86  0.860000     0.86\n",
      "macro avg      0.881042    0.86  0.861890   300.00\n",
      "weighted avg   0.881042    0.86  0.861890   300.00\n"
     ]
    }
   ],
   "source": [
    "tensorflow_complete_metrics = evaluating_metrics(y_true_tensorflow, y_pred_tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microsoft Repo Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_microsoft, y_pred_microsoft = test_model(test_data_microsoft, microsoft_ft_model) ## See results in outputs/cell59output.txt\n",
    "## This specific model testing took 33 minutes to be completed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait for model testing to be over before proceeding. This can take up to 3 hours. You will need is over because when it stops printing predicted vs actual values. This can take up to 2 hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: {'TP': 84, 'FP': 24, 'FN': 15, 'TN': 175}\n",
      "bug: {'TP': 82, 'FP': 22, 'FN': 17, 'TN': 177}\n",
      "question: {'TP': 71, 'FP': 15, 'FN': 29, 'TN': 183}\n",
      "Precision = 0.7972735705293845\n",
      "Recall = 0.79\n",
      "F1-score = 0.7916849121782707\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_true_microsoft, y_pred_microsoft, 'metrics/confusion_matrix_ms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-score: 79.17%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "bug            0.788462    0.82  0.803922    100.0\n",
      "feature        0.777778    0.84  0.807692    100.0\n",
      "question       0.825581    0.71  0.763441    100.0\n",
      "micro avg      0.795302    0.79  0.792642    300.0\n",
      "macro avg      0.797274    0.79  0.791685    300.0\n",
      "weighted avg   0.797274    0.79  0.791685    300.0\n"
     ]
    }
   ],
   "source": [
    "microsoft_complete_metrics = evaluating_metrics(y_true_microsoft, y_pred_microsoft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitcoin Repo Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_bitcoin, y_pred_bitcoin = test_model(test_data_bitcoin, bitcoin_ft_model) ## See results in outputs/cell65output.txt\n",
    "## This specific model testing took 32 minutes to be completed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait for model testing to be over before proceeding. This can take up to 3 hours. You will need is over because when it stops printing predicted vs actual values. This can take up to 2 hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: {'TP': 92, 'FP': 18, 'FN': 7, 'TN': 182}\n",
      "bug: {'TP': 77, 'FP': 28, 'FN': 23, 'TN': 171}\n",
      "question: {'TP': 61, 'FP': 23, 'FN': 39, 'TN': 176}\n",
      "Precision = 0.7652958152958153\n",
      "Recall = 0.7666666666666667\n",
      "F1-score = 0.7634844888821559\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_true_bitcoin, y_pred_bitcoin, \"metrics/confusion_matrix_bc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score: 76.35%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score  support\n",
      "bug            0.733333  0.770000  0.751220    100.0\n",
      "feature        0.836364  0.920000  0.876190    100.0\n",
      "question       0.726190  0.610000  0.663043    100.0\n",
      "micro avg      0.769231  0.766667  0.767947    300.0\n",
      "macro avg      0.765296  0.766667  0.763484    300.0\n",
      "weighted avg   0.765296  0.766667  0.763484    300.0\n"
     ]
    }
   ],
   "source": [
    "bitcoin_complete_metrics = evaluating_metrics(y_true_bitcoin, y_pred_bitcoin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV Repo Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_opencv, y_pred_opencv = test_model(test_data_opencv, opencv_ft_model) ## See results in outputs/cell65output.txt\n",
    "## This specific model testing took 32 minutes to be completed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait for model testing to be over before proceeding. This can take up to 3 hours. You will need is over because when it stops printing predicted vs actual values. This can take up to 2 hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: {'TP': 81, 'FP': 12, 'FN': 19, 'TN': 187}\n",
      "bug: {'TP': 81, 'FP': 29, 'FN': 19, 'TN': 170}\n",
      "question: {'TP': 78, 'FP': 18, 'FN': 21, 'TN': 182}\n",
      "Precision = 0.80661045943304\n",
      "Recall = 0.8\n",
      "F1-score = 0.8022417257058263\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_true_opencv, y_pred_opencv, \"metrics/confusion_matrix_oc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-score: 80.22%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "bug            0.736364    0.81  0.771429    100.0\n",
      "feature        0.870968    0.81  0.839378    100.0\n",
      "question       0.812500    0.78  0.795918    100.0\n",
      "micro avg      0.802676    0.80  0.801336    300.0\n",
      "macro avg      0.806610    0.80  0.802242    300.0\n",
      "weighted avg   0.806610    0.80  0.802242    300.0\n"
     ]
    }
   ],
   "source": [
    "opencv_complete_metrics = evaluating_metrics(y_true_opencv, y_pred_opencv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial results  \n",
    "With results gathered for all repositories tested against their respective trained models, we're poised to consolidate the confusion matrix data and derive the overall metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6 entries, bug to weighted avg\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   precision  6 non-null      float64\n",
      " 1   recall     6 non-null      float64\n",
      " 2   f1-score   6 non-null      float64\n",
      " 3   support    6 non-null      float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 412.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "opencv_complete_metrics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Results: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Bug': {'Precision': 0.7927727896458546,\n",
       "  'Recall': 0.842,\n",
       "  'F1-Score': 0.8154649666286623},\n",
       " 'Feature': {'Precision': 0.8614302057154972,\n",
       "  'Recall': 0.85,\n",
       "  'F1-Score': 0.8518485917359564},\n",
       " 'Question': {'Precision': 0.8042192037041882,\n",
       "  'Recall': 0.74,\n",
       "  'F1-Score': 0.7636076797774194},\n",
       " 'Average': {'Precision': 0.8194740663551799,\n",
       "  'Recall': 0.8106666666666668,\n",
       "  'F1-Score': 0.8103070793806794}}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_average(values):\n",
    "    total = 0\n",
    "    for value in values:\n",
    "        total += value\n",
    "    return total/len(values)\n",
    "\n",
    "# Calculating overall (average) values  \n",
    "overall_bug_f1 = calculate_average([facebook_complete_metrics['f1-score'].loc['bug'], tensorflow_complete_metrics['f1-score'].loc['bug'], microsoft_complete_metrics['f1-score'].loc['bug'], bitcoin_complete_metrics['f1-score'].loc['bug'], opencv_complete_metrics['f1-score'].loc['bug']])\n",
    "overall_bug_precision = calculate_average([facebook_complete_metrics.precision.loc['bug'], tensorflow_complete_metrics.precision.loc['bug'], microsoft_complete_metrics.precision.loc['bug'], bitcoin_complete_metrics.precision.loc['bug'], opencv_complete_metrics.precision.loc['bug']])\n",
    "overall_bug_recall = calculate_average([facebook_complete_metrics.recall.loc['bug'], tensorflow_complete_metrics.recall.loc['bug'], microsoft_complete_metrics.recall.loc['bug'], bitcoin_complete_metrics.recall.loc['bug'], opencv_complete_metrics.recall.loc['bug']])\n",
    "overall_feature_f1 = calculate_average([facebook_complete_metrics['f1-score'].loc['feature'], tensorflow_complete_metrics['f1-score'].loc['feature'], microsoft_complete_metrics['f1-score'].loc['feature'], bitcoin_complete_metrics['f1-score'].loc['feature'], opencv_complete_metrics['f1-score'].loc['feature']])\n",
    "overall_feature_precision = calculate_average([facebook_complete_metrics.precision.loc['feature'], tensorflow_complete_metrics.precision.loc['feature'], microsoft_complete_metrics.precision.loc['feature'], bitcoin_complete_metrics.precision.loc['feature'], opencv_complete_metrics.precision.loc['feature']])\n",
    "overall_feature_recall = calculate_average([facebook_complete_metrics.recall.loc['feature'], tensorflow_complete_metrics.recall.loc['feature'], microsoft_complete_metrics.recall.loc['feature'], bitcoin_complete_metrics.recall.loc['feature'], opencv_complete_metrics.recall.loc['feature']])\n",
    "overall_question_f1 = calculate_average([facebook_complete_metrics['f1-score'].loc['question'], tensorflow_complete_metrics['f1-score'].loc['question'], microsoft_complete_metrics['f1-score'].loc['question'], bitcoin_complete_metrics['f1-score'].loc['question'], opencv_complete_metrics['f1-score'].loc['question']])\n",
    "overall_question_precision = calculate_average([facebook_complete_metrics.precision.loc['question'], tensorflow_complete_metrics.precision.loc['question'], microsoft_complete_metrics.precision.loc['question'], bitcoin_complete_metrics.precision.loc['question'], opencv_complete_metrics.precision.loc['question']])\n",
    "overall_question_recall = calculate_average([facebook_complete_metrics.recall.loc['question'], tensorflow_complete_metrics.recall.loc['question'], microsoft_complete_metrics.recall.loc['question'], bitcoin_complete_metrics.recall.loc['question'], opencv_complete_metrics.recall.loc['question']])\n",
    "overall_average_f1 = calculate_average([facebook_complete_metrics['f1-score'].loc['macro avg'], tensorflow_complete_metrics['f1-score'].loc['macro avg'], microsoft_complete_metrics['f1-score'].loc['macro avg'], bitcoin_complete_metrics['f1-score'].loc['macro avg'], opencv_complete_metrics['f1-score'].loc['macro avg']])\n",
    "overall_average_precision = calculate_average([facebook_complete_metrics.precision.loc['macro avg'], tensorflow_complete_metrics.precision.loc['macro avg'], microsoft_complete_metrics.precision.loc['macro avg'], bitcoin_complete_metrics.precision.loc['macro avg'], opencv_complete_metrics.precision.loc['macro avg']])\n",
    "overall_average_recall = calculate_average([facebook_complete_metrics.recall.loc['macro avg'], tensorflow_complete_metrics.recall.loc['macro avg'], microsoft_complete_metrics.recall.loc['macro avg'], bitcoin_complete_metrics.recall.loc['macro avg'], opencv_complete_metrics.recall.loc['macro avg']])\n",
    "\n",
    "print(\"Overall Results: \")\n",
    "# Formatting the results\n",
    "formatted_metrics = {\n",
    "    \"Bug\": {\n",
    "        \"Precision\": overall_bug_precision, \n",
    "        \"Recall\": overall_bug_recall, \n",
    "        \"F1-Score\": overall_bug_f1\n",
    "    },\n",
    "    \"Feature\": {\n",
    "        \"Precision\": overall_feature_precision, \n",
    "        \"Recall\": overall_feature_recall, \n",
    "        \"F1-Score\": overall_feature_f1\n",
    "    },\n",
    "    \"Question\": {\n",
    "        \"Precision\": overall_question_precision, \n",
    "        \"Recall\": overall_question_recall, \n",
    "        \"F1-Score\": overall_question_f1\n",
    "    },\n",
    "    \"Average\": {\n",
    "        \"Precision\": overall_average_precision, \n",
    "        \"Recall\": overall_average_recall, \n",
    "        \"F1-Score\": overall_average_f1\n",
    "    }\n",
    "}\n",
    "formatted_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning: Method 2  \n",
    "Upon analysis, opportunities for enhancement in our cleaning method surfaced, leading to the implementation of a new cleaning function.  \n",
    "In the revised cleaning method (Method 2), emphasis was placed on stripping markdown text while adopting a strategy of replacing certain text elements to uphold the intended meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned 5998 times.\n",
      "Returned original text 2 times.\n"
     ]
    }
   ],
   "source": [
    "# Function to convert Markdown to plain text\n",
    "def strip_markdown(text):\n",
    "    # Remove Markdown links\n",
    "    text = re.sub(r'\\[([^\\]]*)\\]\\([^\\)]*\\)', r'\\1', text)\n",
    "    \n",
    "    # Remove Markdown emphasis (* or _)\n",
    "    text = re.sub(r'(\\*|_)(.*?)\\1', r'\\2', text)\n",
    "    \n",
    "    # Remove Markdown inline code (`)\n",
    "    text = re.sub(r'`([^`]+)`', r'\\1', text)\n",
    "    \n",
    "    # Remove Markdown headers (##, ###, etc.)\n",
    "    text = re.sub(r'#+\\s*(.*?)\\n', r'\\1\\n', text)\n",
    "    \n",
    "    # Remove other Markdown elements as needed\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Initialize counters for text cleaning\n",
    "cleaned_count = 0\n",
    "original_count = 0\n",
    "\n",
    "def clean_text(text):\n",
    "    global cleaned_count, original_count\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        original_count += 1\n",
    "        return text\n",
    "\n",
    "######################################\n",
    "#        Standardize The Text        #\n",
    "######################################\n",
    "\n",
    "    # Lowercasing should be one of the first steps to ensure uniformity\n",
    "    text = text.lower()\n",
    "\n",
    "######################################\n",
    "#         Remove Characters          #\n",
    "######################################\n",
    "\n",
    "    # Remove emojis, special characters, and punctuation\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", '', text)\n",
    "\n",
    "######################################\n",
    "#         Remove/Replace Text        #\n",
    "######################################\n",
    "\n",
    "    # Remove specific phrases \"Website or app\" and \"local react development\"\n",
    "    text = text.replace(\"website or app\", \"\")\n",
    "    text = text.replace(\"local react development\", \"\")\n",
    "\n",
    "    # Replace URLs, HTML tags, user mentions, and markdown image references\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '<URL>', text)\n",
    "    text = re.sub(r'<.*?>', '<HTML_TAG>', text)\n",
    "    text = re.sub(r'@\\w+', '<USER>', text)\n",
    "    text = re.sub(r'!\\[image\\]\\(.*?\\)', '<IMAGE>', text)\n",
    "\n",
    "    # Remove text starting with \"DevTools\" and ending with \"(automated)\"\n",
    "    text = re.sub(r'DevTools.*?\\(automated\\)', '', text)\n",
    "\n",
    "\n",
    "\n",
    "        # Strip markdown formatting\n",
    "    text = strip_markdown(text)\n",
    "\n",
    "######################################\n",
    "#        Tidy Up Whitespaces         #\n",
    "######################################\n",
    "\n",
    "    # Remove consecutive whitespaces and replace with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "######################################\n",
    "#            Final Things            #\n",
    "######################################\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    # Remove words that are over 20 characters\n",
    "    words = [word for word in words if len(word) <= 20]\n",
    "\n",
    "    # Join the remaining words back into cleaned text\n",
    "    cleaned_text = ' '.join(words)\n",
    "\n",
    "    cleaned_count += 1\n",
    "    return cleaned_text\n",
    "\n",
    "# Applying clean_text function to test and train data\n",
    "test_data['body'] = test_data['body'].apply(clean_text)\n",
    "test_data['title'] = test_data['title'].apply(clean_text)\n",
    "\n",
    "train_data['body'] = train_data['body'].apply(clean_text)\n",
    "train_data['title'] = train_data['title'].apply(clean_text)\n",
    "\n",
    "# Displaying cleaning statistics\n",
    "print(f\"Cleaned {cleaned_count} times.\")\n",
    "print(f\"Returned original text {original_count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_facebook2, train_data_tensorflow2, train_data_microsoft2, train_data_bitcoin2, train_data_opencv2, test_data_facebook2, test_data_tensorflow2, test_data_microsoft2, test_data_bitcoin2, test_data_opencv2 = split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved models  \n",
    "Upon analyzing the step metrics of the fine-tuned models, it became evident that certain models, specifically those associated with the TensorFlow, Microsoft, and OpenCV repositories, exhibited training_loss figures indicating potential for improvement.\n",
    "\n",
    "Considering this insight, we opted to develop new fine-tuned models, augmenting the epochs and integrating the enhanced cleaning method for these specific repositories.\n",
    "\n",
    "## Tensorflow Improved model\n",
    "For this tensorflow improved model we utilized the cleaning method 2 and 10 epochs on the fine-tuning processes. All the initial models displayed above on this notebook used cleaning method 1 and 3 epochs on the fine-tunning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new tensorflow conversational data with cleaning method 2\n",
    "tensorflow_conversational_data_new = create_conversational_data(train_data_tensorflow2, \"data/conversationaldata/conversational_data_tensorflow_new.jsonl\")\n",
    "## Create new tensorflow training file\n",
    "tensorflow_training_file_new = create_training_file(tensorflow_conversational_data_new)\n",
    "\n",
    "## Creating new tensorflow fine-tuning job using gpt-3.5-turbo-1106 baseline model, 10 epochs, and cleaning method 2\n",
    "tensorflow_fine_tuning_job_new = client.fine_tuning.jobs.create(\n",
    "    training_file = tensorflow_training_file_new.id, \n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    suffix= \"tensorflow\",\n",
    "    hyperparameters={\"n_epochs\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ftjob-zifIfmVpYAPDW7Q2xgLo9agK'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow_fine_tuning_job_new.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-1106:northern-arizona-university-nau:tensorflow:8xHuEgsD\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the state of a fine-tune\n",
    "tensorflow_ft_model_new = client.fine_tuning.jobs.retrieve(tensorflow_fine_tuning_job_new.id).fine_tuned_model\n",
    "print(tensorflow_ft_model_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait Before Continuing Again\n",
    "\n",
    "For each repository (facebook, tensorflow, microsoft, bitcoin, opencv) please wait until the fine tuning job is done. You can ensure that by checking when the code snippet above does not return \"None\". You could also run the snippet below to track the progress of your fine-tuning job by checking the latest events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can track the progress of your fine-tuning job by listing the lastest events. On our models it took about 3 hours to fine-tune each model\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=tensorflow_fine_tuning_job_new.id, limit=2reftg0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_tensorflow_new, y_pred_tensorflow_new = test_model(test_data_tensorflow2, tensorflow_ft_model_new) ## See results on outputs/cell90output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait for model testing to be over before proceeding. This can take up to 3 hours. You will need is over because when it stops printing predicted vs actual values. This can take up to 2 hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: {'TP': 85, 'FP': 6, 'FN': 15, 'TN': 194}\n",
      "bug: {'TP': 87, 'FP': 7, 'FN': 13, 'TN': 193}\n",
      "question: {'TP': 89, 'FP': 26, 'FN': 11, 'TN': 174}\n",
      "Precision = 0.8778369641459373\n",
      "Recall = 0.87\n",
      "F1-score = 0.8716221830866581\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_true_tensorflow_new, y_pred_tensorflow_new, 'metrics/confusion_matrix_tf_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "bug            0.925532    0.87  0.896907   100.00\n",
      "feature        0.934066    0.85  0.890052   100.00\n",
      "question       0.773913    0.89  0.827907   100.00\n",
      "accuracy       0.870000    0.87  0.870000     0.87\n",
      "macro avg      0.877837    0.87  0.871622   300.00\n",
      "weighted avg   0.877837    0.87  0.871622   300.00\n"
     ]
    }
   ],
   "source": [
    "tensorflow_complete_metrics_new = evaluating_metrics(y_true_tensorflow_new, y_pred_tensorflow_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook Improved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new tensorflow conversational data with cleaning method 2\n",
    "facebook_conversational_data_new = create_conversational_data(train_data_facebook2, \"data/conversationaldata/conversational_data_facebook_new.jsonl\")\n",
    "## Create new facebook training file\n",
    "facebook_training_file_new = create_training_file(facebook_conversational_data_new)\n",
    "\n",
    "## Creating new facebook fine-tuning job using gpt-3.5-turbo-1106 baseline model, 10 epochs, and cleaning method 2\n",
    "facebook_fine_tuning_job_new = client.fine_tuning.jobs.create(\n",
    "    training_file = facebook_training_file_new.id, \n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    suffix= \"facebook\",\n",
    "    hyperparameters={\"n_epochs\": 7}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ftjob-JipjimxPsrWjtEHPDjFyOYwR'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facebook_fine_tuning_job_new.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-1106:northern-arizona-university-nau:facebook:8xjH103N\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the state of a fine-tune\n",
    "facebook_ft_model_new = client.fine_tuning.jobs.retrieve(facebook_fine_tuning_job_new.id).fine_tuned_model\n",
    "print(facebook_ft_model_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_facebook_new, y_pred_facebook_new = test_model(test_data_facebook2, facebook_ft_model_new) ## See results on outputs/cell98output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: {'TP': 87, 'FP': 12, 'FN': 13, 'TN': 188}\n",
      "bug: {'TP': 93, 'FP': 20, 'FN': 7, 'TN': 180}\n",
      "question: {'TP': 75, 'FP': 13, 'FN': 25, 'TN': 187}\n",
      "Precision = 0.8513564852060428\n",
      "Recall = 0.85\n",
      "F1-score = 0.8484945454472442\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_true_facebook_new, y_pred_facebook_new, 'metrics/confusion_matrix_fb_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "bug            0.823009    0.93  0.873239   100.00\n",
      "feature        0.878788    0.87  0.874372   100.00\n",
      "question       0.852273    0.75  0.797872   100.00\n",
      "accuracy       0.850000    0.85  0.850000     0.85\n",
      "macro avg      0.851356    0.85  0.848495   300.00\n",
      "weighted avg   0.851356    0.85  0.848495   300.00\n"
     ]
    }
   ],
   "source": [
    "facebook_complete_metrics_new = evaluating_metrics(y_true_facebook_new, y_pred_facebook_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BITCOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new tensorflow conversational data with cleaning method 2\n",
    "bitcoin_conversational_data_new = create_conversational_data(train_data_bitcoin2, \"data/conversationaldata/conversational_data_bitcoin_new.jsonl\")\n",
    "## Create new bitcoin training file\n",
    "bitcoin_training_file_new = create_training_file(bitcoin_conversational_data_new)\n",
    "\n",
    "## Creating new bitcoin fine-tuning job using gpt-3.5-turbo-1106 baseline model, 10 epochs, and cleaning method 2\n",
    "bitcoin_fine_tuning_job_new = client.fine_tuning.jobs.create(\n",
    "    training_file = bitcoin_training_file_new.id, \n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    suffix= \"bitcoin\",\n",
    "    hyperparameters={\"n_epochs\": 7}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ftjob-RWphxqFI3CI3DvA9UQfa0YMo'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_fine_tuning_job_new.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-1106:northern-arizona-university-nau:bitcoin:8xrdS2jR\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the state of a fine-tune\n",
    "bitcoin_ft_model_new = client.fine_tuning.jobs.retrieve(bitcoin_fine_tuning_job_new.id).fine_tuned_model\n",
    "print(bitcoin_ft_model_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_bitcoin_new, y_pred_bitcoin_new = test_model(test_data_bitcoin2, bitcoin_ft_model_new) ## See results on outputs/cell105output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: {'TP': 88, 'FP': 17, 'FN': 12, 'TN': 183}\n",
      "bug: {'TP': 74, 'FP': 18, 'FN': 26, 'TN': 182}\n",
      "question: {'TP': 72, 'FP': 31, 'FN': 28, 'TN': 169}\n",
      "Precision = 0.780490730131929\n",
      "Recall = 0.78\n",
      "F1-score = 0.7795765082035057\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_true_bitcoin_new, y_pred_bitcoin_new, 'metrics/confusion_matrix_bc_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "bug            0.804348    0.74  0.770833   100.00\n",
      "feature        0.838095    0.88  0.858537   100.00\n",
      "question       0.699029    0.72  0.709360   100.00\n",
      "accuracy       0.780000    0.78  0.780000     0.78\n",
      "macro avg      0.780491    0.78  0.779577   300.00\n",
      "weighted avg   0.780491    0.78  0.779577   300.00\n"
     ]
    }
   ],
   "source": [
    "bitcoin_complete_metrics_new = evaluating_metrics(y_true_bitcoin_new, y_pred_bitcoin_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV Improved Model\n",
    "Cleaning method 2 and 6 epochs on fine-tuning process.\n",
    "\n",
    "Employing a new cleaning method alongside 6 epochs, we chose this iteration as our experimentation with 10 epochs indicated it to be excessive for our TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new tensorflow conversational data with cleaning method 2\n",
    "opencv_conversational_data_new = create_conversational_data(train_data_opencv2, \"data/conversationaldata/conversational_data_opencv_new.jsonl\")\n",
    "## Create new opencv training file\n",
    "opencv_training_file2 = create_training_file(opencv_conversational_data_new)\n",
    "\n",
    "## Creating new opencv fine-tuning job using gpt-3.5-turbo base model, 6 epochs, and cleaning method 2\n",
    "opencv_fine_tuning_job_new = client.fine_tuning.jobs.create(\n",
    "    training_file = opencv_training_file2.id, \n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    suffix= \"opencv\",\n",
    "    hyperparameters={\"n_epochs\": 6}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ftjob-1CfSvYPxWkm1RFTkpbj66P9f'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opencv_fine_tuning_job_new.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-1106:northern-arizona-university-nau:opencv:8xNlytzM\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the state of a fine-tune\n",
    "opencv_ft_model_new = client.fine_tuning.jobs.retrieve(opencv_fine_tuning_job_new.id).fine_tuned_model\n",
    "print(opencv_ft_model_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait Before Continuing Again\n",
    "\n",
    "For each repository (facebook, tensorflow, microsoft, bitcoin, opencv) please wait until the fine tuning job is done. You can ensure that by checking when the code snippet above does not return \"None\". You could also run the snippet below to track the progress of your fine-tuning job by checking the latest events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can track the progress of your fine-tuning job by listing the lastest events. On our models it took about 3 hours to fine-tune each model\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=opencv_fine_tuning_job_new.id, limit=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_opencv_new, y_pred_opencv_new = test_model(test_data_opencv2, opencv_ft_model_new) ## See results on outputs/cell115output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait for model testing to be over before proceeding. This can take up to 3 hours. You will need is over because when it stops printing predicted vs actual values. This can take up to 2 hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: {'TP': 73, 'FP': 10, 'FN': 26, 'TN': 189}\n",
      "bug: {'TP': 79, 'FP': 19, 'FN': 20, 'TN': 180}\n",
      "question: {'TP': 88, 'FP': 29, 'FN': 12, 'TN': 169}\n",
      "Precision = 0.8125924244685003\n",
      "Recall = 0.8\n",
      "F1-score = 0.8022846378213909\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_true_opencv_new, y_pred_opencv_new, 'metrics/confusion_matrix_oc_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "bug            0.806122    0.79  0.797980    100.0\n",
      "feature        0.879518    0.73  0.797814    100.0\n",
      "question       0.752137    0.88  0.811060    100.0\n",
      "micro avg      0.805369    0.80  0.802676    300.0\n",
      "macro avg      0.812592    0.80  0.802285    300.0\n",
      "weighted avg   0.812592    0.80  0.802285    300.0\n"
     ]
    }
   ],
   "source": [
    "opencv_complete_metrics_new = evaluating_metrics(y_true_opencv_new, y_pred_opencv_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microsoft Improved model\n",
    "Cleaning Method 1 and 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since we are just adding more epochs to the existing Microsoft model we don't have to create new conversational data or training files.\n",
    "\n",
    "## Creating a fine-tuned model\n",
    "microsoft_ft_job_file_new = client.fine_tuning.jobs.create(\n",
    "  training_file = microsoft_ft_job_file.training_file, ## Using same file with cleaning method 1\n",
    "  model = microsoft_ft_model, ## Using old model as the base model\n",
    "  suffix= \"ms-issueclassifier\",\n",
    "  hyperparameters={\"n_epochs\": 7}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-De6dIrMKz8BhAfcbANUgojrG', created_at=1709165781, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=7, batch_size='auto', learning_rate_multiplier='auto'), model='ft:gpt-3.5-turbo-0613:northern-arizona-university-nau:ms-issueclassifier:8wwuk30C', object='fine_tuning.job', organization_id='org-RQmLagMyfsDY9gy4UMq97uCI', result_files=[], status='validating_files', trained_tokens=None, training_file='file-EjuEwJyG8siTlN11etUaBzhP', validation_file=None, user_provided_suffix='ms-issueclassifier')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microsoft_ft_job_file_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-0613:northern-arizona-university-nau:ms-issueclassifier:8xPhaSQC\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the state of a fine-tune\n",
    "microsoft_ft_model_new = client.fine_tuning.jobs.retrieve(microsoft_ft_job_file_new.id).fine_tuned_model\n",
    "print(microsoft_ft_model_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait Before Continuing Again\n",
    "\n",
    "For each repository (facebook, tensorflow, microsoft, bitcoin, opencv) please wait until the fine tuning job is done. You can ensure that by checking when the code snippet above does not return \"None\". You could also run the snippet below to track the progress of your fine-tuning job by checking the latest events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can track the progress of your fine-tuning job by listing the lastest events. On our models it took about 3 hours to fine-tune each model\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=microsoft_ft_job_file_new.id, limit=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_microsoft_new, y_pred_microsoft_new = test_model(test_data_microsoft, microsoft_ft_model_new) ## See results on outputs/cell126output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait for model testing to be over before proceeding. This can take up to 3 hours. You will need is over because when it stops printing predicted vs actual values. This can take up to 2 hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: {'TP': 87, 'FP': 30, 'FN': 13, 'TN': 170}\n",
      "bug: {'TP': 78, 'FP': 15, 'FN': 22, 'TN': 185}\n",
      "question: {'TP': 75, 'FP': 15, 'FN': 25, 'TN': 185}\n",
      "Precision = 0.805210918114144\n",
      "Recall = 0.8\n",
      "F1-score = 0.799869052541097\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_true_microsoft_new, y_pred_microsoft_new, 'metrics/confusion_matrix_ms_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "bug            0.838710    0.78  0.808290    100.0\n",
      "feature        0.743590    0.87  0.801843    100.0\n",
      "question       0.833333    0.75  0.789474    100.0\n",
      "accuracy       0.800000    0.80  0.800000      0.8\n",
      "macro avg      0.805211    0.80  0.799869    300.0\n",
      "weighted avg   0.805211    0.80  0.799869    300.0\n"
     ]
    }
   ],
   "source": [
    "microsoft_complete_metrics_new = evaluating_metrics(y_true_microsoft_new, y_pred_microsoft_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Results\n",
    "\n",
    "To obtain the overall results we utilized the metrics from the regular facebook and bitcoin models, and the improved tensorflow, microsoft and opencv models. We then calculated the average of each metrics to have a complete overall metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Results: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Bug': {'Precision': 0.8255923808642173,\n",
       "  'Recall': 0.8260000000000002,\n",
       "  'F1-Score': 0.8241397426633768},\n",
       " 'Feature': {'Precision': 0.8531013072948557,\n",
       "  'Recall': 0.8559999999999999,\n",
       "  'F1-Score': 0.8528364713995196},\n",
       " 'Question': {'Precision': 0.7942096460595828,\n",
       "  'Recall': 0.7780000000000001,\n",
       "  'F1-Score': 0.7841061949277026},\n",
       " 'Average': {'Precision': 0.8243011114062186,\n",
       "  'Recall': 0.82,\n",
       "  'F1-Score': 0.8203608029968661}}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_average(values):\n",
    "    total = 0\n",
    "    for value in values:\n",
    "        total += value\n",
    "    return total/len(values)\n",
    "\n",
    "# Calculating overall (average) values  \n",
    "overall_bug_f1 = calculate_average([facebook_complete_metrics_new['f1-score'].loc['bug'], tensorflow_complete_metrics_new['f1-score'].loc['bug'], microsoft_complete_metrics_new['f1-score'].loc['bug'], bitcoin_complete_metrics_new['f1-score'].loc['bug'], opencv_complete_metrics['f1-score'].loc['bug']])\n",
    "overall_bug_precision = calculate_average([facebook_complete_metrics_new.precision.loc['bug'], tensorflow_complete_metrics_new.precision.loc['bug'], microsoft_complete_metrics_new.precision.loc['bug'], bitcoin_complete_metrics_new.precision.loc['bug'], opencv_complete_metrics.precision.loc['bug']])\n",
    "overall_bug_recall = calculate_average([facebook_complete_metrics_new.recall.loc['bug'], tensorflow_complete_metrics_new.recall.loc['bug'], microsoft_complete_metrics_new.recall.loc['bug'], bitcoin_complete_metrics_new.recall.loc['bug'], opencv_complete_metrics.recall.loc['bug']])\n",
    "overall_feature_f1 = calculate_average([facebook_complete_metrics_new['f1-score'].loc['feature'], tensorflow_complete_metrics_new['f1-score'].loc['feature'], microsoft_complete_metrics_new['f1-score'].loc['feature'], bitcoin_complete_metrics_new['f1-score'].loc['feature'], opencv_complete_metrics['f1-score'].loc['feature']])\n",
    "overall_feature_precision = calculate_average([facebook_complete_metrics_new.precision.loc['feature'], tensorflow_complete_metrics_new.precision.loc['feature'], microsoft_complete_metrics_new.precision.loc['feature'], bitcoin_complete_metrics_new.precision.loc['feature'], opencv_complete_metrics.precision.loc['feature']])\n",
    "overall_feature_recall = calculate_average([facebook_complete_metrics_new.recall.loc['feature'], tensorflow_complete_metrics_new.recall.loc['feature'], microsoft_complete_metrics_new.recall.loc['feature'], bitcoin_complete_metrics_new.recall.loc['feature'], opencv_complete_metrics.recall.loc['feature']])\n",
    "overall_question_f1 = calculate_average([facebook_complete_metrics_new['f1-score'].loc['question'], tensorflow_complete_metrics_new['f1-score'].loc['question'], microsoft_complete_metrics_new['f1-score'].loc['question'], bitcoin_complete_metrics_new['f1-score'].loc['question'], opencv_complete_metrics['f1-score'].loc['question']])\n",
    "overall_question_precision = calculate_average([facebook_complete_metrics_new.precision.loc['question'], tensorflow_complete_metrics_new.precision.loc['question'], microsoft_complete_metrics_new.precision.loc['question'], bitcoin_complete_metrics_new.precision.loc['question'], opencv_complete_metrics.precision.loc['question']])\n",
    "overall_question_recall = calculate_average([facebook_complete_metrics_new.recall.loc['question'], tensorflow_complete_metrics_new.recall.loc['question'], microsoft_complete_metrics_new.recall.loc['question'], bitcoin_complete_metrics_new.recall.loc['question'], opencv_complete_metrics.recall.loc['question']])\n",
    "overall_average_f1 = calculate_average([facebook_complete_metrics_new['f1-score'].loc['macro avg'], tensorflow_complete_metrics_new['f1-score'].loc['macro avg'], microsoft_complete_metrics_new['f1-score'].loc['macro avg'], bitcoin_complete_metrics_new['f1-score'].loc['macro avg'], opencv_complete_metrics['f1-score'].loc['macro avg']])\n",
    "overall_average_precision = calculate_average([facebook_complete_metrics_new.precision.loc['macro avg'], tensorflow_complete_metrics_new.precision.loc['macro avg'], microsoft_complete_metrics_new.precision.loc['macro avg'], bitcoin_complete_metrics_new.precision.loc['macro avg'], opencv_complete_metrics.precision.loc['macro avg']])\n",
    "overall_average_recall = calculate_average([facebook_complete_metrics_new.recall.loc['macro avg'], tensorflow_complete_metrics_new.recall.loc['macro avg'], microsoft_complete_metrics_new.recall.loc['macro avg'], bitcoin_complete_metrics_new.recall.loc['macro avg'], opencv_complete_metrics.recall.loc['macro avg']])\n",
    "\n",
    "print(\"Overall Results: \")\n",
    "# Formatting the results\n",
    "formatted_metrics = {\n",
    "    \"Bug\": {\n",
    "        \"Precision\": overall_bug_precision, \n",
    "        \"Recall\": overall_bug_recall, \n",
    "        \"F1-Score\": overall_bug_f1\n",
    "    },\n",
    "    \"Feature\": {\n",
    "        \"Precision\": overall_feature_precision, \n",
    "        \"Recall\": overall_feature_recall, \n",
    "        \"F1-Score\": overall_feature_f1\n",
    "    },\n",
    "    \"Question\": {\n",
    "        \"Precision\": overall_question_precision, \n",
    "        \"Recall\": overall_question_recall, \n",
    "        \"F1-Score\": overall_question_f1\n",
    "    },\n",
    "    \"Average\": {\n",
    "        \"Precision\": overall_average_precision, \n",
    "        \"Recall\": overall_average_recall, \n",
    "        \"F1-Score\": overall_average_f1\n",
    "    }\n",
    "}\n",
    "formatted_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
