{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas sentence-transformers setfit scikit-learn datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"all-mpnet-base-v2\"\n",
    "RANDOM_SEED = 42\n",
    "OUTPUT_PATH = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"data/issues_train.csv\")\n",
    "test_set = pd.read_csv(\"data/issues_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.groupby([\"repo\", \"label\"]).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset):\n",
    "    dataset['text'] = dataset['title'] + \" \" + dataset['body']\n",
    "    dataset = dataset[['text', 'label', 'repo']]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = process_dataset(train_set)\n",
    "test_set = process_dataset(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_repo = lambda dataset: {\n",
    "    repo: Dataset.from_pandas(dataset[dataset[\"repo\"] == repo]).class_encode_column(\"label\")\n",
    "    for repo in dataset[\"repo\"].unique()\n",
    "}\n",
    "\n",
    "train_sets = group_by_repo(train_set)\n",
    "test_sets = group_by_repo(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    repo: {'train': train_sets[repo], 'test': test_sets[repo]} for repo in train_sets.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = defaultdict(dict)\n",
    "for repo in datasets.keys():\n",
    "    train_set, test_set = datasets[repo]['train'], datasets[repo]['test']\n",
    "    model = SetFitModel.from_pretrained(BASE_MODEL)\n",
    "\n",
    "    trainer = SetFitTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_set,\n",
    "        loss_class=CosineSimilarityLoss,\n",
    "        metric=\"accuracy\",\n",
    "        batch_size=16,\n",
    "        num_epochs=1,\n",
    "        num_iterations=20,\n",
    "    )\n",
    "    trainer.train()\n",
    "    y_pred = trainer.model.predict(test_set['text'])\n",
    "    results[repo]['metrics'] = classification_report(test_set['label'], y_pred, digits=4, output_dict=True)\n",
    "    results[repo]['predictions'] = y_pred.tolist()\n",
    "    results['label_mapping'] = {train_set.features[\"label\"].int2str(x): x for x in range(train_set.features[\"label\"].num_classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in results.keys():\n",
    "    print(repo)\n",
    "    print(results[repo]['metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = [results[repo]['metrics']['macro avg']['f1-score'] for repo in results.keys()]\n",
    "mean_score = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print(f\"Mean F1 score: {mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'results.json'\n",
    "with open(os.path.join(OUTPUT_PATH, output_file_name), 'w') as fp:\n",
    "    json.dump(results, fp)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
