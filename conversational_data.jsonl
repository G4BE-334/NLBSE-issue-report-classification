{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"1\" because a node with that id is already in the Store.\nwebsite or app private repo cannot give access to application repro steps 1 run application how often does this bug happen every time devtools package automated devtools version automated 4280035a41c4e error message automated cannot add node 1 because a node with that id is already in the store error call stack automated text at at bridgeemit at at listener error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Devtools extension build failing in windows and ubuntu \nwebsite or app na repro steps been working on react devtools extension for a while now my mac got some issue so i switched to a windows machine but currently i am unable to build the react devtool extension and run it locally here is the napshot of the error windows powershell 7282023 104305 am how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Deprecated __REACT_DEVTOOLS_GLOBAL_HOOK__ ????\nwebsite or app repro steps hi i have heard that the new versions of react will not support the if there any information about this update that you can share is there a new way to achieve the same result of using the but with a different method what is the future of react without the reactime and react inspector in the chrome store use this hook how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot remove node \"0\" because no matching node was found in the Store.\nwebsite or app local repro steps open reactdevtools how often does this bug happen every time devtools package automated reactdevtoolscore devtools version automated 42782468a8735 error message automated cannot remove node 0 because no matching node was found in the store error call stack automated text at at femit at at at arrayforeach at lheonmessage at at at aemit nodeevents51328 at eexportsf at eexportsemit nodeevents51328 error component stack automated no response github query string automated text remove node because no matching node was found in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot remove node \"103\" because no matching node was found in the Store.\nwebsite or app localhost repro steps how often does this bug happen every time devtools package automated devtools version automated 42782468a8735 error message automated cannot remove node 103 because no matching node was found in the store error call stack automated text error component stack automated no response github query string automated text remove node because no matching node was found in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: App not recognized in Firefox, but works in Chrome\nwebsite or app repro steps on both firefox 103 and 104 the react devtools extension says this page doesnt appear to be using react on the most recent version of chrome its working just fine i cannot share the project since its a private project unfortunately but i suspect this is a regression introduced with the recent especially since the devtools were working perfectly fine until maybe one or two weeks ago it does work in incognito mode in firefox how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Using different React instances across multiple frames throws errors\nwebsite or app repro steps 1 visit the codepen linked above 2 be sure to open the debug view so codepen doesnt add any additional iframes more info 3 observe warning in the console tab invalid renderer id 1 error in the components tab uncaught error cannot add node 3 because a node with that id is already in the store after dismissing the error all components seem to be accounted for you might need to adjust the hide components where option in my actual application the error pops up for every change in the tree making the devtools virtually unusable note this only seems to happen if the iframe is added some time after the initial react tree was mounted in the parent window when i remove the settimeout so the iframe is added synchronously i no longer see any warnings related issues how often does this bug happen every time devtools package automated no response devtools version automated manual 4277 572023 in google chrome version 11205615165 official build 64bit error message automated manual cannot add node 3 because a node with that id is already in the store error call stack automated manual at at bridgebridgeemit at at listener error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot remove node \"226752\" because no matching node was found in the Store.\nwebsite or app repro steps how often does this bug happen every time devtools package automated devtools version automated 42767f8c501f6 error message automated cannot remove node 226752 because no matching node was found in the store error call stack automated text at at bridgebridgeemit at at listener error component stack automated no response github query string automated text remove node because no matching node was found in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot remove node \"197\" because no matching node was found in the Store.\nwebsite or app repro steps 1 accessing react dev from a local app how often does this bug happen sometimes devtools package automated devtools version automated 42767f8c501f6 error message automated cannot remove node 197 because no matching node was found in the store error call stack automated text at at bridgebridgeemit at at listener error component stack automated no response github query string automated text remove node because no matching node was found in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Unable to build the extension locally\nwebsite or app na repro steps i am trying to build the chrome extension for react dev tools locally to test changes as i am looking forward to fix this issue but there seem to be some error with the packages looking forward to get some help windows powershell 4252023 94403 am how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: can not build react devtools for local development, instructions lead to error\nwebsite or app repro steps follow the instructions here to build local version of react devtools extension git clone cd react yarn install yarn buildfordevtools stuck on this step everytime yarn buildfordevtools throw afunction error signedsourcesignfile cannot sign file without token at object at modulecompile at at moduleload at functionmoduleload at modulerequire at require at object at modulecompile at is there anything else i need to set up in order to make this work how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Could not find node with id \"364\" in commit tree\nwebsite or app private repro steps private how often does this bug happen every time devtools package automated devtools version automated 427328ce1c171 error message automated could not find node with id 364 in commit tree error call stack automated text at at mapforeach at at at at mf at qk at mk at lk at sj error component stack automated text at at div at div at div at at profilerprofiler at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text not find node with id in commit tree intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: copy operations don't work in Chrome\nwebsite or app repro steps 1 go to components tab 2 for any component try to copy the value in props hooks etc to clipboard image how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: \nwebsite or app localhost repro steps in react routers latest version inside the loader or action function one is not able to use reduxjs functions like how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: Component is not a function when using Suspense and forwardRef\nreact version steps to reproduce i havent been able to create a minimal example yet if needed i will spend more time on it however it only seems to occur when suspending components rerender in a specific order description the component is not a function error is thrown when using suspense and forwardref together in a specific way it seems like reactreconciler doesnt properly handle forwardrefs in either renderwithhooksagain or the component variable is not a function in this case but a typeof render props ref any renderwithhooksagain tries to execute componentprops secondarg which throws this error im not too familiar with react internals if you can tell me how to trigger this codepath i can make a minimal reproduction more easily img width1303 altscreenshot 20230314 at 14 55 13 src"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: Nested useTransition makes isPending of outer one always false\nnested starttransition call takes over and makes parent starttransition unable to track ispending seb says its a bug repro 1 click the button 2 ispending in indexpagejs is true however ispending in appjs is false expected ispending in appjs is also true"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"792\" because a node with that id is already in the Store.\nwebsite or app repro steps log in to chatgpt how often does this bug happen often devtools package automated devtools version automated 427147f63dc54 error message automated cannot add node 792 because a node with that id is already in the store error call stack automated text error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug(@next): legacy `ReactDOM.render` crashes when rendering into `document` container\nplease provide a clear and concise description of what the bug is include screenshots if needed please test using the latest version of the relevant react packages to make sure your issue has not already been fixed react version steps to reproduce 1 reactdomrender into a document container your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react issues without reproduction steps or code examples may be immediately closed as not actionable link to code example the current behavior throws with react expected an element to exist in the document but one was not found react never removes the documentelement for any document it renders into so the cause is likely in some other script running on this page reactdomrender clears the container before rendering into it but with the new hostsingletons we expect an existing documentelement the odd part is that it seems like affected the next release even though enablehostsingletons is disabled for that release cc gnoff the expected behavior no crash like in reactdom1820"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: useSyncExternalStore will cause hydration missmatch in `StrictMode` if `serverSnapshot` is different from `snapshot`\nreact version react version problem in strictmode when using hydrateroot to render a component that using usesyncexternalstore it seems that useses will do hydration twice but in second hydration process useses does not use the result of getserversnapshot as initial state which will cause hydration error this problem will only happen in development mode reproduce link to code example it works well in react 182"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Can not work on devtools, instructions lead to error\nwebsite or app repro steps because react requires java not on macos but assumes brew installed brew update brew install java sudo ln sfn export zshrc export zshrc export because react requires node before v17 but assuming you have nvm installed nvm install 16 then the real stuff directions inside folders like chrome are quite wrong git clone cd react yarn install yarn buildfordevtools cd yarn buildchrome yarn buildchromelocal yarn run testchrome now inside devtools uncaught evalerror refused to evaluate a string as javascript because unsafeeval is not an allowed source of script in the following content security policy directive scriptsrc self wasmunsafeeval at at webpackrequire at at what exactly are you doing that works in order to build test and develop this extension how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n ERROR  TypeError: Cannot read property 'createElement' of undefined, js engine: hermes\napp using flipper dor react devtools repro steps migrate to current version of rn0711 using flipper enable hermes engine run the app how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated error typeerror cannot read property createelement of undefined js engine hermes error call stack automated text error typeerror cannot read property createelement of undefined js engine hermes this is related to path function initialize canvas canvasstylecsstext n xxbackgroundcolor redn xxopacity 05n bottom 0n left 0n pointerevents nonen position fixedn right 0n top 0n zindex 1000000000n var root rootfirstchild error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot remove node \"0\" because no matching node was found in the Store.\nwebsite or app app repro steps 1reactnative run android 2reactdevtools 3adb reverse tcp8097 tcp8097 4open dev tools on phone 5error how often does this bug happen every time devtools package automated reactdevtoolscore devtools version automated 427147f63dc54 error message automated cannot remove node 0 because no matching node was found in the store error call stack automated text at at femit at at at arrayforeach at aeonmessage at at at aemit eventsjs31520 at eexportsl at eexportsemit eventsjs31520 error component stack automated no response github query string automated text remove node because no matching node was found in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: The extension brokes some JavaScripts - React is not used.\nwebsite or app repro steps with the code in the sandbox but in a real page when the extension is enabled the tree is expanded and cannot be collapsed anymore image there are no errors in the console of the page but many in the extension i dont know if its correlated note this code is provided by symfony a popular php framework so many developer faces this issue note 2 this issue is quite new i also created an issue in symfony how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Element \"1307\" not found\nwebsite or app no source code available publically repro steps working on my local react project how often does this bug happen every time devtools package automated devtools version automated 427147f63dc54 error message automated element 1307 not found error call stack automated text at error component stack automated text at at suspense at at div at at at div at div at at at componentscomponents at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text not found intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"1\" because a node with that id is already in the Store.\nwebsite or app personal repro steps go on a react app open panel observe error how often does this bug happen every time devtools package automated devtools version automated 427147f63dc54 error message automated cannot add node 1 because a node with that id is already in the store error call stack automated text at at bridgebridgeemit at at listener error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: use() causes nested Suspense boundaries to not reveal \nnested suspense boundaries should reveal as the content becomes ready however this doesnt seem to work with use repro case expected suspense boundaries reveal separately actual it waits for everything before revealing anything"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Element \"51\" not found\nwebsite or app local app repro steps working on the browser presentation api not really sure what i did to make this happen how often does this bug happen every time devtools package automated devtools version automated 4270bd2ad89a4 error message automated element 51 not found error call stack automated text at error component stack automated text at at suspense at at div at at at div at div at at at componentscomponents at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text not found intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Element \"744\" not found\nwebsite or app repro steps occurred during mui datagrid setup how often does this bug happen every time devtools package automated devtools version automated 4270bd2ad89a4 error message automated element 744 not found error call stack automated text at error component stack automated text at at suspense at at div at at at div at div at at at componentscomponents at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text not found intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot remove node \"0\" because no matching node was found in the Store.\nwebsite or app repro steps devtools bug cannot remove node 0 because no matching node was found in the store how often does this bug happen every time devtools package automated reactdevtoolscore devtools version automated 426144e2ca393 error message automated cannot remove node 0 because no matching node was found in the store error call stack automated text at at femit at at at arrayforeach at aeonmessage at at at aemit eventsjs31520 at eexportsl at eexportsemit eventsjs31520 error component stack automated no response github query string automated text remove node because no matching node was found in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Element \"12\" not found\nwebsite or app chrome repro steps went to check react component dev tools for state values and got error how often does this bug happen every time devtools package automated devtools version automated 4270bd2ad89a4 error message automated element 12 not found error call stack automated text at error component stack automated text at at suspense at at div at at at div at div at at at componentscomponents at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text not found intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Element \"3\" not found\nwebsite or app repro steps as soon as the component is rendered as soon as the application is loaded i get the element 3 error above which stays consistent throughout every state change in my application start quizdata score isscored but i am not getting any console errors and the app is working as expected but i have no access to my react components or any visibility of the state changes occurring within the app how often does this bug happen every time devtools package automated devtools version automated 4270bd2ad89a4 error message automated element 3 not found error call stack automated text at error component stack automated text at at suspense at at div at at at div at div at at at componentscomponents at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text not found intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Element \"9\" not found | Also \"Element \"10\" not found\" / \"Element \"12\" not found\"...\nwebsite or app repro steps on first load i get multiple error warnings on all app components from down they are identified with different element numbers but appear to be directed to the same issue the error was thrown at if you select begin game in app the error in component can be dismissed but new errors appear on all newly rendered components below once again all have different element numbers directed to the same location mainjs3955815 this is issue is probably related to devtools bug element 41 not found chrome is up to date version 1080535971 official build x8664 and restarted i also tried reinstalling react extension running 4270 the app is using redux which one commenter in other thread mentioned might be a commonality how often does this bug happen every time devtools package automated devtools version automated 4270bd2ad89a4 error message automated element 9 not found error call stack automated text at error component stack automated text at at suspense at at div at at at div at div at at at componentscomponents at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text not found intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Element \"20\" not found\nwebsite or app website repro steps added a useeffect to a functional component how often does this bug happen sometimes devtools package automated devtools version automated 4270bd2ad89a4 error message automated element 20 not found error call stack automated text at error component stack automated text at at suspense at at div at at at div at div at at at componentscomponents at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text not found intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Element \"41\" not found\nwebsite or app repro steps in branch litmustools featurelit5 i just run the app and it throws this error how often does this bug happen every time devtools package automated devtools version automated 4270bd2ad89a4 error message automated element 41 not found error call stack automated text at error component stack automated text at at suspense at at div at at at div at div at at at componentscomponents at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text not found intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"47\" because a node with that id is already in the Store.\nwebsite or app private repro steps when we have multiple react application in the same page how often does this bug happen often devtools package automated devtools version automated 4250336ac8ceb error message automated cannot add node 47 because a node with that id is already in the store error call stack automated text error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"1\" because a node with that id is already in the Store.\nwebsite or app local personal app repro steps i was using global context how often does this bug happen every time devtools package automated devtools version automated 4250336ac8ceb error message automated cannot add node 1 because a node with that id is already in the store error call stack automated text at at bridgebridgeemit at at listener error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: react-devtools standalone launching and quitting after 2 seconds with no errors on Ubuntu 22.04\nwebsite or app repro steps run reactdevtools in the terminal an empty window appears for maybe 2 seconds and then disappears the terminal doesnt show any messages whatsoever there is another issue here regarding reactdevtools failing silently on debian where the submitter alleged that it was related to insufficient permissions to run electron not sure if thats related to this issue but i can run electron just fine its just reactdevtools that are failing os is ubuntu 2204 kubuntu node is v16160 reactdevtools 4250 updated to add url how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot read properties of undefined (reading 'isCollapsed')\nwebsite or app repro steps 3 how often does this bug happen sometimes devtools package automated devtools version automated 4250336ac8ceb error message automated cannot read properties of undefined reading iscollapsed error call stack automated text at at at at listrender at uj at sj at gl at fl at el at tl error component stack automated text at list at div at autosizer at div at div at treetree at div at div at at at componentscomponents at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text read properties of undefined reading iscollapsed intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: useReducer bail-out w/ useEffect + Suspense causes infinite loop (StrictMode error with next/experimental builds)\ni just found our lib doesnt pass tests with latest build unreleased ones react version steps to reproduce jsx const component const count dispatch usereducerprev prev 0 useeffect dispatch return count const app maximum update depth exceeded this can happen when a component repeatedly calls setstate inside componentwillupdate or componentdidupdate react limits the number of nested updates to prevent infinite loops link to code example the current behavior warning in strictmode the expected behavior no warning in strictmode 25049 seems related im not sure if its a bug or a misusage"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"1\" because a node with that id is already in the Store.\nwebsite or app website repro steps refresh page how often does this bug happen sometimes devtools package automated devtools version automated 4250336ac8ceb error message automated cannot add node 1 because a node with that id is already in the store error call stack automated text at at bridgebridgeemit at at listener error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"1\" because a node with that id is already in the Store.\nwebsite or app react developer tools repro steps open components in web developer tools how often does this bug happen only once devtools package automated devtools version automated 4250336ac8ceb error message automated cannot add node 1 because a node with that id is already in the store error call stack automated text error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: \"Hook parsing failed\" Components tab\nwebsite or app repro steps click components tab click on component click parse hook names how often does this bug happen every time devtools package automated no response devtools version automated 4250 error message automated hook parsing failed error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot remove node \"20025\" because no matching node was found in the Store.\nwebsite or app repro steps on inspecting comment modal how often does this bug happen every time devtools package automated devtools version automated 4250336ac8ceb error message automated cannot remove node 20025 because no matching node was found in the store error call stack automated text at at bridgebridgeemit at at listener error component stack automated text comment github query string automated text remove node because no matching node was found in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot remove node \"1390\" because no matching node was found in the Store.\nwebsite or app repro steps 1 create account 2 redirect to verify email page 3 copy otp from email 4 paste it in email page 5 redirect login 6 keep redirecting between login page and verify email page how often does this bug happen every time devtools package automated devtools version automated 42477f673317f error message automated cannot remove node 1390 because no matching node was found in the store error call stack automated text at at bridgebridgeemit at at listener error component stack automated no response github query string automated text remove node because no matching node was found in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPossible Suspense bug\ni think ive trapped a bug where– after react suspends and the data has resolved react bails out before rerendered some of the suspended components its possible the bug is in my suspense cache logic i realize im working with unfinalized apis here is a loom walk through of the code in question here is a replay recording of the bug with annotations from myself and andarist to reproduce the bug directly 1 checkout replay commit 1 in the main directory run yarn install 1 in run yarn dev 1 open and scroll down until you see loading below the entry containing cc acdlite who seemed interested in looking into this sometime obviously no hurry"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot remove node \"0\" because no matching node was found in the Store.\nwebsite or app react native app repro steps 1 run react native app 2 npx reactdevtools 3 adb reverse tcp8097 tcp8097 4 reload the app this error should come as mentioned below how often does this bug happen every time devtools package automated reactdevtoolscore devtools version automated 42477f673317f error message automated cannot remove node 0 because no matching node was found in the store error call stack automated text at at femit at at at arrayforeach at aeonmessage at at at aemit eventsjs31520 at eexportsl at eexportsemit eventsjs31520 error component stack automated no response github query string automated text remove node because no matching node was found in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Selecting/deselecting boolean from DevTools Component props causing loss of class functions\nwebsite or app repro steps 1 install webpack react babel with npm install in terminal 2 bundle app with webpack via webpack watch modedevelopement in terminal 3 open up indexhtml in chrome and open react devtools under components there should be a dog component within a person component where the person is passed as a prop to the dog 4 under dog props there should be a person object with a value of present being true if you click the button the value of present should change to false the number should switch to 0 and the checkbox should get deselected however if you manually select the checkbox to change between truefalse the prop seems to lose its prototype references to the original js class as an error stating it cannot find the function will be shown how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot remove node \"1168\" because no matching node was found in the Store.\nwebsite or app 1 repro steps 1 how often does this bug happen often devtools package automated devtools version automated 42477f673317f error message automated cannot remove node 1168 because no matching node was found in the store error call stack automated text at at bridgebridgeemit at at listener error component stack automated text 1 github query string automated text remove node because no matching node was found in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Component tree panel becomes unresponsive after clicking on a few components\nwebsite or app multiple but you can check at repro steps 1 access a website in chrome that uses react 2 open chrome developer tools 3 open the react developer tools components tabpanel 4 click on 5 10 components in the component tree individually to inspect them notes this started happening on all reactbased websites after updating to chrome version 1020500561 on my work macbook x8664 and my personal macbook arm64 reverting back to chrome 100 seems to help i had a coworker test as well with the same result you can still select individual components using the picker even after the panel locks up the lockup seems to happen quicker when expand component tree by default is selected in the components tab in the panel settings but will still lock up if you manually expand enough components how often does this bug happen every time devtools package automated devtools version automated 4246 5122022 error message automated none error call stack automated na error component stack automated na github query string automated na"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: \"Reload and profile\" aways disabled on Timeline tab\nwebsite or app betareactjsorg local development repro steps 1 2 yarn dev reload and profile is enabled for flamegraph img width724 altscreenshot 20220523 at 21 28 07 src but disabled for timeline img width671 altscreenshot 20220523 at 21 28 12 src and yet i can reload and profile in flamegraph then switch to timeline and it works so this doesnt add up how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"1\" because a node with that id is already in the Store.\nwebsite or app expo init repro steps all you have to do is use expo init or npx createreactnativeapp and make a fresh app with a blank template when i open it with expo start or npm start i get this message every time in the debugger when i press the dismiss button i get a box that says unsupported devtools backend version you are running reactdevtools version 4140d0ec283819 this requires bridge protocol version 1 however the current backend version uses bridge protocol version 2 to fix this upgrade the devtools npm package npm i g reactdevtools4220 i follow all the steps i can find to solve the issue including yarn resolutions updating nodejs and packages etc but nothing works at all i cannot initialize new apps without getting the error i really want this debugger to work again how often does this bug happen every time devtools package automated reactdevtoolscore devtools version automated 4140d0ec283819 error message automated cannot add node 1 because a node with that id is already in the store error call stack automated text at at cemit at at at arrayforeach at sgceonmessage at sn at semit eventsjs31520 at eexportsp at eexportsemit eventsjs31520 at eexportsdatamessage at eexportsgetdata at eexportsstartloop at eexportswrite at dowrite at writeorbuffer streamwritablejs3875 error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: console.log() crashes the app\nwebsite or app local development repro steps in order to reproduce it type consolelogany variable or functionality if using console log for printing string it works with not errors how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: When inspecting with DevTools, it fails to select correct react component when there are multiple react-dom instances in the application\nwebsite or app repro steps when using devtools in the linked codesandbox i am not able to select react components that are rendered by the microfe using the inspect tool steps to reproduce 1 go to 2 open react devtools and click on inspect icon with the select an element on the page to inspect it tooltip 3 inspect the component with the pink background and text microfe example heading 4 devtools selects app as the component or if the component type filter is disabled it selects the div where the microfe is mounted ideally it would actually select either the microferoot component or the corresponding html node if the filter is disabled i was able to get it working by doing the following change in the how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: I believe that UI and UX from React DevTools is a big bug\nwebsite or app repro steps hello community victoryhand i have an big question about the react devtools why is so different in comparasion with vue devtools all is more hard see the context indentify the states the components unamusedface in comparasion with vue devtools the react devtoosl dont have a pretty and functional ui and ux the contexts states and components dont have a ui ogarnized to easy indentification on vue devtools there tabs to components store contexts events and some other features see below image the vuex contexts in react environment image timeline of events image how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: TreeContext error: Can't access property \"id\" in undefined\nwebsite or app repro steps unfortunately i dont know how to reproduce this bug it was just logged to sentry it seems like theres a logic bug here though if selectedelementindex is null or is empty then flatindex would be 0 still– and this statement would result in an undefined entry js preventry 1 how often does this bug happen only once devtools package automated reactdevtoolsinline devtools version automated 4244 error message automated error cant access property id n is undefined error call stack automated text react errorboundary error cant access property id n is undefined at at at at at at at at at error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: forwardRef components not marked as \"rendered\" if context changed\nwebsite or app repro steps 1 goto 1 start profiling 3 enter a into the input 4 stop profiling how often does this bug happen every time devtools package automated no response devtools version automated 424346a98cff2 error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Error in event handler: Error: Attempting to use a disconnected port object\nwebsite or app repro steps 1 create a react app yarn create reactapp testreact cd testreact yarn start 2 create envdevelopment file in root httpstrue port4100 browsernone 3 visit in chrome v10004896127 4 open react devtools by inspecting page some times it shows components tab but in large application it does not show the components tab if it shows the tab the error message is sent to dev tools every second 5 see error message in 6 this is not reproducible in firefox v9901 how often does this bug happen every time devtools package automated no response devtools version automated 4243 3302022 error message automated error in event handler error attempting to use a disconnected port object error call stack automated buildbackgroundjs139 lone functionmodules webpackbootstrap the module cache var installedmodules the require function function check if module is in cache return create a new module and put it into the cache var module i moduleid l false exports execute the module function module moduleexports webpackrequire flag the module as loaded modulel true return the exports of the module return moduleexports expose the modules object webpackmodules webpackrequirem modules expose the module cache webpackrequirec installedmodules define getter function for harmony exports webpackrequired functionexports name getter name name enumerable true get getter define esmodule on exports webpackrequirer functionexports iftypeof symbol undefined symboltostringtag symboltostringtag value module esmodule value true create a fake namespace object mode 1 value is a module id require it mode 2 merge all properties of value into the ns mode 4 return value when already ns object mode 81 behave like require webpackrequiret functionvalue mode ifmode 1 value webpackrequirevalue ifmode 8 return value ifmode 4 typeof value object value valueesmodule return value var ns objectcreatenull webpackrequirerns default enumerable true value value ifmode 2 typeof value string forvar key in value webpackrequiredns key functionkey return valuekey bindnull key return ns getdefaultexport function for compatibility with nonharmony modules webpackrequiren functionmodule var getter module moduleesmodule function getdefault return moduledefault function getmoduleexports return module a getter return getter webpackrequireo functionobject property return property webpackpublicpath webpackrequirep build load entry module and return exports return 115 115 functionmodule exports webpackrequire use strict global chrome const ports const isfirefox 0 port let tab null let name null if isnumericportname tab portname name devtools else tab portsendertabid name contentscript if portstab portstab devtools null contentscript null portstabname port if portstabdevtools function isnumericstr return str str function file buildcontentscriptjs function function doublepipeone two function lonemessage function ltwomessage function shutdown onedisconnect twodisconnect function tabid tabid tabid path 16 icons16 reactbuildtype png 32 icons32 reactbuildtype png 48 icons48 reactbuildtype png 128 icons128 reactbuildtype png tabid tabid popup popups reactbuildtype html function return url new urlurlprotocol chrome function if tab tabid update popup page of any existing open tabs if they are restricted browser pages we cant update for any other types proddevoutdated etc as the content script needs to be injected at documentstart itself for those kinds of detection todo show a different popup pageto reload current page probably for old tabs opened before the extension is installed if isfirefox chrometabsquery tabs changeinfo tab listen to url changes on the active tab and update the devtools icon changeinfo tab if isfirefox we dont properly detect protected urls in firefox at the moment however we can reset the devtools icon to its loading state when the url changes it will be updated to the correct icon by the onmessage callback below if tabactive changeinfostatus loading tabid else dont reset the icon to the loading state for chrome or edge the onupdated callback fires more frequently for these browsers often after onmessage has been called sender var requestpayload portsid const tab sendertab if tab const id tabid this is sent from the hook content script it tells us a renderer has attached if we use browseraction instead of pageaction because this lets us display a custom default popup when react is not detected it is specified in the manifest id else switch requestpayload requestpayload null requestpayload void 0 void 0 requestpayloadtype case case forward the result of fetchinpage requests back to the extension const devtools portsid portsid null portsid void 0 void 0 portsiddevtools if devtools break error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add child \"foo\" to parent \"bar\" because parent node was not found in the Store.\nwebsite or app repro steps steps to reproduce 1 install all dependencies 2 run the project with npm start 3 navigate to 4 enter any number into phone number and click on get otp 5 enter any number into the text boxes and click on sign in 6 allow access to location 7 check the dev tools for the error how often does this bug happen every time devtools package automated devtools version automated 424346a98cff2 error message automated cannot add child 986 to parent 985 because parent node was not found in the store error call stack automated text error component stack automated no response github query string automated text add child to parent because parent node was not found in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nConsole dimming on second StrictMode render forces string cast\nplease provide a clear and concise description of what the bug is include screenshots if needed please test using the latest version of the relevant react packages to make sure your issue has not already been fixed react version 1800 congrats on the release smilingface steps to reproduce 1 during rendering of a component log something that doesnt naturally cast to a string eg consolelognew set 2 wrap the tree in strictmode 3 observe the console link to code example note that the console dimming isnt applied to the inline codesandbox dev tools so to see the issue you need to visit the fullscreen view here the current behavior in chrome img width479 altscreen shot 20220407 at 4 19 09 pm src as expected there are two console logs one dimmed unfortunately the way that the dimming works forces the second log to be serialized to a string this has two issues 1 it can result in two of the same logs looking very different from each other which is confusing to developers for example in the screenshot above its pretty surprising that those two console lines occur from the same consolelog call 2 it prevents browser dev tools introspection this can make it inconvenient or impossible to compare the two values if the string cast doesnt include the value as in the screenshot above this is problematic because a key use case of printing both values is to check whether theyre the same you can kind of work around the second issue by writing your own string cast at the log callsite but you lose the dx of introspection which is pretty unfortunate especially in the case of largedeeplynested objects etc easier to compare two native console values than two jsonstringify dumps the expected behavior while there is a new appreciated dev tools option to suppress logging for the second render entirely there is no way to disable the dimming feature any of the following options would solve the issue 1 provide a dev tools option to disable dimming 2 remove the dimming feature entirely so that both logs are always printed the same way 3 update the dimming implementation so that it doesnt force a string cast guessing this isnt possible 4 improve serialization of complex values imo this isnt a great option because it doesnt solve the issue of consistencyconfusion but it would be better than the current behavior if all other options are ruled out thanks for considering"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: [eslint-plugin-exhaustive-deps] hook wrongly marked as conditional (at exact number of conditionals in FC)\nplease provide a clear and concise description of what the bug is include screenshots if needed please test using the latest version of the relevant react packages to make sure your issue has not already been fixed when using an exact number of conditionals before and after a react hook the react hook hookname is called conditionally react hooks must be called in the exact same order in every component render rule is wrongly flagged as being violated this is a really weird bug and its kind of hard to explain just take a look at the code and watch as eslint flags the hook as somehow being conditional while this may seem like a huge edge case this actually triggered in our code base and caused all hooks in the component to be flagged as conditional react version 1800 doesnt seem to matter steps to reproduce 1 check out this project run yarn and run yarn eslint appfootsx 2 watch as the hook is incorrectly flagged as conditional 3 removing or adding one of the conditionals in the return statement makes the bug go away the same goes for removing one of the conditionals above the hook link to code example unfortunately i couldnt get it to work online because of a lack of terminals the current behavior hook is incorrectly flagged as conditional image the expected behavior hook should not be conditional"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: [eslint-plugin-exhaustive-deps] can't find unstable value.\nplease provide a clear and concise description of what the bug is include screenshots if needed please test using the latest version of the relevant react packages to make sure your issue has not already been fixed react version 1800 not important steps to reproduce ill show as a code img width593 alt스크린샷 20220404 오전 12 01 05 src link to code example please provide a codesandbox a link to a repository on github or provide a minimal code example that reproduces the problem you may provide a screenshot of the application if you think it is relevant to your bug report here are some tips for providing a minimal example the current behavior exhaustivedeps cant found unstable dependency the expected behavior warn lint message opinion i know this code is super weird but this code may be improved something like add more core lint rule like usestate is always declared as a const should find reallocation value and calculate real value or just stay it i just wonder what is your opinion thank you"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReact DOM UMD always warns in React 18\nthis is a false positive img width952 altscreenshot 20220330 at 18 25 00 src"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: No warning on infinite useEffect loop in React 18\nthis is supposed to consoleerror but it doesnt 17 warns"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"1\" because a node with that id is already in the Store.\nwebsite or app repro steps just opening the console and going to components or profiler shows this error i noticed that in the console there are two warnings for contentscriptjs i am assuming this file is part of this extension ﻿ contentscriptjs113 violation message handler took 210ms contentscriptjs113 violation message handler took 891ms how often does this bug happen sometimes devtools package automated devtools version automated 424082762bea5 error message automated cannot add node 1 because a node with that id is already in the store error call stack automated text at at bridgebridgeemit at at listener error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Error occurs when installing react-devtools in yarn berry project\nwebsite or app repro steps i tried to install reactdevtools with yarn berry so i encountered this error log  yarn add reactdevtools d ➤ yn0000 ┌ resolution step ➤ yn0002 │ d995e doesnt provide reactdom pd70ba requested by reactariaoverlays ➤ yn0002 │ d995e doesnt provide reactdom pa0a11 requested by ➤ yn0002 │ d995e doesnt provide reactdom pd5c9c requested by reactariacombobox ➤ yn0002 │ doesnt provide babelcore pff6e6 requested by ➤ yn0002 │ doesnt provide babelcore p4f633 requested by ➤ yn0002 │ doesnt provide babelcore pa1fad requested by babelpresetenv ➤ yn0002 │ devfeedworkspace doesnt provide typesreact p5404d requested by nativebase ➤ yn0002 │ devfeedworkspace doesnt provide reactdom pf66e9 requested by nativebase ➤ yn0002 │ devfeedworkspace doesnt provide reactdom pfc556 requested by reactuse ➤ yn0060 │ devfeedworkspace provides p3bb21 with version 421 which doesnt satisfy what nativebase requests ➤ yn0060 │ devfeedworkspace provides reactnativesvg pc0baf with version 1230 which doesnt satisfy what nativebase requests ➤ yn0002 │ doesnt provide babelpresetenv p1529d requested by jscodeshift ➤ yn0000 │ some peer dependencies are incorrectly met run yarn explain peerrequirements for details where is the sixletter pprefixed code ➤ yn0000 └ completed ➤ yn0000 ┌ fetch step ➤ yn0000 └ completed in 0s 393ms ➤ yn0000 ┌ link step ➤ yn0001 │ error while cloning enoent no such file or directory scandir ➤ yn0000 └ completed in 3s 361ms ➤ yn0000 failed with errors in 3s 927ms how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReact Devtools won't connect to Application running on iOS Simulator\nreact devtools doesnt connect to the instance running in the ios simulator react devtools screenshot image ios simulator screenshot image react native appears to have some interactivity as you can see devtools initialized and the inspector on the ios simulator is running in the condensed mode os macos monterey 1221 chip apple m1 pro"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot read properties of undefined (reading 'split')\nwebsite or app repro steps 1 enter the site 2 open reactdevtools 3 select wemaybe suspenses child component 4 and show following errors how often does this bug happen every time devtools package automated devtools version automated 4230e28a0db22 error message automated cannot read properties of undefined reading split error call stack automated text at at at gg at dj at jl at il at hl at wk at al at uk error component stack automated text at at div at at at div at div at at at componentscomponents at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text read properties of undefined reading split intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Unsupported Bridge operation \"0\"\nwebsite or app local app development repro steps just install react devtools and downgrade to 4110 how often does this bug happen every time devtools package automated reactdevtoolscore devtools version automated 4230e28a0db22 error message automated unsupported bridge operation 0 error call stack automated text at at cemit at at at arrayforeach at aeonmessage at at at aemit eventsjs31520 at eexportsl at eexportsemit eventsjs31520 error component stack automated no response github query string automated text bridge operation intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: DevTools failed to load source map\nwebsite or app inital react app npm createreactapp repro steps 1 created initial react app 2 typed npm start inside app folder 3 check console of chrome browser this is what i get on my console in chrome version 980475882 official build 64bit image as these messages are annoying please let me know how to fix this how often does this bug happen every time devtools package automated no response devtools version automated 4230 error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Unsupported Bridge operation \"0\"\nwebsite or app none repro steps gaolinxiong how often does this bug happen only once devtools package automated reactdevtoolscore devtools version automated 4230e28a0db22 error message automated unsupported bridge operation 0 error call stack automated text at at cemit at at at arrayforeach at aeonmessage at at at aemit eventsjs31520 at eexportsl at eexportsemit eventsjs31520 error component stack automated text 123 github query string automated text bridge operation intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDevTools should not crawl unmounted subtrees when profiling starts\npreviously we crawled all subtrees even notyetmounted ones to initialize context values this was not only unecessary but it also caused an error to be thrown this commit adds a test and fixes that behavior resolves 22970 test before screen shot 20220121 at 10 51 54 am test after screen shot 20220121 at 10 52 03 am"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Chrome Dev Tools extension shows websites built with other framework as React web sites\nwebsite or app repro steps 1 go to or 2 click on react dev tools extension 3 you should see message this page is using the production build of react checkmarkbutton how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Highlight updates when components render.\nwebsite or app nothing repro steps create a component list memoized reactmemo and if you only modify 1 of them this will mark that all are rendered but if they are memoized the report says not rerenders detected screenshot from 20220115 215108 if you see near to typography all those children are memoized and they arent rerendering expected but devtools still highliting them if u see those yellow boxes how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: 'This page is using the react build message' in every site\nwebsite or app youtubecom githubcom gmailcom lucidchartapp repro steps 1 open any web app not made with react eg youtubecom amazoncom githubcom gmailcom lucidchartapp 2 the react icon is on and the popover message says this page is using the production build of react checkmarkbutton how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReact 18: Context providers are reset to initial value in SSR during rendering\nask a question or share feedback about the react 18 release here while testing ssr streaming in latest react 18 experimental and alpha versions we noticed that context providers are reset to their initial values during rendering under certain conditions it works well when handling 1 request at a time however when the server gets 2 or more requests at the same time the context providers seem to get confused the context is correct at the beginning of the rendering for each request but it gets lost after a while theres a reproduction here using gaearon s demo to my understanding since the react tree is wrapped in a provider in ssr usecontext should never return null in the server have a look at the terminal and see how it actually logs null sometimes when getting multiple requests 0 this should never be null read function read 0 this should never be null read function read 0 this should never be null null 0 this should never be null null run the following code from the console to simulate multiple requests js function dorequest return fetch headers accepttexthtmlthenr rtext await promisealldorequest dorequest we saw this same issue in different setups using both webpack and vite thanks"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Error: Could not find ID for Fiber \"...\"\nwebsite or app repro steps 1 install repo 2 run repo 3 visit playground in your browser of choice 4 navigate to the dev tools and you should see the error how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot read properties of undefined (reading 'push')\nwebsite or app repro steps just view the components tab this site is written in rescript actually this is all the rescript code you need to break devtools rescript reactcomponent let make let unit unit reactupdatenoupdate reactuseeffect none reactupdate is provided by rescriptreactupdate how often does this bug happen every time devtools package automated devtools version automated 42200229baee2 error message automated cannot read properties of undefined reading push error call stack automated text at f at h at at inspectelementraw at objectinspectelement at at bridgeemit at at listener error component stack automated text at at suspense at at div at at at div at div at at at componentscomponents at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text read properties of undefined reading push intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"1\" because a node with that id is already in the Store.\nwebsite or app app repro steps 1 run npm start for native 2 run android for native 3 run react native debugger and thats how happened how often does this bug happen every time devtools package automated reactdevtoolscore devtools version automated 4140d0ec283819 error message automated cannot add node 1 because a node with that id is already in the store error call stack automated text at at cemit at at at arrayforeach at sgceonmessage at sn at semit eventsjs31520 at eexportsp at eexportsemit eventsjs31520 at eexportsdatamessage at eexportsgetdata at eexportsstartloop at eexportswrite at dowrite at writeorbuffer streamwritablejs3875 error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: \nusing reactdom1800rc0 inside a nextjs projectnext1207 then opening a antd dropdown will cause page to be deadly frozen after downgraded react to 1702 the issue disappears my wild guess this issue caused by some conflict btw dom manipulation and animation im happy to show detailed stuff if the react team needs react version 1800rc0"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"1\" because a node with that id is already in the Store.\nwebsite or app repro steps accualy this bug appears only on react native debugger the web version of debugger doesnt show any errors the project is new and i just installed packages expo install reactnavigation expo install reactnavigationstack expo install expoapploading expo install reactnativescreens expo install so my dependencies are json dependencies expo 4302 expostatusbar 110 react 1701 reactdom 1701 reactnative 0643 reactnativeweb 0171 reactnavigation 444 reactnavigationstack 2104 expoapploading 121 reactnativescreens 380 332 i checked and now this bug appears in every new expo init even if it is just blank project old projects work fine how often does this bug happen every time devtools package automated reactdevtoolscore devtools version automated 4140d0ec283819 error message automated cannot add node 1 because a node with that id is already in the store error call stack automated text at at cemit at at at arrayforeach at sgceonmessage at sn at semit eventsjs31520 at eexportsp at eexportsemit eventsjs31520 at eexportsdatamessage at eexportsgetdata at eexportsstartloop at eexportswrite at dowrite at writeorbuffer streamwritablejs3875 error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nreact-devtools report Error: Cannot find module './app'\nreactdevtools version 4220 npm g install reactdevtools reactdevtools throw err error cannot find module app require stack at at functionresolve at object at modulecompile at at moduleload at functionmoduleload at as runmain at code modulenotfound requirestack"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Fetch API cannot load webpack-internal:///... URL scheme \"webpack-internal\" is not supported\nwebsite or app repro steps most actions in devtools search for component click on component hook parsing profile record etc cause this error i am using nextjs 12 within a nx monorepo how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"1\" because a node with that id is already in the Store.\nwebsite or app repro steps 1 open chrome with 50 tabs 2 run reactbased website locally 3 open chrome dev tools to investigate activelink component hierarchy inside navbar component 4 activelink component from next was used 5 get uncaught error screenshot how often does this bug happen sometimes devtools package automated devtools version automated 42102f8f60ca8 error message automated cannot add node 1 because a node with that id is already in the store error call stack automated text at at bridgebridgeemit at at listener error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: Error checking code is skipped for async useEffect argument\nplease provide a clear and concise description of what the bug is include screenshots if needed please test using the latest version of the relevant react packages to make sure your issue has not already been fixed react no longer complains when the function passed to useeffect returns a promise either directly or by being labeled async im not in the habit of doing this so it was only when i watched someone else make the function async and there were no errors that i realized that something had changed since 6131 the newest version i could find that still complained i can see the functionality is still present in in but when i trace through it the effecttag is set to a different value and the test is skipped i realize that we now have an eslint rule that provides the same message but the lack of warning caused confusion about whether asynchronous functions were now allowed react version 1702 steps to reproduce 1 write a useeffect that has an async function 2 open the console and observe that it doesnt complain your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react issues without reproduction steps or code examples may be immediately closed as not actionable link to code example please provide a codesandbox a link to a repository on github or provide a minimal code example that reproduces the problem you may provide a screenshot of the application if you think it is relevant to your bug report here are some tips for providing a minimal example the current behavior the code runs with no complaints and the cleaner function is ignored the expected behavior the console should show the warning warning an effect function must not return anything besides a function which is used for cleanup it looks like you wrote useeffectasync or returned a promise instead write the async function inside your effect and call it immediately useeffect async function fetchdata you can await here const response await myapigetdatasomeid fetchdata someid or if effect doesnt need props or state"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReact 18 Bug: react-dom/server \"Detected multiple renderers...\" if preceeded by react-test-renderer\nplease provide a clear and concise description of what the bug is include screenshots if needed please test using the latest version of the relevant react packages to make sure your issue has not already been fixed react version steps to reproduce 1 render a context with reacttestrenderer wrapped in act 2 render the same context with reactdomserver your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react issues without reproduction steps or code examples may be immediately closed as not actionable link to code example js const context function component renderer return let testrendererroot reacttestrendereract testrendererroot reacttestrendereract the current behavior rendertostring results in the console error warning detected multiple renderers concurrently rendering the same context provider this is currently unsupported the expected behavior no error like in react 17 considering all renders are wrapped in their corresponding act i dont expect that im concurrently rendering i tried to understand when we reset the renderersigil responsible for checking if we concurrently rendering is reset and it seems like we never reset it but only initialize it when creating the context createcontext so it either seems like multiple renderers in the same module are not supported anymore or the reset is missing"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot read properties of undefined (reading 'push')\nwebsite or app repro steps i stumbled across the weirdest bug with react devtools and hooks that causes it to error out when inspecting a component a minimal test case is documented in the code sandbox link along with more details on the behavior and seeminglyarbitrary fixes this does not affect the actual functionality of the app itself in any way it behaves exactly as expected how often does this bug happen every time devtools package automated devtools version automated 42102f8f60ca8 error message automated cannot read properties of undefined reading push error call stack automated text at j at l at at inspectelementraw at objectinspectelement at at bridgeemit at at listener error component stack automated text at at suspense at at div at at at div at div at at at componentscomponents at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text read properties of undefined reading push intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: React instrumentation encountered an error: Error: Could not find ID for Fiber \"Portal\"\nplease provide a clear and concise description of what the bug is include screenshots if needed please test using the latest version of the relevant react packages to make sure your issue has not already been fixed react version 1702 steps to reproduce 1 when i execute modalhide 2 image your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react issues without reproduction steps or code examples may be immediately closed as not actionable link to code example image please provide a codesandbox a link to a repository on github or provide a minimal code example that reproduces the problem you may provide a screenshot of the application if you think it is relevant to your bug report here are some tips for providing a minimal example the current behavior the expected behavior"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] dispatcher.useId is not a function\nwebsite or app repro steps 1 open 2 inspect app how often does this bug happen every time devtools package automated devtools version automated 42102f8f60ca8 error message automated dispatcheruseid is not a function error call stack automated text at useid at app at l at at inspectelementraw at objectinspectelement at at bridgeemit at at listener error component stack automated text at at suspense at at div at at at div at div at at at componentscomponents at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text is not a function intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: use-sync-external-store fails to install via npm\nwhen trying to install the usesyncexternalstore package via npm i receive an error that it depends on a version of react that doesnt seem to exist react version 17 steps to reproduce 1 mkdir example cd example npm init 2 npm i react reactdom usesyncexternalstore the current behavior npm fails to install the usesyncexternalstore package with the following error npm i usesyncexternalstore npm err code eresolve npm err eresolve unable to resolve dependency tree npm err npm err while resolving example100 npm err found react1702 npm err nodemodulesreact npm err react1702 from the root project npm err npm err could not resolve dependency npm err peer from npm err npm err usesyncexternalstore from the root project npm err npm err fix the upstream dependency conflict or retry npm err this command with force or legacypeerdeps npm err to accept an incorrect and potentially broken dependency resolution npm err the expected behavior it successfully installs the package and i can use it in react v17 and the latest alpha version"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"1\" because a node with that id is already in the Store.\nscreen shot 20211021 at 12 23 23 pm screen shot 20211021 at 12 22 57 pm website or app daily harvest repro steps 1 enable debug on the ios emulator 2 enable inspector 3 disable inspector navigate to a different screen 4 try enabling inspector again how often does this bug happen every time devtools package automated reactdevtoolscore devtools version automated 4180f58bbcf9a error message automated cannot add node 1 because a node with that id is already in the store error call stack automated text at at cemit at at at arrayforeach at aeonmessage at at at aemit eventsjs31520 at eexportsf at eexportsemit eventsjs31520 error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Blank tools localhost - react_devtools_backend.js:5821 Uncaught Error: Could not find ID for Fiber\nwebsite or app repro steps react devtools 4200 react 1686 not sure if relevant but reactscripts 403 first i get an blank devtools components but when picking select element arrow and hover over elements a lot of errors like this one shows up in the console uncaught error could not find id for fiber contextprovider at getfiberidthrows at at at showoverlay at onpointerover getfiberidthrows getfiberidfornative inspect showoverlay onpointerover no other errors occur devtools works fine on deployed version eg works fine pr and issue that could be related issue 22577 pr 22527 maybe relevant comment from author and maintainer of react devtools earlier fiber problem how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Blank tools localhost only\nwebsite or app googlecom repro steps this started after last update 4200 image image how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"1\" because a node with that id is already in the Store.\nwebsite or app repro steps not able to see how often does this bug happen sometimes devtools package automated devtools version automated 419220ca9b565 error message automated cannot add node 1 because a node with that id is already in the store error call stack automated text at at bridgebridgeemit at at listener error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Cannot add node \"2934\" because a node with that id is already in the Store.\nwebsite or app httplocalhost3000 repro steps when i was using react select and dropdown i clicked on and before opening the dropdown this error showed up and react dev tools stopped working how often does this bug happen sometimes devtools package automated devtools version automated 41902178a831a error message automated cannot add node 2934 because a node with that id is already in the store error call stack automated text at at bridgebridgeemit at at listener error component stack automated no response github query string automated text add node because a node with that id is already in the store intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Could not inspect element with id \"15\". Error thrown:Cached data for element \"15\" not found\nwebsite or app repro steps cd repo and then start the server using npm start in browsermozilla firefox when i try to add the user and age and trying to debug the output in listusers component i m facing this error screenshot from 20211001 185236 how often does this bug happen only once devtools package automated devtools version automated 41902178a831a error message automated could not inspect element with id 15 error throwncached data for element 15 not found error call stack automated no response error component stack automated text suspense div div div div div div div div github query string automated text not inspect element with id error thrown cached data for element not found intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Emoji as visual helper produce strange symbole\nwebsite or app repro steps emoji seem supported but produce strange symbole image to test emoji on window os use win greensquare how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]:  Emoji seem supported but produce strange symbole\nwebsite or app repro steps emoji seem supported but produce strange symbole image very low priority maybe because it affect nothing how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: Hook parsing fails with fetch error\nwebsite or app repro steps have a webpack project that uses a domain mapped to your local ip such as appxwhenidevnet in my case thats served with https try to resolve hook names check console and observe the million errors shows my console how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDevTools: Backend console settings reportedly not synced to RN backend\nfeedthejim reported that disabling the break on warning feature does not update the backend settings in memory without a reload for react native screen shot 20210914 at 11 07 04 am i believe the new settings should be updated here but it sounds like they arent we should investigate"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug] Could not inspect element with id \"28\". Error thrown:Cached data for element \"28\" not found\nwebsite or app website url localhost repro steps clicked the reload devtools button to turn devtools in light mode devtools were already in light mode how often does this bug happen only once devtools package automated devtools version automated 4180f58bbcf9a error message automated could not inspect element with id 28 error throwncached data for element 28 not found error call stack automated no response error component stack automated text at at suspense at at div at at at div at div at at at componentscomponents at at div at div at themeprovider at portaledcontent at div at div at div at themeprovider at at at at at at devtoolsdevtools github query string automated text not inspect element with id error thrown cached data for element not found intitle isissue isopen ispublic labelcomponent developer tools repofacebookreact"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Bug]: provide an icon to Edge devtools?\nwebsite or app website repro steps 1 open developer tools in edge 2 go to settings experiment enable focus mode reload devtools 3 we can see the react extension is loaded as below in devtools image 4 since the react extension doesnt provide the icon when its created devtools fallback to use the default icon to represent the extension however weve received couple of requests from users that theyd like to see the icon in the panel for instance image wondering if its possible to provide an icon to edge in the thank you for your support how often does this bug happen every time devtools package automated no response devtools version automated no response error message automated no response error call stack automated no response error component stack automated no response github query string automated no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: `onResize` media event is missing\nnote i’m happy to make a pull request to fix this i just wanted to log it first to ensure there’s interest react’s synthetic media events contain several existing media events for instance onloadedmetadata and onvolumechange but there is no onresize handler resize is a standard media event that triggers when one or both of the videowidth and videoheight attributes have just been updated it’s useful for responding to resolution changes in video players react version 1702 latest release as of initial issue report steps to reproduce 1 create a element with an onresize prop 2 check the console for the following warning warning unknown event handler property onresize it will be ignored link to code example the current behavior onresize handlers are ignored on elements the expected behavior onresize handlers are valid on elements"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFeature Request(devtools): `launch-editor` for selected component\nwhy user can open the source file in editoride by oneclick it is a useful feature in vuedevtools how add a click event on here call add to devserveror any scaffold handle by himself before anyonemaybe me sends a pr i want to know how do the reactteam thinks about it"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFeature proposal: Hook equivalent to createSlice from Redux Toolkit?\nwould this be useful a function that accepts an initial state an object full of reducer functions and a slice name and automatically generates action creators and action types that correspond to the reducers and state from createslice"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[DevTools Feature Request] Break on Warnings\nitd be nice to have a toggle to pause the debugger when warnings fire so you can inspect the stack as its happening consoleerror function if isbreakon debugger see"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAllow opting out of invokeGuardedCallbackDev\nat the moment when in development mode react uses a special workflow for callbacks to avoid using trycatch it works well so well that several testing frameworks also get their uncaught exception handling triggered example with mocha js import react from react import render from testinglibraryreact function mycomponent dothrow if dothrow throw new errorim bad return itshould throw function expect render tothrow behavior when running the test with the production build of reactreactdom the test passes with the usual warning of act being unsupported in prod build when running the test with the development build of reactreactdom the test fails with error uncaught error im bad the root cause is runs the callback in an event to avoid using a trycatch block… and trips mochajs uncaught exception detector note i am aware of error boundaries i removed it from the example because the behavior is identical with it note i used testinglibrary for clarity but using act and renderdom manually yields the same result expected behavior either make it work out of the box or have the possibility to opt out of and force the use of the regular trycatch implementation in development too"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDevTools: Hovering \"Rendered by\" list should highlight elements\nthis list is pretty awesome img width390 altscreenshot 20200403 at 00 12 08 src but always struggle to guess which component in the owner list i need to jump to we should make hovering the owner list highlight components just like the main tree view does hristokanchev interested"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd colors to component's name ( in Component tree ) for visual feedback about type of Component or Node\nwhat is the current behavior all the components name in the component tree are of the same color what is the expected behavior it would be helpful if they have different colors indicating the type of component whether its native html node or contexts or simple react component i know we can filter it but visual indication will be helpful too"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nreact-refresh: add options to override $RefreshReg$ and $RefreshSig$ for better System.js integration\ndo you want to request a feature or report a bug feature right now babel plugin emits globals js windowrefreshreg windowrefreshsig type type it would be nice to have them configurable that would allow to use importmeta in environments like systemjs and have simpler implementation js import runtime from reactrefreshruntime function url return url refreshsig refreshreg type id id url id runtimeregistertype id if you dont mind i could create pr with changes to reactrefreshbabel next week environment js systemjs 614 react 16110 reactdom 16110 reactrefresh 060"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nApply props/state/hooks edits on blur\ndo you want to request a feature or report a bug feature what is the current behavior trigger by press enter button what is the expected behavior trigger by out of focus or pressing enter button"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReact DevTools force re-render button\nid like to have a button that forces a rerender of the selected component when clicked for example adding a button like this on the right of the component controls image this can be accomplished today by adding a new prop and changing the prop but its more work than i want to do this would be useful for use while profiling how a component performs with unnecessary rerenders right now i just have a button thats tied to a forcerender function jsx function useforcererender const set reactusestate return reactusecallback set function filtercomponent const forcererender useforcererender return force rerender more jsx would be cool to have this builtin"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nEnhance React DevTools \"Why did this render?\" for values nested in prop objects\ndo you want to request a feature or report a bug feature what is the current behavior as demonstrated here why did this render does a great job reporting what prop changed but it does not yet report which nested value changed for props that are comprised of nested objects what is the expected behavior the why did this render shows a collapsible tree with the leaf value that changed inside the prop object displayed a couple use cases this would benefit in some cases it is most convenient creating props that are nested objects for instance maybe you need to pass an object to a library and youd like to avoid storing the individual object items as separate prop variables such that you dont need to redefine them together as a dict later on but changes are due to a single element in the dict that youd like visibility on in react devtools in rarer cases it is unavoidable having props that arent nested objects for instance how could i preserve the prototype key of my props object without react stripping it if i wrap my props inside an object that key can be preserved but now all my props are considered 1 prop to the profiler and i have no visibility on which prop changed with this change i could expand the tree and drill down to which individual values changed which versions of react and which browser os are affected by this issue did this work in previous versions of react new feature never before released in react devtools i am using 1686"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nShow property type of value (string,int,etc) on state/props.\nfeature what is the current behavior on the new developer tool you are unable to see what property type the value you used to be able to see if the value was a string or int because of the quotation marks for example id 1 string or id 1 int both string and int are shown without quotes what is the expected behavior i want to see if the value inside the prop or state is an string or integer by using quotation marks on the value id 1 which versions of react and which browser os are affected by this issue did this work in previous versions of react im using version 405 8192019 did this work in previous versions of react yes 3"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDevtools V4: Where is Highlight Updates?\nif i understood correctly this is the correct repository for devtools v4 right i just noticed that react devtool were updated im missing the highlight updates function how can i activate it image image version 402 8152019"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNew Devtools Cannot Expand Obervables\ndo you want to request a feature or report a bug bug what is the current behavior devtools used to be able to expand observables created by mobx with the new update that is no longer possible image if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below check the props of the wrappedcomponent in devtools storethings does not expand what is the expected behavior devtools should expand observables as it does any other object which versions of react and which browser os are affected by this issue did this work in previous versions of react this only seems to be an issue with observables created by mob v4 v5 works as expected"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Feature Request] Finish/normalize Portal API\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug feature what is the expected behavior portals are in a weird state the core react knows about them but you can only create them from other libs eg reactdom you have to branch your code because they can’t be serverside rendered and so on this is just a prerfc to brainstorm ways that portals can become firstclass citizens extend reactcreateref to allow an optional rendererspecific argument eg the dom element matching useref add ref note the use of ref rather than a eg a direct dom element deprecate reactdomcreateportal now with some thought into the structure of your app with modals they could be eg serverside rendered with function appprops const modal userefnull return propscontent function modalprops const modal return reactcreateportal propschildren modal somewhere in propscontent tree return visible hello world after reactdomcreateportal is deprecated legacy web or those with no need to ssr portals can simply upgrade with thisel for the same behavior as an initial version react can error if refcurrent is null when it goes to mount the portal some sort of dirty flag could be considered separately if proven necessary but with the pattern proposed above it shouldn’t be necessary as the portal host would always be mounted first as a natural consequence of how react works"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAllow ReactNode as a type for the child of <option/>\ndo you want to request a feature or report a bug feature what is the current behavior currently the options element only allows types number and string what is the expected behavior an option should allow for a reactnode as a child in addition to a number string which versions of react and which browser os are affected by this issue did this work in previous versions of react all versions all browser types to the best of my knowledge no ps this is my first feature request here so let me know if i need to adjust the feature request in any way"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProvide withHooks HOC to decouple hooks and components\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug feature what is the current behavior currently the recommended way to use hooks involves coupling them with components by this i mean that components are aware of the hooks they consume and depend on them explicitly this issue thread on the recompose repo discusses this issue in some detail and how recompose favored keeping components dumb but wraps them in hocs to make them smart hooks promote baking the smartness right into the component itself what is the expected behavior react should offer a way to decouple components from the hooks they consume i suggest a withhooks hoc that maps hooks to props this will be a familiar model for those who have used redux with react jsx const withhooks maphookstoprops wrappedcomponent return props let hookprops maphookstopropsprops return const counter props return counter propscounter increment decrement const maphookstoprops props let counter setcounter usestate0 return counter increment setcounterprev prev 1 decrement setcounterprev prev 1 const enhancedcounter demo some reasons why this is nice 1 it decouples components from the things that make them smart some examples of things that could make dumb components smart include hooks redux and good ol parent components by mapping hooks to props we make it very easy to swap a dumb components hookpowered brain for a new brain say a reduxpowered brain 2 not sure if its a good idea but i know several people trying to replace redux with hooks in their applications for these people migrations from redux to hooks would be dead simple because they could replace mapstatetoprops and mapdispatchtoprops with maphookstoprops and wouldnt have to worry about touching the underlying component 3 testing is also easier because we can test the component in isolation without the hooks baked in 4 it makes prop overrides possible in the case of our enhancedcounter we could override the counter prop by doing a real world example of hooks making things harder to override includes materialuis new styling approach via hooks because classes are provided via hook and no longer via props we would need custom logic to override classes via props with the new hookbased approach jsx export default function hookprops let classes usestyles classes classes propsclasses return hook which versions of react and which browser os are affected by this issue did this work in previous versions of react for versions of react 168"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfeature request: export of ReactDOM libraries\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug its a feature what is the current behavior internal shared libraries of reactdom is not exported if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below na what is the expected behavior it is great that some shared libraries such as iscustomcomponent or domnamespaces are exported from reactdom and available externally they are useful to know what types of html tags are regarded to be valid one by react for example with static analysis issued at which versions of react and which browser os are affected by this issue did this work in previous versions of react na"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd option in shallow renderer to run effects/componentDidUpdate/componentDidMount\ndo you want to request a feature or report a bug feature what is the current behavior the shallow renderer does not run componentdidupdate componentdidmount or useeffect functions ill call them effect functions for short what is the expected behavior see this enzyme issue for more details about where this request is coming from but the general idea is that it is often nice to run effect functions even when shallow rendering rather than having to use full rendering on those specific tests if the shallow renderer provided an option to run the effect functions it would allow people who test with shallow rendering to more easily test their components enzyme currently supports this in class components by calling directly on the component instance but this would be a much harder thing to do for hooks since they are usually anonymous enzyme used to not allow this at all but then added an option to turn on this behavior in their shallow renderer before finally turning it on by default and then adding an option to turn it off it didnt seem to cause too many issues for them so i think this approach could work well for the react shallow renderer as well obviously im only asking for an option to turn it on now not to change the default or anything which versions of react and which browser os are affected by this issue did this work in previous versions of react all and no it was never supported afaik"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUsing context to pass down mount order to children with concurrent\ndo you want to request a feature or report a bug feature use case what is the current behavior it seems currently there is no way to get the order of children from the children themselves with context what is the expected behavior ive run into this now in three use cases when building a style system breadcrumbs segmented views and text rhythmspacing example 1 breadcrumbs you want to show an arrow on all but the last breadcrumb but they may be deeply nested ts let breadcrumborder createcontext index 1 total 1 let button props let order return total 1px solid red none props let myview return where myview should provide the ordering so that the subviews can access total and index and properly style the other use cases are basically identical but for different patterns one is for joining together buttons that are in a row in the interface segmented and the other is for collapsing margins when you have text elements in a vertical column really this ticket encompasses more of a question or request for documentation clarity here im not sure how it is not preconcurrent but im assuming mountorder will be nondeterministic if not now then shortly is there any reference to a pattern that works for this use case namely how children can access their mount order total children i can do it now usereducercontext but ive seen it mount in a weird order at least once and think it was due to a suspense type thing and would be curious a better practice for this"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[useContext] Throw error if 'useContext' is used outside function components\ndo you want to request a feature or report a bug feature need better errors what is the current behavior consider the following functional component import react usecontext from react const myfunctioncomponent props hello usecontext the immediate reaction for most of us newbies to hooks to refactor the above code to accomodate usecontext is as follows import react usecontext from react import mycontext from mycontext react does not throw error const mycontextvalue usecontextmycontext const myfunctioncomponent props hello usecontext mycontextvalue the way to actually refactor is to explictly convert the arrow function return expression into a function body and then accomodate usecontext inside along with a return statement like this import react usecontext from react import mycontext from mycontext const myfunctioncomponent props const mycontextvalue usecontextmycontext return hello usecontext mycontextvalue not only react does not throw error react app actually compiles while the component in question fails to load with no information this is very difficult to pin the reason to this specific issue what is the expected behavior react should ideally throw some kind of error when usecontext is used outside of function components this lack of error really bites us for people who are refactoring function components without a return statement which versions of react and which browser os are affected by this issue did this work in previous versions of react react 168x with hooks support"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[ESLint] Hardcore rule allowing default hooks using only inside custom ones\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug feature what is the current behavior there is no rule what is the expected behavior we have some hardcore plugins like eslintpluginlodashfp why not have eslint hardcore rule allowing default hooks using only inside custom ones"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPass dependencies to `useMemo` callback as arguments\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug feature what is the current behavior the usememo factory function does not receive any arguments what is the desired behavior the usememo factory function would receive the dependencies as arguments why this would allow more compact syntax for memoizing components because of implicit returns and desctructuring this came to mind after experiencing some of the issues in 14110 there may be other potential use cases too example of current behavior jsx const avatar const src usesomeglobalstate state stateuseravatarsrc return usememo src example of proposed behavior jsx const avatar usememo src stateuseravatarsrc which versions of react and which browser os are affected by this issue did this work in previous versions of react react 1681"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnhelpful warning for `act` for react-dom@16.8\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug featureimprovement what is the current behavior if there is test code that should be wrapped in act then the current warning is given consoleerror warning an update to null inside a test was not wrapped in act when testing code that causes react state updates should be wrapped into act act fire events that update state assert on the output this ensures that youre testing the behavior the user would see in the browser learn more at when upgrading a large code base this is basically useless what is the expected behavior provide at least the test name if not the line number of code that triggered the warning which versions of react and which browser os are affected by this issue did this work in previous versions of react react1680 reactdom1680"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nadding if directive \nif you added if directive to any element for showing the element or not that would be better than making a js expression in my opinion regular way js const app props reactiftrue let name propsname return name koko name null reactdomrender my way i edited the react file btw and it worked js const app props let name propsname return name reactdomrender mmm i hope you talk that into consideration i mean less than 1kb will not make difference d react code js var reservedprops key true ref true self true source true reactif true if config null if hasvalidrefconfig ref configref if hasvalidkeyconfig key configkey i added that if configreactif reactif configreactif if reactif false return null else if reactif true reactif false consoleerrorreactif expression didnt return bolean value self configself undefined null configself source configsource undefined null configsource remaining properties are added to a new props object for propname in config if propname propspropname configpropname"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupport Proxy as child\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug feature what is the current behavior objects are not valid as a react child if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below na what is the expected behavior im trying to build a system that autodetects if data is used in a react component to do this i detect usage during render by using proxies which can register all access this data in turn is used to prevent needless rerenders a parent component can pass a proxy which represents a string for example to a child component which without knowing it is a proxy can use this value in a calculation eg propsvalue 1 or the value is propsvalue this can be handled with which is called by js automatically when used in this sort of expression however this doesnt work if the child now passes the proxy directly to react as a child jsx return thispropschildvalue react will do a typeof on the child find it is an object and report objects are not valid as a react child unfortunately typeof cannot be spoofed with proxy and it will always return object the relevant code is found here the alternative could be for react to check if theres a and if so evaluate it to find the intended value and to retry with this value as the child it could be as simple as inserting the following code here js if typeof symbol undefined const toprimitive if toprimitive const value toprimitivestring if typeof value object return value namesofar callback traversecontext it would be great if react would support this usecase the alternative is for parent components to resolve the value which would attribute the access to the parent component instead of the child where its really being used this in turn would cause the parent to be rerendered when only the child is being changed if the child is aware it may be receiving proxy objects it can resolve the value itself however the whole point of using proxies is to automate all the refresh logic like also not needing to resolve the value would allow the value to propagate through to descendant components which may be wholly unaware of the proxy which versions of react and which browser os are affected by this issue did this work in previous versions of react all version never worked before"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMake it easier to debug when Context uses defaultValue accidentally due to no provider\ni just spend several hours debugging app blaming everything except me ofc i am using this usetheme hook ts import react from react import themecontext from contextsthemecontext const usetheme const theme if theme null throw errorusetheme please provide themecontext value return theme export default usetheme some styles were light while other dark very strange then i found the bug in my code themecontextprovider was sometimes used after using usetheme themecontext had an initial value different than provided while its probably fine that react allows us to use default context value without a parent provider it can lead to hard to find bugs therefore i decided to never provide default context value and throw an exception in usefoocontext hook to warn about it because of dx react should reconsider default initial context values in my humble opinion"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\neslint-plugin-react-hooks should report errors inside unnamed functions\ni want to report a bug for the hooks plugin what is the current behavior there was no error report after running eslint but the component failed when running in the browser from the chrome dev console it reported uncaught error rendered fewer hooks than expected this may be caused by an accidental early return statement if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react here is a link to the github repo what is the expected behavior followed the hooks api guide which says react hooks provides a linter plugin to enforce these rules it should have reported a usage violation when the eslint hooks plugin is specified which versions of react and which browser os are affected by this issue did this work in previous versions of react using window 10 os and chrome browser 1 first ran npx createreactapp hooks 2 installed react 1670alpha2 and reactdom 1670alpha2 3 installed eslint dev dependencies babeleslint 900 babelloader 804 eslint 590 eslintconfigairbnb 1710 eslintloader 211 eslintpluginimport 2140 eslintpluginjsxa11y 612 eslintpluginreact 7111 000 4 created the eslintrcjson following the instructions from the hooks api doc then ran package script lint as follows npm run lint no errors reported then ran package script start as follows npm start the react component counthooks calls usestate incorrectly and reports error in the browser dev console"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFeature Idea: useError hook\ndo you want to request a feature or report a bug feature idea what is the current behavior currently there is no hook for dealing with errors in a components subtree what is the expected behavior have a hook that allows for functional components to act as error boundaries example function myerrorboundary const caughterror useerrorcatching if caughterror null return return which versions of react and which browser os are affected by this issue did this work in previous versions of react na"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nreact-is memo\nfeature request what is the current behavior reactis now doesnt have method to check if element is memolike isforwardref maybe there are some reasons why its not implemented"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupport reporting Suspense loading indicator outside of the suspended tree\ncryptic title i can imagine but i am not aware that something like this would have been mentioned anywhere so far i have a page showing some statistics and its split into two even panels the left panel is showing some numbers and contains a form to set necessary filters the right panel is showing some other details about filtered data initially only filter form is visible nothing else the user sets the filter and hits the filter button to send out a request there is a requirement to show a text loader in the left panel and the right panel should be showing content loader animation too many loaders perhaps well it kinda makes sense in this context now my confusion is how to achieve that obviously i dont want each panel to run the same query on its own i would like to do that once in the upper level i can surely pass down the isloading prop to both panels however i am not too happy about it because once there will be a fully fledged data fetching relying on the suspense it would mean that for such scenarios i will need to fall back to a regular solution am i misunderstanding something in here"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSynthetic KeyboardEvent should support KeyboardEvent.code\ndo you want to request a feature or report a bug feature what is the current behavior the current synthetic keyboard event does not support the keyboardeventcode property what is the expected behavior the synthetic keyboard event should pass along the keyboardeventcode property this is currently in the wd of dom events but is part of replacing keycode and charcode and is much more consistent and easy to use this is currently only supported by ff and chrome caniuse so it may be a bit premature to fully integrate however keycode charcode and which are being deprecated so this will eventually need to be added edit i spoke too quickly caniuse shows that ff chrome safari and opera support it ie edge and most mobile browsers do not"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProvide a way to trigger useEffect from tests\nhello i tried testing components that use the cool new hooks api but useeffect doesnt seem to work with the test renderer heres a small failling jest test js import react useeffect from react import create as render from reacttestrenderer itcalls effect return new promiseresolve render function effectfulcomponent effect useeffecteffect return null and heres a minimal reproducing repo note that other use apis seemed to work eg usecontext"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n16.6 contextType + getDerivedStateFromProps\ndo you want to request a feature or report a bug feature what is the current behavior context not passed into static state context just curious with the new static contexttype it would save a lot of nesting if i could access context now from when using this pattern i gave it a shot assuming it may work already but i get undefined from the third argument just curious if theres been any discussion on this"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nConditional Components\nnote if the issue is about documentation or the website please file it at feature what is the current behavior often we will use expressions like this x null what is the desired behavior we would like to have expressive components such as in many cases this generic syntax is preferred over an explicit child component or pure function which knows about what it is supposed to render the issue is that this will evaluate the children even if they ultimately are not returned since they are passed as children to the when component what is desired is for the syntax above to be able to behave exactly like a conditional expression in that the contained children are not actually processed at all unless a condition is met in reality the component could be something else entirely such as which will only process and render the children if the current user is a super user or to only process and render items between 8 am and 11 am or similar the key thing is that we do not want the props passed into the children or the children themselves produced unless a condition has been satisfied which versions of react and which browser os are affected by this issue did this work in previous versions of react presumably any version of react"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIs it possible to use Profiler server side?\nim trying to use the profiler server side rendering with rendertostring but the onrender callbacks are not getting called is there a way to do it im using 1651 nodeenv development my code looks like this works fine client side javascript import react unstableprofiler from react const profilercallback id phase actualtime basetime starttime committime consolelogids phase phase consolelogactual time actualtime consolelogbase time basetime consolelogstart time starttime consolelogcommit time committime const mycomponent"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCache Provider: Add hooks to read and preload in dev mode\nthis topic originally came up in a reactdevtools discussion do you want to request a feature or report a bug feature what is the current behavior the package simplecacheprovider does not presently provide hooks to understand when weve pulled a resource for the first time hit the cache or dropped something from the cache due to maxsize due to this tools such as reactdevtools cannot provide an interface around our cached resources which makes debugging inspection harder what is the expected behavior it would be great if there was a way to expose callbacks events for when the cache resource has resolved an idea would be to fire these callbacks events in the existing switch statement in read preload if we are in dev mode with this information we could have a reduxdevtoolsesque interface to better understand where our data is coming from and when were hitting the cache in dev mode tools like this would also be useful to people new to the suspend api to visually see their resources transition between the various record states"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProvide a `testInstance.context` property to facilitate context testing\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug feature request what is the current behavior testinstance provides a props property but does not provide a context property allowing for context tests what is the expected behavior testinstancecontext should return an object containing the instances current context which versions of react and which browser os are affected by this issue did this work in previous versions of react at least 1641"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAbility to use return value of React.Children.map with React.Children.only\nas stated in the docs and shown in 4410 the return value of reactchildrenmap is incompatible with the reactchildrenonly function and will return with the error message invariant violation invariant violation reactchildrenonly expected to receive a single react element child if used this incompatibility causes some fairly annoying restrictions however from what i understand this means that you cant edit the properties of a components children at runtime if they contain any component that requires a single child eg you cant dynamically set the disabled prop of a child component in the parent i believe this is due to the type differences between the thispropschildren parameter and the reactchildrenmap return value the former being a valid element and the latter not see 4424 and id like to make a request to have the return type of reactchildrenmap be the same as the type of thispropschildren which will fix these quirks and be much more intuitive a separate static function that converts the return type of reactchildrenmap to the same type as thispropschildren would also solve the issue it feels like some sort of fix is in order since its a broad and strange restriction on the components you can use"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIdentify different instances of react component in performance measures\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug feature can fiberdebugid also be part of performance measure label along with component namedisplayname to distinguishtrack multiple instances of a react component in performance measures please let me know if there is any other way already available to achieve this"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd a way to compare relative positions of deep children\nhey it seems like there is currently no way to take two mounted component instances and tell which one of them is coming earlier in the application structure they could have been mounted asynchronously and tracking the time is not enough ideologically i cannot traverse the application tree that is understandable though the relative positions are needed sometimes my use case — i track focusable elements in the application using context each focusable element reports of its existence to a focus manager which is provided by the context this is needed to be able to limit the of all elements which are outside of the currently shown modal dialogpopup so that the focus is trapped inside for the sake of better accessibility i need to automatically focus first focusable in the modal dialog when im in the keyboard navigation mode so i have the references to all focusable elements inside the dialog but i cannot tell which one comes first using public react api for web there is a workaround to finddomnode and but that doesnt work with react native can we have something similar to but for react component instances thanks"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSynthetic (keyboard) events don't implement the .code property\ndo you want to request a feature or report a bug feature what is the current behavior code is undefined what is the expected behavior code is a very useful part of the keyboardevent spec which versions of react and which browser os are affected by this issue did this work in previous versions of react i am on react 163 but i saw no mention of this in todays 164 changelog"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProvide HOC for new context API\ni find myself needing a higherorder component every once in a while when using render props so i can get stuff from context in my lifecycle methods its pretty easy to create a hoc from a render prop so i was wondering how open yall would be to adding a hoc to the new context api we can already do this in userland with a little withcontext helper js function withcontextcontext component return props return context const appwithcontext withcontextmycontext app it would be useful to have this builtin to the new context api something like js const mycontext reactcreatecontext const appwithcontext mycontextprovideapp the second argument to provide the prop name could default to context anyway just thought id open this up for discussion before making an actual pr that adds this thanks for your consideration edit removed example using thiscontext"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCursor jumps to end of input when onChange doesn't call setState\nedit im asking for a feature current behaviour an input onchange function that returns a value equalling the prior value causes the cursor to jump to the end of the input this is the same as this comment from 995 formally raised as a feature request repro sandbox that same code javascript import react from react import render from reactdom class input extends reactcomponent state value typeanumber onchange e let nextvalue etargetvalue if 09testnextvalue nextvalue thisstatevalue thissetstate value nextvalue render return input typetext valuethisstatevalue onchangethisonchange render what is the expected behavior id like the cursor not to jump in the special case where the returned changed value is a rejected change ie the noop change i understand fully that react cannot predict cursor position if the value is changed in onchange however i cannot currently find an npm module that allows freelength regex filters vs a fixed length mask or a way to implement a filter myself without the cursor jumping in this case edit since raising i now fully see this as a feature request for handling a special case of a behaviour that indeed is not a bug differently it would be a nice to have as it would allow very straightforward implementation of filters regarding the nonclarity of how to deal with the general case of nonjumping cursors i think a modernized best practice example would be ideal but that discussion still lives at 955 id be totally fine with this issue being closed by assisting instead with the education of handling the general case though this would still be a nice to have for the api if possible"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAllow to specify displayName for createContext() providers and consumers\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug bug what is the current behavior in react tree name of a context must be like its name in code if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below js const mycontext js data lets have a look at react tree in chrome extentions page here is context not mycontext what is the expected behavior expexted to see mycontext which versions of react and which browser os are affected by this issue did this work in previous versions of react 1632"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDon't call getDerivedStateFromProps on a PureComponent if props are the same?\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug feature what is the current behavior is called on a purecomponent even if the props havent changed if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below what is the expected behavior as is which versions of react and which browser os are affected by this issue did this work in previous versions of react all i was hoping wouldnt be called on a purecomponent if the props hadnt changed any reason why this shouldntcouldnt be the case"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupport hydration after HTML minification\ndo you want to request a feature or report a bug report a bug what is the current behavior reacthydrate replaces the dom after a ssr page is served and two sibling links in the page have the href attributes wrongly set i did a little repl to replicate this behaviour here when the server responds the html is correct screen shot 20180404 at 16 08 06 but right after hydration the first href is changed screen shot 20180404 at 16 08 20 and whitespace artifacts are added what is the expected behavior the first href should not be changed which versions of react and which browser os are affected by this issue did this work in previous versions of react react v162 chrome 650 macos"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProvide a better error on React.cloneElement(null/undefined)\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug what is the current behavior if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below what is the expected behavior which versions of react and which browser os are affected by this issue did this work in previous versions of react image"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIssues with ReactControlledValuePropTypes\ndo you want to request a feature or report a bug see below what is the current behavior 1 bug inconsistency jsx no warning 2 feature request jsx warning failed prop type you provided a checked prop to a form field without an onchange handler this will render a readonly field if the field should be mutable use defaultchecked otherwise set either onchange or readonly 3 bug jsx no warning what is the expected behavior 1 passing a falsy value or checked attribute will not trigger a warning but a truthy value does 2 if onchange is passed as undefined or null this should be considered as an acknowledgement and silence the warning i have a case where i split the render method from the component and use it as a preview when the component is interactive i use the component when doing a preview i pass undefined as my change handler a warning is shown to tell me i forgot it but i intended it to be this way 3 going along with 2 i can pass readonlyhandlechange but according to definitelytyped this isnt a valid attribute for select i cant use disabled because it changes the appearance of the field which versions of react and which browser os are affected by this issue did this work in previous versions of react 1620 chrome 65 other a proposed fix would be to change to js if propname in props fixes 1 onchange in props fixes 2 propsreadonly propsdisabled and to js if propname in propspropname fixes 1 onchange in props fixes 2 propsreadonly propsdisabled"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProduction reconciler Instrumentation\napologies if this is documented somewhere but i was unable to find anything related after a pretty exhaustive search of docs code are there any production instrumentation hooks for the reconciler specifically im looking for callbacksevents that would allow me to track overall reconciliation time spans nothing more granular eg equivalent to the react tree reconciliation span as best i can tell there are performancetimings spans reported as of fiber and reactperf prior but those are only enabled in development mode"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDoes react still require non-toplevel submit handler?\ndo you want to request a feature or report a bug bug maybe what is the current behavior using nondelegated handler for submit event what is the expected behavior after ie9 at least i know submit event bubbled up which versions of react and which browser os are affected by this issue did this work in previous versions of react 1620"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nExtracting a Context Stack\na useful feature of context is creating a custom stack of things to see what your component is embedded in side i think the primary use case is logging explicitly currently that is pretty expensive to maintain just in case you need it see 12234 as an example we could provide an api that lazily extracts a whole path of contexts from the tree js js class app extends reactcomponent log var stack logtoserverstack foo bar baz render return it would basically synchronously rerender the shortest path to recreate the context at the time of the call to create the stack lazily cc acdlite"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProvide a way to perform a synchronous render into another root during the commit phase\ndo you want to request a feature or report a bug bug what is the current behavior reentrancy checks prevent synchronous reactdomrender in a nested react component this used to work before react 16 and seems related to this issue about nested reactdom renders if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below heres a jsfiddle that documents the problem with a simulation of the external dependency where this manifests what is the expected behavior im running into what i think is a similar problem to this one with a nested reactdomrender except where the difference is that i dont think we can use portals to address our usecase we have a component which manages the dom tree for all nodes below it outside of react — its a contenteditable node and uses the bestinclass prosemirror library to manage its children the component looks something like this javascript class prosemirror extends component componentdidmount prosemirror manages the dom for all nodes below thisel setrefel thisel el render return as part of its render cycle our configuration of prosemirror ends up calling javascript reactdomrender to render an isolated child node of and wants to be able to immediately afterwards be able to leverage javascript but this piece of the dom is no longer available synchronously and it looks like this is because of the reentrancy change that came about in react 16 portals dont work for us because the site where the reactdomrender is being called isnt itself directly part of the root react tree this is clearer to observe in the fiddle the hierarchy is something like opaque prosemirror rendering code is there a way to skip these reentrancy checks in these cases where theres an isolated react render happening in a grandchild of a component but where the react tree isnt the immediate parent which versions of react and which browser os are affected by this issue did this work in previous versions of react querying the dom immediately after reactdomrender worked in versions prior to react 16 were excited about the async possibilities for our main react tree but curious if there are workarounds where we can ignore the reentrancy checks for these isolated renders"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd oldProps as additional argument to getDerivedStateFromProps ?\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug feature what is the current behavior only receives the nextprops and previousstate as arguments if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below the deprecated used to allow code like thispropsfoo nextpropsfoo with the new function theres no choice because it is a static method but to constantly copy nextpropsfoo into state in order to access it later this is illustrated in the example posted to twitter by gaearon what is the expected behavior ideally if its not difficult to implement the would also take the current previousold props as an argument something like prevstate prevprops this would eliminate the need to constantly assign props to state purely for comparison purposes a quick look at the source doesnt make it clear to me how easy this would be though which versions of react and which browser os are affected by this issue did this work in previous versions of react 1630"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncan React support feature like keep-alive in Vue?\ni found this issue and sophiebits said that react never reuses an instance after its been unmounted does it means that react will never support feature like keepalive in vue or there is other way to maintain components state"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHave Fragments support dangerouslySetInnerHTML\nthe addition of the fragment in 1620 is fantastic and helps keep our html semantic and clean unfortunately there is still no way to inject html without a wrapping tag jsx const html hello world which will render html hello world it would be mostly helpful for rendering html from jsx on the back end rather than in the spa context to me fragment seems to be the ideal candidate to support so that you may inject html without wrapping elements jsx const html hello world would render jsx hello world simple obvious and aligned with the current api"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSymbols as keys in children as arrays or iterators\ndo you want to request a feature or report a bug i want to request a feature what is the current behavior using symbols as element keys throws a type error if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below when using keysymbolmykeysymbol we get the following typeerror cannot convert a symbol value to a string at codesandbox here what is the expected behavior using symbols as keys should work seamlessly in my opinion element keys are a perfect usecase for symbols which versions of react and which browser os are affected by this issue did this work in previous versions of react using react 1600 and the browsers affected are safari chrome and firefox on osx but im pretty sure this is not browser dependent but a matter of implementation thanks"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd React.createRef() as the migration path for string refs\ncreating this issue to track i intend to close the pr as its outdated but we probably want to turn it into a real rfc and potentially get it in during 16x"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nLifecycle method to build initial state for classes\nfeature request we need to have a way to build the initial state of reactcomponent in case of usage of classes what is the current behavior warning in case thisstate modified in willcomponentmount access to partially constructed object in case of somewhat complex state building logic in the constructor for example if we have a hierarchy of classes with the buildstate method called in the constructor to generate an initial state derived class overrides the buildstate method to have a richer state in result part of the object related to the derived class wont be constructed yet and cant be accessed in the buildstate the buildstate approach is currently used in resub framework what is the expected behavior rather no warning in case of thisstate modification or new lifecycle method which is called right after constructor call which returns the state which versions of react and which browser os are affected by this issue did this work in previous versions of react react 16 is affected"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFeature request: Global state at the render/hydrate level\nthis is a feature request it relates to this has been a pain point for me and im sure we can do better the issue how to have some state available to all components without passing everything down on props through the component tree im speaking about global state so why not use context i have a couple of issue with it 1 its not the root components job to receive and disseminate state the root component is just some component it shouldnt care if its root or not maybe you have example using express resrenderhomepagejsx but some other page might just as well have where otherpage has components can be composed however you like they shouldnt care what depth theyre at 2 above is talking about a multipage app the thinking around react seems to be so skewed toward to the special case of single page app spa is sometimes the right choice if youre google maps its clearly right if youre something broader in scope like amazoncom its clearly not the general case is much more interesting to solve 3 having every root component wrapped in some that publishes context downwards and every nonroot component wrapped in some receiver higher level component that declares context is just boilerplate its not expressive its bookkeeping 4 alternatives there arent any as far as i know each component only knows about the props and possibly context passed in it doesnt have any handle on data for the current render call simply importing global state through commonjs or es6 modules is impossible on the serverside for anything request scoped like query params route params cookies headers anything generated by middleware based on these things proposal why not just handle global state at a higher level than props passed component to component why not extend reactdomrender to take a 4th argument for global context it would just make everyones life easier dont even worry about changes firing at least as a first version think of it as analogous to express and the req object thats passed around one should always have access to some per request object so many things would be useful to put in there authenticated user geolocation store from redux query and route params etc etc it would look like somediv callback request specific data where request specific data might have things that are truly request specific and also things that are the same across requests the latter can be done with imports but its a bit messy you end up with code like if typeof window undefined client get value from window object else server get value from filesystem or wherever just having global data available to all components in the tree simplifies things a lot dont you think"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd hooks to ReactDOMServer to support caching\ndo you want to request a feature or report a bug feature what is the current behavior reactdom ssr performance could be improved using serverside cache but currently the reactpartialrenderer is currently not accessible from the reactdom package desired behavior on the server only it would be nice if plugins could be used to improve render performance currently the only way to do this would be to externally maintain a renderer implementation however the reactpartialrenderer already contains all the behavior required to support plugins with a little refactoring ive refactored the reactpartialrenderer and created a proof of concept for supporting plugins for react server side rendering you can see the in this fork its comprised of 3 different commits 1 strict refactoring of reactpartialrenderer the only addition is exporting the reactpartialrenderer from the reactdom server package 2 create the by extending the refactored reactpluginrenderer and introduce a plugin interface 3 proof of concept plugin implementations and application example you can view instructions for running the example in the repo i understand that exporting reactpartialrenderer exposes the internal api which is far from ideal is there any scenario in which reactpartialrenderer would be made to be accessible from the reactdom package or would a plugin implementation similar to above be required to maintain its own forked reactpartialrenderer maintaining the plugin renderer in its own repo isnt a problem but it would be great if plugins could be used without needing to maintain the core server renderer thanks adam"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nstopImmediatePropagation is not available for synthetic events\nin order to call this method youd have to access it via itd be awesome if this was supported on event itself i did see a prior issue for this but it was for a use case that sip wasnt required for for a specific use case if you want to kill hover events for touch input ontouchstart will trigger onmouseover and cancels that internal cascade"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd a way to opt out of User Timing API calls\ndo you want to request a feature or report a bug bug or v16 feature dont know what is the current behavior when building in dev environment performance timeline measures appear by default ie without reactperf query string as in v15 described here react1600 if its not a bug then whats the way to disable react perf measures need a way to clear timeline to focus on my own custom perf measures"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRelease a tool for statistical perf analysis (a replacement for ReactPerf)\ndo you want to request a feature or report a bug a feature what is the current behavior na what is the expected behavior its great that react 16 integrates with the timeline in browsers dev tools and that is very helpful in cases where you are trying to fix the performance of a specific thing however i do miss the perf tool from previous versions and could not find any issue tracking a reimplementation of such a tool what was great in the perf tool that is not covered as well with timeline integration easily see which components render needlessly and therefore should be easily eliminated with scu and what impact it will give easily see the collective render time of a component i might for example have a component that renders very fast but which have very many instances and thus contribute to a significant render time anyway give an overview of which components are slow by themselves and which are fast by themselves but render slow components the flamegraph shows this but i find it to specific in some scenarios with too much detail that can distract basically the wasted exclusive and inclusive tables the dom table i feel is much better represented by the timeline integration which versions of react and which browser os are affected by this issue did this work in previous versions of react 16 yes the perf addon in 15 was good"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd `code` property to `SyntheticKeyboardEvent`\ndo you want to request a feature or report a bug improvement what is the current behavior does not currently support the code property code mdn is nice to have when you want to write keyspecific handling—rather than inputspecific dependent on layout and modifier keys handling what is the expected behavior already exposes a keycode property it should have a code property as well currently if you want to use the keyboardevents code you must access it through nativeevent which versions of react and which browser os are affected by this issue did this work in previous versions of react affects react 16 and earlier i assume"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAsync componentWillReceiveProps to allow state update\ndo you want to request a feature or report a bug feature what is the current behavior an almost immediate rerender is due after is called unless says otherwise what is the expected behavior if new props in cause an async call thats soon going to update the state anyway wont it be cool if react might as well wait for that async call to do its thing which calls setstate and do one render instead of two potential solution react can see if returns a promise if it does it defers the rerender until it resolves javascript async const postid nextprops const posttitle await fetch thissetstate posttitle return"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReact16 not compatible with x3dom\nthis is both bug feature i used to be able to use x3dom with react it was great react 15 i was able to use the is property to generate custom elements and custom attributes that could be picked up by x3dom ie now with react16 i get many warning messages for all of the custom x3dom tag elements likewise it seems that certain attributes arent getting rendered either for instance if i do x3dom elements like so ill get output without the size attribute i dont think react should have to know what x3dom tags are nor should they be hardcoded into react there has got to be a way to have react output custom tags without throwing warning messsages why not just reintroduce the is attribute to indicate that its a custom tag with custom attributes"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nLoosen up type requirements for event handlers\ndo you want to request a feature or report a bug feature what is the current behavior when adding event handlers it is common practice to do something like js const mybutton canclick onclick this was fine in react 15x but in 16 it reports a warning which is technically correct expected onclick listener to be a function instead got a value of boolean type however this now forces you to use the more verbose variant js const mybutton canclick onclick what is the expected behavior i think it makes sense to allow null false and undefined in addition to function types for event handlers or just anything falsy although that may be too much to ask i definitely understand the rationale from a type safety perspective but this does make it less pragmatic i am personally a huge fan of how js evaluates null 0 and undefined to false and it reduces the amount of boilerplate needed to conditionally wire up handlers which versions of react and which browser os are affected by this issue did this work in previous versions of react react 16 all browsers this did not emit a warning in react 15 and below"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProduction Check in react-test-renderer\nwhen upgrading to 1600 from 1561 reacttestrenderer started failing on my tests with the message test renderer is not available in production mode i have in fact been running unit tests using this renderer during my production build im trying to understand why was this restriction introduced i saw the change was made in 9514 but couldnt find any explanation on the pull request or the documentation as to why production mode is now disallowed for this renderer thanks alex"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n\"Did not expect server HTML to contain the text node\" due to whitespace in React 16\nwe have updated our react v15 application to v16 everything seems to work fine instead the fact that this error appears warning did not expect server html to contain the text node in we are using reactdomhydrate and our app was completely ssr ready in v15 ive found an old issue on stackoverflow where someone wrote that this could be a problem with the markup which is send from server client but as far as we can see the html code is the same without any markup problem"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAttach third-party tools to monitor component state updates\ndo you want to request a feature or report a bug feature that exists in previous releases of react what is the current behavior feature is not implemented which versions of react and which browser os are affected by this issue did this work in previous versions of react react 16 worked in previous versions hey we would really like to be able to use reactinstrumentation with fiber i have found gaearon s pull request but work on it was stopped would like to know why and if we can pick this up and implement it i have also asked why in the pull request but figured it might get ignored since it is a closed pull request omer"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`select` should warn if `value` is not available\nimo yes no should warn because there is no foo option it should probably also warn if value is not specified because there is no empty option either one could also argue that the change handler should be called with value yes when the component renders and the first option is selected instead of an invalidnonexisting one"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAccept Ref Objects as Refs?\nreason react uses first class ocaml refs to store mutable values instead of on this instances these are basically just an object with a mutable contents property these can be updated with callback refs n refcontents n but it would be a nice convenience feature to just have that builtin we could also make these first class objects on isomorphic react js reactcreateref contents null js class foo extends reactcomponent state mydiv reactcreateref componentdidmount if mydivcontents mydivcontentsfocus render return basically the implementation would just be js if typeof ref function refnewvalue else if typeof ref object refcontents newvalue else if typeof ref string ownerrefsref newvalue this is something that needs to be implemented in the core runtime and not as part of any particular component api since refs cross that boundary cc adamjernst"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAsync Top-level Hook Before Commit\nthis isnt needed for 160 i think were missing a toplevel api if you want to integrate with nonreact code around you in an async way then you probably have some parents around you its not always the case that you want to show those parents before react is done maybe you can hide them and then show them at the callback time however it would be better if you could start building the tree async with react and then get a callback before we trigger lifecycles so that you can insert the tree into the actual dom and do whatever manipulation you need only after that do we trigger the lifecycles that way they will have the css and layout information available to them by virtue of being in the document already i see two possible routes a we just call out for this hook and then commit immediately after b we invoke a callback and pass another function that function when invoked does the actual commit this approach has precedence in the dom with append async and offscreen canvas the second option is probably preferable but we should only do that if we can do it efficiently and cleanly"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Feature Suggestion] Publish react also as ES2015 code\ndo you want to request a feature or report a bug feature what is the current behavior react is published to npm only as es5 code what is the expected behavior publish react also in es2015 with es2015 entry point in the packagejson motivation performance leverage the targeted client native es features its part of the angular 4 package format"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNicer Formatting of SSR Validation\nthe new validation in 10026 only issues a warn for the first difference found in a html hydration scenario ideally it should instead queue up all the differences and then at the end commit issue a single warning with a nicely formatted diff 1 instead of warning add these warn calls to a global buffer array map set whatever 2 inside prepareforcommit issue all the currently batched up warnings as a single message 3 format that message in terms of a jsx diff in a nicely formatted way with only the relevant nodes parent and child with changes irrelevant child content can be replaced with ellipsis eg … this strategy wont yield perfect results because if were asynchronously hydrating and it gets interrupted by another tree well flush a warning before the actual hydrating particular tree is flushed so we might show a partial diff in that case this is probably its just a warning"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFeature request: Support server-side rendering of non-standard DOM attribute names (eg. AMP's [prop]=\"value\")\ndo you want to request a feature or report a bug request a feature i am working on project to build amp page with react server side rendering i am having an issue to add custom attribute to builtin amp element in order to be able to use ampbind we need to be able to output “bindings” which are special attributes of the form attribute eg slideselectedslide ampcarousel layoutlayout heightheight widthwidth slideslide here is amp carousel example that work with ampbind what is the current behavior parsing error unexpected token fatal which versions of react and which browser os are affected by this issue did this work in previous versions of react all for more information you can read all the discussion in this pr"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFeature request: renderTypes\ndo you want to request a feature or report a bug request a feature per some discussion today with tomocchino and thejameskyle id like a nonflow mechanism to annotate what types of elements a component expects to render heres some examples with flow types for comparison that i realize may not be currently checked in flow yet jsx function foo yes return yes foorendertypes bar div class bar extends reactcomponent static rendertypes button render return jsx function foo yes reactelement return yes class bar extends reactcomponent render reactelement return inside airbnb we have lots of use cases where we have container components in a separate package say a and we have intentionally restrictive proptypes on its children prop to only allow a button also in the same package however in an app that consumes this component library package a dev may want to create a that in turn renders a however theyre unable to pass it into buttonrow our proptype warnings fail tests even though conceptually it should be permitted having rendertypes would allow us to widen our children proptype to allow for either a or anything that renders a which helps us maintain separation of concerns the package doesnt have to know about to accept it as well as maintain strictness the package doesnt have to allow any wacky element inside i imagine the implementation to be 1 when render is called or an sfc is invoked in async rendering itd be when the component resolves i suppose 1 in development only and if rendertypes exists on the component 1 evaluate the equivalent of elementtype children renderedvalue children 1 just like proptypes log the error if one is returned cc spicyj"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd React.Children.find\ni think a reactchildrenfind method would be really useful in situations where you need to iterate over your children and find just one that satisfies a particular condition im running into this situation more and more often in my react code a few examples in react router the component iterates over its children to figure out which matches the url in a component we use in our training workshops we need to iterate over the s to figure out which label we should show in the select box i wonder if there would be any interest from others in seeing something like this"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWarn when `static propTypes/static defaultProps` in ES6 class is a function\ndo you want to request a feature or report a bug bug what is the current behavior class testwrongproptypes extends component static proptypes return children proptypesstring missing static defaultprops return children default props via static function render return thispropschildren in this example react will silently skip proptypes checking and default props setting for testwrongproptypes component if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem via or similar template what is the expected behavior i know that in order to work proptypes definition should be static get proptypes or but id like to have warning like is function but should be either property or getter to prevent such errors which versions of react and which browser os are affected by this issue did this work in previous versions of react discovered in react 15x but probably the same behavior will be also in earlier versions"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[RFC] Add traversal utility to ReactTestUtils matching toTree shape\nproblem the reacttestrenderer now supports a new api totree which returns an easily traversed tree representing the internal state of the instance and its rendered nodes the existing solution for this in testutils is which traverses the root and lets you provide a test function it will call to reduce a tree based on a predicate the predicate function is passed the public instance for the node the issue with that is that it makes the predicate function polymorphic and requires every consuming utility to check if its being passed a component instance or a dom node solution i propose that we implement a new api similar to that calls the predicate function with the result of calling totree on the internal instance instead of the public instance this would mean the predicate function will always be called with the same data structure a tree node thirdparty traversal utilities can be shared between reacttestrenderer and reacttestutils since they would operate on the same tree structure you could actually assert on functional components which currently have no instance and just call the predicate with null this new api could just be a pure traversal utility leaving it up to the consumer to accumulate results js import renderintodocument traversetree from reactdomtestutils var root renderintodocument var results traversetreeroot node if somepredicatenode resultspushnode implementation with a brief review it looks like we could just export the totree function that is currently inlined in reacttestrenderer and provide a way to change js var publicinst nodestatenode if testpublicinst retpushpublicinst to js var treenode totreenode if testtreenode retpushtreenode cc gaearon bvaughn lelandrichardson"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nExpose DEV-mode warnings in devtools UI\nreact has made recent developer experience improvements to lifecycle error handling and logging errors thrown during render can be recovered from using unstablehandleerror componentdidcatch errors thrown during lifecycle methods are also automatically logged to the console with the component stack location to make them easier to identify see 8785 the team has discussed similar improvements for warnings such as using a yellow box approach to make warnings stand out more in developer mode see prs 7360 and 8861 there has been some pushback though to the idea of react modifying the dom for warning purposes see issue 8784 im not sure how that will play out yet but in the meanwhile could we improve at least some of these use cases by making better use of the devtools for example what if react exposed a new api that allowed associating a warning with one or more components in the devtools panel eg a method that when called recorded the current component stack and notified devtools if present react could use this for things like missing or nonunique keys 3rd party libraries may also benefit from this eg reactvirtualized could use this to warn about missing or incomplete positioning styles for cells heres a rough outline of some of the features components with warnings could be highlighted in some emphasized way eg yellow background in devtools to make them easier to spot a new toolbar option could be added to show all warnings eg filter the tree view to show only components with warnings warning message could be shown inline in the settings panel for the selected component heres a rough mockup screen shot 20170315 at 3 47 31 pm limitations not everyone uses devtools so this would not help a lot of people this would not address issues like using the development mode of react for production sites thoughts ideas suggestions"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRFC: ReactFiberReconciler release artifact\nthis issue is intended to be a discussion for how to distribute the file and dependencies for custom renderers currently firstclass renderers within the react codebasefacebook ecosystem do not have any concerns for this because of haste access to the reactjs build publish tooling within this codebase 3rd party renderers are currently adding reactdom to their dependency list and requiring to build and expose their custom renderer ideally would be distributed with the react package or as a standalone reactfiberreconciler package whether this is at reactreconcilerjs or reactlibreconcilerjs idk i think at the root is better to continue the discouragement of looking in reactlib for anything i understand flat bundles are coming too i don’t know if that should block this or if this could be a flat bundle or any other alternative is this something the team is ready to commit to and support if we came to a decision on approach and i put together a pr related issues 6795 create separate copies of each renderer 5472 include flow type definitions flow type distribution proposal at sebmarkbage spicyj"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProvide a way for external tools to list nodes with event info\ni would like to add react event bubbles to the markup tree of firefox developer tools to do this i need a way to get a list of nodes and their attached event listeners if somebody can provide a way for me to do this it will be added within a day is this possible at the moment and if not what can be done to make this possible"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[RFC] Idea: forceDeepUpdate() and forceDeepUpdateWithScope(scope)\njust going to put it out there for feedback motivation subscription management comes with a cost and that eats into the wins of async rendering since it needs to be managed synchronously not just managing the direct subscriptions themselves but managing the dynamic dependency graph so that it can be invalidated meanwhile most of what subscriptions are used for is data that will never update at least in our apps it is a pure loss the use case is when youre connecting to third party systems that arent as easily connected to the top level data tree proposal js thisforcedeepupdate same use case as forceupdate if you are reading from global mutable state for some reason you can use this to bypass in an entire subtree basically rerender everything when combined with fiber this can be a lowpriority update so its not so bad for things that change a lot of things a good example would be changing the locale regardless if you read a global mutable locale like airbnb does or a context locale like yahoo does this lets you change it when you need to without needing to manage subscriptions for all those cases when you dont need it js js class foo extends reactcomponent return scopestore userstore scopeid thispropsuserid render would traverse the subtree and only start rendering if returns true for the arbitrary scope argument this allows for a bit more of a targeted update with some convenience overhead additionally react would cache the pair of scope and components that responded for some number of scopes back if a new component gets mounted with a we might check it against the cache to see if we need to add it to the cache effectively this creates lazy subscriptions the use case is something like typing into an input field that then updates some global store which immediately displays in a completely different place on the page the first character might be a bit slower but still with responsive levels and the subsequent characters are fast to update caveat the major downside of this proposal is that it relies on mutation as we know react doesnt really like mutation for many more reasons than just the effect in fiber for example is that any component that gets a higher priority update will start using the new value components that rely on mutable state effectively become upprioritized which is not good 1 it can temporarily show inconsistent data 2 the point of making this kind of update lower priority is because it is likely to be large larger updates will stall the page if they take the same priority as higher priority updates thereby defeating the benefits of fiber anyway id like to try to come up with a variant of this api that doesnt rely on mutation"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReactTestRenderer custom depth rendering\ndo you want to request a feature or report a bug feature what is the current behavior jsx mycomponentjs import react from react import thirdpartycomponent from thirdpartycomponent function myinternalcomponent return test export default function mycomponent return testjs import reacttestrenderer from reacttestrenderer import react from react import mycomponent from mycomponentjs const renderer this renders whole tree of dom which is actually expected behaviour the problem is that i dont want render thirdpartycomponent only myinternalcomponent shallow renderer isnt answer because shallow would not render myinternalcomponent at all which is problem because its hard to divide component into smaller internal chunks i have done some work in order to achieve this in 5513 it was fully working patch it was done as part of shallowrenderer but now we have testrenderer besides this patch is pretty old so resolving conflicts would be very hard what is the expected behavior i would love to provide blacklist of components which i dont want to render js import thirdpartycomponent from thirdpartycomponent const renderer dontrender thirdpartycomponent this would return jsx js test so we can test props returned for thirdpartycomponent and internal logic its combine of full and shallow renderer i have some ideas of implementation but i dont want waste my time writing code which wont be marged into master anyway this possibly would allow to resolve"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nshouldComponentUpdate doesn't work well if component accepts children\nreacts based performance improvements work great for improving the performance of mediumweight components with large numbers of instances they even work well with event handlers as you can ignore event handler changes and instead pass a locally bound method thatll access thispropson on demand however this all fails apart you start passing react elements to pure components js use strict import react component proptypes from react import reactdom from reactdom import shallowequal from fictional function that works like shallowequal but ignores changes to a list of props passed as the third argument class button extends component static proptypes icon onclick proptypesfunc onclick e thispropsonclicke note doesnt actually work return nextprops onclick render const icon thisprops return icon ref icon thisiconref icon class icon extends component static proptypes name color proptypesstring return nextprops render const name color thisprops return getsvgiconname color const nilclick reactdomrender alertclicked icon reactdomrender 2nd invovation reactdomrender 3rd invovation given this sample a component that expects an icon to be passed as an icon prop and a simple both are pure components and button is also coded to not rerender whenonclick is changed pretend that button actually has a heavy render but its props and state dont change frequently on the second invocation icon should not require any prop change or render and button should have its onclick prop changed but not require a render on the third invocation icon should require a render while button itself does not need to render except for the change to icon however in practice button will always rerender including during the second invocation when nothing changes this is because will always result in a new instance and will never be the same normally you could work around this within the component itself without telling users they have to store in a variable until they think they need to change its props for functions you could pass a function that will use thisprops itself and for objects you can do a deep comparison if you know the structure of the object but for react elements even though allows react to know if the current component has a render dependency on a subcomponent you do not have access to this information so button cannot tell if icon requires a render in practice this can turn out to be a problem when youre writing some libraries rather than an application notably material ui suffers from this problem in production enhancedswitchs render is not light enhancedswitch is used by radiobutton and checkbox both use a checkedicon and uncheckedicon react element prop you can reasonably have 100 checkboxes on one page even if they were pure they cannot identify whether an icon requires an update as a result a render of the component containing the checkboxes to check a single checkbox will result in the render of all 100 enhancedswitch instances i can think of a few ideas on what type of api could be added to react to solve this issue helper the most obvious api would be a toplevel react function that given the instance context old reactelement and new reactelement would return the result of a components then heavy parent components can use that to implement a that is aware of render dependencies in its children as a bonus theoretically you could temporarily remember this while youre walking the current tree then instead of calling multiple times for every potentially nested component the result is simply that calls are raised up to the highest level where a component is renderdependent on them thispropsicon nextpropsicon however i expect the problem we have with this is that is also responsible for state dependent updates and this is supposed to be a rendered instance not a reactelement instance while you know context from passing the current instance you do not have a reference to the state from either of the props ref based helper the second most obvious api would be a helper that instead uses a ref nextpropsicon the downside to this is that to get a ref for a component you didnt create you inevitably have to use reactcloneelement render passthrough the next idea i had was a render passthrough a way during the render process for a component to say i do not need a renderupdate but these children of mine may which would tell react to skip render and then run on the instances deeper in the tree however those components only know if they need updates if you pass them the new props so a passthrough wont work wed instead need a way to tell react that it should not run render but do pass on an update to a specific component instance nextpropsicon the advantage of this over using is that instead of only allowing medium components wrapping light components to only render when a child requires it we also allow heavy components to never render unless they themselves require it while still allowing them to permit their light children to update partial renders that based renderref only applying updates to a component child feels somewhat awkward and forced though so a more robust idea might be a partial render lifecycle that optionally runs when false and can call for the render of a subtree that belongs to the current component js class heavycomponent extends component ignore icon and children return nextpropstext thispropstext render const text icon children thisprops text return ref icon thisiconref icon text children nextstate ref icon thisiconref icon thissubrender thisrefssubtree children though thissubrender probably has potential for conflicts so i expect the most reactline way to name that would be something like nextelement component which would be invoked using subtree thisrefssubtree the i used would be a really light component that probably would just render its children its there because should probably not accept dom refs this should be part of react lifecyclewalker not part of client side browser only reactdom like"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIs there a way to let users know which invalid type was returned?\nthis is the error message in question labelbutton a valid react element or null must be returned you may have returned undefined an array or some other invalid object not very helpful is it technically possible to show what was returned"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nClean up top-level event listeners after unmounting all roots\ndo you want to request a feature or report a bug bug maybe intended behaviour what is the current behavior background i have an app that needs to be embedded by other apps other customers the idea being our react app has its javascript loaded in an iframe but the main window hosts dom elements from the customers and our react app that bit works fine as time goes on our react ui is no longer needed and then react root is removed and the iframe destroyed these apps are often long lived so there will be times when the react app needs to appear again and the iframe is recreated and everything reloaded this can and will happen many times goal we would like to not keep the iframe around when its not actually needed but rather recreate just in time when it is needed this app is used by customers and they would like to embed our react app without interference with their app and all its javascript which is why we are doing the iframe thing problem it is evident by watching the chrome dev tools timeline memory graph that memory always increases each time a new iframe is created and the react ui is initd unmounting and destroying the iframe never causes the memory to drop to near original before load value repeating this process multiple times slowly show an increase memory this also causes a more immediate problem in that react is throwing exceptions on every event click type etc because the window of the iframe is now null proof first symptom event exceptions only happens in my app these exceptions only happen in my cant share app i cant repo them but parts of this apply to all react apps please read thru it will all make sense when you get to the end and if you examine my poc destroying the iframe leaves react and its event dispatching system in memory i have a mixture of xtag webcomponents which are used to create the iframe and load the react app after the custom element is used lets call it the console starts showing exceptions all within react code this is a side effect of the react dispatchevent still being active and trying to do stuff javascript uncaught typeerror cannot read property nodename of null shouldusechangeevent extractevents extractevents handletoplevel handletoplevelimpl perform batchedupdates batchedupdates dispatchevent i know about below where i can disable react i havent actually tried to avoid the exceptions but that would leave the memory leak javascript dispatchevent functiontopleveltype nativeevent if return its rather easy to prove that react remains in memory simply goto the compiled app find the react dispatchevent and insert a consolelog and watch as it continues to print stuff after unmounting the last component even though there are no listeners in my case the exception is caused because all extractevents eventually default to window as the target there are multiple copies of the same basic idea in various react functions where it tries to get a target that it assumes will never be null if one doesnt load react in an iframe then window is always defined javascript var targetnode targetinst window later the shouldusechangeevent tries to read the nodename of the now undefined window because its iframe has been destroyed but that now results in an exception null pointer etc javascript function var nodename elemnodename return nodename select nodename input elemtype file if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem via or similar template what is the expected behavior there are probably two possible solutions that work in tandem 1 firstly react should provide an api that will remove all its global event listeners naturally it could complain if there are any active components that remain mounted this api may be internalprivate not public if 2 was implemented it might be called something like reactshutdownall because everything is gone the next react render would setup all its globals again 2 react should dispose of all its global event handlers when the last or root component is unmounted this would call the new api mentioned in 1 either option solves my problem where i wish to either let react shutdown gracefully with this in mind i could unmount iframe powered react ui component call reactdisposeglobals mentioned above if unmounting auto calls an internal reactshutdownall then this step is skipped destroy iframe proof 2 goto your compiled out locate the dispatchevent and add a consolelog notice even after the last root container is unmounted stuff will continue to be printed because the event listeners are still active i did a very quick scan of the abstraction around adding listeners and i couldnt see the remove function being stored and then called to cleanup proof 3 look at my last section below where i have a proof of concept form of the popular todomvc react example which versions of react and which browser os are affected by this issue did this work in previous versions of react react 1502 reactdom 1502 reactredux 445 might be useful to know reproducable use case sorry i tried but decided that using the facebook jsfiddle wasnt really a smart thing for the following reasons the compile the jsx content means loading babel etc to compile babel jsfiddle etc too many moving parts its hard to get the root component that is inserted into the output box and its even just too hard to put the jsx compiled output into somewhere for the iframe src to load i have forked the popular todomvc app and added a few minor edits to recreate reload renderunmount x100 destroy everything about the app and try again in a loop separated by a sleep todomvc main site todomvc github my fork with comments and snapshots of chrome dev tools timeline memory graph hopefully we can trust the todomvc guys are doing the right thing no dumb memory leaks if you examine it should be obvious the only thing im adding is support for my horrible create app run app renderunmount many times render unmount sleep a bit and then loop again until counter exhausted sorry if this is boring but as a convenience i will list the basic instructions to run the react version of my branch on your local machines 1 clone 2 in the root run gulp to compile everything 3 run something like python m simplehttpserver 4a navigate to 4b navigate to examplesreact corresponds to the distexamplesreact directory that gulp built into my poc supports 3 concepts rerun todomvc over and over again in same window create iframe load todomvc js in the iframe but render to outer window unmount destroy iframe try 20x create custom element webcontainer creates iframe and load todomvc js in the iframe but render to outer window unmount destroy custom element try 20x if you look at my pr against todomvc you will see many helpful pictures with memory leak graphs from chrome dev tools for each of the 3 described scenarios and some commentary"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nExpose React build mode/flags\nkittens has expressed concern that people will forget to set the nodeenv when building their react application which will result in babel producing bloated builds due to our new devmode transforms the source and self should never be set in production and having them set on every element would introduce substantial bloat that you wouldnt want in a production environment we probably want to be able to warn when this happens in this case i think we might want to expose reactmode dev or something such that the transform could add runtime checks to verify that react is in dev mode and warn if not i know were thinking about switching to real build flags for the various features and maybe we want to expose all those individual flags anyway opening the issue so we have a place to discuss and track"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nImprove error messages for invalid states\ni think we should create a test suite that throws errors in different lifecycle methods and make sure we have relatively sensible invariants as early as possible preferably with component names 6990 is an example of this but we’ll keep regressing until we actually test for something like this explicitly cc jingc yungsters facebookreactcore"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProvide an opt-in way to easily manage `this` in event handlers\ntheres no shortage of places in react where a dev will write something like onclick thissetbookssubjects or alternatively its not ideal to recreate these functions on each render so the alternative would be some form of autobinding in the classs constructor all of which recreate these functions once per instance and require boilerplate id love to see the react team add some way of opting in to having a handler called with the current component set as this by current component i mean the component whose render created the element i dont know what it should be called but for example if it were called ownclick it would look like this click me and so when that button is clicked foo would be called with the object that owns the render method which rendered the button set as this"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWarn on inline style update with a bad value\nif set an inline style attribute for a component such as backgroundcolor yellow and then update the state with a bad value to make the inline style like this backgroundcolor nonexistcolor this currently takes no effect on the component and the backgroundcolor will remain yellow live example i suppose this is not the correct behavior the old value should be override by new value even the value is nonstandard so it can fallback to use the parent style just like plain html if leave the previous style as is the behavior of component will lose connection with component state the style will become chaotic and unpredictable"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n<datalist> support\nnot a ton of browser support for this right now but it appears to be on the horizon for webkit right now im not getting any dom events fired from it in chrome wonder if syntheticevent could prollyfill"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHave React ignore a specific DOM element\nas per my chat here with gaearon im filing an issue to discuss this further i would like to avoid a specific element that i rendered on the server from beeing further updated by react once it reaches the client one specific use case is rendering ad server tags that are kind of a pain in the ars using things like documentwrite etc i render them using but sometimes when react is doing the reconciliation client side they get rerender so they stop executing now i managed to track down some of these cases by fixing render differences between server and client which would trigger dom patching but it still seems to happen any advice"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd comments/attribute indicating which component was rendered\nas per the discussion today sometimes you are developing on a platform that doesnt have devtools safari etc the problem is that you are looking at a whole pile of markup and cant tell which components rendered it without devtools the output markup is really hard to navigate it would be cool if we had comment nodes or a datareactcomponent attribute that helps users navigate the output these nodes would be rendered only in dev mode or with some flag turned on or something"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAllow specifying multiple fallback values for inline styles (e.g. for vendor prefixing with SSR)\nive been using the string hack to override css values in react components for example if you want to have display with different values you do styleobjdisplay webkitboxdisplay mozboxdisplay msflexboxdisplay webkitflexdisplay flex i have an npm module for polyfilling my styles in my react components all of that worked perfectly in v014 no warnings no nothing updated to v150 today and everything is breaking a normally there are deprecation warnings i didnt notice any warnings on that change b in the changelog i cannot see anything related to that to understand what changed am i missing something"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd support for CSS variables in style attributes\ncss variables is now supported in chromium which we use for rendering they enable us to write cleaner more flexible code sadly i cannot seem to use them in react without resorting to various tricks ideally i would like to be able to use them like which would make the variable available inside the scope of the div i am able to add them using the following syntax but then they arent updated if i try assigning a new value—which ruins much of the point of using a variable i am able to add and remove them using reactdom and hotpink but that gets it out of sync with the dom updates in addition to not being pretty if there are any questions on the usefulness of css variables ill be more than happy to explain"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupport DOM nodes as children\nit would be nice to be able to do the equivalent of it seems entirely doable now with our new fancy renderer i think obviously it wouldnt be supported for ssr though so you would have to provide your own fallback if necessary"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuestion about React.Fragment and dangerouslySetInnerHTML\nreact version 1700 reactfragment why not property"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: Data is losing during page refresh in Reactjs-Redux; Tried using 'redux-persist' and localstorage , but not working.\nin our were built in django and through this we are getting the authorization details and this was stored as reduxdata and was used in the rest of the application which is built in reactthere was no refresh issue during that timeevenif the store was getting disapper but we are getting it backnowwe shifted all that we done in django into react and used the same redux storage method in loginbut we are facing the data losage during refreshstore is not getting restore and we are having 403 status for 2 apis for getting the user detailsthis was not happening in former case we used reduxpersist package to avoid this data losage and also tried using localstorage persisting facing the issue storejs import createstore applymiddleware compose from redux import thunk from reduxthunk import rootreducer from reducers import persiststore persistreducer from reduxpersist import storage from const persistconfig key root storage const composeenhancers compose const persistedreducer const store const persistor persiststorestore export default store export persistor actionjs import axios from axios import setprofile setfeaturetoggles from actiontypes import clientrequestdata from config const redirecttologin delete if 1 windowlocationhref accountslogin export const fetchuserprofile dispatch axios clientrequestdata clientrequestdata thenresp dispatch type setprofile payload respdata catche todo figure out what do do here if eresponsestatus 403 redirecttologin export const fetchfeaturetoggles dispatch axios clientrequestdata clientrequestdata thenresp dispatch type setfeaturetoggles payload respdata catche todo figure out what do do here if eresponsestatus 403 redirecttologin import setfeaturetoggles from actiontypes const intialstate export default state intialstate action switch actiontype case setfeaturetoggles return actionpayload default return state 2userprofilejs import setprofile from actiontypes const intialstate export default state action switch actiontype case setprofile return actionpayload default return state appjs import react useeffect suspense from react import connect from reactredux import cssbaseline from import themeprovider from materialuistyles import muithemeprovider from import provider from reactredux import browserrouter switch route from reactrouterdom import theme from thememuitheme import i18n import home from screenshome import as actions from reduxactions import userservice from servicesuserservice import baseurl from config import login from login import signup from signup import logout from logout import resetpassword from resetpassword import resetsuccess from resetsuccess import store from reduxstore const app props const userprofile featuretoggles fetchuserprofile fetchfeaturetoggles props useeffect fetchuserprofile fetchfeaturetoggles return route exact path render return userprofile null featuretoggles null const mapstatetoprops state userprofile stateuserprofile featuretoggles statefeaturetoggles export default actionsapp indexjs import promisefinally from import react suspense from react import reactdom from reactdom import indexcss import cssbaseline from import themeprovider from materialuistyles import muithemeprovider from import provider from reactredux import as serviceworker from serviceworker import app from app import theme from thememuitheme import storepersistor from reduxstore import i18n import home from screenshome import login from login import signup from signup import logout from logout import persistgate from promisefinallyshim reactdomrender also tried with localstorage localstoragejsin redux export const loadstate try const serializedstate if serializedstate null return undefined return catch err return undefined export const savestate state try const serializesstate jsonstringifystate serializesstate catch err consolelogerr corresponding storejs import createstore applymiddleware compose from redux import thunk from reduxthunk import rootreducer from reducers import from reduxpersist import storage from import fetchfeaturetoggles from actions import loadstatesavestate from localstorage import throttle from lodash const persistconfig key root storage const composeenhancers compose const persistedstate loadstate const persistedreducer const store 1000 const persistor persiststorestore export default store export persistor"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nreact developer tools \ni successfully installed the extensions but i am not able to see the the news tabs components and react"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuestion: startTransition behavior\nim very sorry that im using the issue tracker to ask this question but i think others might ask the same question after reading i dont have commenting rights js function handleinputchangee const input etargetvalue setinputvalueinput starttransition setsearchqueryinput what happens if the user types ab ie js pseudocode representing the first event handler triggered by keystroke a setinputvaluea starttransition setsearchquerya pseudocode representing the second event handler triggered by keystroke b setinputvalueab starttransition setsearchqueryab from my understanding setinputvaluea and setinputvalueab will batch generating a single rerender the callback setsearchquerya passed to the first starttransition will be cancelled and only the second callback setsearchqueryab passed to the second starttransition will be executed ie js pseudocode representing the final logic after keystrokes a and b setinputvaluea will batch with setinputvalueab starttransition setsearchquerya noop this callback will be cancelled setinputvalueab starttransition setsearchqueryab am i correct i think this question is important because if the first callback passed to starttransition really gets cancelled and i try to do more work inside it i should have in mind that the additional work will not happen cc gaearon acdlite"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nExperimental createRoot method not available in React 17\ni am using react and reactdom v1702 and i was trying to use the unstablecreateroot method to render my app but looks like that method is not even present in react v1702 can someone comment if this is expected or not thanks arpit"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: strict mode, initial state changes, and useMemo (with dependency) doesn't seem to be recomputed\nplease provide a clear and concise description of what the bug is include screenshots if needed please test using the latest version of the relevant react packages to make sure your issue has not already been fixed react version 1702 i ran in to this interesting dynamic that i cannot explain today 1 the code sets some initial state which is a random number and logs this initial value 2 it converts the number to a string using usememo which logs the number it is converting and is dependant on that number not the string and 3 when the component is mounted i force a rerender by changing a boolean state once the result is that the initial value of the number is changed and the log is output so you see the number being set twice to two different values this only happens in strictmode it is surprising is it expected you also see the usememo being computed once only the first time so seemingly it does not recompute a new string value but the output in the html is the correct and shows the stringified value of the second number so what is happening here is the console log swallowed is usememo behaving correctly and more importantly is the initialvalue of usestate supposed to change like that steps to reproduce typescript export default function app const rand usestatemathrandom const setstate usestatefalse consolelognumber rand useeffect setstatetrue const text usememo consolelogcomputing text from rand return randtostring rand return rand rand text text and wrap your app in strictmode link to code example the current behavior initial state computed twice usememo seemingly not run twice the expected behavior initial state computed once or usememo runs twice"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuestion:  is there any way to retrieve React Devtool performance data?\nhi guys i want to get react devtool performanceprofiler results probably a json data and send to our local server i read through the reactdevtoolscore but unfortunately do to get any clue how to do this"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuestion about getting the latest state value in the concurrent mode\nplease provide a clear and concise description of what the bug is include screenshots if needed please test using the latest version of the relevant react packages to make sure your issue has not already been fixed react version 1701 steps to reproduce 1 enable strict mode for checking for possible issues in the future concurrent mode 2 create the below component and run the code import usecallback usestate from react const example onincrement const count setcount usestate0 const incrementhandler usecallback onincrementcount count 1 is count guaranteed to be the latest state here due to including count in the usecallback dependency array setcountcount count 1 count onincrement return count increment const parent example incrementedcount alert count before incrementing currentcount after increment incrementedcount export default parent your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react issues without reproduction steps or code examples may be immediately closed as not actionable please provide a codesandbox a link to a repository on github or provide a minimal code example that reproduces the problem you may provide a screenshot of the application if you think it is relevant to your bug report here are some tips for providing a minimal example the current behavior in this simple example everything seems to be fine but in a more complicated situation full of event handlers that change the count or async callbacks that may change the count like data fetching callbacks the count value is not guaranteed to be the latest state and if i change the incrementhandler function like below const incrementhandler usecallback setcountcount onincrementcount count 1 return count 1 count onincrement then the onincrement will run twice in development while in strict mode and may run twice in production in concurrent mode according to documentation and if you suggest running the onincrement in useeffect callback with count and onincrement in effects dependencies array how can i know that the onclick event of the increment button has caused the effect and not another event for example decrement or anything else you may say by setting another state that shows what is responsible for the effect then i may need the previous state which unlike this example may be impossible to recalculate you may suggest using a ref for storing the previous state count then i will end up with one extra state or ref for storing what is responsible for the effect to run one extra ref for storing the previous state and a useeffect hook to run the onincrement click event handler the expected behavior providing a second callback argument to setstate like in class components that will run after this state update so we can save the current and next state and use it in the callback like below const incrementhandler usecallback let prevcount nextcount setcount count prevcount count nextcount count 1 return nextcount onincrementprevcount nextcount onincrement in my humble opinion this doesnt collide with the async nature of setcount and can be implemented unlike belowgetstate proposals that if it will be asynchronous it may not return the desired state and if it will be synchronous it will not return the latest state too because setstate is not executed yet wrong solution const count setcount getcount usestate0 const incrementhandler usecallback setcountcount count 1 const currentcount getcount const nextcount currentcount 1 nextcount onincrement or providing a third array to usecallback for accessing the latest state can not be implemented due to the same problem with getstate and async nature of setstate please tell me if im missing something or ive misunderstood things if not please tell me if there is a simple solution for this scenario or similar ones or tell me the best practices for running a callback or event handler with the latest state thank you"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: It seems that the default value in functional React component gets updated after render.\nplease provide a clear and concise description of what the bug is include screenshots if needed please test using the latest version of the relevant react packages to make sure your issue has not already been fixed it seems that the default value in functional react component gets updated after render react version 1701 steps to reproduce i created a question on stackoverflow but also repeat it here const mycomponent initialise data with a random value const data setdata reactusestate const data samplesizerange5 3 print data on initialisation consoleloginit data in default data return data reactuseeffect print data after the component is rendered consoleloginit data after render data return data the output in console is log init data in default – 0 3 1 3 log init data after render – 2 1 3 3 my understanding is that before the component is rendered the function under usestate is called the value returned by the function is assigned to data and the data values is used to render the component on the screen the function under usestate is called only once and we never call setdata so the value should be the same maybe i miss something your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react issues without reproduction steps or code examples may be immediately closed as not actionable link to code example please provide a codesandbox a link to a repository on github or provide a minimal code example that reproduces the problem you may provide a screenshot of the application if you think it is relevant to your bug report here are some tips for providing a minimal example the current behavior the output in console before and after render is different the expected behavior the output in console before and after render should be the same"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDev tools Chrome Extension only works properly in Incognito window\nhi folks at some point win the last 5 months or so the dev tools chrome extension stopped working properly for me in nonincognito chrome windows its a bit hard to explain but ill try when i use the extension react components show up but they are basically just high level wrapper components that we use in our app for example i cannot inspect a button component a container component an input component etc in the ui this issue disappears in incognito mode however and i can use the extension just fine chrome version 8704280141 extension version 4101 react version 16131 ive been unable to find anyone else with this issue please let me know if there is other information i can provide you with thank you"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuestion: CM mode and useEffect cleanups\nsince cm mode now runs useeffects cleanups async are we still guaranteed that theyll resolve in order by that i mean if a component gets cleanup rerendered and cleaned up again that the first cleanup will resolve before the second componenta 1 thrown away componenta 2 thrown away will that 2 effectively await on the 1 to cleanup first"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSome questions about lanes.\nfirst of all thank you for reading and patience ive been studying the principle of react lanes recently and its implementation is interesting to me but i still dont know what the specific problems it solves this constraint was designed before suspense was a thing and it made some sense in that world when all your work is cpu bound theres not much reason to work on tasks in any order other than by their priority but when you introduce tasks that are iobound ie suspense you can have a scenario where a higher priority iobound task blocks a lowerpriority cpubound task from completing from the explanation of acdlite it seems to solve the blocking problem of io operation on low priority tasks but i couldnt figure out what asynchronous io blocked？ js based on the above example before lanes where is blocked and where is the problem solved after lanes or do you have a better demo to explain for developers the new technology related information is too little binary is also very abstract thank you again for your patience"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhy does React warn about multiple renderers using the same context provider?\ni am currently developing a web app that uses both reactpixi and reactbabylonjs both of these libraries use reactreconciler and have a custom renderer i also use redux in my project so they share the same context in the two libraries it displays a warning on console after every redux state updating but everything works well both renderers can trigger an update i want to know if there is any risk in doing this or is this just a false warning react version 16131 steps to reproduce 1 using multiple react renderers 2 using the same context provider between that react renderers link to code example the current behavior it will throw a warning message after every state updating warning detected multiple renderers concurrently rendering the same context provider this is currently unsupported but everything works well both renderers can trigger an update the expected behavior dont show any warning"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nShowing an Array in string Format in UI\nin js array rendered with in between each element eg piyush sinha piyushsinha but in react array rendered without in between each element eg piyush sinha piyushsinha"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Micro React Apps] - Need to render another React App into existing React App\nhi i need to render another react app ie app2 into existing react app ie app1 on run time i have hosted my app2 on a remote server i read assetmanifestjson file from it and on runtime i append those js chunks in our head tag this overall code i call from my app1 to load my app2 on runtime but i am not able to trigger app2 how should i triggered app2 component inside app1 component my application have lot of other internal dependencies such redux reduxthunk etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndevtool Api request : add api for customize renderer inspect element\nim wirte a custimse renderer for render element in canvaslike reactpixi i want intergrate with react dev tool i can hightlight element when click element in react dev tool compoent panel use code ts eleinfo eleinfo const id rendererid eleinfo const renderer rendererid const nodelist as sprite customise render engin hightlight code i want hightlight ele when mouse move in canvas i can use find node fiber id i can use bridge send hightlint msg to backend just like the code but i cant get store object and get enugh infomation send to backend maybe dev tool can expose proper api for this function"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSelenium integration\nhello im not sure if this is an issue but i would like to know a little more about how react developer tools work i want to get reacts props with selenium in order to make easier the debugging of a website id be thankful with any kind of help you can give me best regards"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReact Hooks will render multiple times after await\nconst html sethtml usestate const script setscript usestate const update script html setscriptscript sethtmlhtml updatea b the above code works fine react hooks will render once and combine setscript sethtml const html sethtml usestate const script setscript usestate const update async script html await new promiseresolve settimeoutresolve 10 setscriptscript sethtmlhtml updatea b the above code doesnt work anymore react hooks will render twice and it doesnt combine setscript sethtml i can change to the code to const state setstate usestate html script const update async script html await new promiseresolve settimeoutresolve 10 setstate script html updatea b the above code only renders once but it has a new bug the cursor in the textarea where script and html go will move to the end of the textarea instead of staying at where it is"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nExtention React non définie sur chrome\nreact developer tools 460 google chrome version 8003987149 loutil de développement react est inactif sur la console google chrome"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuestion: Why not useCallback always return static value without deps?\ntsx function userefcallback voidcallback t const ref userefcallback refcurrent callback return any args parameters return refcurrentapplythis args as t i think userefcallback is safe to replace usecallback in any code and its better than usecallback because it will never cause recalculation"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuestion: How to remove dynamic children from Parent State?\nim using react hook usecontext i have two identical components siblings each that use the same context that is a list scenario 1 the first sibling is created calls usecontext and then pushes something into the list 2 the second sibling is then created using the same usecontext and then pushes something into the list issue the second sibling has the current state of list which has two items but the first sibling state is not updated with the second item that was pushed in by the second sibling expected that each component that is using the same usecontext will be updated amongst all components that use the same context is this a bug or am i misusing this any help or guidance is appreciated personbowing"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWebpack can't find ReactDOM.createRoot\nhi im kinda in doubt if this is an error or is just me doing something wrong i am trying the new react experimental in a very simple existing app i have although i had installed the react experimental versions in my packagejson it seems it doesnt recognize reactdomcreateroot when i try to run my project i receive the error message from the console uncaught typeerror is not a function at mainchunkjs2437 at webpackrequire runtimebundlejs786 at fn runtimebundlejs151 at object0 mainchunkjs4324 at webpackrequire runtimebundlejs786 at checkdeferredmodules runtimebundlejs46 at as push runtimebundlejs33 at mainchunkjs1 this only happens when i try using reactdomcreateroot using reactdomrender everything works perfectly any idea why this is happening dependencies chalk 300 compression 174 express 4171 morgan 191 uuid 340 devdependencies babelcli 784 babelcore 784 babelnode 784 774 774 774 774 774 775 777 774 774 774 babelpresetenv 784 babelpresetreact 774 783 hotloaderreactdom 16110 511 testinglibraryreact 940 autoprefixer 974 babeleslint 1100beta2 babeljest 2510 babelloader 806 230 1107 230 520 cleanwebpackplugin 300 connectedreactrouter 661 copywebpackplugin 511 corejs 362 csshotloader 144 cssloader 341 deepfreeze 001 eslint 680 eslintloader 303 eslintpluginbabel 530 eslintpluginimport 2201 eslintpluginjsxa11y 623 eslintpluginramda 251 eslintpluginreact 7183 230 113 eslintwatch 601 fileloader 502 0131 history 4101 htmlwebpackplugin 320 immer 534 jest 2510 jeststyledcomponents 700 lodash 41715 minicssextractplugin 090 moment 2240 nock 1171 normalizr 350 npmrunall 415 open 702 503 pm2 423 postcssflexbugsfixes 420 postcssloader 300 proptypes 1572 ramda 0270 react reactdom 060 reacthotloader 41219 reactis 16120 reactredux 713 reactrouter 512 reactrouterdom 512 reacttestrenderer 16120 redux 405 reduxactions 265 2138 reduxlogger 306 reduxsaga 113 reduxsagatestplan 400rc3 regeneratorruntime 0133 reselect 400 sourcemaploader 024 styleloader 113 styledcomponents 501 stylelint 1300 200 300 1900 011 060 stylelintorder 400 190 210 threadloader 213 typescript 375 urlloader 300 webpack 4414 webpackdevmiddleware 372 webpackhotmiddleware 2250 220 webpackmerge 422 webpackpwamanifest 411 workboxwebpackplugin 500"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: Nested setState and unstable_batchedUpdates (are they ignored?)\nnested setstate and are them ignored react version 1612 steps to reproduce open profile after click you will see 3 commit it seems that even if we use nested setstates called on do not get batched"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhile using useRef , some data has been updated by context value from reducers, when the context value was updated from some other user event, variable used with useRef also updated, then how to use instance variables in hooks?\nconst props const state dispatch usecontextstore const draftdata useref useeffect if draftdatacurrent useeffect debugger draftdatacurrent when value in store context changes useeffect of draftdatacurrent also called please suggest hwo to resolve"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuestion:  Just for my app test. Thanks.\npolicecarlight this issue tracker is not for questions policecarlight as it happens support requests that are created as issues are likely to be closed we want to make sure you are able to find the help you seek please take a look at the following resources coding questions if you have a coding question related to react and react dom it might be better suited for stack overflow its a great place to browse through frequent questions about using react as well as ask for help with specific questions talk to other react developers there are many online forums which are a great place for discussion about best practices and application architecture as well as the future of react proposals if youd like to discuss topics related to the future of react or would like to propose a new feature or change before sending a pull request please check out the discussions and proposals repository"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuestion: React apollo hooks fails after adding react-native to monorepo\ni am trying to create a react web app and reactnative app with monorepo by using yarn workspaces so i created web and controllers and it works fine i was able to make graphql queries to my apolloexpress server but after adding reactnative application i see this enter image description here11 1 i am 100 that i am not breaking any react hooks rules because before adding reactnative application it was work fine is there any way how can i solve it apollo controller import usequery from apolloreacthooks import gql from graphqltag export const usehelloquery usequery gql hello react component function test const data usehelloquery return awesoe before adding reactnative it was exactly same"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuestion: react lib context overrides app context\nhi i believe that this can potentially be an issue though im not sure i was wondering about good patterns concerning the react context lets get a public library for example reactintl that exposes a provider intlprovider lets create a library barlib that uses reactintl to manage translations internally and that also exposes a provider now lets imagine i create a web app and use both barlib and reactintl i dont expect the barlib to ever override my reactintl context because im not aware it uses internally the reactintl lib but the barlib can accidentally override the reactintl context this kinda breaks the isolation of libs imo i see several solutions dont use an other lib context in the barlib pretty extreme check that there is not already an intl context in the barlib if so merge the context values im not convinced with either solutions what do you guys think about it"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuestion: why cann't I set echarts instance using useState?\ncoding questions i try to store the echart instance using usestate but after setinstance instance is always undefined const instance setinstance usestateundefined const chartinstance setinstanceprev consolelogprev instance prev first time undefined then echarts instance return prev chartinstance consoleloginstance instance chartinstance instance is always undefined"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nhelp~When I use React.createElement directly and How to pack the component?\nhello all i was met a problem when i published a react component i need to help and discuss with you all i am going to write a component to load react component from cdn and make it like a wrapper component jsx import react component from react import scriptjs from scriptjs const devscript const prodscript class phoenixheaderwrapper extends component constructorprops superprops thistype null thisscripturl propsscripturl propsenv prod devscript prodscript thisstate cmp null componentdidmount thistype windowphoenixheader const scripturl otherprops thisprops if thistype consoleerrorload component failed return const cmp otherprops this is point thissetstate cmp render const cmp thisstate return cmp scripturl env prod export default phoenixheaderwrapper and then i do it just like do a normal react component that i was set the webpack config like below js phoenixheader output publicpath filename phoenixheaderjs path pathsappbuild library phoenixheader librarytarget commonjs2 libraryexport default mode production externals react commonjs react commonjs2 react amd react root react reactdom commonjs reactdom commonjs2 reactdom amd reactdom root reactdom and then i run the npm run build npm publish to publish it in my own object which use the phoenixheader component as a npm package jsx appjsx import react from react import phoenixheader from phoenixheader import appcss function app return edit srcappjs and save to reload a classnameapplink href targetblank relnoopener noreferrer learn react export default app after npm start it show me a error image that it is my confusion is why createelement not in this scope so i try to make react set into global js windowreact react yes its work for me but someone would like to tell me why need to make react set into global and am i need to build this wrapper component which do not external the react when i was build lets discuss or give me more suggest about this wrapper component please foldedhands"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRendering React component on server to take a screenshot of it\nmy react application has a list of to do lists like this img width1082 altfigmacanvases src replace the figma canvas preview images with todo lists above in the list of todo lists id like to include a preview of each list as well as its name heres what i thought of to achieve this whenever a todo list is updated run a aws lambda nodejs environment job which generates html for the todo list serverside using then serve that html locally visit the page using puppeteer and take a screenshot of the page however this seems like a lot of work is there an easier way of achieving this is there anything in the steps above that wont work ive looked at repng 1 so far but it hasnt worked for the components i tested it with 1"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nI can't get the latest status value in the initialization method\ni try to get the latest state value in the initialization method but the result is not satisfactory。 all this happens in function components。 1react version is 16120； 2reactdom version is 16120； this is my demo code import from react const app button click const btnclick consoleloginitbutton getting state isnowstate cant get now state all is init value init a button const inittitle return click const title settitle usestate now state const nowstate setnowstate usestate0 consolelognow state isnowstate useeffect settitleinittitle return title setnowstatenowstate 1change now state export default app"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[TypeScript]Is there any way to define the state variables when using functional component? \nnote if the issue is about documentation or the website please file it at if there is a lot of state variables i guess it is hard to get a whole picture the state variables verse class components do you want to request a feature or report a bug what is the current behavior if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below what is the expected behavior which versions of react and which browser os are affected by this issue did this work in previous versions of react"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ngetDerivedStateFromProps is executed after setState #13015\nideally should not be called due to current components setstate but it is behaving so can someone explain couldnt find solution in 13015"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhy only one component can be render at root div?\ni called two render methods to same root div renderdomrender root renderdomrender root and what i get rendered on my screen is only a app component just want to know that the one render method override the previous render method"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug: React table - Element type is invalid: expected a string (for built-in components) or a class/function (for composite components) but got: undefined.\ndo you want to request a feature or report a bug bug what is the current behavior hello i am new in react and i am trying to create a simple react table to display data from db with login for user authentication until i added the login it worked momentally it still throws the same mistake no matter what none of the existing solutions helped me i tried to repair imports and exports i reinstalled nodejs reinstalled nodemoduls first i verify the user by logging in to redirect me to the records page after verification verification is ok but then it crashes if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below edit login password admin admin edit blackvoice2z6y5 errormessage which versions of react and which browser os are affected by this issue did this work in previous versions of react nodejs version v8100 npm version 6133 ubuntuchrome please give me any advice thank you in advance"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow do suspense and subscriptions interact?\ndo you want to request a feature or report a bug ask a question what is the current behavior with suspense a component throws a promise when it encounters something thats not ready however our companys data fetching is subscriptionoriented at a very high level the following happens 1 component renders and calls usefooid name amount discounts 2 internally the hook adds a callback to the fooloader which is responsible for batching and sending async requests the callback will invoke the setter for a usestate inside the hook to force a rerender of the consuming component 3 the hook returns a remotedata which could contain the data if it was locally available or is just a constant that says i havent asked for this data yet 4 when the data becomes available or the request for the data fails the fooloader invokes the hookpassedin callback method which triggers the rerender which presents the new component state at no point in there does the component have a promise as a result im not sure its possible for it to throw anything its depending on the usestate inside usefoo to trigger rerender when data is available but if we throw then that never happens and we wouldnt ever complete throwing a promise from inside the hook doesnt seem right as it would be very difficult to combine multiple data dependencies in a single component the only alternative seems to be a pretty sizable plumbing change to return a promise instead of the loading state constant but that seems to force a lot of allocations and boilerplate code to handle the maybe not ready the first time case note posting in response to this tweet by gaearon"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhy include refs as a feature? -- seems broken and unnecessary\nrefs never seem to work is this a broken feature why not remove them and just let people use like normal people also what does this mean function components cannot have refs did you mean to use reactforwardref"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDevTools component filter does not work with location\ndo you want to request a feature or report a bug report a bug what is the current behavior in devtools when a component filter is added with field set to location and regex set to nothing is filtered out btw no documentation in this subject is available anywhere what is the expected behavior at least some components be filtered out it would also be awesome if the location was shown somewhere for the selected component so that users can know what kind of regex they should put together which versions of react and which browser os are affected by this issue did this work in previous versions of react react devtools 420 on firefox 6903"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhy is useEffect hook not activating when a component is reloaded after previously throwing an error?\ni am learning react and redux within a typescript environment i have managed to implement a container that dispatches a fetch action and subscribes to corresponding fetch success and error state notifications from a redux store the source code is listed below container typescript import react useeffect from react import connect from reactredux import grid from materialuicoregrid import gridspacing from materialuicoregrid import course from import coursemodels from reduxfeaturescourse import courseselectors from reduxfeaturescourse import fetchcoursesasync from import rootstate from reduxtypes type errorreport haserror boolean error error type stateprops isloading boolean courses coursemodelscourse error errorreport redux dispatch and state mappings const dispatchprops fetchcourses const mapstatetoprops state rootstate stateprops isloading courses error component property type definitions type props returntype typeof dispatchprops courselist component const courselist courses error fetchcourses isloading propas jsxelement fetch course action on mount useeffect consolelogcourselist fetching courses fetchcourses fetchcourses if isloading return loading if error errorhaserror errorerror throw errorerror if throw an error then encapsulating error boundary catches and displays however when the container is loaded again via clicking on a navbar link the useeffect action does not trigger alternatively if the error is rendered inside the container then the useeffect hook is still activated if the container is loaded again eg via clicking on a navbar link return null 2 return coursesmapelement exports export default connect mapstatetoprops dispatchprops courselist if i throw an error within the container then the encapsulating error boundary catches and displays it however when the container is reloaded via clicking on a navbar link the useeffect action does not trigger subsequently the fetchcourses action is not dispatched why is the useeffect hook not triggered on second load after it previously threw an error my errorboundary component includes a home button for navigating to however after clicking home if i then click on link to display my courselist container the errorboundary is again displayed i do not see the console log message displayed from useeffect when navigating back to courses shouldnt this recreate the courselist container is this not happening because the error was thrown in render previously so the container is being reused what is best practice for resetting a component that threw an error for surrounding errorboundary"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUtilize Suspense to express app init loader\nwith concurrent mode getting finalized i went to try to solve an old problem i have the app needs to run a series of init steps before it can do anything viable each steps depends on the previous one this is expressed as nested components the fairly elaborate animated logo is shown for that process but its being restarted for each step and the experience is not that nice ive prepared a demo with some experiments the first one thats active initially is what we currently have the second is what we would like to have but with less naive coding of decreasing counter the last one is my attempt to use suspense but i definitely missing something out here because it behaves very oddly and i cannot seem to figure out why i wonder if the new usetransition should be used somehow or whats going on here"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWeird behavior with functional components and useState, A bug or \"Another rule!\"\nnote if the issue is about documentation or the website please file it at react 1690 sample code javascript import react from react import reactdom from reactdom function optionone return blue pill const optiontwo reactmemofunction optiontwo return red pill function app const option setoption reactusestatenull return one two option const rootelement reactdomrender rootelement well the expected behavior was option one wasnt suppose to throw an error setstate in class components didnt mind if a key value was a pure functional component or a class component even but it seams the usestate hook is sensitive to the value passed using the setter if its another functional component it throws a confusing error worst if the pure functional component passed to setvlaue of usestate hook uses hooks of its own then you get multiple misleading hooks errors to debug so is the usestate hook working like its suppose to a rule not to pass a pure functional component as a value to the setvalue of the usestate hook or a bug"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ni was trying to pass through Hook effect, and the codes used are declared no where. like ChatApi \njs import react usestate useeffect from react function friendstatusprops const isonline setisonline usestatenull function useeffect handlestatuschange return handlestatuschange if isonline null return loading return isonline online offline"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhy does parent's componentDidMount gets called first, then child's?\ni thought it was always the case that first childs componentdidmount would be called and then parents however in this example first parents componentdidmount is called then childs check the logs this happens after i use this in child export default compose withstylesstyles withwidth child does anyone have explanation why this happens"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRead latest state value in event handler\ni have this question i could have asked on stack overflow but i think it is more suitable for people from react team or more experienced users so i will give it a try to ask it here imagine i have event handler below where i want to read latest state value and do something with it however not do a new setstate onclick let data thisstatedata apimakerequesturl data here1 dan abramov says it is safe to read state in event handler in the sense it will be up to date however he says this applies to react 16 otherwise he suggests to use functional setstate to get current state i have question what if i want to read latest state value in event handler however such that it works also in later react versions 17 without hooks one option imho would be to use functional setstate but what if like in the beginning of question i said i dont want to setstate just read the state value and do something with it like network request so using functional setstate wouldnt be right for me as it would force me to update state right or i could return empty object from functional setstate to avoid updating state and put the network request code inside it like this onclick thissetstateps using this form only to read current state in event handler which works for 16 and onwards versions probably but this breaks purity of this function apimakerequesturl psdata return but then i would violate that the function passed to functional setstate must be pure is there a solution to the question i asked 1"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDevTools: Component tree navigation\ndo you want to request a feature or report a bug feature what is the current behavior where is no way to collapseexpand component tree or it subtrees if i pick element with select element button i got all the tree expanded not the only one subtree where selected element came fromprobably bug and i dont found way to collapse tree so if you pick something from page your component tree is basically is always expanded on all levels maybe we can have selected row context menu like the one in chrome devtools with options to collapseexpand image image also i guess it maybe good place to add"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nThere is no 'rendered by' section in my extension\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug what is the current behavior if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below what is the expected behavior which versions of react and which browser os are affected by this issue did this work in previous versions of react"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReact devtools always launches in Chrome\nhi i have the extension installed on both chrome and firefox my default browser is firefox each time i try to debug a react native app remotely it launches chrome to use the debugger there how do i change the default browser for devtools to firefox"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nLimitations of context API compared to legacy implementation\nthis isnt technically a bug but a limitation of the new context api implementation and also a question on whether this should be fixed by react or if i should implement a custom inhouse solution instead i have a fairly edgy usecase with a component library that provides several parentchild components eg tabs accordions etc this looks like a standard context usecase so far however the library has to work in a pluginbased environment meaning the parent and child components are rendered by two completely independent apps host app and plugins respectively example jsx content thus two separate instances of the component library are created one for the host app and one in the plugin scope but they still have to communicate with each other behind the scenes while keeping it transparent to the user this worked seamlessly with the legacy context api but now with the new one it breaks that is because reactcreatecontext returns an object that now has to be explicitly shared between the components by means of an import but because of the decoupled architecture of the app and multiple instance of the library being used this seems impossible to do as stated in the docs the legacy context api is deprecated and will be removed in future versions of react 17 so id like to avoid being stuck on react 16 when that happens"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError message when calling work.commit in commit phase\nthis was me just toying around with unstable apis i dont know what these can be used for just tried to make sense of them from their names do you want to request a feature or report a bug error message of batchcommit is confusing what is the current behavior i was experimenting with the apis and just tried to piece together what goes where while looking through the source i found that the work returned from createroot has a parameter called oncommit for me this implied its called after the commit which doesnt seem to be intended however given the code below i get uncaught invariant violation workcommit cannot commit while already rendering this likely means you attempted to commit from inside a lifecycle method js function app return hello codesandbox start editing to see some magic happen const rootelement const root rootrenderthen const batch rootcreatebatch batchrender bad batchcommit settimeout good batchcommit 0 batchthen good batchcommit three things i noticed 1 seems like i need to call batchcommit after the batch is complete changing it to batchthen good batchcommit got rid of the error but i noticed that the original code is used throughout the internal tests in fact moving createbatch and batchcommit the batch well after long timeout the initial rootrender call seemed to allow sync batchrender batchcommit 2 lifecycle should be replaced with something different before these apis get stable since we try to get away from this mental model for example applies setstate in componentdidmount synchronously in a batch could be converted to a sync test and still pass while i wouldve expected can defer a commit by batching it to fail with the invariant violation from above 3 not all lifecycles are during rendering as far as i know componentdidupdate is called during commit if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below what is the expected behavior im basically asking when its safe to call batchcommit during render phase during commit phase outside of these phases eg in some oncomplete callback which versions of react and which browser os are affected by this issue did this work in previous versions of react reactdom1690"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDevtools V4: Breadcrumbs are removed?\nrequest for feature the older devtools used to show a breadcrumbscomponent hierarchy at the bottom it is really useful to navigate the parent component i couldnt find it on the new devtool did we remove it any reason to remove it will we add it back"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhy does DevTool Chrome Extension need access to history?\ni woke up today and the devtool extension for chrome asked for additional permissions more specifically access to history i couldnt find any explanations or reference in the changelog so i opened this issue"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSuspense + Concurrent Mode immediately shows fallback when updated from onChange\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug reporting a bug or at least trying to understand some spooky behavior ghost what is the current behavior i have a simple component which reads from a toy suspenseenabled cache the dummy cache simply waits 100ms before responding to anything the cache key is based on some component state managed with the usestate hook this component is wrapped with and rendered in a react root with concurrent mode enabled javascript function myapp let text settext reactusestatestuff return data settextbananasupdate text from button settextetargetvalue i aint no fallaback div the component has a text field whose value is set to the current cache key with an onchange handler that updates the usestate hook when the text changes it also has a button which updates the state to some fixed string asdf when clicked clicking the button does what i would expect— the page doesnt respond for a fraction of a second while the data is being fetched and then updates with a view of the loaded data editing the text however for instance typing a single letter in the field immediately causes the fallback ui to load and unfocuses the text input this happens even if the settimeout is changed to 0ms or or a setimmediate polyfill rather than directly calling settext within the onchange handler— if i call it within a settimeout 0 it behaves the way i would expect ie without unfocusing the field and loading fallback if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem what is the expected behavior i would expect that it shouldnt really matter whether im updating state from an onchange versus an onclick i would expect that the fallback ui doesnt show up until its max duration is met which versions of react and which browser os are affected by this issue did this work in previous versions of react im using react 1686 i tested it on chrome 75 on macos 1014"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[eslint-plugin-react-hooks]: Can't call hooks on component returned from function\nwrapping a component in a function returning the component tldr javascript export function home return function const items setitems usestate return nothing const root root results in the following error react hook usestate cannot be called inside a callback react hooks must be called in a react function component or a custom react hook function however this works javascript export function home const items setitems usestate return nothing const root root"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nuseEffect for synchronizing state and props\nhi i have a recurring scenario that i’ve been struggling with since the good old days of and now i’ve pretty much run into the same issue with hooks so i was hoping i could get some guidance as to what the idiomatic way of solving this and similar cases in react is problem description starting point i have a list of items every item has an edit button next to it clicking it opens an “editor” where one can change all the fields and either confirm or cancel confirming would send an api call to save the data but this part is not relevant to the problem i am having the “parent” component would render the list with the edit buttons and have an itemunderedit property that would be null from the start clicking on “edit” for a specific item would set the itemunderedit to the clicked item usecase here is the full example with all 3 solutions on codesandbox solution 1 make the “editor” component stateless and controlled it takes in change handlers for every field as props with the parent tracking every change this solution appeals to me since i like pure stateful components that are a onetoone mapping of props to html they are simple to reason about etc etc this kind of goes against the commonly heard “keep your state close to where it is used” advice which also seems reasonable since i don’t really need to know in the parent what the user is typing i am only interested to know when they are done at the end this stateless solution also introduces a lot of props since i need one event handler per field onnamechanged ondescriptionchanged in the example but it could as well be 10 fields which is a lot of props solution 2 make the “editor” component stateful and only get an event when editing is done onconfirmitemtosave or oncancel this seems like the “react” way and is in line with the advice of keeping state close to where it is used since i am only interested to know when the user clicks confirm a stateful “blackbox”component that tracks its own state seems reasonable in order to achieve this however i need to copy my props to the state which according to gaearon is a bad idea const name setname const description setdescription moreover this solution is buggy from the start since clicking on edit for a different item doesn’t “resync” the props with the state it only works if i close the editor and then reopen it statefuleditor1 which brings us to solution 3 solution 3 this one has been one of my biggest painpoints with stateful components in react which is why i prefer stateless components with a state container but those i widely demonized nowadays so i am yet again trying to understand the idiomatic react way of doing this the “old” ways were to sync in and later with now i can do this with useeffect where i specify propsitem as the “dependency” since i want to run it when the item changes useeffect if propsitemname name setnamepropsitemname if propsitemdescription description propsitem this seems to work as expected but i get the linter warning react hook useeffect has missing dependencies description and name either include them or remove the dependency array obviously if i were to add those to the dependency list i wouldn’t be able to change anything in the inputs so how come i get this warning summary this is a question in two parts first one about an idiomatic solution in react as well as feedback to the react team this scenario is simple and common but it’s difficult to know how to implement correctly and safely in a consistent way lifting state up and making the problematic component stateless is good advice that solves the problem but every time it seems like a “temporary” solution it also leads to painful refactoring every time something has to be moved around the component tree so relying on it in the long run is extremely brittle the second part of the question is whether the solution with useeffect is viable at all and in this case why do i get the linter warning clearly i want to run it only when a certain prop changes is there an edgecase where this would result in an unexpected bug"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`static getDerivedStateFromProps()` does not works same as componentWillReceiveProps  \nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug bug what is the current behavior static is not a replacement for if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below what is the expected behavior which versions of react and which browser os are affected by this issue did this work in previous versions of react 16 hi im trying to implement which will be displayed when a user save an item stating item saved successfully below is my code im using which is depreciated i tried static but it didnt work how can i removed assuming the close button shouldnt be in parent componentwhichever is calling jsfiddle working example requirement on click of the button show notificationcard on click on close hide notificationcard jsx class notification extends reactcomponent constructorprops superprops thisstate open true thissetstate open propsshow 8000 handleclick thissetstate open false componentdidmount 8000 render if thisstateopen return null return item saved successfully thishandleclick 10006 class test extends reactcomponent handleclick thissetstate show true render return click reactdomrender"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDeclarative vs. imperative coding style using Hooks\nif this should be asked on stack overflow instead please let me know and feel free to close the issue consider a component that fetches some data in a custom hook saves the fetched data in a state hook and notifies the user that data has been fetched using a prop callback notifying the user can be done imperatively js function componentprops const data setdata usestatenull useapiapidata thensetdata thenpropsonfetched return datatoelementsdata or declaratively using an effect hook js function componentprops const data setdata usestatenull useapiapidata thensetdata useeffect if data propsonfetched data return datatoelementsdata react seems to promote a declarative approach but what ive found is that when components grow large and complex using declarative effect hooks makes the flow of data and actions quite hard to follow if youre not careful a lot of things start to depend on a lot of other things and the predicted results become nonintuitive and hard to wrap your head around i would like to know other peoples opinions on this matter and whether or not an imperative approach might sometimes be better"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to test multiple state changes with act?\ndo you want to request a feature or report a bug bug what is the current behavior with the new act function im unsure how to test state transitions that occur during an event handler processing for example if i have this handler that is called on form submission const issubmitting setissubmitting usestatefalse const handlesubmit async setissubmittingtrue await fetcher setissubmittingfalse then i want to be able to test that issubmitting state is indeed set to true before fetcher is called due to the nature of act i believe it defers all state changes until after its provided function has been run im not sure that this is currently possible previously ive been testing using await new promisesettimeout to flush the current runtime task queue which works fine for this use case i have found a way to make this work without triggering the act warning but it feels like a hack i have to wrap act around my expectation not the submit itdisplays indicator when form is submitting async await actasync ive provided this test in a repo together with a couple of other tests which complete the feature see the link below if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below what is the expected behavior theres a way for me to test this which doesnt feel like a hack which versions of react and which browser os are affected by this issue did this work in previous versions of react 1690alpha0"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Question] about \"._owner.alternate\"\nit seems that in react16 every react element children contains cyclic property image so it is easy to cause maximum call stack exceeded error when developer compares propschildren in deep waylike deepequal this caused bugs for community libraries like reacthelmet i am extremely curious about why react has owneralternate and what it stands for as it is named as “owner” could it be better if we make “owner” not enumerable i tried to search source code and but still can’t find any clue thanks in advance"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nuseState causing children to re-mount?\nbug what is the current behavior i have a hook that is supposed to call a callback after a settimeout when i render a list of children with this hook the callback behaves differently when its in a function component with usestate than it does if its in a class component to see this in action checkout the codesandbox below the demo should show children components being added to the page and then after 2 seconds the child is mounted it should be removed both the examples use the same child components only difference is the parent component being a class vs functional component codesandbox what is the expected behavior the function component should behave like the class component which versions of react and which browser os are affected by this issue did this work in previous versions of react react v1686 latest chrome unsure if this worked with previous versions of hooks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nonAnimationEnd/onTransitionEnd Issues\ndo you want to request a feature or report a bug bug what is the current behavior onanimationend creates unexpected behavior in the following example i am creating a simple notification component from an array each element in the array is used to generate a html element with a class that has a css animation on it the generated div has an onanimationend binding which will remove them from the array of notifications the basic idea is that the notification will fade away using a css animation and then be removed from the array or alternatively i am also allowing the user to manually click on the notification element to remove it the interesting bug is as follows if you add two notifications the first one will trigger its onanimationend and remove itself the remaining notification will suddenly jump to the end of its css animation and never trigger its own onanimationend even more curiously if you add four notifications exactly two of them will have the above bug while the other two function properly in fact exactly half of the added elements will trigger onanimationend properly while the other half will not the onclick functionality to remove the notifications from the array does not cause any unexpected behavior and thus i am forced to conclude that the fault lies with onanimationend since they both run the exact same function if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below click the add notification button then press it again before the first element has faded 7 seconds you will notice that the second notification element gets fast forwarded to the end of its animation when the first notification is removed by its onanimationend trigger the second notification will then be stuck there never triggering its own onanimationend what is the expected behavior onanimationend should trigger for each element in the loop properly which versions of react and which browser os are affected by this issue did this work in previous versions of react current version of 1686 displays this behavior"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUseEffect how to solve conditional paging list\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug bug what is the current behavior useeffect how to solve conditional paging list 1 reset the page number to 1 when the condition changes image 2 request to return the current page and keep the current state image if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below what is the expected behavior properly handle paging and conditions which versions of react and which browser os are affected by this issue did this work in previous versions of react 168 previously treated in class form"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMimic componentDidMount but with hooks\nwe are trying to use hooks and we want to mimic componentdidmount but our eslint is responding with react hook reactuseeffect has a missing dependency checkuser either include it or remove the dependency array if we add checkuser to the dependency in the useeffect we get the checkuser function makes the dependencies of useeffect hook change on every render move it inside the useeffect callback alternatively wrap the checkuser definition into its own usecallback hook if we change the checkuser to use usecallback eslint is responding with react hook reactusecallback has a missing dependency handleuserstate either include it or remove the dependency array what is the correct way to solve this or should we ignore the warnings javascript function some code function checkuser const response someexternalfunction reactuseeffect checkuser run once"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhy function as child is not considered as children?\nafter digging deeper with this question i have found function as a child is not being considered as children take this example class countexpression extends reactcomponent render const children consolelogchildren return one two still this will be ignored as child why this will be included in array thats fine so i would like know why is it so is it a bug or an expected behavior"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n× Maximum update depth exceeded in controled way\ndo you want to request a feature or report a bug maybe bug what is the current behavior my case is that i want to update state n times by adding different types of fields to the state and then render them every updating of domadding new field i have to check whether i should do something more by checking the hight of added elements for example add a break between elements fields are represented by the tree structure of data so i created the class which helps me with going through the tree of fields and i keep it in the class property i know how many times i have to modify the dom so it will be a fully controlled way of state update and it will finish after all fields are added to dom but before i render all fields i am getting the error maximum update depth exceeded do you know how i can handle with such a problem i found a solution by adding settimeout on the way but i am not sure that is the clean solutioncommented code is it ok that i keep in component class property more complex class to manage structure of data i am providing a simple example in codepage which shows the problem and throw the error"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nShould setting state inside discrete events cause cleanup to run?\nthis bug is pretty confusing i think it happens because fn scheduled by setintervalfn 0 jumps in front of the running effect cleanup caused by setrunningfalse so the interval still fires overwriting setlapse0 that happened during the event with its setlapsesomevalue this reminds me of the issue described in or at least a part of it in fact this problem exists even for regular react keystrokes and other “discrete” events the solution to that would be to flush passive effects before we get a discrete event but here it seems like this wouldn’t be sufficient because the effect flips as a result of the click not before it so should setstate inside a discrete event also flush passive effect seems like not that would defeat the purpose of delaying them so this is working as designed and the fix is just uselayouteffect when the timing matters or the raf solution"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nuseLayoutEffect in ssr\nhi i do not understand the situation with this hook a bit i use this hook to perform the animation synchronously with the state update if i use useeffect then i have jumps in the animation because the animation library does not have time to start also the documentation states that uselayouteffect runs on the same phase as componentdidmount that is on the client side and here my server issues complaints to me about my code why is that originally posted by dimensi in"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHooks: useState one-off callbacks\ndo you want to request a feature or report a bug question feature ive been trying to handle a case where i need to execute a piece of code right after the state is set at a particular place in the code i do understand im supposed to use useeffect to respond to changes in state like so javascript const val setval usestatenull useeffect handle changes to val here val but the problem is it will run on all changes made to val anywhere in the code without the second argument of setval being a callback thatll run after the state is set how can i execute something after a specific setval function call sets the state"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProp reassignment in components\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug bug what is the current behavior prop reassignment in components if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below 1 have a parent component that passes a prop to a child 2 have a child assign the prop to the state default 3 unpack the state value and use apush to alter it 4 watch in horror as both the prop and the state changes check childjs what is the expected behavior props should not be reassignable within mounted components which versions of react and which browser os are affected by this issue did this work in previous versions of react all browsers all oss react 1670"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnder what circumstances, unstable_shouldYield will return true？\nin schedulerjs function unstableshouldyield return currentdidtimeout firstcallbacknode null shouldyieldtohost unstableshouldyield return true when currentdidtimeout is false and shouldyieldtohost return true but why shouldyieldtohost function return framedeadline getcurrenttime shouldyieldtohost return true means theres no time left in this idle period currentdidtimeout is false means the schedule is not timeout what relationship between them why does unstableshouldyield depend on them"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nact cannot detect secondary updates\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug bug what is the current behavior if a component performs a second non user triggered update act cannot detect it and warns about the update for example a button is clicked and updates its text after a second the button resets and its text reverts to its original state the reproduction is a bit contrived but demonstrates the issue what is the expected behavior the test runs without warning about being wrapped in act which versions of react and which browser os are affected by this issue did this work in previous versions of react react react dom 1680"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to use useContext hook inline in Context.Provider\ndo you want to request a feature or report a bug not sure if it is a bug or a feature yet this relates to hooks it could also be that this is all expected behaviour and one of the workarounds mentioned is required what is the current behavior i have a hook that depends on the usecontext hook using it as follows works perfectly const myhookedcomponent const contextvalue return do something with contextvalue const return what if i want to use the getcontext hook inline in the same component that declares the democontextprovider const const contextvalue of course this fails due to the context hierarchy return do something with contextvalue i seem to be unable to get this working please note i have a very good reason for solving my issue with context and not passing props the implementation i show above looks trivial and dumb but it is the simplest way to illustrate what the use case is in my implementation the provider sits in a complex component that does a lot of data management which i really want to happen at this level the usual way to use this will be the first working version i noted above it is only in the case where the user would want to use the hook inline inside the provider i have searched for a couple of hours and tried various configurations without success so my apologies if this is a duplicate of another issue what is the expected behavior any method to consume context inline in the provider using the same reusable hook without having to revert back to render props i know i can solve this with render props but i am trying to convert an implementation using render props to hooks i also know i can hoist the context provider higher up but in my implementation it would quadruple the code complexity to develop and maintain while introducing extra complexity into the user interface also by extracting the body inside the provider to a new component i can also solve this but ideally i would not like to have a user do this for this use case"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nreact-router can't pass Hooks\nthis is actually an issue of reactrouter but since its the major routing lib i want to make you aware that there are issues when you want to pass custom hooks via props through your component tree since routing with reactrouter is a regular use case and react hooks is an easyelegant way to manage state through the app they should work together otherwise react hooks is about creating hooks limited to just one component and you cannot share statehooks componentwide maybe i didnt get something right and there is a way"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow will react solve nested contexts?\njs js value1 value2 value3 value4 value5 null"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to catch Error emitted in componentDidMount\ndo you want to request a feature or report a bug bug report what is the current behavior error boundary handles error emitted in componentdidmount and somewhy rethrows it javascript class errorboundary extends reactcomponent constructorprops superprops thisstate error null errorinfo null errorinfo thissetstate error error errorinfo errorinfo render if thisstateerrorinfo return ive handled an error return thispropschildren class mycomponent extends reactcomponent componentdidmount thissetstate throw new errorthis error somewhy was rethrown render return this component is awesome reactdomrender what is the expected behavior it should not rethrow the error which versions of react and which browser os are affected by this issue did this work in previous versions of react react 1670 os win 10 x64 browser chromium 7103578"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nuseCallback/useEffect support custom comparator\ncurrently we can pass an array as second argument when using usecallback or useeffect like below js usecallback dostha b a b how to do deep equal if a is an object the problem is it only compare array items with it there any way to compare complex object support custom comparator as third argument looks not bad js usecallback dostha b complexobject item previousitem custom compare logic return true false here"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsetState hook inside useEffect can cause unavoidable warning  Can't perform a React state update\nbug what is the current behavior example clicking on ok button cause warning cant perform a react state update on an unmounted component the problem that unsubscribe is called during b event setvisiblev false call see logs set visible before unsubscribe warning cant perform a react state update on an unmounted component this is a noop but it indicates a memory leak in your application to fix cancel all subscriptions and asynchronous tasks in a useeffect cleanup function in child created by holder set visible after in our case we have this even without raf call but on transitionend dom event its occurred randomly and rare in our codebase as transitionend event should be called exactly at needed time but example showed what happens seems like it occurred only if you have a setstate call during useeffect callback like setrefreshv v 1 inside provided code after rewriting our codebase to avoid setstate calls in useeffect the error has gone code javascript import react from react import reactdom from reactdom import mitt from mitt const emitter mitt const child const visible setvisible reactusereducers a a true reactuseeffect const handle consolelogset visible before setvisiblev false this call causes unsubscribe and warning about state consolelogset visible after emitteronb handle return emitteroffb handle return visible child text const holder const refresh setrefresh reactusestate0 const visible reactusereftrue reactuseeffect if refresh 1 visiblecurrent false setrefreshv v 1 this state change from effect caused problems const handle setrefreshv v 1 emitterona handle return emitteroffa handle return visiblecurrent function app return button onclick emitteremita emitteremitb ok const rootelement reactdomrender rootelement what is the expected behavior do not provide warning if unsubscription is called during setstate call which versions of react and which browser os are affected by this issue did this work in previous versions of react react 1670alpha2"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ngetDerivedStateFromProps is user-hostile\nso i think as designed turns out to be userhostile the short summary is that it makes the pattern described in the docs impossible for nontrivial cases imagine implementing an hoc that listens to change events on a datasource but where a simple shallowequal on the resultant state isnt sufficient to prevent rendering ie what if you need more complex logic to determine if new data from the datasource should be applied in my case i have a datasource that doesnt guarantee that it will give out objects of the same identity so a check will always return false and cause a rerender but i can do a little bookkeeping on the side and determine whether the data is actually new and should therefore be loaded into state this leads to some problems 1 because is static its not possible to store some internal bookkeeping data on the component instance that gets used to determine whether to query the datasource worst case this bookkeeping information could be stuffed in the state object but thats unnecessarily constraining and a bit ugly from a code organization perspective 2 more importantly its not possible to determine why is being called is it because of a props change or is it because of a change event firing on the datasource this matters because if props have changed data must be fetched and the component rerendered unconditionally but if the props havent changed then its possible all the data loaded is the same as last time and so render can be skipped heres an example using the deprecated api thats no longer possible lightly edited from the hoc example i mention above function datasource getdatafunc return class extends reactpurecomponent componentdidmount subscribe to changes componentwillunmount clean up listener unconditionally update state and rerender since the props changed const possiblynewdata props this remember some metadata about what we fetched for next time thisbookkeeping handlechange update component state whenever the data source changes const possiblynewdata thisprops this the datasource had updated data in it so rerender remember some metadata about what we fetched for next time thisbookkeeping else no new data was fetched so dont update state and dont rerender do nothing… render notice that the behavior is different between and handlechange theres no way to make that distinction with the new api"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCases where hooks don't currently provide a good answer vs HOC\nunsure if this is the right place so trying it out ive noticed that the new react hooks feature is aiming at providing an alternative composition pattern to hoc and render functions but i believe that many of the use cases solved by hoc at the framework level cannot currently be addressed by the new hooks api specifically there is not way to incorporate react hooks with reactmemo unless i am incorrect this means that any system that would like to implement optimisations based on external context such as the reactredux connect function that uses mapstatetoprops to implement an efficient will still need to rely on a hocrenderprop to automate this optimisation the reason i am bringing this up is because one of the main benefits stated in the documentation is to reduce framework level use of hoc that pollute the tree of which the reactredux connect hoc is probably the most prevalent use case additionally redux and useredux are specifically brought up as an exemplary use case although with the current system it will cause large optimisation issues since with no optimised every connected component will rerender on every state change although this might fit into the documentation repo this is a discussion opinion and i do not feel it is a mistake that i should report but rather a discussion on importance an example solution for this could be if there was a way to use contexts in reactmemo which unless im incorrect only have access to props and prevprops"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[npm:create-react-class] No way to implement getDerivedStateFromProps\nthere seems to be no way to implement class methods such as and a few others am i overlooking something there is no mention of it here either"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nElement attributes be removed silently in frameset tag\ndo you want to request a feature or report a bug bug what is the current behavior in some historical reason i am still using obsolete tag frameset in my project and when i render my component which includes frameset tag in react some attributes are ignored like rows cols could anyone tell me why and how to solve it by no hacking way thx input javascript export default class obsoleteelment extends reactcomponent render return old page output javascript old page expect javascript old page which versions of react and which browser os are affected by this issue did this work in previous versions of react react version image node environment image image os image"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAccess React component underlying DOM tree\ndo you want to request a feature or report a bug feature what is the current behavior form component has form field children input checkbox etc that are validated against some custom rules when form is submitted validation works fine what is the expected behavior if the form is invalid i would like to scroll the page to the first invalid element after the form is submitted but unfortunately components do not expose the underlying dom three except via the fiber object and i cannot get the ref of any component which makes scrolling not possible since i dont have the dom reference i am trying to avoid ref forwarding on form field components because i would like the form to handle all validation related code for encapsulation purposes and in case i want to publish this as a library for instance which versions of react and which browser os are affected by this issue did this work in previous versions of react react 1640 is there any way to achieve this"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuestion on reconciliation\ni think i understood reconciliation in react however there is one thing i would like to clarify lets say on first render we render duke key 0 villanova key 1 and on next render connecticut key 0 duke key 1 villanova key 2 if i understood reconciliation correctly on the second render react will check that types eg and keys of first two items from first and second render match hence it will add only the new item with key 2 to the new output hence generate following result duke key 0 villanova key 1 villanova key 2 however i think this is not what react will generate and it seems then there is some issue with my understanding especially the bold part in the previous paragraph can someone explain what i missed in my understanding"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGet keys in react-reconciler\ni am struggling to implement reusable views on mobile platforms and to make it i need to get key values explicitly set and generated in reactreconciler to match two different view trees somewhere outside react is there a way to achieve this thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nhow map ? render An Array Of Elements \nwhat is the current behavior react16 support return array components for example render return 《li》1《li》 《li》2《li》 《li》3《li》 export default arraydemo i want to map it with reactchildrenmap for example import arraydemo from xxxxxx index return 《col span6》item《col》 but arraydemo has become a single element reactchildrentoarray got 0 only what is the expected behavior i expected since react can return array how can i map it for sometimes i want to wrap each element in array which versions of react and which browser os are affected by this issue did this work in previous versions of react 164 or am i missing something important thx a lot"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAvoid reconciliation, alternative component interface\nhello i want to ask a question about a way to avoid reconciliation process today i can see the following process 1 component wants to rerender 2 component render method provides new virtual dom 3 some react diff library tries to find some nonoptimal way to morph old virtual dom into new one please fix me if i am wrong i am not familiar with react codebase i can see an information in docs you don’t have to worry about exactly what changes on every update but your solution has complexity about on or even worse so user should care about what changes sometimes when user knows what changed he will be able to provide olog n or even o1 solution for example i am working with huge data list and i am receiving information from websocket about how to morph my list appendprepend remove swap items etc i dont want to render huge component list and run reconciliation process for each mutation i can tell virtual dom how to morph efficiently append is there a way for user to provide morph method i can imagine some api like render is not defined morphcomponent if componentappend else key 5 do you have any plans to implement it thank you please feel free to ask any questions"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncomponentWillUpdate discussion\nnote if the issue is about documentation or the website please file it at do you want to request a feature or report a bug feature componentwillupdate discussion what is the current behavior the current behavior calls the function before rerendering the render target however there is no indication for when the rerender method should be called if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem your bug will get fixed much faster if we can run your code and it doesnt have dependencies other than react paste the link to your jsfiddle or codesandbox example below what is the expected behavior the expected behavior should call the function before rerendering the render target if there is no returned conditional statement and if there is true should trigger the rerender and false should not which versions of react and which browser os are affected by this issue did this work in previous versions of react 1640 i have a few questions before i try to solve this problem and it gets rejected im assuming that the team has decided to move in the direction of removing willupdates from react all together and have labeled them unsafe ive seen a lot of issues with those functionalities before as well i was curious if providing a conditional statement inside those functions would satisfy the unexpected renders does trigger when to call these functions however in those functions that will run before the render can always be controlled with a conditional statement of its own im getting comfortable with the code base however im curious if the team is removing that functionality all together and using the static function instead has a react lover it is a little confusing and may break a lot of legacy code when updating versions i believe that may solve the problem of unexpected renders after a will change lifecycle event i was curious if that was the case and removing will lifecycles is the next steps for react then how will the did lifecycles work instead i love react and im just curious about the future for react as a whole id love to tackle any bugs or feature requests when i have time i will be writing clean code and create tests for new features or bugs as well"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSuspense: timeout expiration and siblings rendering issues\ndo you want to request a feature or report a bug bug what is the current behavior code for reproducing is here ive also deployed an example to zeit now this is a basic example of using react suspense and simple cache provider postponing text rendering and showing loading spinners when its necessary i can see my use of doesnt really care about ms im passing — it always become expired right after the render you can open a page and the loading bar appears immediately despite 1000ms delay that it has there is content that is placed next to an async component the one thats going to be suspended looking at react suspense tests it is assumed that sibling elements can be rendered in any way what is the expected behavior component only shows placehold when expired sibling content is shown even if an async component was suspended i built sources for react reactdom and simplecacheprovider from the current master updating enablesuspense flag i also used but it didnt seem to make any difference i overall was really satisfied with this feature i hope i did the code correctly so it shows the real bug"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUse and set a component's state within setInterval function\nthis is a question so i apologize if this isnt the best place to ask im trying to work with a components internal state within a setinterval function and i know there are some asynchronous problems i need to be aware of i also know that i can pass setstate a function which would help me protect against async problems but i cant because i need to use the changed state within the setinterval function is what im doing safe or should i be working a different way around this problem ive seen the following that nearly answers my question and am having trouble visualizing adapting this or maybe the behavior i have is fine stackoverflow answer sectiontimerhandler const elapsedsectiontimems 1000 do some stuff with elapsedsectiontimems restartsectiontimer if 0 1000 thissetstate elapsedsectiontimems 0 or would something like the following be bettersafer even though im using 1000 earlier in the function assessmentstate return elapsedsectiontimems 1000"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nContext API bitmask related questions\nim playing with context api bitmask feature to bail out unwanted rerender i have a dynamic model a json object as context value by dynamic i meant the number of keys and structure of the json object is unknown but when the json object changed i know which key is changed it seems difficult to turn the unknown keys to static predefined bitmasks but i thought such use case is very common and the bailout feature should handle it easily by just matching the key also i notice default changedbits and observedbits is maxsigned31bitint does this mean it has a limitation up to 31 type of context change"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Question] Context provider state initialisation.\nconsider a component wrapping a context provider js class valuewrapper extends reactcomponent constructorprops superprops thisstate value null setvalue thissetvalue setvalue value thissetstate value render thispropschildren a consumer then might want to set a default value when it is first mounted the only way i can see to do this using the new api is to check for an existing value on first render js class valueupdater extends reactcomponent state inputvalue 0 handleinputchange e thissetstate inputvalue etargetvalue render value setvalue if value return value but this seems to break the golden rule of updating state in the render method as this would immediately cause a rerender ideally i would be able to call the setvalue from the context in the componentdidmount method of the valueupdater component but with context as a render prop thats not possible as far as i can tell the docs suggest passing props down to another component js render value setvalue but if i tried to do the initialisation in the valueupdaterinput components componentdidmount method it would be called on every render surely as valueupdaterinput would be rerendered each time is there a better pattern than this or am i trying to use context inappropriately"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIs there a way to access new context api within ComponentDidMount?\nwe are building a react mapbox gl module and we use clone and inject props today we were looking into using the 1620 context api but i saw that it will have a new one on 1630 but i can’t seem to find a way to read context details on componentdidmount lifecycle which makes sense for me to use on the map implementation is there a way around this"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPotential Future Bug in getEventKey for Edge with Synthetic Event normalization.\nbug current behavior react currently normalizes keyboard events crossbrowser by falling back on the native keyboardeventkeycode property and using a dictionary object to normalize the key as noted in the source geteventkey is used for normalization of deprecated html5 key values edge currently does not implement the correct key values and this normalization will fall back to keyboardeventkeycode keyboardeventkeycode is deprecated and may be dropped at any time microsoft as per have fixed this issue but it has not yet been released to insider preview releases this means there is the potential for the keyboardeventkeycode to be removed from edge before the fix is made public it may be a good idea to not rely on keycode in this instance refer to line 103 which versions of react and which browser os are affected by this issue did this work in previous versions of react reactdom version 1620 potentially affects future versions of edge"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nstate change in td element\ndisplaying tabular rows when setting data in td element on state change it displays only the currently updated td element dataall the other ones go missing from screen when the same thing is placed within text box in each td element things work fine following is sample the code working code failing code thisstatepriceid"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGetting started docs are terrible\ni just came back to react after about a year or so of not using it and now the getting started docs are pretty much not helpful in the slightest all the docs are now is just links to other websites without any instructions on how to get a react project running i remember a year ago back in react 15 the docs had a step by step walkthrough for how to set up and get a project running from scratch and now they are just links to websites without react specific instructions what happened to the docs when did they become so useless there needs to be a step by step guide added back to the docs a guide that will get you from having nothing to running it in the browser instead of just links to other websites that dont have anything to do with react i remember back in react 15 you could run through the guide and have a hello world app running within 10 minutes no problems i have been trying to figure it out with these new docs for over an hour now and still 0 luck getting this running the instructions used to actually be instructions basically saying install this then that then run this command in terminal then do this and so on the docs now just say well you can use this then has a link to a site that has nothing to do with react there is not even any sort of instruction on the react website on what to do with that just the link without any context around it can these docs please be reverted to the old versions or actually create a proper getting started page to get you from nothing to running"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nConcating react with other resources\nhi i want to use many libraries and frameworks in my project can i concat react with other framework like angular vue ember"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncan't edit the wiki\nhello i cant edit the wiki to add my website to the list there is editing disabled"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTypeError: Cannot read property 'state' of undefined with create-react-class\ni am currently attempting to create a button which is red with the text yes that when you click on it the button changes to a green color with the text confirm before the final stage in which an action takes place where i am currently at is defining buttoncolor as a state which changes on the click of the button the initial color should be fd8f83 and the final color after the click should be a4d87c however i am currently getting the error typeerror cannot read property state of undefined pointing to the stylebackgroundcolor thisstatebuttoncolor line whenever the code is compiled on the webpage defining initial state and behavior on click getinitialstate function return buttoncolor fd8f83 handleclickcolor thissetstate buttoncolor color code inside table in render button stylebackgroundcolor thisstatebuttoncolor yes does anyone have any ideas why this is i am brand new to react so i apologize if its obvious i also learned react using createclass so ive been trying to piece together how to make this work with the new createreactclass package any advice is greatly appreciated react 1620 chrome version 6303239132 official build 64bit"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSluggish scrolling when rendering table with large dataset in React\nso im creating an application with realtime streaming data in a table using react v1611 the number of rows shown at a time can be rather large 400 rows and when those situations occur the scrolling behavior on browsers desktop mobile really takes a hit and staggers when attempting to browse the content has anybody experienced this kind of scrolling behavior when rendering large data sets in a table im expecting react to be able to efficiently drawredraw these elements with ease but that doesnt appear to be the case i tried using jsfiddle to recreate the scenario but did not have much success"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nforceUpdate recalls all ref callbacks\ndo you want to request a feature or report a bug bug maybe what is the current behavior on calling forceupdate ref callbacks called again so doing forceupdate in ref callback makes infinite loop if the current behavior is a bug please provide the steps to reproduce and if possible a minimal demo of the problem via or similar template for react 16 template for react 15 what is the expected behavior do not recall refs which versions of react and which browser os are affected by this issue did this work in previous versions of react react 1611 chrome 62"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncan't access discuss react\ni know this is not related to react directly but didnt know where to turn to am i the only one who cant accesslogin to discussreactjsorg for quite some time already i get error this page isn’t working discussreactjsorg is currently unable to handle this request http error 500 and sometimes when i retry this error sorry there was an error authorizing your account perhaps you did not approve authorization"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nADD Suppport for VEDV (https://github.com/yunielrc/vedv)\nplease go to stack overflow for help and support if you open a github issue here is our policy 1 it must be a bug a feature request or a significant problem with the documentation for small docs fixes please send a pr instead 2 the form below must be filled out 3 it shouldnt be a tensorboard issue those go here heres why we have that policy tensorflow developers respond to issues we want to focus on work that benefits the whole community eg fixing bugs and adding features support only helps individuals github also notifies thousands of people when issues are filed we want them to see you communicating an interesting problem rather than being redirected to stack overflow system information have i written custom code as opposed to using a stock example script provided in tensorflow os platform and distribution eg linux ubuntu 1604 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device tensorflow installed from source or binary tensorflow version use command below python version bazel version if compiling from source gcccompiler version if compiling from source cudacudnn version gpu model and memory exact command to reproduce you can collect some of this information using our environment capture script you can obtain the tensorflow version with bash python c import tensorflow as tf tfversionversion describe the problem describe the problem clearly here be sure to convey here why its a bug in tensorflow or a feature request source code logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached try to provide a reproducible test case that is the bare minimum necessary to generate the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCan't run bert_vocab_from_dataset without TypeError: Tensor is unhashable\nissue type support have you reproduced the bug with tensorflow nightly no source source tensorflow version 213 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior this is the code from you manual i really dont understans that i get this error why is it if i add i get runtimeerror inputdataset attempting to capture an eagertensor without building a function standalone code to reproduce the issue shell data tagspath from import bertvocabfromdataset as bertvocab tokens data the target vocabulary size vocabsize 50000 reserved tokens that must be included in the vocabulary reservedtokenspad unk start end arguments for textberttokenizer arguments for learnparams relevant log output shell typeerror tensor is unhashable instead use tensorref as the key"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFloat16 mixed precision training\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2130 custom code yes os platform and distribution ubuntu 20045 lts mobile device no response python version python 3109 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory a6000 current behavior enabled float16 training by setting the mixed precision policy but why i still need to manually cast the y tensors to float16 before calculating the loss error when no manual cast the tensor image standalone code to reproduce the issue shell confidential relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCKPT to TFLite\nhow can i convert ckpt file to tf lite while ive only ckpt file no metafile present"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhen converting tensorflow model to tflite model, is there any way to fix the output order during inference using tflite as Facing an issue of output order of tflite inference on meraki custom cv\ni took a pretrained model ssd mobilenet 320x320 for object detection from the tensorflow zoo and configuredtuned it according to my data i trained a tensorflow model which detects 2 labels i have used the latest checkpoint to save the model then froze it and finally performed tf lite conversion i did this because i need to upload the tf lite model only to a cisco camera im facing an issue with the output order during tf lite inference as the output arrays get jumbled rearranged i need help on how to convert the tensorflow model to tf lite efficiently my tensorflow version is 210"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDistributed training with parameter servers example using a single binary\nhello everyone i am sorry if this is a duplicate issue but from my considerable search i could not find a single endtoend distributed parameterserver example to run using tensorflow using the keras api with fit method also for some reason the documentation for parameterserver strategy seems a lot more confusing and difficult to get started with compared to multiworker strategy i have been running training jobs using the estimator api before and now trying to update it to tf2x style distributed training job with parameterserver training strategy using a single binary file for all workers and parameterservers i started with the example in documentation here and modified the code to be used as a single binary code import tensorflowdatasets as tfds import tensorflow as tf import os clusterresolver if in worker ps start a tensorflow server and wait server or grpc starttrue serverjoin else parameterserver strategy globalbatchsize 64 x tfrandomuniform10 10 y tfrandomuniform10 dataset yshuffle10repeat dataset dataset datasetprefetch2 with strategyscope model lossmse stepsperexecution10 workingdir myworkingdir logdir ospathjoinworkingdir log ckptfilepath ospathjoinworkingdir ckpt backupdir ospathjoinworkingdir backup callbacks modelfitdataset epochs5 stepsperepoch20 callbackscallbacks to my understanding all workers and paramterservers will start and wait for chief to assign the tasks chief or coordinator documentation uses them interchangeably but is there any difference between the two will automatically divide the work based on the information it gets from clusterresolver let me know if thats wrong interpretation in any case i would highly appreciate if someone can point out what i am doing wrong in this example because i have not been able to get it to work"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhen building from source code, I always end up with a Python 3.10 whl file, instead of a Python3.8 whl file.\nissue type buildinstall have you reproduced the bug with tensorflow nightly no source source tensorflow version 2140 custom code no os platform and distribution linux ubuntu 20046 lts mobile device no response python version 38 bazel version 117 gcccompiler version 940 cudacudnn version 11887 gpu model and memory gtx 1050 ti 4gb current behavior when i try to build the source code from my machine i end up always with a wheel for python 310 although i specified the python path for python38 and i dont even have python310 installed the generated wheel is called can you guide why this is happening and how to solve it standalone code to reproduce the issue shell just trying to build the source code following the steps from this two sites relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIssues running Transformer model example with estimator api\nhello everyone i am trying to run an image classification training example with vision transformer from keras examples everything ran perfectly when i ran it as it is but i started facing issues when i switched training from modelfit to ofcourse i made the appropriate changes to first convert model to estimator from what i understand the problem lies with saving and reloading the model which is done by the estimator api the model has custom classes class patcheslayerslayer def initself patchsize kwargs superinitkwargs selfpatchsize patchsize def callself images batchsize tfshapeimages0 patches imagesimages sizes1 selfpatchsize selfpatchsize 1 strides1 selfpatchsize selfpatchsize 1 rates1 1 1 1 paddingvalid patchdims patchesshape1 patches tfreshapepatches batchsize 1 patchdims return patches personal addition def getconfigself baseconfig supergetconfig baseconfigupdate patchsize selfpatchsize return baseconfig class def initself numpatches projectiondim kwargs superinitkwargs selfnumpatches numpatches selfprojection layersembedding inputdimnumpatches def callself patch positions tfrangestart0 limitselfnumpatches delta1 encoded selfprojectionpatch return encoded personal addition def getconfigself baseconfig supergetconfig baseconfigupdate numpatches selfnumpatches projection selfprojection positionembedding return baseconfig from looking at some related issues i found how we need to provide a getconfig method to save and reload the model with custom classes so i made small personal modifications but now its sort of giving me a different issue i am unable to understand error log warningswarn xtrain shape 50000 32 32 3 ytrain shape 50000 1 xtest shape 10000 32 32 3 ytest shape 10000 1 trainpy225 runconfiginit from is deprecated and will be removed in a future version instructions for updating use tfkeras instead userwarning is deprecated and will be removed after 20201011 to update it simply pass a truefalse value to the training argument of the call method of your layer or model warningswarn traceback most recent call last file trainpy line 257 in history file trainpy line 231 in runexperiment modelest modeldir configrunconfig file line 376 in modeltoestimatorv2 return file line 725 in modeltoestimator warmstartpath customobjects file line 457 in savefirstcheckpoint model kerasmodel file line 230 in cloneandbuildmodel clone file line 806 in cloneandbuildmodel clone clonemodelmodel file line 539 in clonemodel return clonefunctionalmodel file line 222 in clonefunctionalmodel modelconfigs createdlayers file line 298 in config file line 1590 in getnetworkconfig layerconfig file line 295 in copylayer layerfnlayer file line 52 in clonelayer return file trainpy line 108 in fromconfig return clsconfig typeerror init missing 1 required positional argument projectiondim i thought it might be because of patchencoder class constructor has custom objects as argument so i tried to do but to no vail in any case i would highly appreciate if someone can guide me as to where i am going wrong in this"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTesla v100 Tensorflow CUDA Support\nissue type support have you reproduced the bug with tensorflow nightly yes source source tensorflow version 24 custom code yes os platform and distribution rhel 79 mobile device no response python version 36 bazel version no response gcccompiler version 43 cudacudnn version 118 10176 gpu model and memory tesla v100 2gb vram current behavior attempting to fetch value instead of handling error internal failed to get device attribute 13 for device 0 cudaerrorunknown unknown error nvidiasmi give the following output nvidiasmi 4505105 driver version 4505105 cuda version 110 nvccv the following output nvcc nvidia r cuda compiler driver copyright c 20052019 nvidia corporation built on frifeb8190817pst2019 cuda compilation tools release 101 v101105 standalone code to reproduce the issue shell doesnt happen with windows or ubuntu systems relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nParse output of `mobile_ssd_v2_float_coco.tflite`\nissue type support have you reproduced the bug with tensorflow nightly no source source tensorflow version v2111 custom code yes os platform and distribution linux ubuntu 2004 mobile device android python version no response bazel version 620 gcccompiler version 12 cudacudnn version no response gpu model and memory no response current behavior im trying to use the model on a c application im able to execute the inference and get the results based on the netron app i see that its output is image but i couldnt find an example code showing how to parse this output i tried to look into and but the output of the model is different from the one provided here do you have any example code available in java python or even better in c to parse this model output standalone code to reproduce the issue shell no example code is available to parse the output of relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError installing impoerting TF model into Node red\nhello i am getting a tensor flow to install on my node red it seems like there is and install issue and i keep on getting the error pictured below i have also tried import an model from teachable machine too and i get the same error please help capture capture1"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupport for empty GPU batches during distributed training\nissue type support have you reproduced the bug with tensorflow nightly no source source tensorflow version 2120 custom code yes os platform and distribution ubuntu 2004 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior when doing distributed training using mirroredstrategy one may encounter empty gpu batches when dropremainderfalse during dataset construction from 44348 it seems it is a longstanding issue for the last few batches of data it is possible that some replica workers receive an empty tensor as input see here for an example either one must set dropremaindertrue or consider not using tffunction because you would have to add a conditional statement in the trainstep function which wont work with tffunction so from the point of efficiency dropremaindertrue seems the only option in some applications or critical experiments one would not like to drop the remainder data for very precise and reproducible quantitative analysis so can there be a support for handling empty gpu batches in distributed mode standalone code to reproduce the issue shell over 3 replicas results in the following output batch 1 replica 1 0 1 replica 2 2 3 replica 3 batch 2 replica 1 4 5 replica 2 6 7 replica 3 without dropremaindertrue this will cause an incompatible shape error when doing a forward pass relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nConvert tf.Tensor into tensorflow::Tensor\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 213 custom code yes os platform and distribution ubuntu 20 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version 112 gpu model and memory no response current behavior is there any way to convert tftensor from python into tensorflowtensor c standalone code to reproduce the issue shell actually using pybind11 i can get pyobject from tftensor and have no idea how to get tensorflowtensor from pyobject relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to use keras layers to augment both image and label data in image segmentation tasks？\nissue type others have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 26 custom code yes os platform and distribution linux ubuntu 2004 mobile device no response python version python 37 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior how to use tool a to enhance both image and label data in image segmentation tasks i saw an example in the official document of using keras layer for data augmentation which is very useful in the training process of classification models because the data augmentation does not require synchronized operations on labels however in the segmentation task if i embed the data enhancement layer into the model structure i cannot do operations like rotate 、zoom etc on the label and image at the same time because the fit method only feed the original image into the model for inference which results in the label being isolated from the inference process so it is impossible to do synchronize affine transformations with the original image thanks standalone code to reproduce the issue shell i cannot copy my code from the company computer i just want to know how to do efficient data augmentation that can apply gpu acceleration and distribute strategythanks relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSavedModel is not deterministic when saved with enable_op_determinism=True\nissue type support have you reproduced the bug with tensorflow nightly no source source tensorflow version 292 custom code no os platform and distribution ubuntu 2004 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior i have a model with montecarlo sampling layers at train time it is ok for sampling to be random and i do not set a seed at inference this model must output deterministic results so the sampled values must be reproducible i need to save this model after training using and then load it with when training is complete i save the model like so modelseed 42 savepath saveformattf to load it import tensorflow as tf model for in range10 output modelinputtensor trainingfalse i expect output to be always the same for the same input within one python process and when reloading however it is not this is what my model looks like only the relevant portions class def initself args kwargs selfseed none selfmclayer property def seedself return selfseed seedsetter def seedself value if lgrinfosetting random seed selfseed value tfrandomsetseedvalue else lgrinfotf op determinism not set def callself inputs trainingtrue return selfmclayerinputs seedselfseed internally in i use the seed value like so tfrandomsetseedseed samples distsamplenumsamples seedseed where dist is a distribution from when selfseed none which is the case in training distsample will randomly generate values when selfseed is set then i need distsample to be reproducible the loaded model even with op determinism enabled during saving and loading is not reproducible standalone code to reproduce the issue shell see above relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError: Input 0 of layer 'batch_normalization' is incompatible with the layer: expected ndim=2, found ndim=4.\nestoy intentando entrenar un modelo gan utilizando keras en tensorflow pero estoy encontrando el siguiente error input 0 of layer batchnormalization is incompatible with the layer expected ndim2 found ndim4 full shape received none none none 32768 el error ocurre cuando intento entrenar el modelo con el siguiente código python history epochs100 callbackscheckpoint tensorboard ¿alguien podría ayudarme a entender qué está causando este error y cómo puedo solucionarlo gracias"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHi @radres2019, Thank you for reporting the issue!\nhi radres2019 thank you for reporting the issue you are seeing this error because colab has python version 310 tensorflow quantum 072 is compatible with python 37 38 39 and does not support python 310 please refer to the gist where i was able to install tensorflow quantum sucessfully here thank you originally posted by synandi in"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUsing C api and library\nsystem information windows if possible tensorflow lite in play windows google play services version standalone code to reproduce the issue hi i have compiled tflites static library libtensorflowlite a and libtensorflowitecso using cmake according to the official document however when i introduced this library and used c to call it the following error occurred undefined reference to undefined reference to imp do you know what caused it or are there any relevant cases thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhat phone support tensorflow lite GPU delegate?\nclick to expand issue type support have you reproduced the bug with tf nightly no source binary tensorflow version 2120 custom code no os platform and distribution android 13 mobile device android 13 python version 383 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour i tested multiple mobile phones including xiaomi 12s ultra oneplus 8 honor nova 10 oppo reno 9 using the example android apk at on all of the devices the app tells gpu is not supported but nnapi and cpu is ok anything i can do to enable the gpu delegate on these qualcomm snapdragon devices standalone code to reproduce the issue shell the example android apk at relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAbout using C to call tflite\nsystem information riscv standalone code to reproduce the issue hi if i want to compile tflite into a library and then use c to call it how can i effectively optimize and crop it to make the compiled tflite library file smaller because for our model tflite micro is not supported by many operators"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow.map hangs randomly when using for num_parallel_calls a value > 1\nsystem information have i written custom code as opposed to using a stock example script provided in tensorflow yes os platform and distribution eg linux ubuntu 1604 wsl2 on windows tensorflow installed from source or binary binary tensorflow version use command below 2120 python version 3810 cudacudnn version 120 gpu model and memory rtx a5000 24gb describe the problem i am using tensorflow in a docker container on wsl2 for training neural networks but unfortunately everything freezes during the image import if done with the tfmap function with the parameter numparallelcalls set to a value 1 below is a minimal example of the code which causes the console to freeze at a random step and the cpuusage to drop to a minimal level while the ram is still occupied after everything is frozen the docker container is unresponsive and has to be restarted by stopping the process this might even take half a day a few hundred thousand iterations but it allways happens at some point source code logs import tensorflow as tf def return tfioreadfilefilename filenames for i in range 100000 datasettrain datasettrain numparallelcalls 2 datasettrain datasettrainbatch50 for epoch in range1000 for step xbatchtrain in printepoch epoch start train stepstep this issue is similar to others like 32454 but i still cant find a fix bypassing the mapfunction by loading everything at once works definitly during mapping if parallel calls are allowed"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsame Error as #35100 --W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated. \t [[{{node PyFunc}}]]\ni am reproducing the code i followed there requirement but when code reached to 44100 epoch i got this error 20230524 064229554799 w error occurred when finalizing generatordataset iterator failed precondition python interpreter state is not initialized the process may be terminated node pyfunc i tried to to update tensorflow but it stop working because of keras version code requirements package version abslpy 140 astor 081 certifi 2022127 charsetnormalizer 310 colorama 046 filelock 3120 fsspec 202310 gast 053 googlepasta 020 grpcio 1513 h5py 380 huggingfacehub 0141 idna 34 importlibmetadata 600 joblib 120 keras 224 kerasapplications 108 kerasbert 0800 kerasembedsim 0100 0160 kerasmultihead 0290 kerasposembd 0130 080 keraspreprocessing 112 kerasselfattention 0510 kerastransformer 0330 markdown 341 markupsafe 212 mock 501 numpy 1216 packaging 231 pip 2231 protobuf 3201 pyyaml 60 regex 202355 requests 2310 scikitlearn 102 scipy 173 setuptools 6563 six 1160 sklearn 00post5 tensorboard 1131 tensorflowestimator 1130 tensorflowgpu 1131 termcolor 220 threadpoolctl 310 tokenizers 0133 torch 1131 tqdm 4650 transformers 4292 typingextensions 450 urllib3 202 werkzeug 223 wheel 0384 wincertstore 02 wrapt 1150 zipp 3150 and runpy code is codingutf8 from dataloader import datagenerator loaddata from model import e2emodel evaluate from utils import extractitems gettokenizer metric import os argparse 1 from keras import backend as k ifkbackend tensorflow import tensorflow as tf from import setsession config tfconfigproto true sess tried these lines too but not useful config sess parser controller defaulttrue typebool helpto train the hbt model python runpy traintrue defaultvkg typestr helpspecify the dataset from args parserparseargs if name main pretrained bert model config bertmodel casedl12h768a12 bertconfigpath pretrainedbertmodels bertmodel bertconfigjson bertvocabpath pretrainedbertmodels bertmodel vocabtxt bertcheckpointpath pretrainedbertmodels bertmodel bertmodelckpt dataset argsdataset trainpath data dataset traintriplesjson devpath data dataset devtriplesjson testpath data dataset 12345 testpath data dataset normal seo epo testpath data dataset testtriplesjson overall test reldictpath data dataset rel2idjson saveweightspath savedweights dataset bestmodelweights lr 1e5 tokenizer traindata devdata testdata id2rel rel2id numrels loaddatatrainpath devpath testpath reldictpath subjectmodel objectmodel hbtmodel bertcheckpointpath lr numrels if argstrain batchsize 6 epoch 100 maxlen 100 steps lentraindata batchsize datamanager tokenizer rel2id numrels maxlen batchsize evaluator evaluatesubjectmodel objectmodel tokenizer id2rel devdata saveweightspath stepsperepochsteps epochsepoch callbacksevaluator else testresultpath results dataset testresultjson isexactmatch true if dataset wikikbp else false if isexactmatch printexact match else printpartial match precision recall f1score metricsubjectmodel objectmodel testdata id2rel tokenizer isexactmatch testresultpath 35100"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTensorflow Object Detection Project\nclick to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version tf1x custom code no os platform and distribution macos ventura mobile device macbook air 2020 i3 python version 31011 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour so i am making an object detection projetc for school and i need help whenever i run this code this is the error that pops up please help it is due in a few days i have installed all neccesary modules i think standalone code to reproduce the issue shell usrbinenv python coding utf8 detect objects using your webcam this demo will take you through the steps of running an outofthebox detection model to detect objects in the video stream extracted from your camera create the data directory the snippet shown below will create the data directory where all our data will be stored the code will create a directory structure as shown bellow codeblock bash data └── models where the models folder will will contain the downloaded models import os oschdir detection datadir ospathjoinosgetcwd data modelsdir ospathjoindatadir models for dir in datadir modelsdir if not ospathexistsdir osmkdirdir download the model the code snippet shown below is used to download the object detection model checkpoint file as well as the labels file pbtxt which contains a list of strings used to add the correct label to each detection eg person the particular detection algorithm we will use is the ssd resnet101 v1 fpn 640x640 more models can be found in the tensorflow 2 detection model zoo to use a different model you will need the url name of the specific model this can be done as follows 1 right click on the model name of the model you would like to use 2 click on copy link address to copy the download link of the model 3 paste the link in a text editor of your choice you should observe a link similar to 4 copy the xxxxxxxxx part of the link and use it to replace the value of the modelname variable in the code shown below 5 copy the yyyyyyyy part of the link and use it to replace the value of the modeldate variable in the code shown below for example the download link for the model used below is import tarfile import urllibrequest download and extract model modeldate 20200711 modelname modeltarfilename modelname targz modelsdownloadbase modeldownloadlink modelsdownloadbase modeldate modeltarfilename pathtomodeltar ospathjoinmodelsdir modeltarfilename pathtockpt ospathjoinmodelsdir ospathjoinmodelname checkpoint pathtocfg ospathjoinmodelsdir ospathjoinmodelname pipelineconfig if not printdownloading model this may take a while end pathtomodeltar tarfile tarfileclose printdone download labels file labelfilename mscocolabelmappbtxt labelsdownloadbase pathtolabels ospathjoinmodelsdir ospathjoinmodelname labelfilename if not printdownloading label file end import ssl labelfilename pathtolabels printdone load the model next we load the downloaded model 2 suppress tensorflow logging import tensorflow as tf from objectdetectionutils import labelmaputil from objectdetectionutils import visualizationutils as visutil from objectdetectionutils import visualizationutils as vizutils from import modelbuilder suppress tensorflow logging 2 enable gpu dynamic memory allocation gpus for gpu in gpus true load pipeline config and build a detection model configs modelconfig configsmodel detectionmodel istrainingfalse restore checkpoint ckpt ckpt0expectpartial tffunction def detectfnimage detect objects in image image shapes predictiondict shapes detections shapes return detections predictiondict tfreshapeshapes 1 load label map data for plotting label maps correspond index numbers to category names so that when our convolution network predicts 5 we know that this corresponds to airplane here we use internal utility functions but anything that returns a dictionary mapping integers to appropriate string labels would be fine categoryindex usedisplaynametrue define the video stream we will use opencv to capture the video stream generated by our webcam for more information you can refer to the opencvpython tutorials import cv2 cap cv2videocapture0 putting everything together the code shown below loads an image runs it through the detection model and visualizes the detection results including the keypoints note that this will take a long time several minutes the first time you run this code due to tffunctions tracecompilation on subsequent runs eg on new images things will be faster here are some simple things to try out if you are curious modify some of the input images and see if detection still works some simple things to try out here just uncomment the relevant portions of code include flipping the image horizontally or converting to grayscale note that we still expect the input image to have 3 channels print out and try to match the box locations to the boxes in the image notice that coordinates are given in normalized form ie in the interval 0 1 set minscorethresh to other values between 0 and 1 to allow more detections in or to filter out more detections import numpy as np while true read frame from camera ret imagenp capread expand dimensions since the model expects images to have shape 1 none none 3 imagenpexpanded npexpanddimsimagenp axis0 things to try flip horizontally imagenp npfliplrimagenpcopy convert image to grayscale imagenp nptile npmeanimagenp 2 keepdimstrue 1 1 3astypenpuint8 inputtensor 0 dtypetffloat32 detections predictionsdict shapes detectfninputtensor labelidoffset 1 imagenpcopy categoryindex maxboxestodraw200 minscorethresh30 agnosticmodefalse display output cv2imshowobject detection 800 600 if cv2waitkey25 0xff ordq break caprelease cv2destroyallwindows relevant log output shell traceback most recent call last file line 92 in from objectdetectionutils import labelmaputil file line 21 in from import stringintlabelmappb2 file line 36 in file line 561 in new typeerror descriptors cannot not be created directly if this call came from a pb2py file your generated code is out of date and must be regenerated with protoc 3190 if you cannot immediately regenerate your protos some other possible workarounds are 1 downgrade the protobuf package to 320x or lower 2 set but this will use purepython parsing and will be much slower more information"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTypeError: Cannot convert 0.1 to EagerTensor of dtype int64\nclick to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version 2120 custom code yes os platform and distribution googlecolab mobile device no response python version 31011 bazel version colab gcccompiler version colab cudacudnn version colab gpu model and memory colab current behaviour getting this error when i execute the code present in tensowflow website to implement error typeerror cannot convert 01 to eagertensor of dtype int64 python class def initself initiallearningrate initiallearningrate def callself step return step 1 optimizer standalone code to reproduce the issue shell typeerror cannot convert 01 to eagertensor of dtype int64 relevant log output typeerror traceback most recent call last in 7 return step 1 8 9 optimizer 4 frames in initself learningrate momentum nesterov weightdecay clipnorm clipvalue globalclipnorm useema emamomentum jitcompile name kwargs 121 kwargs 122 123 selflearningrate 124 selfmomentum momentum 125 selfnesterov nesterov in learningrate 382 create a variable to hold the current learning rate 383 currentlearningrate tfconverttotensor 384 385 386 tfvariable in callself step 5 6 def callself step 7 return step 1 8 9 optimizer in errorhandlerargs kwargs 151 except exception as e 152 filteredtb 153 raise from none 154 finally 155 del filteredtb in ctx dtype 101 dtype 102 ctxensureinitialized 103 return opseagertensorvalue ctxdevicename dtype 104 105 typeerror cannot convert 01 to eagertensor of dtype int64"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nunable to compile tensorflow c++ code using cmake \ni followed this steps 1 i cloned the repo 2 cd tensorflow 3 mkdir examples in examples folder i created helloworldcc file and cmakelisttxt this is cmakelisttxt file 380 projectexamples specify the path to the tensorflow source directory add the tensorflow source directory to the cmake module path listappend cmakemodulepath add the tensorflow include directories build the helloworld executable helloworldcc tensorflow after running the command cmake build config release i got this error fatal error c1083 cannot open include file tensorflowccclientcl ientsessionh no such file or directory 2 3 4 5"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nShuffle flag is true in make_dataset function\nclick to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version 20 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour just replicating an example of time series forecasting from link tsf there is a function makedataset which uses the function shuffle flag is set to true which is not allowed in time series forecasting standalone code to reproduce the issue shell def makedatasetself data data nparraydata dtypenpfloat32 ds datadata targetsnone sequencestride1 shuffletrue batchsize32 ds dsmapselfsplitwindow return ds makedataset relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBuilding from source with clang and nvcc?\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 211 custom code yes os platform and distribution debian gnulinux 10 mobile device no response python version 39 bazel version no response gcccompiler version gcc9clang12 cudacudnn version 113 gpu model and memory nvidia t4 current behaviour the docs say that tf 211 is supported with gcc 9 but clangllvm builds significantly faster how can i use bazel to at least try to build using clang and nvcc at the same time changing gcchostcompilerpath fails using my own crosstooltop with clang seems to work but im not sure if this ends up building the cuda kernels with clang as well standalone code to reproduce the issue shell from bazelrc build buildcuda repoenv tfneedcuda1 buildcuda buildcuda buildtfgpu actionenv buildtfgpu actionenv pythonlibpathbin buildtfgpu buildtfgpu actionenv buildtfgpu buildtfgpu actionenv tfcudaversion11 buildtfgpu actionenv tfcudnnversion8 buildtfgpu actionenv buildtfgpu actionenv buildtfgpu actionenv buildtfgpu actionenv buildtfgpu actionenv buildtfgpu actionenv buildtfgpu actionenv buildtfgpu actionenv buildtfgpu configcuda relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIssue when importing pix2pix in Google Colab\nhello i wanted to use pix2pix in google colab and here is the command i used to import it pip install git i also tried pip install q git but for both request i get this error looking in indexes collecting git cloning to running command git clone filterblobnone quiet resolved to commit error × python setuppy egginfo did not run successfully │ exit code 1 ╰─ see above for output note this error originates from a subprocess and is likely not a problem with pip preparing metadata setuppy error error × encountered error while generating package metadata ╰─ see above for output note this is an issue with the package mentioned above not pip hint see above for details could you please repair it best regards ps if there is any way for me to use pix2pix in an alternative way could you please indicate me on how to do it because i did not found an alternative"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGetting error with using coco-ssd model with the latest tensorflow\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 450 custom code yes os platform and distribution windows mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour when i try to use the netdetectframe it throws me error typeerror is not a function at backendcpujs991 at enginereadsync enginejs9431 at tensordatasync tensorjs2971 at dinfer even though i am using the latest tensorflow js libraries standalone code to reproduce the issue shell i am trying to use the cocossd model to do object detection in my packagejson i have 222 tensorflowtfjs 450 450 450 for some reasons i want to use the latest tensorflow libraries as my project uses other things also i have the following code const tf const tfcpubackend const tfwebglbackend const cocossd i have also set the tfsetbackendwebgl and tfready before cocossdload but when i try to use the netdetectframe it throws me error typeerror is not a function at backendcpujs991 at enginereadsync enginejs9431 at tensordatasync tensorjs2971 at dinfer even though i am using the latest tensorflow js libraries relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow does average pooling function work in TensorFlow?\nlet us assume a tensor like this x tfconstant1 2 3 4 5 6 7 8 9 to apply the average pooling function i will do this x tfreshapex 1 3 3 1 avgpool2d 2strides2 2 paddingsame avgpool2dx the result is tftensor shape1 2 2 1 dtypefloat32 numpy array3 45 75 9 dtypefloat32 i can follow the logic above 12454 3 362 45 782 75 91 9 i think the logic is the pooling filter is usually situated inside the tensor to perform the pooling operator but when the entire filter does not situate inside the tensor see the below figure for an example we need to specify the number of elements of the filter that are situated inside the tensor a the following figure illustrates the logic for a 4 by 3 tensor with pooling filter and stride sizes of 2 by 2 and padding the same image however it is not always like this for example suppose the following tensor y tfconstant1 2 3 4 5 6 7 8 9 10 then i do this y tfreshapey 1 2 5 1 avgpool2d 4strides4 4 paddingsame avgpool2dy the result is like this tftensor shape1 1 2 1 dtypefloat32 numpy array45 7 dtypefloat32 if i wanted to follow the logic for the first example i expected the result to be like this 123467898 5 5102 75 i am using tensorflow 280 what mistake am i making"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nxla_sharding in new version\nhi what is the replacement for from import xlasharding in tf2120 for example the function is xlashardingsplit"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWe don't have your exam ready right now \ni had purchased the tensorflow exam and tried to start it but it is showing that we dont have your exam ready right nowbut in the candidate portal it is showing resumeso i am gonna post the screenshot of my problem img width960 altscreenshot 20230428 114949 src"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnequal strides support recently removed for DepthwiseConv2D\nplease go to stack overflow for help and support if you open a github issue here is our policy 1 it must be a bug a feature request or a significant problem with the documentation for small docs fixes please send a pr instead 2 the form below must be filled out 3 it shouldnt be a tensorboard issue those go here heres why we have that policy tensorflow developers respond to issues we want to focus on work that benefits the whole community eg fixing bugs and adding features support only helps individuals github also notifies thousands of people when issues are filed we want them to see you communicating an interesting problem rather than being redirected to stack overflow system information have i written custom code as opposed to using a stock example script provided in tensorflow yes os platform and distribution eg linux ubuntu 1604 ubuntu mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device tensorflow installed from source or binary tensorflow version use command below 29 and 211 python version 38 bazel version if compiling from source gcccompiler version if compiling from source cudacudnn version 112 and 81 gpu model and memory exact command to reproduce import tensorflow as tf import numpy as np layer1 printlayer1npones100 28 28 1 dtypenpfloat32 you can collect some of this information using our environment capture script you can obtain the tensorflow version with bash python c import tensorflow as tf tfversionversion describe the problem describe the problem clearly here be sure to convey here why its a bug in tensorflow or a feature request the command would run without any error when i was using it with tf211 version installed previously on the newly installed tf29 version however the code throws an error as invalidargumenterror exception encountered when calling layer depthwiseconv2d1 type depthwiseconv2d functionnode current implementation only supports equal length strides in the row and column dimensions call arguments received by layer depthwiseconv2d1 type depthwiseconv2d • 28 28 1 dtypefloat32 seeing the documentation the error is expected for version 212 but should work for versions 29 and 211 is it that the implementation existing in the earlier versions has been removed recently for all previous and current versions source code logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached try to provide a reproducible test case that is the bare minimum necessary to generate the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndata and ml module missing\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source source tensorflow version 2 custom code no os platform and distribution mac mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour a bug happened standalone code to reproduce the issue shell from data import bodypart from ml import movenet relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTraining data format for EfficientNet\ni would like to train a efficientnetb7 model from scratch to classify 2d arrays into two 2 classes but it seems like i did not prepare my data in the correct format currently my xtrain is a list of float64 arrays with a 600x600 size my ytrain is a list of integers that are either 0 or 1 of course xtrain and ytrain have the same length this is what i have so far from import dense flatten from import efficientnetb7 from import sequential basemodel weightsnone inputshape6006001 classes2 basemodeltrainable true model sequential modeladdbasemodel modeladdflatten modeladddense1 activationsigmoid metricsaccuracy history modelfitxtrain ytrain batchsize8 epochs100 the last line currently gives me an error valueerror failed to find data adapter that can handle input containing values of types containing values of types what would be the right format for training data any help is appreciated"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIssue with obtaining files from this repo via Google Colab\nscreenshot 20230414 162503"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntf.GradientTape.gradients() does not support graph control flow operations like tf.cond or tf.while at this time. Use tf.gradients() instead\nplease go to stack overflow for help and support if you open a github issue here is our policy 1 it must be a bug a feature request or a significant problem with the documentation for small docs fixes please send a pr instead 2 the form below must be filled out 3 it shouldnt be a tensorboard issue those go here heres why we have that policy tensorflow developers respond to issues we want to focus on work that benefits the whole community eg fixing bugs and adding features support only helps individuals github also notifies thousands of people when issues are filed we want them to see you communicating an interesting problem rather than being redirected to stack overflow system information have i written custom code as opposed to using a stock example script provided in tensorflow os platform and distribution eg linux ubuntu 1604 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device tensorflow installed from source or binary tensorflow version use command below python version bazel version if compiling from source gcccompiler version if compiling from source cudacudnn version gpu model and memory exact command to reproduce you can collect some of this information using our environment capture script you can obtain the tensorflow version with bash python c import tensorflow as tf tfversionversion describe the problem describe the problem clearly here be sure to convey here why its a bug in tensorflow or a feature request source code logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached try to provide a reproducible test case that is the bare minimum necessary to generate the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTensorflow Lite library is crashing in WASM library at 3rd inference\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 270 custom code yes os platform and distribution emscripten ubuntu 1804 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell hello i have c code that i want to deploy as wasm library and this code contains tflite library i have compiled tflite library with xnnpack support using emscripten toolchain quite easy so no issue there i have a leightweight convolutiondense model that runs perfectly on desktop but i am starting having problems in the browser in 99 of cases i have an error on the third inference uncaught runtimeerror memory access out of bounds through some trivial debugging i have found out that the issue comes from interpreterinvoke method does not matter if i put any input or not i just need to call invoke three times and i have a crash first thing first i decided to add more memory to my wasm library by adding this line to cmake setcmakecxxflags cmakecxxflags s totalstack134217728 s totalmemory268435456 setcmakecxxflags cmakecxxflags s totalstack134217728 s totalmemory268435456 128 mb and 256 mb in total for 1 mb model i think this is more than enough and on top of that i am allowing memory growth but unfortunately i have exactly the same issue i am beating on this problem for 2 weeks straight and at this stage i have no clue how to fix it also i have tried to set custom allocation using but in this case i have a crash on the very first inference i guess i was not using it right but unfortunately i couldnt find even one tutorial describing how to apply custom allocation in tflite i said that i have a crash in 99 of cases there was one time when wasm library worked and inference worked as well it happens just randomly once and i couldnt reproduce it anymore standalone code to reproduce the issue shell here is the code that does tflite inference include include tflitemodelh include include include tensorflowliteutilh namespace tracker ifdef emscripten void stream stdstring imgstr streamstr stdvector stdcopyimgstrbegin imgstrend imgmodeldatabegin model imgstrsize else void tflitemodelinitconst stdstring path model endif resolver resolverinterpreter for int i 0 i tensorssize i tflitetensor tensor interpretertensori if tensorallocationtype ktflitearenarw tensorallocationtype int alignedbytes tensorbytes tensorbytes customalloc int result tensorbytes if result 0 customallocdata null stdcout posixmemalign does not workn tflitestatus st customalloc stdcout status st stdendl if tensorbytes 0 stdcout bytes stdendl exit0 void cvmat imginput const stdvector lmsinput float modelin stdmemcpymodelin imginputdata imginputtotal imginputelemsize float lmsin stdmemcpylmsin lmsinputdata sizeoffloat lmsinputsize interpreterinvoke float tflitemodelout return stdvector const tflitetensor outtensor tfliteintarray dims outtensordims stdvector sh for int i 0 i size i shpushbackdimsdatai return sh relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to evaluate a pretrained TF mobilenet_v2 saved_model for accuracy on test dataset\nsystem information have i written custom code as opposed to using a stock example script provided in tensorflow no os platform and distribution eg linux ubuntu 1604 ubuntu 2004 tensorflow installed from source or binary binary tensorflow version use command below211 python version 39 describe the problem how can i use a pretrained savedmodel and find its accuracy on a test dataset i have mobilenetv2 saved model which is sourced from i have an imagenet validation dataset consisting of 50000 images and a labelstxt file consisting of ground truth labels for those 50000 images i also have imagenetlabelstxt sourced from consisting of 1001 imagenet classes how do i preprocess this data so that i can run evaluate function to find testdata loss and accuracy of this pretrained model i am currently using the below script but it doesnt seem to work import tensorflow as tf import tensorflowhub as hub import numpy as np import os m outputshape1001 mbuildnone 224 224 3 batch input shape images classes labels homedocumentsvaltxt with openlabels r as f labelname linestrip for line in freadlines classmap with openclasses r as f classes linestrip for line in f for i classname in enumerateclasses classmapclassname i testlabels for label in labelname if label in classmap else printflabel label not found in classmap imagepaths ospathjoinimages filename for filename in oslistdirimages dataset testlabels def image image channels3 image tfimageresizeimage 224224 image tffloat32 image 2550 return image dataset datasetmaplambda imagepath label label dataset optimizerrmsprop metricsaccuracy loss accuracy mevaluatedataset printloss loss printaccuracy accuracy i get the below error here traceback most recent call last file test1234py line 74 in loss accuracy mevaluatedataset file line 70 in errorhandler raise from none file line 15 in tftestfunction retval agldself aglditerator none fscope valueerror in user code file line 1820 in testfunction return stepfunctionself iterator file line 1804 in stepfunction outputs argsdata file line 1792 in runstep outputs modelteststepdata file line 1758 in teststep selfcomputelossx y ypred sampleweight file line 1082 in computeloss return selfcompiledloss file line 265 in call lossvalue lossobjyt yp sampleweightsw file line 152 in call losses callfnytrue ypred file line 284 in call return agfnytrue ypred selffnkwargs file line 2004 in return file line 5532 in valueerror shapes none 1 and none 1001 are incompatible i assume something is wrong in the way i preprocess my data though but not sure how to go about it some insights would be nice thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDocs do not mention discontinuation of support for Python 3.7 in TF 2.11.1\nclick to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version tf 2111 custom code no os platform and distribution no response mobile device no response python version 37 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell the release notes for tensorflow 2120 state that support for python 37 has been discontinued however it seems that python 37 support has also been removed from tensorflow 2111 despite this not being mentioned in the release notes or documentation as a result to maintain compatibility we were forced to limit our application to using tensorflow 2110 standalone code to reproduce the issue shell na relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nJVP using tf.autodiff.ForwardAccumulator becomes None under graph execution\nim new to tensorflow im trying to compute a jacobianvector product using with a train function looks something like the code below the jvp looks fine under eager execution however the jvp becomes a list of nones when activate graph execution using tffunction what could be the issue here tensorflow version tf 260 python version 37 train code shell tffunction def trainself data with tfgradienttape as uppertape loss1 selfloss1data grad1 selfnet1variables with tangentsgrad1 as acc with tfgradienttape as lowertape loss2 selfloss2data grad2 selfnet2variables finalgrad accjvpgrad2 selfnet2variables grad1 and grad2 are correctly computed under both eager mode and graph mode the only problem is with the jvp"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nspam removed\nplease go to stack overflow for help and support if you open a github issue here is our policy 1 it must be a bug a feature request or a significant problem with the documentation for small docs fixes please send a pr instead 2 the form below must be filled out 3 it shouldnt be a tensorboard issue those go here heres why we have that policy tensorflow developers respond to issues we want to focus on work that benefits the whole community eg fixing bugs and adding features support only helps individuals github also notifies thousands of people when issues are filed we want them to see you communicating an interesting problem rather than being redirected to stack overflow system information have i written custom code as opposed to using a stock example script provided in tensorflow os platform and distribution eg linux ubuntu 1604 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device tensorflow installed from source or binary tensorflow version use command below python version bazel version if compiling from source gcccompiler version if compiling from source cudacudnn version gpu model and memory exact command to reproduce you can collect some of this information using our environment capture script you can obtain the tensorflow version with bash python c import tensorflow as tf tfversionversion describe the problem describe the problem clearly here be sure to convey here why its a bug in tensorflow or a feature request source code logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached try to provide a reproducible test case that is the bare minimum necessary to generate the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBuild TensorFlow Lite for iOS failed!!!!\nplease go to stack overflow for help and support if you open a github issue here is our policy 1 bazel build configiosarm64 c opt cxxoptstdc17 ❯ bazel build verbosefailures configiosarm64 c opt info options provided by the client inherited common options isatty1 terminalcolumns170 info reading rc options for build from inherited common options info reading rc options for build from build options define define c opt announcerc definegrpcnoarestrue configshortlogs configv2 info reading rc options for build from build options actionenv actionenv info reading rc options for build from build options info found applicable config definition buildshortlogs in file info found applicable config definition buildv2 in file definetfapiversion2 info found applicable config definition buildiosarm64 in file configios cpuiosarm64 info found applicable config definition buildios in file appleplatformtypeios applebitcodeembedded coptfembedbitcode coptwnoc11narrowing coptw cxxoptstdc17 hostcxxoptstdc17 info build option cxxopt has changed discarding analysis cache error in cctoolchainsuite rule cctoolchainsuite does not contain a toolchain for cpu iosarm64 error analysis of target failed error analysis of target failed build aborted info elapsed time 45455s info 0 processes failed build did not complete successfully 66 packages loaded 1118 targets configured heres why we have that policy tensorflow developers respond to issues we want to focus on work that benefits the whole community eg fixing bugs and adding features support only helps individuals github also notifies thousands of people when issues are filed we want them to see you communicating an interesting problem rather than being redirected to stack overflow system information macosm1max 133 tensorflow292 python 3100 describe the problem describe the problem clearly here be sure to convey here why its a bug in tensorflow or a feature request source code logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached try to provide a reproducible test case that is the bare minimum necessary to generate the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nThread-safety for `tensorflow::Tensor`\nclick to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version 2110 custom code yes os platform and distribution debian gnulinux 10 mobile device no response python version 39 bazel version 610 gcccompiler version llvm 12 cudacudnn version 116 gpu model and memory t4 current behaviour shell are there any methods on tensorflowtensor objects that are threadsafe specifically any of subslice flat unalignedflat shaped standalone code to reproduce the issue shell stdvector output mutex mu bool ready false void eval output tensordatatypedthalf 2 16 one entry per thread nnevaluatorinfer output mulock ready true muunlock void readresultint threadid mulock muunlock can we read tensor result now auto res return res0 relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIf we have any detail information of each CI in tensorflow Github? \nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell hello i have been studying the actions ci of various open source projects on github recently i noticed that tensorflowhas a wellestablished ci so i would like to further understand its composition and structure do you have any relevant materials that i can study and refer to thank you very much standalone code to reproduce the issue shell none relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPlot training and validation losses of object detection model \nhello i am using the following notebook to train my dataset with efficientdetlite0 model i can see for each epoch we get the information of training loss loss and validation loss valloss i would like to plot them like loss modelhistoryloss valloss modelhistoryvalloss pltplotloss labeltraining loss pltplotvalloss labelvalidation loss pltlegendlocupper right pltylabelcross entropy pltylim010 plttitletraining and validation loss pltxlabelepoch pltshow and unfortunately getting the following error attributeerror objectdetector object has no attribute history can you help me to figure out how to plot training and validation losses on the same graph thanks in advance"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nType INT32 (2) not supported.Node ADD (number 0) failed to invoke with status 1.Node WHILE (number 10) failed to invoke with status 1\nsystem information os platform window10 tensorflow installed from source or binary pip tensorflow version or github sha if from source233 board arduino nano 33 ble sense i tried to run tensorflow lite for microcontrollers with arduino nano 33 ble sense the model is my custom lstm and the result type int32 2 not supportednode add number 0 failed to invoke with status 1node while number 10 failed to invoke with status 1invoke failed but it has output values model1 tflite"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to find accuracy of a pretrained tflite model\nsystem information have i written custom code as opposed to using a stock example script provided in tensorflow no os platform and distribution eg linux ubuntu 1604 ubuntu 2004 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device none tensorflow installed from source or binary binary tensorflow version use command below v211 python version 39 describe the problem i have a pretrained tf mobilenetv2 model downloaded from tfhub which i converted to tflite using tflite interpreter converter the original model was trained on imagenet dataset but i want to find out the accuracy of the converted tflite model how do i do that as of now the eval function is specific to models generated from modelmaker what is the best way to find the model accuracy thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to benchmark TFLite object detection model\nit seems that only classification models can be benchmarked there is no explanation for how to run benchmarking on tflite object detection models under could anybody point me into the right direction to get the modifications needed to run the tflite benchmark on my custom tflite object detection model after running bash ➜ tensorflow gitmaster adb shell am start s n es args numthreads4 when i check logcat bash ➜ tensorflow gitmaster adb logcat grep inference timings in us i see shell 0315 140051294 12836 12836 i tflite inference timings in us init 36618 first inference 1530248 warmup avg 153025e06 inference avg 149712e06 0315 141343409 13393 13393 i tflite inference timings in us init 33412 first inference 307818 warmup avg 297955 inference avg 333826 basically my model inference fails and it falls back onto the classification model click to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version 2110 custom code no os platform and distribution linux ubuntu 1804 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour standalone code to reproduce the issue shell the app falls back onto the classification model once the object detection one fails 0315 140051294 12836 12836 i tflite inference timings in us init 36618 first inference 1530248 warmup avg 153025e06 inference avg 149712e06 0315 141343409 13393 13393 i tflite inference timings in us init 33412 first inference 307818 warmup avg 297955 inference avg 333826 relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTypeError: VariableMetaclass._variable_v1_call() got an unexpected keyword argument 'experimental_enable_variable_lifting'\nclick to expand issue type support have you reproduced the bug with tf nightly no source binary tensorflow version 2120rc1 custom code no os platform and distribution windows 10 mobile device no response python version 311 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell selfmodel kerassequential file line 205 in methodwrapper result methodself args kwargs file line 70 in errorhandler raise from none file line 285 in call return kwargs typeerror got an unexpected keyword argument standalone code to reproduce the issue shell selfmodel kerassequential keraslayersdense1 inputdimselfdegree keraslayersdense1 lossloss selfmodelsummary relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nResource exhausted error during training\nresource exhausted error during training i would like to train the deep learning task semantic segmentation specifications model with 31 million parameters image size minimum 1024x1024 batch size 256 framework tensorflow keras 27 total image samples 30000 label mask samples 30000 does colab pro plus allow the training for this specification with out oom error issue currently facing is even with 2000 number of images and 512x512 size for batch size 32 results in out of memory error in colab pro subscription"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`Unsupported object type numpy.ndarray` on multi-input `Dataset`\nclick to expand issue type support have you reproduced the bug with tf nightly no source binary tensorflow version 2110 custom code yes os platform and distribution kaggle kernel mobile device no response python version 3712 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell im trying to return tuple to a dataset to be used in a multiinput model but its throwing an error saying unsupported object type numpyndarray previosuly i was setting shape with setshape but right now i simply dont know how to set shape for a different input shape standalone code to reproduce the issue shell def readimagepath rel blah blah blah read somehow return image def readimage1path1 filter0 blah blah blah read somehow return image def preprocessx y def funcx y x jsonloadsx ximg1 readimagexpath xrel 3d image ximg2 readimagexpathfork xfilter 2d image with different shape image resizing will lose data y todo yeah ill optimize it never return ximg1 ximg2 y x y tfnumpyfunctionfunc x y tffloat32 tffloat32 xsetshape256 256 3 previously i used to do this ysetshape10 return x y here x is an array of string and those strings are actually jsondictionary def tfdatasetxy batch16 dataset y dataset dataset datasetmappreprocess dataset datasetbatchbatch dataset datasetprefetch16 return dataset relevant log output shell internalerror graph execution error unsupported object type numpyndarray node pyfunc iteratorgetnext here is what im trying to do multi input model with tfdatadataset"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFailing to run hexagon delegates on android\nclick to expand issue type support have you reproduced the bug with tf nightly no source binary tensorflow version 2100 custom code yes os platform and distribution windows 10 mobile device qcs6125 python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell problem with hexagon delegates the hexagon libs from hexagon delegates page are set into arm64v8a folder cpu architecture 8 adb shell getprop roboardplatform trinket adb shell getprop roproductdevice trinket standalone code to reproduce the issue shell implementation implementation running tensorflow example from quickstart for android relevant log output shell tflite failed to fetch hexagon nn version this might be because youre using incompatible versions of libhexagoninterface and libhexagonnnskel you must use compatible versions refer to tensorflow lite hexagon delegate guide"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTensorflow Import error\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 210 custom code yes os platform and distribution no response mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i cannot import the tensorflow package in my jupyter notebook i have checked the installations in conda and pip but everything seems to work so whenever i try to import it i get the following error importerror traceback most recent call last file line 62 in from import importerror dll load failed while importing a dynamic link library dll initialization routine failed is it a problem of the environment or a problem with package itself i am starting now to study dl so i would appreciate a lot a quick response thank you standalone code to reproduce the issue shell import tensorflow as tf relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRunning tensorflow distributed on Multiple workers\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 26 custom code yes os platform and distribution linux hpc mobile device no response python version 383 bazel version no response gcccompiler version no response cudacudnn version 1131 gpu model and memory 4 rtx 2080 ti workers each having 8 gpus current behaviour shell i am trying to run tensorflow distributed training code on multiple worker nodes i initially tried it using the mirrored strategy using a single worker with multiple gpus and the code was working fine and the training process was getting distributed among multiple gpus when i have tried it with multiple worker nodes the training process is actually executing seperately on different workers rather than the load getting distributed among the workers my linux systems has 4 worker nodes with each node having 8 2080ti gpus and the gpus are connected through pcie system i also not sure how to configure the tfconfig can anyone help me on this standalone code to reproduce the issue shell if name main get mpi rank from getonehot import getonehot from mpi4py import mpi comm mpicommworld rank commgetrank load in the parameter files from json import load as loadf with openparamsjson r as infile params loadfinfile get data files and prep them for the generator import tensorflow from tensorflow import distribute as d callbacks devices getdevices printdevices settfconfigmpi strat create network from sys import argv resumetraining false printargv if resumelatest in argv resumetraining true with stratscope scheduler if str get the string for the importable function lr paramslearningrate from import use a dummy learning rate paramslearningrate 01 model createmodelparams get the importable function lr lrsplit baseimport importlr0 globals locals lr1 0 lr getattrbaseimport lr1 make a schedule lr callbacksappendlr resume model modelname none if resumetraining initialepoch modelname if modelname is none initialepoch0 model createmodelparams resumetraining false else from import loadmodel model loadmodelmodelname load data from disk import numpy if root in paramskeys root paramsroot else root if filename in paramskeys filename paramsfilename else filename restricted euc1 e1 x1 y1 z1 euc2 e2 x2 y2 z2 euc3 e3 x3 y3 z3 x y getonehotformatroot filename restrictedrestricted params valfilename valx valy getonehotformatroot valfilename restrictedrestricted valx valy none none paramsgbatchsize paramsbatchsize lendevices printxshape xshape printyshape yshape printepochs paramsepochs typeparamsepochs printbatch paramsbatchsize typeparamsbatchsize printgbatch paramsgbatchsize typeparamsgbatchsize load data into a distributed dataset dataset object does nothing in place from tensorflowdata import dataset data y create validation set v paramsvalidation if valx is not none vrecord valxshape0 val valy validation val datatakevrecord else vrecord intxshape0v validation datatakevrecord validation validation validation need to do kfold one day this set should not be distributed vsteps vrecord paramsgbatchsize if vrecord paramsgbatchsize 0 vsteps 1 data data records xshape0 vrecord steps records paramsgbatchsize if records paramsgbatchsize steps 1 printsteps steps note that if we are resuming that the number of remaining epochs has changed the number of epochs steps is the numbers of samples to drop printinitial cardinality datacardinality printinitial v cardinality datacardinality data validation printfinal cardinality datacardinality printfinal v cardinality datacardinality data split into validation and training callbacks callbacks rank resumetraining printcallbacks printfitting model printdata import tensorflow as tf options tfdataoptions traindata valdata history modelfittraindata epochsparamsepochs stepsperepochsteps verbose0 callbackscallbacks printfitting model done if rank 0 modelsavemodelfinal else slurm script binbash sbatch jobnamejob1 job name sbatch mem30000 job memory request sbatch gresgpu4 number of requested gpus sbatch time3230000 time limit dayshrsminsec sbatch constraintrtx2080 specific hardware constraint sbatch errorslurmerr error file name sbatch outputslurmout output file name sbatch nodes2 sbatch ntaskspernode1 sbatch cpuspertask1 sbatch array121 if d modelfinal then scancel slurmarrayjobid else module load anaconda3202007 module load mpirun python u mainpy resumelatest fi relevant log output shell i log each and every epoch in a csv file i see two csv files created and each one has different workers running"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTensorflow grad\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source source tensorflow version tf 2x custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell hi if i want to slimming network standalone code to reproduce the issue shell i want to ask how i can get the gradient value of each iteration in the model training process relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow static library of windows: missing few files\nplease go to stack overflow for help and support if you open a github issue here is our policy 1 it must be a bug a feature request or a significant problem with the documentation for small docs fixes please send a pr instead 2 the form below must be filled out 3 it shouldnt be a tensorboard issue those go here heres why we have that policy tensorflow developers respond to issues we want to focus on work that benefits the whole community eg fixing bugs and adding features support only helps individuals github also notifies thousands of people when issues are filed we want them to see you communicating an interesting problem rather than being redirected to stack overflow system information have i written custom code as opposed to using a stock example script provided in tensorflow its tensorflow provided code as given in os platform and distribution eg linux ubuntu 1604 windows 10 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device laptop tensorflow installed from source or binary static library from tensorflow version use command below 211 python version na bazel version if compiling from source na gcccompiler version if compiling from source 122 cudacudnn versionna gpu model and memory na exact command to reproduce took static library from tensorflow ebsite from link below have taken windows version of cpu version unzipped and created hellotfc as mentioned in same webpage compiled the hellotfc as below gcc hellotfc i o hellotf got error as in file included from hellotfc2 fatal error tensorflowctfbufferh no such file or directory 23 include tensorflowctfbufferh compilation terminated then took tfbufferh from github repo to see if the error is only dependent on tfbufferh but then got another error dtensorflowlibgcc hellotfc i o hellotf in file included from from from hellotfc2 fatal error no such file or directory 19 include compilation terminated you can collect some of this information using our environment capture script you can obtain the tensorflow version with bash python c import tensorflow as tf tfversionversion describe the problem describe the problem clearly here be sure to convey here why its a bug in tensorflow or a feature request took static library from tensorflow ebsite from link below have taken windows version of cpu version unzipped and created hellotfc as mentioned in same webpage compiled the hellotfc as below gcc hellotfc i o hellotf got error as in file included from hellotfc2 fatal error tensorflowctfbufferh no such file or directory 23 include tensorflowctfbufferh compilation terminated then took tfbufferh from github repo to see if the error is only dependent on tfbufferh but then got another error dtensorflowlibgcc hellotfc i o hellotf in file included from from from hellotfc2 fatal error no such file or directory 19 include compilation terminated source code logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached try to provide a reproducible test case that is the bare minimum necessary to generate the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhat is the final training result of asynchronous synchronous parallel distributed training？\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version tf28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell when distributed training adopts asynchronous synchronous parallel the parameters updated by each worker are inconsistent is the final result of distributed training the slowest parameter updated by workers standalone code to reproduce the issue shell when distributed training adopts asynchronous synchronous parallel the parameters updated by each worker are inconsistent is the final result of distributed training the slowest parameter updated by workers relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\nclick to expand issue type support have you reproduced the bug with tf nightly no source binary tensorflow version 211 custom code yes os platform and distribution ubuntu 22041 lts mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell the warning appears warningabslfound untraced functions such as while saving showing 5 of 6 these functions will not be directly callable after loading can you please explain what is meant by this warning and how to fix it i have the following accompanying questions to it function traces are basically graph representations of functions or something else if these jit traces are not found in a loaded model will they be generated again is model compilation needed for regeneration are these functions needed only for training or also for predictionevaluation i have found in keras docs that i can disable saving the traces with the following note disabling this will decrease serialization time and reduce file size but it requires that all custom layersmodels implement a getconfig method why would the getconfig method be only needed when i disable saving the traces thanks in advance for any explanations given shell reproducer its not my code but the warnings appear eg here relevant log output warningabslfound untraced functions such as while saving showing 5 of 6 these functions will not be directly callable after loading"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to use exported automl tensorflow model for tabular data in Python\nclick to expand issue type support have you reproduced the bug with tf nightly no source binary tensorflow version 29 custom code yes os platform and distribution linux ubuntu mobile device no response python version 37 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell hello i followed the instructions from google cloud to export and load a trainen automl model training was done with data from bigquery as we want to integrate this model in our spark flow i need to load it and make predictions on it in python directly i tested the model with the tensorflow serving docker image as described in the documentation this works perfectly fine however when i try to use the model directly i get an erro error dataloss failed skipping unrequested field input must be a string tensor i tried several formats json csv but none of them seemed to be correct can anybody give me a hint on how to convert the tabular data into a string tensor in a way that the model accepts the data and returns a prediction thanks in advance kay standalone code to reproduce the issue shell import struct2tensor import tensorflow as tf import json import requests modelpath predictsample animals 00 apparel 00165423884627339 arts 0000893240417492657 baby 00 business 00 cameras 0000158694043359865 electronics 00 food 64749054130615e05 furniture 00 hardware 0000247099237409669 health 000928790329794604 home 00442892335578687 luggage 365980448833796e05 mature 00 media 070324946112978 office 0000297127488105344 religious 00 software 00 sporting 00 toys 00 vehicles 725524348202571e06 aovbench 598599307847218 aovrep 0 avgprice 12704623853211 bouncerate 8106 brandsearchvolume 0 00 category adult competition 00 cpc 00 crbench 000972125074728272 date 20220801 directshare 4079 displayshare 00 domaincat1 0 domaincat2 0 00 domainsearchvolume 0 ekpsaov 26859908543707 ekpscr 00194748958674429 iibbench 104867824234893 int64field0 1 lineid 1 mailshare 00 maincountry germany maincountryshare 8425 nocat 0224926250022808 organicshare 5766 pageviews 174154466250536 paidsearchshare 00 request to tensorflowserving docker container works perfectly response requestspost jsoninstances predictsample prints predictions 00056517720222473145 printresponsetext model infer no matter what i tried as input here i always get error error consuming error dataloss failed skipping unrequested field to feed model with one string tensor relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTFlite minimal example failing on latest tensorflow repo\nwhen i run latest tensorflow lite example minimal and it is failing on linux machine with the below error followed steps mentioned here and ran on x8664 gnulinux 100 linking cxx executable minimal usrbinld in function registercctext0x1cd undefined reference to usrbinld registercctext0x1ed undefined reference to usrbinld registercctext0x207 undefined reference to usrbinld registercctext0x227 undefined reference to usrbinld registercctext0x241 undefined reference to usrbinld registercctext0x25b undefined reference to usrbinld registercctext0x27b undefined reference to usrbinld registercctext0x29b undefined reference to usrbinld registercctext0x2bb undefined reference to usrbinld registercctext0x2db undefined reference to usrbinld registercctext0x2fb undefined reference to usrbinld registercctext0x315 undefined reference to usrbinld registercctext0x335 undefined reference to usrbinld registercctext0x355 undefined reference to usrbinld registercctext0x375 undefined reference to usrbinld registercctext0x395 undefined reference to usrbinld registercctext0x3b5 undefined reference to usrbinld registercctext0x3d5 undefined reference to usrbinld registercctext0x3f5 undefined reference to usrbinld registercctext0x40f undefined reference to usrbinld registercctext0x42f undefined reference to usrbinld registercctext0x449 undefined reference to usrbinld registercctext0x463 undefined reference to usrbinld registercctext0x483 undefined reference to usrbinld registercctext0x4a3 undefined reference to usrbinld registercctext0x4c0 undefined reference to usrbinld registercctext0x4e0 undefined reference to usrbinld registercctext0x500 undefined reference to usrbinld registercctext0x520 undefined reference to usrbinld registercctext0x540 undefined reference to usrbinld registercctext0x55a undefined reference to usrbinld registercctext0x57a undefined reference to usrbinld registercctext0x59a undefined reference to usrbinld registercctext0x5ba undefined reference to usrbinld registercctext0x5da undefined reference to usrbinld registercctext0x5fa undefined reference to usrbinld registercctext0x614 undefined reference to usrbinld registercctext0x634 undefined reference to usrbinld registercctext0x654 undefined reference to usrbinld registercctext0x66e undefined reference to usrbinld registercctext0x68e undefined reference to usrbinld registercctext0x6ae undefined reference to usrbinld registercctext0x6ce undefined reference to usrbinld registercctext0x6ee undefined reference to usrbinld registercctext0x70e undefined reference to usrbinld registercctext0x72e undefined reference to usrbinld registercctext0x74e undefined reference to usrbinld registercctext0x76e undefined reference to usrbinld registercctext0x78e undefined reference to usrbinld registercctext0x7ae undefined reference to usrbinld registercctext0x7ce undefined reference to usrbinld registercctext0x7e8 undefined reference to usrbinld registercctext0x808 undefined reference to usrbinld registercctext0x822 undefined reference to usrbinld registercctext0x842 undefined reference to usrbinld registercctext0x862 undefined reference to usrbinld registercctext0x882 undefined reference to usrbinld registercctext0x89c undefined reference to usrbinld registercctext0x8bc undefined reference to usrbinld registercctext0x8dc undefined reference to usrbinld registercctext0x8fc undefined reference to usrbinld registercctext0x91c undefined reference to usrbinld registercctext0x93c undefined reference to usrbinld registercctext0x95c undefined reference to usrbinld registercctext0x97c undefined reference to usrbinld registercctext0x99c undefined reference to usrbinld registercctext0x9b6 undefined reference to usrbinld registercctext0x9d0 undefined reference to usrbinld registercctext0x9ea undefined reference to usrbinld registercctext0xa04 undefined reference to usrbinld registercctext0xa24 undefined reference to usrbinld registercctext0xa3e undefined reference to usrbinld registercctext0xa5e undefined reference to usrbinld registercctext0xa78 undefined reference to usrbinld registercctext0xa92 undefined reference to usrbinld registercctext0xab2 undefined reference to usrbinld registercctext0xad2 undefined reference to usrbinld registercctext0xaf2 undefined reference to usrbinld registercctext0xb12 undefined reference to usrbinld registercctext0xb32 undefined reference to usrbinld registercctext0xb52 undefined reference to usrbinld registercctext0xb6c undefined reference to usrbinld registercctext0xb86 undefined reference to usrbinld registercctext0xba0 undefined reference to usrbinld registercctext0xbc0 undefined reference to usrbinld registercctext0xbe0 undefined reference to usrbinld registercctext0xc00 undefined reference to usrbinld registercctext0xc1a undefined reference to usrbinld registercctext0xc3a undefined reference to usrbinld registercctext0xc54 undefined reference to usrbinld registercctext0xc6e undefined reference to usrbinld registercctext0xc88 undefined reference to usrbinld registercctext0xca8 undefined reference to usrbinld registercctext0xcc8 undefined reference to usrbinld registercctext0xce2 undefined reference to usrbinld registercctext0xcfc undefined reference to usrbinld registercctext0xd16 undefined reference to usrbinld registercctext0xd30 undefined reference to usrbinld registercctext0xd50 undefined reference to usrbinld registercctext0xd70 undefined reference to usrbinld registercctext0xd8a undefined reference to usrbinld registercctext0xda4 undefined reference to usrbinld registercctext0xdbe undefined reference to usrbinld registercctext0xdd8 undefined reference to usrbinld registercctext0xdf8 undefined reference to usrbinld registercctext0xe18 undefined reference to usrbinld registercctext0xe38 undefined reference to usrbinld registercctext0xe58 undefined reference to usrbinld registercctext0xe72 undefined reference to usrbinld registercctext0xe92 undefined reference to usrbinld registercctext0xeac undefined reference to usrbinld registercctext0xecc undefined reference to usrbinld registercctext0xeec undefined reference to usrbinld registercctext0xf06 undefined reference to usrbinld registercctext0xf20 undefined reference to usrbinld registercctext0xf3a undefined reference to usrbinld registercctext0xf5a undefined reference to usrbinld registercctext0xf74 undefined reference to usrbinld registercctext0xf8e undefined reference to usrbinld registercctext0xfa8 undefined reference to usrbinld registercctext0xfc2 undefined reference to usrbinld registercctext0xfdc undefined reference to usrbinld registercctext0xff6 undefined reference to usrbinld registercctext0x1010 undefined reference to usrbinld registercctext0x102a undefined reference to usrbinld registercctext0x104a undefined reference to usrbinld registercctext0x1064 undefined reference to usrbinld registercctext0x1084 undefined reference to usrbinld registercctext0x109e undefined reference to usrbinld registercctext0x10b8 undefined reference to usrbinld registercctext0x10d2 undefined reference to usrbinld registercctext0x10ec undefined reference to usrbinld registercctext0x1106 undefined reference to usrbinld registercctext0x1120 undefined reference to usrbinld registercctext0x113a undefined reference to usrbinld registercctext0x1154 undefined reference to usrbinld registercctext0x116e undefined reference to usrbinld registercctext0x1188 undefined reference to usrbinld registercctext0x11a2 undefined reference to usrbinld registercctext0x11bc undefined reference to usrbinld registercctext0x11d6 undefined reference to usrbinld registercctext0x11f0 undefined reference to usrbinld registercctext0x120a undefined reference to usrbinld registercctext0x1224 undefined reference to usrbinld registercctext0x123e undefined reference to usrbinld registercctext0x1258 undefined reference to usrbinld registercctext0x1272 undefined reference to usrbinld registercctext0x1292 undefined reference to usrbinld registercctext0x12ac undefined reference to usrbinld registercctext0x12c6 undefined reference to usrbinld registercctext0x12e0 undefined reference to usrbinld registercctext0x12fa undefined reference to usrbinld registercctext0x1314 undefined reference to usrbinld registercctext0x132e undefined reference to usrbinld registercctext0x134e undefined reference to usrbinld registercctext0x136a undefined reference to usrbinld registercctext0x1386 undefined reference to usrbinld registercctext0x13a2 undefined reference to usrbinld in function undefined reference to usrbinld undefined reference to collect2 error ld returned 1 exit status gmake2 minimal error 1 gmake1 error 2 gmake makefile136 all error 2"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOn MTK platforms, tflite calls the GPU with clGetPlatformIDs return -1001\nsystem information android device information use adb shell getprop robuildfingerprint if possible tensorflow lite in play services sdk version found in buildgradle 29 google play services version settings apps google play services app details standalone code to reproduce the issue on mtk platforms code if ktfliteok logedelegate init failed exit1 get clgetplatformids returned 1001 or clgetplatformids returned 30 any other info logs this mtk platform has a gpu device"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to create `tf.keras.layers.Input` without batch_size dimension?\nclick to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version 291 custom code no os platform and distribution centos7 mobile device no response python version 3814 bazel version 50 gcccompiler version 102 cudacudnn version 114 gpu model and memory a30 current behaviour one input of my model has nothing to do with batchsize for example its shape is 123 how to avoid automatically adding 1 dimension when creating tfkeraslayersinput if i manually slice it the slice operator will be introduced resulting in a decrease in inference performance standalone code to reproduce the issue shell import tensorflow as tf x xshape none 32 64 x x0 xshape 32 64"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ngraph execution error\nim facing an issue that says graph execution error tried to solve it but couldnt"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to invoke .h5 model instead of .tflite model for pose classification?\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 27 custom code yes os platform and distribution ubuntu 2004 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell a bug happened standalone code to reproduce the issue shell i need to implement poseclassifierh5 model instead of poseclassifiertflite relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\npass additional parameters to @tf.custom_gradient\nissue type support have you reproduced the bug with tf nightly no source source tensorflow version 280 current behaviour currently we can define a custom gradient using tfcustomgradient following what im looking for is to be able to pass to this function additional information in my case the loss of my network for example its stupid but its to give an idea to take the incoming gradient and multiply it by loss that has generated that gradient"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCan't convert custom model to tflite with model config and weights file being separate\nhi i am trying to convert a custom model to tflite with these steps creates a custom model that i have previously defined resnet50 as a backbone pretrained weights transformer encoder mlp head model createmodelclasses5 the best weights file obtained after my custom model training converter tfmodel converterconvert with tflitemodel tflite wb as f fwritetfmodel i do not get any output on this no errors as well the question is is it possible to convert my custom model with creating the model without saving it and then loading the weights the way i have done is there any other way how to make my model smaller after training"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError in importing tensor flow \nclick to expand issue type support have you reproduced the bug with tf nightly no source source tensorflow version tf 49 custom code no os platform and distribution windows mobile device no response python version 388 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i have installed tensorflow using below command pip install tensorflow pip install keras then i tried to import and throwing error attributeerror module numpy has no attribute typedict current numpy version numpy1241 numpy121 standalone code to reproduce the issue shell i have installed tensorflow using below command pip install tensorflow pip install keras then i tried to import and throwing error attributeerror module numpy has no attribute typedict current numpy version numpy1241 numpy121 relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMissing fp16 ops when converting from TF to TFLite\nsystem information os platform and distribution eg linux ubuntu 1604 ubuntu 2004 tensorflow installed from source or binary pip install tensorflow version or github sha if from source 211 provide the text output from tfliteconvert fullerrortxt error failed while converting main some ops are not supported by the native tflite runtime you can enable tf kernels fallback using tf select see instructions tf select ops addv2 cast concatv2 conv2d elu gatherv2 max minimum mul pad realdiv relu sqrt sum transpose standalone code to reproduce the issue converter tflitemodel converterconvert"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTensorflow data validation-visualize_statistics()-Not working on databricks\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version tf28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i am unable to display the output of output on databricks where as the same is working on local system is it because that facets are not supported on databricks please provide a solution on how i can use modules of tensorflow data validation library on databricks standalone code to reproduce the issue shell link relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nModel save issues with custom optimizer - DPKerasSGDOptimizer\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version tf28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell problem a keras sequential model was compiled using dpkerassgd optimizer and saved but when the saved model is loaded it throws the below error unknown optimizer dpoptimizerclass please ensure you are using a and that this object is included in the scope see for details expected behaviour since the model was already compiled using the optimizer it should run perfectly fine when fitted with the data whereas the same works when the optimizer is replaced please provide a solution on how to save the model with this custom optimizer standalone code to reproduce the issue shell building the model model tfkerassequential activationrelu activationrelu activationrelu tfkeraslayersdense1 activationsigmoid compiling the model modelcompile metrics saving the model modelsavemymodel loading the model throws the error relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to get label of detection after (@tensorflow/tfjs-tflite) predict returns result from a custom tflite model in Reactjs web App\nclick to expand issue type support have you reproduced the bug with tf nightly yes source binary tensorflow version tfjs370 custom code no os platform and distribution windows 10 mobile device windows laptop python version 27 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i am using import as tflite from tensorflowtfjstflite and have successfully loaded a custom tflite model tflitemodel await as well as gotten a prediction var outputtensor await the code works well when i only have 1 label to detect initially now i need to detect multiple labels i created a new custom model and tested that it is able to detect multiple labels in an android project eg i can get labels l1 and l2 can i detect multi labels using the code above after i load in the new model if not what changes do i have to make to detect multi labels and know which label i am detecting eg obtain the name of the label standalone code to reproduce the issue shell see above not a bug issue relevant log output shell instance of result outputtensors value outputtensor kept false isdisposedinternal false shape 1 25 dtype float32 size 25 strides 25 dataid id 364 id 364 ranktype 2 kept false isdisposedinternal false shape 1 25 4 dtype float32 size 100 strides 100 4 dataid id 365 id 365 ranktype 3 kept false isdisposedinternal false shape 1 dtype float32 size 1 strides dataid id 366 id 366 ranktype 1 kept false isdisposedinternal false shape 1 25 dtype float32 size 25 strides 25 dataid id 367 id 367 ranktype 2"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError while evaluating tflite model with bazel run_eval \nhi i managed to train a ssdmobilenetv1 using modelmaintf2py after that i managed to export with changing the maxdetections paramenter to 33 and then i successfully exported a tflite model i tried then to run some inference with the new tflite model and it worked as expected i decided then to try to evaluate the tflite model using this guide but when i run this command bazel run c opt debugmodetrue output shows odd results like this object 0 score 33 classid 1 bounding box normalized top 0999825 normalized bottom 0999262 normalized left 0999445 normalized right 0999066 object 1 score 0 classid 1 bounding box normalized top 0998896 normalized bottom 0997808 normalized left 0998822 normalized right 0996969 object 2 score 0780337 classid 1 bounding box normalized top 0996294 normalized bottom 0988497 normalized left 0994716 normalized right 0985629 object 3 score 0479028 classid 1 bounding box normalized top 0972919 normalized bottom 00584207 normalized left 00640493 normalized right 00434026 object 4 score 0 classid 1 bounding box normalized top 00374295 normalized bottom 00290796 normalized left 00313877 normalized right 00227272 object 5 score 0 classid 1 bounding box normalized top 00221782 normalized bottom 00208216 normalized left 00213712 normalized right 00207996 object 6 score 0 classid 1 bounding box normalized top 00199532 normalized bottom 00192215 normalized left 00193954 normalized right 00187497 object 7 score 0 classid 1 bounding box normalized top 00186509 normalized bottom 00180727 normalized left 00181409 normalized right 00176707 object 8 score 0 classid 1 bounding box normalized top 00176005 normalized bottom 202493 normalized left 00637459 normalized right 0325256 this is for the first image of the folder i used one thing i noted is that the first score of the first object is always 33 that is the parameter i changed when i exported the trained model with is there a way to fix this so i can evaluate my tflite model thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nserialized_pb\nplease go to stack overflow for help and support if you open a github issue here is our policy 1 it must be a bug a feature request or a significant problem with the documentation for small docs fixes please send a pr instead 2 the form below must be filled out 3 it shouldnt be a tensorboard issue those go here heres why we have that policy tensorflow developers respond to issues we want to focus on work that benefits the whole community eg fixing bugs and adding features support only helps individuals github also notifies thousands of people when issues are filed we want them to see you communicating an interesting problem rather than being redirected to stack overflow system information have i written custom code as opposed to using a stock example script provided in tensorflow os platform and distribution eg linux ubuntu 1604 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device tensorflow installed from source or binary tensorflow version use command below python version bazel version if compiling from source gcccompiler version if compiling from source cudacudnn version gpu model and memory exact command to reproduce you can collect some of this information using our environment capture script you can obtain the tensorflow version with bash python c import tensorflow as tf tfversionversion describe the problem describe the problem clearly here be sure to convey here why its a bug in tensorflow or a feature request source code logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached try to provide a reproducible test case that is the bare minimum necessary to generate the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to design tf.keras callback to save model predictions for each batch and each epoch\nclick to expand issue type bug have you reproduced the bug with tf nightly no source source tensorflow version 211 custom code yes os platform and distribution ubuntu 2204 mobile device no response python version 37 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i want to create a tfkeras callback to save model predictions for each batch and each epoch during the training using the training data sets to a numpy array i have tried the following callback however it gives error like attributeerror predictioncallback object has no attribute xtrain standalone code to reproduce the issue shell class def onepochendself epoch logs ypred printprediction at epoch formatypred epoch epoch cnnmodelfitxtrain verbose1 relevant log output shell attributeerror predictioncallback object has no attribute xtrain i also tried tensorflow create keras callback to save model predictions and targets for each batch during training stack overflow but not get success yethope experts will help methanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n cannot import name 'build_info' from 'tensorflow.python.platform'\nclick to expand issue type support have you reproduced the bug with tf nightly yes source source tensorflow version 2110 custom code yes os platform and distribution windows 11 22h2 mobile device no response python version 3106 bazel version no gcccompiler version no response cudacudnn version no response gpu model and memory mx150 2gb vram current behaviour shell cannot import name buildinfo from standalone code to reproduce the issue shell cannot import name buildinfo from import tensorflow as tf from objectdetectionutils import configutil from import pipelinepb2 from googleprotobuf import textformat relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ni want to reduce the app size with TensorFlowLiteSelectTfOps\n1 system information ios tflite model cocoapods pod tensorflowliteobjc 270 pod 001nightly20210521 2 code and question with parsing linkmap file i found the take 74 mb which is too bigger when converting the tflite model my model just use three tensorflow flextensorliststack who can tell me some ways to reduce the size of app with"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\na bug in tensorflow\nsu standalone code to reproduce the issue relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n8222c1cfc866126111f23bd9872998480cebf2c1.tar.gz    404\nclick to expand issue type support source binary tensorflow version 28 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell this file can download at is 404 standalone code to reproduce the issue shell this file can download at is 404 relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nERROR: Could not find a version that satisfies the requirement tensorflow==1.15.2\ni use google colab and was wondering if anyone can solve this problem if you want to fix my notebook i will leave a link down below thanks if you solve it"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nerror: 'tf.Conv2D' op is neither a custom op nor a flex op\n1 system information os platform and distribution eg linux ubuntu 1604 linux ubuntu 2004 tensorflow installation pip package or built from source pip package tensorflow library version if pip package or github sha if built from source v210 2 code code for conversion converter tflitemodel converterconvert save the model with openfnametflite wb as f fwritetflitemodel code for the model latent keraslayersinputnh nw 4 decoder decoder decoder decoderlatent class def initself superinit x 1 018215 x paddedconv2d4 1 paddedconv2d512 3 padding1 resnetblock512 512 attentionblock512 resnetblock512 512 resnetblock512 512 resnetblock512 512 resnetblock512 512 2 paddedconv2d512 3 padding1 resnetblock512 512 resnetblock512 512 resnetblock512 512 2 paddedconv2d512 3 padding1 resnetblock512 256 resnetblock256 256 resnetblock256 256 2 paddedconv2d256 3 padding1 resnetblock256 128 resnetblock128 128 resnetblock128 128 paddedconv2d3 3 padding1 3 failure after conversion conversion fails 5 optional any other info logs errorlog some ops are not supported by the native tflite runtime you can enable tf kernels fallback using tf select see instructions tf select ops conv2d details tfconv2dtensor tensor tensor dataformat nhwc device dilations 1 1 1 1 explicitpaddings padding valid strides 1 1 1 1 usecudnnongpu true tfconv2dtensor tensor tensor dataformat nhwc device dilations 1 1 1 1 explicitpaddings padding valid strides 1 1 1 1 usecudnnongpu true tfconv2dtensor tensor tensor dataformat nhwc device dilations 1 1 1 1 explicitpaddings padding valid strides 1 1 1 1 usecudnnongpu true tfconv2dtensor tensor tensor dataformat nhwc device dilations 1 1 1 1 explicitpaddings padding valid strides 1 1 1 1 usecudnnongpu true tfconv2dtensor tensor tensor dataformat nhwc device dilations 1 1 1 1 explicitpaddings padding valid strides 1 1 1 1 usecudnnongpu true tfconv2dtensor tensor tensor dataformat nhwc device dilations 1 1 1 1 explicitpaddings padding valid strides 1 1 1 1 usecudnnongpu true tfconv2dtensor tensor tensor dataformat nhwc device dilations 1 1 1 1 explicitpaddings padding valid strides 1 1 1 1 usecudnnongpu true according to the error message i suspect that it can not recognize the input shape but as you can see on the above code input is specified for the functional api for decoder model fyi the inference code is called with predictonbatch method i found out other model with predictonbatch is converted successfully but that model doesnt contain conv2d block inside can using predictonbatch together with conv2d be a problem im sure conv2d is on the allowlist for tflite operators any suggestions for this problem thank you"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n__init__() got an unexpected keyword argument 'reduction'\nclick to expand issue type support source source tensorflow version tf 270 custom code yes os platform and distribution windows 10 mobile device no response python version 383 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell compile a model with does not raise error the training process seems also good however if we save the model and try to reload it it does not work now i know we could not use tfkeraslosses in metrics we must use some functions in tfkerasmetrics or some customized metrics but the error message init got an unexpected keyword argument reduction gives no information why not raise an error during the training or even during the compiling that would be much more friendly for new comers standalone code to reproduce the issue shell import numpy as np from import dense dropout import tensorflow as tf inputlength 2 latentdim 512 outputlength 2 model tfkerassequential denselatentdim activationrelu dropoutrate05 denseunitslatentdim activationrelu xtrain nponesshape150000 2 ytrain nponesshape150000 2 history modelfitxtrain ytrain epochs2 batchsize128 pretrained relevant log output shell traceback most recent call last file dvscodem2smcdebugpy line 26 in pretrained file line 67 in errorhandler raise from none file line 784 in fromconfig return clsconfig typeerror init got an unexpected keyword argument reduction"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntf.custom_gradient with multiple input and output\nsystem information have i written custom code as opposed to using a stock example script provided in tensorflow os platform and distribution eg linux ubuntu 1604 ubuntu 2004 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device tensorflow installed from source or binary tensorflow version use command below 292 python version 39 bazel version if compiling from source gcccompiler version if compiling from source cudacudnn version gpu model and memory exact command to reproduce describe the problem i have a function with 4 inputs x1 x2 x3 x4 and 2 outputs y1 y2 using tensorflow i would like to specify the gradients since i perform some nonautodiff operations inside the function i need to specify the derivatives of the outputs with respect to the inputs we can see these derivatives as a jacobian of size 24 regarding this i have 8 derivatives dy1dx1 dy1dx2 dy1dx3 dy1dx4 dy2dx1 dy2dx2 dy2dx3 and dy2dx4 however the grad function used in this tfcustomgradient needs to have the same length as the inputs this is 4 so i do not know how tensorflow handles with the introduction of the 8 derivatives using just 4 elements i tried to include them as lists but it gives the error here is a general code to reproduce the error import tensorflow as tf tfcustomgradient def barx1 x2 x3 x4 def graddy1 dy2 dy1dx1 x22 x33 x44 360000 dy1dx2 x1 2x2 x33 x44 480000 dy1dx3 x1 x22 3x32 x44 540000 dy1dx4 x1 x22 x33 4x43 576000 dy2dx1 x22 x33 x44 698 dy2dx2 x1 2x2 x33 x44 697 dy2dx3 x1 x22 3x32 x44 684 dy2dx4 x1 x22 x33 4x43 575 return dy1dx1 dy2dx1 dy1dx2 dy2dx2 dy1dx3 dy2dx3 dy1dx4 dy2dx4 y1 x1 x22 x33 x44 y2 x1 x22 x33 x44 return y1 y2 grad x1 tfconstant20 dtypetffloat32 x2 tfconstant30 dtypetffloat32 x3 tfconstant40 dtypetffloat32 x4 tfconstant50 dtypetffloat32 with as tape tapewatchx1 tapewatchx2 tapewatchx3 tapewatchx4 z barx1 x2 x3 x4 printtapegradientz x1 dy1dx1 dy2dx1 printtapegradientz x2 dy1dx2 dy2dx2 printtapegradientz x3 dy1dx3 dy2dx3 printtapegradientz x4 dy1dx4 dy2dx4 the error says customgradient function expected to return 4 gradients but returned 8 instead i expect someway to specify the correspondent 8 derivatives thank you in advance"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nStrange C macro generated by tensorflow.lite.python.util.convert_bytes_to_c_source()\n1 system information although i believe the system setup does not matter in this issue here goes windows 10 and ubuntu 2210 python 37 python 38 python 310 tensorflow lite 210 and 211 pip package 2 code generates the following strange c macro we need to keep the data array aligned on some architectures ifdef hasattribute define haveattributex hasattributex else define haveattributex 0 endif if haveattributealigned definedgnuc definedclang define dataalignattribute attributealigned4 else define dataalignattribute endif the strange part is definedgnuc definedclang if the code is compiled with the gnu c compiler then of course it is not compiled with the clang compiler the definedclang seems redundant and if its not redundant can someone explain it to me"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to reduce power consumption for gpu delegate on android\nclick to expand issue type performance source source tensorflow version 210 or 211 custom code yes os platform and distribution android mobile device android python version 37 bazel version no gcccompiler version no cudacudnn version no response gpu model and memory no response current behaviour shell here it is not a bug i want to reduce power consumption for gpu delegate on androidbecause i find the execution of tflite model using gpu occupys many power（ma） i use opencl backend do you have some optimization method in order to reduce power of model thank you very much standalone code to reproduce the issue shell my configuration is following gpuoptions relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n How to release memory when I want to change model with tf.saved_model.load already?\nclick to expand issue type support source source tensorflow version tf 211 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i use tfsavedmodelload to load a trained model i want to change another model when it done but the memory is still high how to release the memory i have test and gccollect all of these didnt work standalone code to reproduce the issue shell model gccollect relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to calculate the model's flops when I use tensorflow?\nclick to expand issue type support source source tensorflow version tf 28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i dont find a good way to calculate the models flops by tensorflow standalone code to reproduce the issue shell i dont find a good way to calculate the models flops by tensorflow relevant log output shell i dont find a good way to calculate the models flops by tensorflow"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDeploy yolo5 model into TensorFlow Lite Object Detection Android\nhello tensorflow team i checked your real time object detection app which works good with the initial models mobilenet v1 efficientnet lite0 efficientnet lite1 efficientnet lite2 but i receive errors when i try to add other model for example yolo5s model trained on coco dataset which converted from pt format to tflite with exportpy script below you can find converted models for yolo5s fp16 and int8 options i already checked they are working fine with detectpy is it possible to deployintegrate yolo5 model into your real time object detection app if yes can you please check if you can deploy into app one of those two models fp16 or int8 i shared with you above in case if it works for you can you share your experience what did you exactly modify in initial tensorflow lite object detection app scripts thank you in advance"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nwhich encoding can i use to parse tensorflow_stats.pb?\nissue type others source binary tensorflow version tf 28 custom code yes os platform and distribution ubuntu 1604 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour i get a tensorflowstatspb file by tfprofiler code like this loss i want to read tensorflowstatspb in my python code but i dont know which encoding this file use the file content is ä°\u0001 zb91\bź zba1\bź zbi1\bź zbać i9×łp ia×łp ii×łp iaiś\u000fâ­¤i veđç\u0001\u0007unknown iůţbyč\u0001\u0007unknown b\b \u0012\u0004host\u001a"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to convert model with multiple input?\n1 system information os platform and distribution eg window 10 tensorflow installation pip package tensorflow library tensorflow 291 2 code provide code to help us reproduce your issues using one of the following options im use code as below what should i change to make convertion success import numpy as np import tensorflow as tf from tensorflow import keras how to write function def for in range20 data1 nprandomrand1 3 16 16astypenpfloat32 data2 nprandomrand1 3 16 16astypenpfloat32 yield data1 data2 build model kinput1 kerasinputshape16 16 3 batchsize1 nameinput1 kinput2 kerasinputshape16 16 3 batchsize1 nameinput2 conv1 keraslayersconv2d16 3 2kinput1 conv2 keraslayersconv2d16 3 2kinput2 out conv1 conv2 kerasmodel kinput2 outputsout kerasmodeltrainable false kerasmodelsummary convert converter tfuint8 or tfint8 tfuint8 or tfint8 tflitemodel converterconvert with openmodeltflite wb as fp fpwritetflitemodel 3 failure after conversion if the conversion is successful but the generated model is wrong then state what is wrong model produces wrong results andor has lesser accuracy model produces correct results but it is slower than expected 4 optional rnn conversion support if converting tf rnn to tflite fused rnn ops please prefix rnn in the title 5 optional any other info logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached error info valueerror the inferenceinputtype and inferenceoutputtype must be tffloat32"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTF-lite model with a Conv2DTranspose layer is fail to run on mobile gpu.\n1 system information os platform and distribution eg linux ubuntu 1604 conversion env centos7 test env galaxy s10 tensorflow installation pip package or built from source pip install tensorflow library version if pip package or github sha if built from source 2100 2 code provide code to help us reproduce your issues using one of the following options def getmodel inputs tfkerasinputshape64 64 3 x keraslayersconv2d16 3 activationrelu nameconv1inputs x keraslayersconv2d16 3 activationrelu nameconv2x x 3 strides2 activationrelu namedeconv1x x 3 strides2 activationrelu namedeconv2x outputs x model outputsoutputs namecustom x tfones5 64 64 3 y modelx printxshape printyshape return model def tflitesavedir converter tffloat32 tflitemodel converterconvert with opentflitesavedir wb as f fwritetflitemodel if namemain model getmodel currentpath savedir custom1 savedir tflitesavedir mymodeltflite convertmodelsavedir tflitesavedir 3 failure after conversion tf lite conversion and run on the mobile phone with cpu is ok but when running with gpu an error occurs i tested the model in adb shell image"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd support for 3rd part object storage (S3) in Docker image\nclick to expand issue type support source binary tensorflow version 26 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell when using tensorflow docker image to run tensorboard kubeflow uses this method out of the box the image only supports gcsfilesystem and to support for 3rd party object storage eg s3 due to the dependency on tensorflowio the ask is to make tensorflowio as required pip dependency while docker build happens that way lot of customizations could be avoided and the support is out of the box standalone code to reproduce the issue shell when using the below sample spec simplified to make the reproducibility easy spec affinity containers args awsregionuseast1 s3endpoint awssecretaccesskey someawssecret logdirs3logspath bindall command binsh c image imagepullpolicy ifnotpresent name tensorboard ports containerport 6006 protocol tcp resources devterminationlog file workingdir dnspolicy clusterfirst imagepullsecrets name regcred restartpolicy always schedulername defaultscheduler securitycontext 30 relevant log output shell when the above spec is deployed we will run into the following error error unsupported filename scheme s3 supported schemes ram file gs for additional filesystem support consider instal │ │ ling tensorflow io via pip install tensorflowio"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_unique_id'\nclick to expand issue type bug source source tensorflow version 210 custom code yes os platform and distribution debian64 unix mobile device no response python version 3104 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell hello to everyone i need to training an actor network for a reinforcement learning algorithm but in time i am trying to predict continuous actions i have a problem with the function zip grads2 std also this one gives me the same error zip grads1 grads2 std please note that with the following function all goes well lossactions varlist std tape tapeactions the problem seems to be caused by the external variable std that it is not internal to the model did i make some mistakes is there a way to clipbynorm the std variables gradients best regards samir standalone code to reproduce the issue shell one tfones dtype float std tfvariable one dtype float name std sample selfreplaysample with tfgradienttape persistent false as tapeactions tapeactionsreset actionslocal selfactormodel sample 0 tfpdist loc actionslocal scale std newprobs tfpdistlogprob sample 1 newprobs tfmathreducesum newprobs axis 1 newprobs tfmathexp newprobs ratio newprobs sample 3 0 ratio tfmathreducemin tfconverttotensor ratio sample 4 tfclipbyvalue ratio clipvaluemin 1 01 clipvaluemax 1 01 sample 4 axis 0 lossactions tfmathreducemean ratio grads tapeactionsgradient lossactions std grads1 tfclipbynorm t w clipnorm 075 for w in grads 0 grads2 tfclipbynorm t w clipnorm 075 for w in grads 1 zip grads1 zip grads2 std relevant log output shell deprecationwarning the imp module is deprecated in favour of importlib and slated for removal in python 312 see the modules documentation for alternative uses import fnmatch glob traceback errno sys atexit locale imp stat traceback most recent call last file line 43 in file line 295 in crossentropyloss selfplayep ie trainmode true file line 78 in playep print selftrainingforelite realstepstotrain print file line 169 in trainingforelite selftraining realstepstotrain file line 272 in training zip grads2 std file line 695 in applygradients file line 959 in createallweights file line 126 in createslots selfaddslotvar m file line 1017 in addslot varkey varkeyvar file line 1650 in varkey return varuniqueid file line 446 in getattr selfgetattributename attributeerror object has no attribute uniqueid"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow much FPS in iOS (Swift)?\nclick to expand issue type support source source tensorflow version pod tensorflowliteswift 001nightly subspecs coreml metal custom code yes os platform and distribution macos mobile device iphone x python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell can i increase number of frames per second standalone code to reproduce the issue shell how much fps in ios swift relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTensorFlow Lite Quantization Debugger Issue\n1 system information os platform and distribution eg linux ubuntu 1604ubuntu 18043 tensorflow library version if pip package or github sha if built from 2 code def denseblockinputs filters y y batchnormalizationy return y def model inputs inputshape 112 112 3 x denseblockx 1 inputsize111256 outputsize1111 return modelinputs x 3 conversion is successfulbut the predicted value of int8 tflite has a large error value with the pb weights file if the conversion is successful but the generated model is wrong then state what is wrong model produces wrong results and accuracy drop 715 5 optional any other info logs question1 my weights pb file is successfully quantized into an int8 tflite model when doing the rmsescale value of the last layerconv2d is 2 which is far more than 0289 but the rmsescale values ​​in other layers are all it is around 0289 and if i change the output of the last layer to more nodes the value of rmsescale of the last layer will be closer to 0289 does anyone know what could be causing this to happen thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfrom keras.models import load_model raises no module named tensorflow.compat error\nclick to expand issue type support source binary tensorflow version 211 custom code no os platform and distribution windoes 11 mobile device no response python version 379 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell when doing kerasmodels import loadmodel an error saying no module named tensorflowcompat appears standalone code to reproduce the issue shell just open python 37 and type kerasmodels import loadmodel relevant log output shell traceback most recent call last file cusersnoah ryucodingaiteachable machineguesser3py line 1 in from kerasmodels import loadmodel tensorflow is needed for keras to work file cusersnoah line 21 in from keras import models file cusersnoah line 18 in from import functional file cusersnoah line 24 in import tensorflowcompatv2 as tf modulenotfounderror no module named tensorflowcompat"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nthere is no operator to calculate the matrix's inverse using tflite\nand tflinalgsvd is not supported in tflite batchmatrixinverse is not available in graphdef version 1205 hence， how to calculate the matrixs inverse using tflite i need some op to calculate the matrixs inverse best wishes"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndifference between core/grappler/optimizers/graph_optimizer.h and core/common_runtime/graph_optimizer.h\nclick to expand issue type support source source tensorflow version 26 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell this is not a bug report just a question now im learning the source code of tensorflow and i cant understand the difference between these two and can anyone explain this for me thanks standalone code to reproduce the issue shell none relevant log output no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nold versions of tflite native benchmark binaries\nhi is it possible to download old versions of tflite native benchmark binaries i can find here only the nightly version"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRunning TensorFlow on SHArC processors?\nare there any information on the possibility to compile tensorflow lite c targeting sharc processor from analog devices"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nimplement llama 2 using Tensorflow\nissue type feature request have you reproduced the bug with tensorflow nightly no source source tensorflow version tf 28 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior standalone code to reproduce the issue shell relevant log output shell"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWill there a MLP model in the future version?\nissue type feature request have you reproduced the bug with tensorflow nightly no source source tensorflow version 2130 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior when building deep learning models like multilayer perceptrons mlps code reusability and conciseness are crucial factors currently using tfkerassequential in tensorflow allows for convenient creation of sequential models however manually adding common operations such as batch normalization or dropout to each layer can lead to code redundancy and an increased burden in terms of coding and maintenance therefore proposing the addition of a feature in tensorflow to directly create mlps with batch normalization and dropout is highly beneficial here are several reasons why this feature would be advantageous for tensorflow users 1 simplified code users wont need to manually add batch normalization and dropout operations to each layer resulting in cleaner more readable and maintainable code 2 reduced error rate manual copypasting of code is errorprone especially as model complexity increases automating the integration of batch normalization and dropout operations can reduce issues arising from code errors 3 increased productivity developers can build and iterate on models more swiftly focusing on design and parameter tuning rather than rewriting the same code segments for every new model 4 education and learning for newcomers to tensorflow this feature can provide a quicker onboarding process lowering the learning curve and enabling them to grasp and apply deep learning concepts faster certainly heres the additional information i also believe that pytorch has implemented mlp functionality quite effectively an example of this can be found in the following url pytorch mlp pytorchs approach to creating mlps provides a good reference for how tensorflow could potentially integrate similar features standalone code to reproduce the issue origin python model tfkerassequential tfkeraslayersrelu tfkeraslayersdense64 tfkeraslayersrelu tfkeraslayersdense32 tfkeraslayersrelu tfkeraslayersdense10 with mlp model python model tfkerasmlp hiddenchannels128 64 32 10 dropout02 relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\npybind11_proto from python to C++\nblaziusmaximus thanks for the explanation ive been exploring how to update the importgraphdef codepath to use pybind11protobuf and i could use your help with the following similar to how pybind11protobuf allows us to pass protos directly from c to python is there a way to pass a graphdef proto from python to c without performing serialization this would be needed to invoke the from pywrap session in c originally posted by othakkar in"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Feature] The Heaviside step function as a activation function\nsome of the implementations like single layer perceptron needs discrete outputs like 0 or 1 adding this could make the model building ease"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfloat8 support for array ops\nissue type feature request have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2120 custom code no os platform and distribution mobile device no response python version 396 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior please add fp8 datatype support for array ops like reshape transpose gatherv2 expanddims squeeze concatv2 split pack unpack and stridedslice standalone code to reproduce the issue shell import tensorflow as tf from import dtypes a tfconstant12345678 23456789 34567891 45678912 56789123 67891234 dtypedtypesfloat16 printa afp8 tfcasta dtypesfloat8e4m3fn printafp8 b afp812 b tftransposeafp8 1 0 relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIssue still tittle\nissue type documentation feature request have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior what you see what im see standalone code to reproduce the issue shell us see you relevant log output shell productive projects"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nthe tf keras models load_model() used for loading ml model is not able to load model\nclick to expand issue type feature request have you reproduced the bug with tf nightly yes source source tensorflow version tf 28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour hi i am trying to load my deep learning model using tensorflow keras models loadmodel when i run it for first time it got loaded but from next time it is not loading like it is in this function for more than 30 min i store my model in h5 format model size is approx 13 mb at the time of saving deep learning i use modelsave i am using a machine with 128 gb ram i am using multiprocessing with no of worker 16 sometime it worked and sometime is got stucked standalone code to reproduce the issue shell relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntf.keras.metrics.Precision treats label as binary?\nclick to expand issue type documentation feature request have you reproduced the bug with tf nightly yes source binary tensorflow version 2140dev20230611 custom code yes os platform and distribution linux mobile device na python version 3113 bazel version na gcccompiler version na cudacudnn version no response gpu model and memory no response current behaviour is returning precision assuming the label is binary it looks so to me see in 4 m mupdatestate0 1 2 3 0 1 2 2 mresultnumpy out4 10 in 5 import tensorflow as tf in 6 m mupdatestate0 1 2 3 0 1 2 2 mresultnumpy out6 10 in 7 tfversion out7 2140dev20230611 in 8 m mupdatestate0 5 3 3 0 1 2 2 mresultnumpy out8 10 above shouldnt be 10 if labels are treated as non binary it appears to me that 0s are treated as 0 while non zeros are treated as 1 but nowhere in the doc mentions this behavior i cant find categorical precision or similar either please update doc to explain this behavior standalone code to reproduce the issue shell see above relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCould not interpret loss function \"NDCG Lambda Weight V2\"\na erro happened could not interpret loss function ndcg lambda weight v2 modelcompile optimizeroptimizer modelfittraindataset epochs20 some error happened in modefit valueerror could not interpret loss function identifier"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGPU Delegate dynamic tensor input shape (Feature Request)\nclick to expand issue type feature request have you reproduced the bug with tf nightly yes source source tensorflow version tf 2120 custom code yes os platform and distribution android mobile device android python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour hello im writing you to ask are there plans to implement dynamic input shape in gpu delegate in near future right now dynamic input shape working fine on cpu but on gpu delegate im getting the issue internal error error applying delegate this is very important feature if this feature already exist and it is possible somehow to rung with dynamic shape will be good to have some information in documentation standalone code to reproduce the issue shell private fun context interpreter val tfliteoptions interpreter options if delegate null 1 else 4 val interpreter tfliteoptions intarrayof1 modelheight modelwidth 3 true return interpreter relevant log output shell internal error error applying delegate method"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd docs reference to latest numpy version for `tf.experimental.numpy` functions\nclick to expand issue type documentation feature request have you reproduced the bug with tf nightly no source binary tensorflow version 2120 custom code no os platform and distribution linux ubuntu 1804 mobile device no response python version 310 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour as the tf version requirements for running the latest version we need the latest version of numpy and all tfexperimentalnumpy functions point to the numpy v116 i am thinking if we can update the referencing docs link thanks standalone code to reproduce the issue shell check this relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNetwork-Level Control of Precision (fp32 in training, fp16 in inference)\nclick to expand issue type feature request have you reproduced the bug with tf nightly yes source binary tensorflow version tf 212 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour a very common use case is that we train and export the model in fp32 then use fp16 mode in inference but it seems xla doesnt support this it would be good if xla can support networklevel control of precision like tensorrt standalone code to reproduce the issue shell na relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to write custom XLA op for tensorflow\nclick to expand issue type documentation feature request have you reproduced the bug with tf nightly yes source binary tensorflow version 2120 custom code yes os platform and distribution linux mobile device no response python version 310 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour hi i have custom tensorflow ops implemented in c using this guide which are invoked during training they work fine as long as xla is not used however im unable to get them working and even a dummy custom xla op the test op i have written is mentioned below and compiled by following the guide linked above the compilation succeeds but i get following runtime error when the module with custom op is imported nonokstatus lookupstatus status notfound op type not registered xlatestop in binary running on make sure the op and kernel are registered in the binary running in this process im not able to find any more info how to resolve this issue standalone code to reproduce the issue shell c xla op implementation include include include include include include include include include include include include void testopcudastreamt stream void buffers const char opaque sizet opaquelen stdcout executing testopn class xlatestop public xlaopkernel public explicit ctx xlaopkernelctx void ctx override xlaxlabuilder const builder ctxbuilder xlaxlaop input ctxinput0 use output aliasing to reuse input buffer for output stdpair xlashapeindex 0 xlashapeindex xlashape outputshape xlaxlaop outputop xlacustomcall builder testop input outputshape opaque hassideeffectfalse literalnullptr ctxsetoutput0 outputop xlatestop cuda relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNeed Add Perl to Supported API Languages\nthis page lists all the languages with support for the tensorflow api thanks to an official grant from the perl foundation we have recently released a perl api how do we go about getting perl added to the list"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMake time series_from_array() more intuitive to use\nclick to expand issue type feature request have you reproduced the bug with tf nightly no source source tensorflow version 2100 tensorflowmacos custom code yes os platform and distribution macos 1321 mobile device no response python version 3108 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour timeseriesgenerator is deprecated and tensorflow docs encourage the use of time seriesfromarray instead however this is not intuitive to use requiring far more boilerplate code to achieve the same effect in addition the results are not as expected i spent hours debugging my code to realise time seriesfromarray is not behaving as expected using the code below i would expect there to be 6 different inputs and outputs however there are only 3 running the same code with timeseriesgenerator without the 4 and 4 indexing produces the expected 6 inputs and outputs standalone code to reproduce the issue shell x npzeros10 3 y nparray1 2 3 4 5 6 7 8 9 10 test y4 sequencelength4 batchsize2000 relevant log output shell array0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 array5 6 7 code for timeseriesgenerator expected output python test y length4 test0 expected output shell array0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 array 5 6 7 8 9 10"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to build with xnnpack\nclick to expand issue type feature request have you reproduced the bug with tf nightly yes source source tensorflow version tf 2100 custom code yes os platform and distribution ubuntu 2004 mobile device qualcomm python version 38 bazel version 511 gcccompiler version 930 cudacudnn version no response gpu model and memory no response current behaviour shell i want to build without xnnpack or with xnnpackqs8 diabled how to achieve that standalone code to reproduce the issue shell i tried with and define but it seems that they didnt work relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFreeze zero weights during training\nclick to expand issue type feature request have you reproduced the bug with tf nightly yes source source tensorflow version 211 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell is there any way to freeze zero weights during model retraining this is different than freezing a layer which is already available in tf this is relevant to model pruning for example i want to retrain only nonzero weights of a pruned model is it possible to use tfindexedslices efficiently for this standalone code to reproduce the issue shell i think we can achieve this if theres any feature in tf to calculate grads only for nonzero weights i couldnt find any method to achieve this tffunction def trainstepinputs targets with tfgradienttape as tape predictions modelinputs trainingtrue lossvalue lossfntargets predictions grads return lossvalue relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCast int32 to bfloat16 does not run on A100 GPU\nclick to expand issue type feature request have you reproduced the bug with tf nightly yes source source tensorflow version tensorflow version 2130dev20230215 custom code yes os platform and distribution ubuntu 2004 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version 11886 gpu model and memory single a100 80g current behaviour shell when using tfcast to cast tfint32 tensor to tfbfloat16 tensor op run on gpu when i convert int32bfloat16 it run on cpu when i convert int32float32bfloat16 it run on gpu is it expected standalone code to reproduce the issue shell import tensorflow as tf from tensorflowkeras import mixedprecision policy printpolicyname class def buildself inputshape selfkernel selfaddweightkernel inputshape1 10 def callself inputs out tflinalgmatmulinputs selfkernel out2 tfones10 10 dtypetfint32 out2 tfcastout2 tffloat32 namecastout21 out2 tfcastout2 outdtype namecastout22 out3 out out2 return out3 layer toylayer y layertfones10 10 relevant log output shell 20230217 162634748024 i this tensorflow binary is optimized to use available cpu instructions in performancecritical operations to enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler flags 20230217 162635370677 w tftrt warning could not find tensorrt mixedbfloat16 20230217 162636876507 i created device with 78915 mb memory device 0 name nvidia a100 80gb pcie pci bus id 000100000 compute capability 80 input arg 20230217 162636886233 i input arg eagerconst eagerconst 20230217 162636886254 i eagerconst eagerconst outputretval retval 20230217 162636886267 i outputretval retval 20230217 162636889118 i executing op eagerconst in device input arg 20230217 162637293473 i input arg eagerconst eagerconst 20230217 162637293513 i eagerconst eagerconst outputretval retval 20230217 162637293521 i outputretval retval 20230217 162637294777 i executing op eagerconst in device dims devicearg 20230217 162637295227 i dims devicearg value arg 20230217 162637295238 i value arg fill fill 20230217 162637295250 i fill fill outputretval retval 20230217 162637295257 i outputretval retval 20230217 162637295729 i executing op fill in device 20230217 162637297303 i executing op eagerconst in device 20230217 162637297667 i executing op eagerconst in device 20230217 162637297928 i executing op eagerconst in device 20230217 162637298227 i executing op eagerconst in device seed arg 20230217 162637298533 i seed arg 20230217 162637298547 i keyretval retval 20230217 162637298561 i keyretval retval counterretval retval 20230217 162637298573 i counterretval retval 20230217 162637299212 i executing op in device 20230217 162637300704 i executing op eagerconst in device shape devicearg 20230217 162637300963 i shape devicearg key arg 20230217 162637300974 i key arg counter arg 20230217 162637300979 i counter arg alg devicearg 20230217 162637300993 i alg devicearg 20230217 162637300999 i outputretval retval 20230217 162637301008 i outputretval retval 20230217 162637301526 i executing op in device x arg 20230217 162637302304 i x arg y arg 20230217 162637302316 i y arg sub sub 20230217 162637302332 i sub sub zretval retval 20230217 162637302338 i zretval retval 20230217 162637302706 i executing op sub in device x arg 20230217 162637303361 i x arg y arg 20230217 162637303372 i y arg mul mul 20230217 162637303379 i mul mul zretval retval 20230217 162637303391 i zretval retval 20230217 162637303748 i executing op mul in device x arg 20230217 162637304205 i x arg y arg 20230217 162637304216 i y arg addv2 addv2 20230217 162637304223 i addv2 addv2 zretval retval 20230217 162637304229 i zretval retval 20230217 162637304663 i executing op addv2 in device resourceretval retval 20230217 162637305249 i resourceretval retval varhandleop varhandleop 20230217 162637305263 i varhandleop varhandleop 20230217 162637305637 i executing op varhandleop in device resource arg 20230217 162637306104 i resource arg value arg 20230217 162637306122 i value arg assignvariableop assignvariableop 20230217 162637306139 i assignvariableop assignvariableop 20230217 162637306554 i executing op assignvariableop in device x arg 20230217 162637307498 i x arg cast cast 20230217 162637307523 i cast cast yretval retval 20230217 162637307532 i yretval retval 20230217 162637307943 i executing op cast in device resource arg 20230217 162637308714 i resource arg readvariableop readvariableop 20230217 162637308734 i readvariableop readvariableop valueretval retval 20230217 162637308743 i valueretval retval 20230217 162637309154 i executing op readvariableop in device 20230217 162637309366 i executing op cast in device a arg 20230217 162637309693 i a arg b arg 20230217 162637309710 i b arg matmul matmul 20230217 162637309727 i matmul matmul productretval retval 20230217 162637309738 i productretval retval 20230217 162637310165 i executing op matmul in device 20230217 162637897703 i executing op eagerconst in device 20230217 162637897841 i executing op eagerconst in device dims arg 20230217 162637898261 i dims arg value arg 20230217 162637898272 i value arg fill fill 20230217 162637898280 i fill fill outputretval retval 20230217 162637898285 i outputretval retval 20230217 162637898934 i executing op fill in device x devicearg 20230217 162637899509 i x devicearg cast cast 20230217 162637899523 i cast cast yretval retval 20230217 162637899530 i yretval retval 20230217 162637899935 i executing op cast in device x arg 20230217 162637900335 i x arg y arg 20230217 162637900348 i y arg mul mul 20230217 162637900361 i mul mul zretval retval 20230217 162637900369 i zretval retval 20230217 162637901006 i executing op mul in device"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFeature Request: More descriptive get_weights() method\nissue type feature request tensorflow version tf 2110 os platform and distribution windows 11 python version 3109 hello currently i can get the weights of each layer of a keras model by calling tensorflows getweights method additionally this method returns the bias of the layer if the usebias term is true there is no mention of the order in which weights and biases are returned in tensorflow or keras documentation when the method returns two or more numpy arrays how can we determine what these layers represent it would be awesome if the getweights method could also indicate whether a particular numpy array is a weights array bias array etc standalone code to reproduce the issue shell import tensorflow as tf def getmodel mnistmodel tfkerassequential 28 activationrelu activationrelu tfkeraslayersdense10 return mnistmodel def for index layer in enumeratemodellayers statedict"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProto file missing in nightly wheels\nhave you reproduced the bug with tf nightly yes tensorflow version tf 212 current behaviour i work on the tensorflowdirectml plugin and we use the proto files included in the tf wheel to generate pbccpbh files needed by the plugin one of the files needed is the file which has not been included in the nightly wheels so far would it be possible to make sure that its included for tf 212"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to change specific body line colour eg. Hip-Knee-Ankle line in swift \nclick to expand issue type bug have you reproduced the bug with tf nightly yes source source tensorflow version pod tensorflowliteswift 001nightly subspecs coreml metal custom code yes os platform and distribution macos mobile device iphone x python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell unable to change specific body line colour eg hipkneeankle line in swift standalone code to reproduce the issue shell how to change specific body line colour eg hipkneeankle line in swift relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nkeras.models.clone_model not working\nclick to expand issue type bug have you reproduced the bug with tf nightly no source source tensorflow version tf 210 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell to clone a model using to keep ema weights standalone code to reproduce the issue shell when cloning a model that inherits from tfkerasmodelsmodel cant use relevant log output shell valueerror traceback most recent call last input in 20 in 1 gan 5 define losses 6 generatorloss discriminatorloss getlossnsl input in 19 in adatganinitself generator discriminator 4 superadatgan selfinit 5 selfgenerator generator 6 selfemagenerator 7 selfdiscriminator discriminator 8 selfnoisedim noisedim file in clonemodelmodel inputtensors clonefunction 501 return clonesequentialmodel 502 model layerfnclonefunction 503 504 else 505 return clonefunctionalmodel 506 model layerfnclonefunction 507 file in inputtensors layerfn 167 raise valueerror 168 expected model argument 169 to be a functional model instance 170 fgot a sequential instance instead model 171 172 if not modelisgraphnetwork 173 raise valueerror 174 expected model argument 175 to be a functional model instance 176 fbut got a subclassed model instead model 177 179 newinputlayers cache for created layers 180 if inputtensors is not none 181 make sure that all input tensors come from a keras layer valueerror expected model argument to be a functional model instance but got a subclassed model instead"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to train with mobilenet models using model_spec.get() ??\nhello i am using this tutorial to train my dataset for the object detection and efficientdetlite 04 models are working fine i found a documentation for modelspecget and it seems you can train only with efficientdetlite models is there any way to train the model with ssdmobilenetv2 or ssdmobilenetv1 models and what i should write inside of modelspecget look forward to hearing from you"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRequest: Some way to initialise a dynamically-sized state variable in TFLite\nsystem information os platform and distribution eg linux ubuntu 1604 all tensorflow installed from source or binary binary tensorflow version or github sha if from source 291 provide the text output from tfliteconvert unable to lift tensor because it depends transitively on placeholder via at least one path eg zeros fill shape shape arr placeholder standalone code to reproduce the issue i want to define a stateful graph where the shape of the state variable is defined when model is loaded not when its saved as a simple example lets say i just want to compute a temporal difference ie a graph that returns the difference between the input in two consecutive calls the following should pass func runtimeshape 60 80 rng ims for in range3 assert npallclosefuncims0 ims0 assert npallclosefuncims1 ims1ims0 assert npallclosefuncims2 ims2ims1 however as far as i know there is not way i can save a model or define some function loadtflitemodelfunc for loading it that would make this work for any runtimeshape because variables in the graph can only be saved with a predetermined size a full standalone notebook demonstrating the issue is here request is for tflite to be able to initialise statevariables where the shape of the initialised variable can depend on the inputshape see also"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupport for keepdims and padding in tf.boolean_mask or tf.ragged.boolean_mask\nclick to expand issue type feature request source source tensorflow version tf 28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour given two example tensors input and mask input tfrandomnormal235 input tftensor shape2 3 5 dtypefloat32 numpy array 11260294 005932725 085893923 15332409 06681451 08833729 08421117 060990584 008593109 05969471 020015325 09459327 10818844 17254639 051545954 036073774 024315724 15217028 15075827 005745999 02570101 15501927 017113225 016063859 095638955 048955616 011943919 03523262 010750653 11027677 dtypefloat32 mask tfconstant010101 mask tftensor shape2 3 dtypeint32 numpy array0 1 0 1 0 1 dtypeint32 i need to mask out input according to mask where values are 0 however since the number of masked out elements for each example in the batch input might be different to keep the output a valid tensor the output should be maskedinput tftensor shape2 3 5 dtypefloat32 numpy array 08833729 08421117 060990584 008593109 05969471 0 0 0 0 0 0 0 0 0 0 036073774 024315724 15217028 15075827 005745999 048955616 011943919 03523262 010750653 11027677 0 0 0 0 0 dtypefloat32 ie in the output the masked input keeps only elements where mask is 1 and with zeropadding at the end to ensure that the output is a valid tensor ive searched around and tried using 1 tfgather however still cant figure out how to proceed 2 tfbooleanmask however it doesnt support masking but just drops the first zeroth dimension as shown below tfbooleanmaskinput mask tftensor shape3 5 dtypefloat32 numpy array 08833729 08421117 060990584 008593109 05969471 036073774 024315724 15217028 15075827 005745999 048955616 011943919 03523262 010750653 11027677 dtypefloat32 3 tfraggedbooleanmask this is by far the closest one to what i want it keeps the dimension however still doesnt support masking so the result is a ragged tensor similar issues are mentioned in github in short tensor 1 2 3 4 5 6 7 8 9 mask nparraytrue false true false false true true true true booleanmasktensor mask keepdimsfalse 1 3 6 7 8 9 booleanmasktensor mask keepdimstrue padval0 1 3 0 6 0 0 7 8 9 standalone code to reproduce the issue as mentioned above relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTensorFlow Lite Image Classification - add a new model\nhello i tested your tensorflow lite image classification android app and it works perfect with these models mobilenet v1 efficientnet lite0 efficientnet lite1 efficientnet lite2 which are downloading automatically by the downloadgradle file then i wanted to add my own classification model which has different labels compared to models mentioned above i placed my model in assets folder appsrcmainassets and then did some modification in file val modelname when currentmodel modelmymodel mymodeltflite modelmobilenetv1 mobilenetv1tflite else mymodeltflite companion object const val delegatecpu 0 const val delegategpu 1 const val delegatennapi 2 const val modelmymodel 0 const val modelmobilenetv1 1 private const val tag while i build and launch the app i received the following error launching app on xiaomi install successfully finished in 6 s 117 ms adb shell am start n a c connected to process 15146 on device xiaomi can you please let me know how to fix the issue and do i need to do other modification in scripts to make it work with my model look forward to hearing from you and thank you in advance"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nExpecting the same names when converting to tflite model\nhello i have created very simple model and i want to export it to tflite model to benchmark it on android device and run simple inferences this is code to create model python import tensorflow as tf import numpy as np from tensorflow import keras from tensorflowkeras import layers input0 kerasinputshape64 nameinput0 input1 kerasinputshape16 nameinput1 input2 kerasinputshape16 nameinput2 layer0 layersdense3 activationrelu namelayer0input0 layer1 layersdense5 activationrelu namelayer1input1 layer2 layersdense7 activationrelu namelayer2input2 x0 layer1 layer2 x1 layer1 layer2 output0 layersdense3 nameoutput0x0 output1 layersdense7 nameoutput1x1 model kerasmodel inputsinput0 input1 input2 outputsoutput0 output1 lossmeansquarederror converter tflitemodel converterconvert with openmodeltflite wb as f fwritetflitemodel environment google colab i expect that tflite model would have input0 input1 input2 input names and output0 output1 output names but real names are"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTensorflow Lite iOS Interpreter production logs\nclick to expand issue type feature request source source tensorflow version 2100 custom code no os platform and distribution ios mobile device ios python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell the log outputs of the interpreter cannot be disabled for production use but we would need that see would be nice if you could introduce another option for the interpreter where you could set log outputs enableddisabled or even with loglevels standalone code to reproduce the issue shell interpretermodelpath path options options relevant log output shell initialized tensorflow lite runtime"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFeature request (TensorFlow Lite): Implement mechanism to load Flex ops in C for Android\nsystem information have i written custom code no os platform and distribution macos monterey 126 tensorflow installed from source tensorflow version 2100 python version 3108 bazel version 511 gcccompiler version apple clang 1400 clang1400029202 cudacudnn version not using cuda gpu model and memory not using gpu acceleration exact command to reproduce feature request no describe the problem this is a feature request in tensorflow lite 27 and higher if a model contains flex ops you must go through java to load the flex library see and flexdelegatejava we develop a crossplatform app where most of the ml inference logic runs in a separate c library we test that library separately from the rest of the app using gtest without going through the android runtime for our purposes it would be much more convenient if we could load the flex library directly in c as a tentative implementation we could move the logic in to c so that we could automatically load flex ops when creating models from the c api with tflitemodelcreate the existing java classes could be kept as shallow wrappers to the underlying c implementation java and c entry points could be toggled at build time through a flag is this something that you would consider implementing and if not would you accept prs that go in that direction"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`tf.identity` docs missing instructions, GPU to CPU\nissue type documentation feature request source binary tensorflow version 2100 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour the docs do not describe how cpu should be accomplished standalone code to reproduce the issue shell import tensorflow as tf tfconstant1cpu relevant log output shell eagertensorbasecpu from is deprecated and will be removed in a future version instructions for updating use tfidentity instead"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDocument behavior of tf.keras.layers.Bidirectional with return_state=True\nclick to expand issue type documentation feature request source source tensorflow version 210 custom code no it is unclear from the documentation how a layer will behave if returnstate is true ie in what order the hiddencell states will be returned and what if any interaction there is with mergemode per the source code any states of forward layer are returned after the outputs followed by any states of the backward layer this should be documented if selfreturnstate states y1 yrev1 y y0 yrev yrev0 if selfreturnstate if selfmergemode is none return output states return output states return output"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to enable GSPMD?\nclick to expand issue type support source binary tensorflow version tf 27 custom code no os platform and distribution linux mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell we are trying to utilize gspmd on a server with 8 gpus we find the uttest cases as follows to dump the irs we enable the environment variables as tfxlaautojit2 mytensorflowprogram but only 4 irs are saved none of them is related to spmd pass it seems that our current run does not enable gspmd functionality at all is there any tutorial or instructions for us to follow to enable gspmd on multiple gpus standalone code to reproduce the issue shell from import xlasharding from tensorflowpythonops import arrayops from tensorflowpythonops import mathops from import testutil from import dtypes from import ops import numpy as np from import deffunction class def testdotsplitself deffunctionfunction def splithelpertensor devicemesh nparray0 1 2 3 4 5 6 7 splittensor devicemesh 0 1 opstensor splitsharding splitshape expectedshape 2 4 splitshape ytensor arrayopsones8 8 dtypedtypesfloat32 ysplit devicemesh 0 1 result ysplit devicemesh nparray0 1 2 3 4 5 6 7 result devicemesh 0 1 result mathopssqrtresult result devicemesh 1 0 return result intensor 2 npsqrt2 arrayopsones8 8 dtypedtypesfloat32 result splithelper arrayopsones8 8 dtypedtypesfloat32 result if name main xlasharding xlashardingtest relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupport for C++ Builder 11.2 \nclick to expand issue type others source binary tensorflow version tf 28 custom code no os platform and distribution windows 11 x64 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell is there anyway to support c builder 112 current static libs are in a format not supported by c builder static libs are only in coff format so they cant be linked with in c builder they need to be in omf format for c builder to link the static libs the only way i can solve this is to do a loadlibrary in code and get proc address of each function standalone code to reproduce the issue shell no able to link static libs only in msvc not c builder relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nLeakyRelu in Tensorflow lite with the Hexagon Delegate not supported\nwhen using a tflite model 8bits quantized via tensorflow lite conversion framework that includes the activation function leakyrelu the hexagon delegate from tensorflow framework cannot perform the dnn inference on the whole graph but rather it falls back to the cpuxnnpack delegate this is due to the fact that leakyrelu operation is not supported by the hexagon delegate confirmed in tensorflow doc when using relu activation function and relu6 as well we can see below that the tf hexagon delegate can process the whole dnn graph unfortunately the qualitative results i get are much worse hence the need of having leaky relu implemented in the hexagon delegate we can easily reproduce this behavior by using tensorflow benchmark tool see below could we consider to implement leaky relu in tensorflow lite dsp delegate system information os platform and distribution android 10 ndk r21e tensorflow installed from source or binary from source using the release tag 291 tensorflow version or github sha if from source 291 provide the text output from tfliteconvert warningabslfound untraced functions such as while saving showing 5 of 23 these functions will not be directly callable after loading userwarning statistics for quantized inputs were expected but not specified continuing anyway for quantized inputs were expected but not 20221013 181316990773 w ignored outputformat 20221013 181316991046 w ignored 20221013 181316998334 i reading savedmodel from 20221013 181317027069 i reading meta graph with tags serve 20221013 181317027795 i reading savedmodel debug info if present from 20221013 181317269741 i mlir v1 optimization pass is not enabled 20221013 181317291178 i restoring savedmodel bundle 20221013 181318176412 i running initialization op on savedmodel bundle at path 20221013 181318475762 i savedmodel load for tags serve status success ok took 1477588 microseconds 20221013 181319015757 i disabling mlir crash reproducer set env var to enable found 7390 files belonging to 1 classes fullyquantize 0 inferencetype 6 inputinferencetype 9 outputinferencetype 9 process finished with exit code 0 standalone code to reproduce the issue here is a colab link with the code used to generate the model that include leaky relu op quantize and save the model in int8 ops colab code link link to the quantized model the tool below from tensorflow allow to run any model when running the model above it fails because leakyrelu is not supported link to tensorflow benchmark tflite benchmark command line tfbenchmark usehexagontrue when performing the inference on dsp using tensorflow lite benchmark tool for android we get the following error message tfbenchmark usehexagontrue starting log parameter values verbosely 0 graph require full delegation 1 use hexagon 1 hexagon lib path datalocaltmp loaded model info initialized tensorflow lite runtime loaded libcdsprpcso hexagon delegate created info delegate 6 nodes delegated out of 12 nodes with 5 partitions verbose replacing 6 nodes with delegate node yielding 6 partitions disallowed cpu fallback detected benchmarking failed if i disable the usage of the dsp then it works properly tflite benchmark command line tfbenchmark logs tfbenchmark starting log parameter values verbosely 0 graph loaded model info initialized tensorflow lite runtime the input model file size mb 0038384 initialized session in 057ms running benchmark for at least 1 iterations and at least 05 seconds but terminate if exceeding 150 seconds count1141 first4613 curr428 min427 max4613 avg438004 std125 running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds count2311 first433 curr428 min427 max627 avg432374 std14 inference timings in us init 570 first inference 4613 warmup avg 438004 inference avg 432374 note as the benchmark tool itself affects memory footprint the following is only approximate to the actual memory footprint of the model at runtime take the information at your discretion memory footprint delta from the start of the tool mb init0 overall309766 if i replace leakyrelu by relu then it works properly here is a colab link with the code used to generate the model that include relu op quantize and save the model in int8 ops colab code link link to the quantized model myquantmodelreluzip tflite benchmark command line tfbenchmark usehexagontrue logs tfbenchmark usehexagontrue starting log parameter values verbosely 0 graph require full delegation 1 use hexagon 1 hexagon lib path datalocaltmp loaded model info initialized tensorflow lite runtime loaded libcdsprpcso hexagon delegate created info delegate 8 nodes delegated out of 8 nodes with 1 partitions verbose replacing 8 nodes with delegate node yielding 1 partitions explicitly applied hexagon delegate and the model graph will be completely executed by the delegate the input model file size mb 00374 initialized session in 17422ms running benchmark for at least 1 iterations and at least 05 seconds but terminate if exceeding 150 seconds count918 first796 curr537 min324 max3378 avg540937 std180 running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds count1754 first701 curr537 min443 max2552 avg565409 std136 inference timings in us init 174220 first inference 796 warmup avg 540937 inference avg 565409 note as the benchmark tool itself affects memory footprint the following is only approximate to the actual memory footprint of the model at runtime take the information at your discretion memory footprint delta from the start of the tool mb init348047 overall348047"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMaking tensorflow.tile similar to numpy.tile and torch.tile\nclick to expand issue type feature request source source tensorflow version 291 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell running this code tftiletfones321 will currently give an error for tensorflow since the dimension length of the input and the multiples is different numpy and pytorch handle this by modifying the dimension of the multiples or the input argument i believe it would be nice if tensorflow did this too standalone code to reproduce the issue shell import tensorflow as tf tftiletfones321 relevant log output shell tensors devicename opname expected multiples argument to be a vector of length 1 but got length 2 optile"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupporting int32 value type in TextFileInitializer.\nclick to expand issue type feature request source source tensorflow version tf 29 custom code no os platform and distribution linux mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell in textfileinitializer we have a validation to check whether the valuedtype is of type tfint64 wondering why do we have such constraints the context is that we are trying to initialize a vocabulary lookup table in the tensorflow model and would like to save memory for the hashtable both the key and value type can be of int32 type but seems that the value type is restricted to int64 standalone code to reproduce the issue shell initializer vocabfile keydtypetfint64 keyindex0 valuedtypetfint32 valueindex1 delimiter relevant log output shell 0 vocabtable numoovbuckets1 0 file line 1235 in init 0 dtypesint64 0typeerror invalid value dtype expected but got"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to build TensorFlow from source with Clang?\nclick to expand issue type buildinstall source source tensorflow version v2100 custom code no os platform and distribution ubuntu 2004 mobile device no response python version 38 bazel version 511 gcccompiler version clang 14 cudacudnn version no response gpu model and memory no response current behaviour shell i am trying to build tensorflow with clang and add options for generating coverage information however it fails with clang build standalone code to reproduce the issue shell bazel build verbosefailures repoenvccclang coptfcoveragemapping removing coptfcoveragemapping also fails relevant log output shell error compiling failed undeclared inclusions in rule this rule is missing dependency declarations for the following files included by target failed to build info elapsed time 138453s critical path 6333s info 7649 processes 4288 internal 3361 local failed build did not complete successfull"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdan optimizer\nclick to expand issue type feature request source binary tensorflow version tf 291 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell adan seems to be a superior optimizer compared to adam and its variants can we introduce this in tfkeras optimizers please find a few references below adan paper pytorch implementation blog article standalone code to reproduce the issue shell na relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGPU detection src location\nclick to expand issue type others source source tensorflow version 2 custom code no os platform and distribution ubuntu 2004 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version 117 gpu model and memory tesla v100 current behaviour shell hello im a student researcher and i am only posting this as i got no response on the tensorflow google group please direct me to next place to the answer im trying to develop a feature where if tensorflow does not detect a local gpu i direct the binary to my custom application a gpu virtualization framework for it to talk to a remote gpu execute the calls i want to know in the large codebase of tensorflow where should i start looking for this i need source file where it decides no gpu so use cpu or something similar standalone code to reproduce the issue shell na relevant log output shell na"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntf.image.combined_non_max_suppression crash with segmentation fault\nclick to expand issue type bug source binary tensorflow version 2110dev20220916 custom code no os platform and distribution ubuntu 18044 lts x8664 mobile device no response python version 376 bazel version no response gcccompiler version no response cudacudnn version na gpu model and memory no response current behaviour shell crash with segmentation fault when maxtotalsize is given a large value standalone code to reproduce the issue shell import numpy as np import tensorflow as tf scoresnpones221 boxesnpones2214 relevant log output shell 20220919 205642880536 w could not load dynamic library libcudaso1 dlerror libcudaso1 cannot open shared object file no such file or directory 20220919 205642880586 w failed call to cuinit unknown error 303 20220919 205642880661 i no nvidia gpu device is present devnvidia0 does not exist 20220919 205642881322 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 avx512f fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20220919 205642924370 w detected a large value for maxtotalsize this may cause oom error maxtotalsize 1916847725 segmentation fault core dumped"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nInclude \"name\" parameter in tf.keras.models.clone_model() function to give a new name to the clone.\nclick to expand issue type feature request source source tensorflow version 282 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell when using the function it assigns the same name as previousmodel to the created clone i want to assign a new name to the created clone this can probably be done by passing a name parameter to the clonemodel function standalone code to reproduce the issue shell prem1 tfkerassequential sentenceencoderlayer namepretrainedm1 prem2 in the summary the name of prem2 is printed as pretrainedm1 ie same as prem1 printprem2summary relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFeature: Balanced Accuracy\nclick to expand issue type feature request source binary tensorflow version tf 2100rc3 custom code no os platform and distribution debian 11 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version 112 gpu model and memory no response current behaviour i suggest adding balanced accuracy as additional keras metrics it is useful for training with an imbalanced validation dataset note i see various suggestions on stackoverflow 1 2 standalone code to reproduce the issue shell import tensorflow as tf metrics relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntf.image.rot90 should add a note for the case k<0\nclick to expand issue type documentation feature request source source tensorflow version tf28 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell the documentation only describes how the code runs when k0 and dont mention k0 the code shows that when k0 the image will be rotated clockwise i think a note should be added to explain what happens when k0 standalone code to reproduce the issue shell import tensorflow as tf results try arg0 2 1 minval256 maxval257 dtypetfint64 dtypetfint32 k 1 resultsres tfimagerot90arg0kk except exception as e resultserr errorstre printresults relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`tf.pad` fails when executing in `tf.autodiff.ForwardAccumulator`\nclick to expand issue type bug source binary tensorflow version tf 291 custom code yes os platform and distribution linux ubuntu 2004 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell tfpad fails when executing in and throws typeerror however if we run tfpad outside of forwardaccumulator with the same input it will pass standalone code to reproduce the issue shell import tensorflow as tf inputtensor tfrandomuniform3 1 1 1 minval20 maxval30 dtypetffloat32 paddings tfrandomuniform4 2 minval0 maxval5 dtypetfint64 mode constant constantvalues 0 result tfpadinputtensor paddings modemode printresultshape pass tangent tfreshapetfonehot1 tfsizeinputtensor with tangent as acc result tfpadinputtensor paddings modemode fail relevant log output shell 8 3 8 4 typeerror input y of sub op has type int64 that does not match type int32 of argument x"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nwhen will tensorflow support FP8?\nclick to expand issue type feature request source binary tensorflow version tf29 custom code no os platform and distribution linux ubuntu 2004 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell pytorch added fp8 support will tf add fp8 support sometime for both e4m3 and e5m2 standalone code to reproduce the issue shell no source code just a feature request question relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPlease publish official wheels for Apple Silicon\nclick to expand issue type buildinstall source binary tensorflow version 291 custom code no os platform and distribution macos 12 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour users of macs with apple silicon m1 m2 etc cannot pip install tensorflow because wheels for the architecture are not published on pypi the current state of this august 2022 is that these wheels are published under a different package name tensorflowmacos which is released separately by apple this makes it more complicated to install software that uses tensorflow on macos eg a requirementstxt file might have to look something like tensorflow sysplatform darwin or platformmachine arm64 tensorflowmacos sysplatform darwin and platformmachine arm64 apples repository tensorflowmacos is archived which makes it unclear where users should get support is it here moreover at the time of writing tensorflowmacos is version 392 which is one bugfix release ahead of the latest official tensorflow so comparing version numbers across the two is difficult and it leaves many other unanswered questions are these being tested in ci how soon after an upstream release will tensorflowmacos get an update finally both tensorflow and tensorflowmacos support intelbased macs which is another potential point of confusion—which is preferred cc kulinseth jhavukainen standalone code to reproduce the issue shell venv arch arm64 venv python3 m pip install tensorflow error could not find a version that satisfies the requirement tensorflow from versions none error no matching distribution found for tensorflow"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to fix the \"undefined reference\" problem for the TF Lite? A suggestion.\nwhen cmakeliststxt is used to build a shared library of tf lite it is impossible to link with it because of the undefined reference problem those undefined reference objects reside on the tensorflow main branch but the following macro populatetfsourcevars has never populated a single line of main tensorflow code for the tf lite build yet the main code is referenced by it no wonder we see the undefine reference i did try to use populatetfsourcevars to bring those missing objects to tf lite unfortunately however the references will quickly escalate to reference a lot of main tensorflow stuff that defeats the very motivation of having a lite version of tensorflow doesnt it can you please make tf lite stop referencing those objects because they dont seem to be important if you do think they are important can you make a light version of them just for tf lite the problem usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIs possible to measure height of person using tensorFlow pose Estimation \nclick to expand issue type feature request source source tensorflow version pod tensorflowliteswift 001nightly subspecs coreml metal custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i want to performe vertical jump test want to measure distance between floor to ankle standalone code to reproduce the issue shell i want to performe vertical jump test want to measure distance between floor to ankle relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRsqrt doesn't support for tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8\nsystem information os platform and distribution eg linux ubuntu 1604 tensorflow installed from source or binary tensorflow version or github sha if from source provide the text output from tfliteconvert copy and paste here standalone code to reproduce the issue provide a reproducible test case that is the bare minimum necessary to generate the problem if possible please share a link to colabjupyterany notebook also please include a link to a graphdef or the model if possible any other info logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAre there on-device training with Tensorflow lite in Arduino IDEs???\nclick to expand issue type feature request source source tensorflow version tf28 custom code no os platform and distribution windows mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell is there a way to perform ondevice training with tensorflow lite in arduino ide i see an option for java and c with android but cant find the c doc seems like c aint supported too standalone code to reproduce the issue shell no code relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Feature Request] GELU activation with the Hexagon delegate\nsystem information os platform and distribution eg linux ubuntu 1604 ubuntu 2004 tensorflow installed from source or binary binary tensorflow version or github sha if from source 291 i think id be able to implement this myself but wanted to see if there was any interest in including this upstream most of this im writing out to make sure my own understanding is correct the problem id like to add support for the gelu op to the hexagon delegate the motivation for this is mostly for use with distilbert which uses this activation function in its feedforward network layers also used by bert gpt3 roberta etc adding this as a supported op for the hexagon delegate would avoid creating a graph between dspcpu each time the gelu activation function is used how id implement this gelu in tf lite is implemented as a lookup table when there are integer inputs here and here this same approach could be used for the hexagon delegate as it has int8uint8 data types and also supports lookup tables id plan to do this by adding a new op builder in the delegate populating a lookup table for each node as is currently done for the cpu version of the op and then using the gather8 nnlib library function to do the lookup possible workaround a workaround i thought of im going to try removing the pattern matching for approximate gelu in mlir and then using the approximate version of gelu so that using tanh and not erf this will probably be slower but should let me keep execution on the dsp since this will then be tanh addition multiplication ops instead of gelu they should all be runnable by the dsp"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[TF.io] Incompatible with AWS S3 filepaths\nclick to expand issue type bug source binary tensorflow version 291 custom code no os platform and distribution rhel mobile device no response python version 3712 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour apparently from the aws logs it seems the headers are obtained but the response body is empty im using tfds however its accessing via etils the tf backend to create a stream for the s3 object hence why its reproducible from a tf method this was the full error from tfds for those interested to verify that it does indeed call tfio as a backend to execute the request traceback most recent call last file scriptskecamtesterpy line 47 in tfrecords of bdd100k dataset long only delayed by 60 frames for each tuple file line 80 in writemetadata f for f in datadiriterdir if file line 80 in f for f in datadiriterdir if file line 126 in iterdir for f in file line 191 in listdir return selfgfilelistdirpath file line 769 in listdirectoryv2 messagecould not find directory formatpath could not find directory standalone code to reproduce the issue shell import tensorflow as tf insert any s3 filepath tfiogfilelistdirs3 relevant log output shell traceback most recent call last file line 1 in file line 769 in listdirectoryv2 messagecould not find directory formatpath could not find directory s3"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCMAKE has no key to disable the build of python wrapper when building TF lite from source using Xcode or Android Studio\nclick to expand issue type feature request source source tensorflow version tf29 custom code no os platform and distribution linux ubuntu 18 or macos mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell cmake has no key to disable the build of python wrapper when building tf lite from source using xcode or android studio current cmake in with the a non optional python wrapper which triggers errors when using tensorflow as a submodule in an xcode or android studio project python interpreter wrapper shared excludefromall to remove lib prefix properties prefix public tfliteincludedirs tensorflowlite cmakedllibs public private i would expect a cmake key to enable or disable the python wrapper eg iftfliteenablepywrap endif standalone code to reproduce the issue shell cmake has no key to disable the build of python wrapper when building tf lite from source using xcode or android studio relevant log output shell cannot find pythonh"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCustom Op written in C API errors when requesting GPU_Device stream\nclick to expand issue type documentation feature request source binary tensorflow version 28 custom code yes os platform and distribution linux mobile device 07010841551 python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell hi there i was trying to write a custom op using the tensorflow c api and in the cuda version i was facing errors while requesting for the gpudevice stream my questions are 1is there any way to convert spstreamreturned by to cudastream 2what is the equivalent of eigendevicestream c for the c api 3where is the implementation of tfopkernelcontext thanks yoga standalone code to reproduce the issue shell c code cudastreamt equivalent c code cudastreamt thestream relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReproducible sparse-dense matrix multiplication\nclick to expand issue type feature request source binary tensorflow version v29018gd8ce9f9c301 291 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell there is currently no deterministic sparsedense matrix multiplication implementation on the gpu i would like to have one standalone code to reproduce the issue shell import tensorflow as tf m tfsparsetensor indices0 0 0 1 valuesnparray1 2 dtypenpfloat32 denseshape3 2 v tfconstant1 1 dtypetffloat32 v relevant log output shell unimplementederror a deterministic gpu implementation of is not currently available"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTensorflow GPU Delegate Limit resources (Feature Request)\nhello sometimes when im running the tflite model on gpu delegate it use almost all gpu resources while execution and this behaviour freeze ui because of lack resources if it possible will be good to have some initial option with percentage of gpu use os android for example 08 this feature will provide more control over resources"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIs it possible to sync tensorflow stream_executor's cuda stream with cuda stream outside?\nin tensorflow streams including cuda streams are handled by streamexecuter now i make some modification to tensorflow and create an independent cuda stream outside streamexecuter i was wondering is it possible to sync the independent cuda stream with the streams that wrap a cuda stream in streamexecuter i really appreciate if someone has advices"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCustom Op written in C API compilation Issue\nclick to expand issue type documentation feature request source binary tensorflow version 28 custom code yes os platform and distribution linux mobile device 07010841551 python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell hi there is there any example where custom op written using c api was compiled successfully and executed after tfloadlibrary i have referred the entire kernelsh opsh and capih files of the official github tf repo but i am not able to figure it out could someone give the command to execute a c api custom op file along with the code thanks yoga standalone code to reproduce the issue shell include tensorflowckernelsh include tensorflowcopsh include tensorflowctftensorh include include include include include shape inference void ctxtfstatus status tfshapehandle handle tfnewshapehandle 0 handle status 0 handle status tfok typedef struct basic tftensor input tftensor output basic static void context basic k basic calloc1 sizeofbasic tfstatus status tfnewstatus initialize the fields of k as needed tfok tfdeletestatusstatus return void k static void basiccomputevoid k tfopkernelcontext ctx compute the result tftensor inputtensornull tfstatus status tfnewstatus tfgetinputctx 0 inputtensor status tfsetoutputctx 0 inputtensor status tfok tfdeletestatusstatus static void basicdeletevoid kernel delete staticcastkernel op and kernel registration void initplugin tfstatus status tfnewstatus opbuilder tozero int32 zeroed int32 status tfok tfdeletestatusstatus tfstatus status1 tfnewstatus auto builder tensorflowdevicecpu basiccreate basiccompute basicdelete builder status1 asserttfok tfgetcodestatus1 tfattributeunused static bool if registerbasickernel return true relevant log output shell module has no attribute basic"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd tf.Complex to tflite ops. Support padding and slicing of complex tensors\nclick to expand issue type feature request source binary tensorflow version 291 custom code no os platform and distribution linux ubuntu 2004 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell it would be great if we could get support in tflite for the tfcomplex op as well as support for slicing and padding complex numbers this is very important for audio use cases as it often involves running stfts and working with complex numbers heres the error i currently get when i try to convert my model some ops are not supported by the native tflite runtime you can enable tf kernels fallback using tf select see instructions tf select ops complex pad stridedslice details tfcomplextensor tensor tensor device tfpadtensor tensor tensor device tfstridedslicetensor tensor tensor tensor tensor beginmask 15 i64 ellipsismask 0 i64 endmask 11 i64 newaxismask 0 i64 shrinkaxismask 0 i64 standalone code to reproduce the issue shell na relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nF1 score metric\nissue type feature request tensorflow version 291 current behaviour no f1 score metric its a holistic measure for classification standalone code to reproduce the issue"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIs it possible to change colour of specific keypoint in iOS\nclick to expand issue type feature request source source tensorflow version pod tensorflowliteswift 001nightly subspecs coreml metal custom code yes os platform and distribution macos mobile device iphone x python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i want to change colour of specific body landmarks is it possible to achieve in ios using swift standalone code to reproduce the issue shell multicolor on overlay image relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBuilding Tflite compiling out pthread\nclick to expand issue type buildinstall source source tensorflow version tf29 custom code no os platform and distribution linux ubuntu 16042 lts mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell i am trying to build tflite example minimal for a device which does not support posix thread i know one can disabled multithreading by setting numthreads 1 in the interpreter but what i am trying to get is disabling pthread fully during compilation is there a way to achieve this thanks standalone code to reproduce the issue shell you can run the test relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to display custom label with angles in iOS?\nclick to expand issue type feature request source source tensorflow version pod tensorflowliteswift 001nightly subspecs coreml metal custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell how to display degree of angle on every keypoint standalone code to reproduce the issue shell below code for to create degree of angle i used func angle firstlandmark cgpoint midlandmark cgpoint lastlandmark cgpoint cgfloat let radians cgfloat atan2lastlandmarky midlandmarky lastlandmarkx midlandmarkx atan2firstlandmarky midlandmarky firstlandmarkx midlandmarkx var degrees radians 1800 pi var degrees radians pi 180 pi degrees absdegrees angle should never be negative if degrees 1800 degrees 3600 degrees always get the acute representation of the angle let roundedvalue1 rounddegrees return roundedvalue1 relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to calculate 45 degree standing position of body from camera in swift (Pose estimation)\nclick to expand issue type feature request source source tensorflow version pod tensorflowliteswift 001nightly subspecs coreml metal custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell how to calculate 45 degree standing position of body from camera in swift standalone code to reproduce the issue shell how to calculate 45 degree standing position of body from camera in swift using the body keypoints pose estimation relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nis it possible to calculate Body degree angle using pose estimation\nclick to expand issue type feature request source source tensorflow version pod tensorflowliteswift 001nightly subspecs coreml metal custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell how to calculate degree of angles using body keypoints pose angle ie 45 degree 90 degree standalone code to reproduce the issue shell i want to detect human body pose angle is it possible relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRestore non max suppression (nms) support for Tensorflow Lite GPU Delegate.\nclick to expand issue type feature request source binary tensorflow version 290 custom code yes os platform and distribution google colab mobile device no response python version 3713 google colab bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell tldr please restore support for nonmaxsuppression for tensorflow lite gpu delegate it was supported before tf 23 and is not supported now background back in tensorflow version 23 one could take and run object detection model eg from tensorflow object detection api and run it fully on the tflite with gpu via delegate right now it is impossible operations that were previously supported like nonmaxsuppression are now unsupported by dropping support to these operations users are forcedlocked to use older tensorflow version please bring back support for nonmaxsuppression as it was previously supported standalone code to reproduce the issue shell colab link lets verify support with tflites authoring tool import tensorflow as tf tftensorspecshape1 100 4 dtypetffloat32 boxes tftensorspecshape1 100 1 dtypetffloat32 scores def nmsboxes scores return boxes scores maxoutputsize15 verify this works boxes tfonesshape1 100 4 scores tfonesshape1 100 1 numvalid nmsboxes scores verify crashes tflite gpu delegate authoring tool targetspec tflitetargetspec gpu functotest nms raiseexceptiontrue functotestboxes scores relevant log output shell the log output is rather long and covers multiple sub ops im only pasting the lower part during handling of the above exception another exception occurred compatibilityerror traceback most recent call last in decodeerrorself err 244 245 if selfraiseexception and selflogmessages 246 raise at reprselffunc 247 248 def logself message compatibilityerror at"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[TFLite] Dynamic batch size with GPU delegate\nclick to expand issue type feature request source source tensorflow version 2100dev20220427 custom code yes os platform and distribution linux ubuntu 1804 mobile device linux ubuntu 1804 python version 310 bazel version 511 gcccompiler version 750 cudacudnn version cuda 116 gpu model and memory nvidia geforce gtx 1650 4bg current behaviour considering these two assertions please tell me if they are wrong it is not possible to use dynamicsized tensors with the gpu delegate nor is it possible to use a batch size greater than one with the gpu delegate edit it seems that when i saw the bug with batch size greater than one the gpu delegate switched to opengl instead of opencl i do not know the reason and now that it is working with opencl after rebooting the computer the inference can run on the gpu with any batch size thus it would still mean that this feature should be available with opengl however it would very convenient to be able to modify the batch size before creating the network on the gpu or if requested by the user to recreate the network at any time with a different batch size this would allow to convert and store a single model with dynamicsized tensors the size of which would actually be known ie batch size would be set before making use of the network then it would be possible to perform ondevice training on the gpu with a batch of inputs once issue 56151 is solved standalone code to reproduce the issue try running this ondevice training tutorial with both flex and gpu delegates using the experimental c api relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBuild/release Python 3.10 tflite-runtime wheels to PyPI\nclick to expand issue type buildinstall source binary tensorflow version 290 custom code no os platform and distribution linux macos mobile device no response python version 310 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour tensorflow 290 was released with python 310 support we would like to support python 310 in production but in order to do this we need all of the following packages to support python 310 tensorflow tensorflowmacos for arm macos tfliteruntime for stripped down production on linux neither tensorflowmacos or tfliteruntime have 290 releases on pypi yet standalone code to reproduce the issue create a python 310 virtual environment on linux bash venv python m pip install tfliteruntime create a python 310 virtual environment on macos arm bash venv python m pip install tensorflowmacos relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n3D SSIM \nhi is it possible to add 3d ssim batched into tensorflow we need this feature for 3d inference currently tfimagessim only accepts batched 2d input if not is there any internal beta version of 3d ssim for tryout thanks"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntf.keras.optimizers.experimental.AdamW only support constant weight_decay\nclick to expand issue type feature request source source tensorflow version 28 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell only supports constant weight decay but usually we want the weightdecay value to decay with learning rate schedule standalone code to reproduce the issue shell the legacy tfaoptimizersadamw supports callable weightdecay which is much better relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to resize (downsample) 5D samples in tensorflow? \nissue type feature request source binary tensorflow version tf 28 custom code yes os platform and distribution windows 10 python version 39 note reposting from here its closed in keras and recommended to post it on the tensorflow side because this functionality is not precisely available in tensorflow it may need to write lowlevel ops in tf for best performance current behaviour currently for 5d data batchsize h w depth channel the or upsampling3d can be used to upsampling purpose for example i can do python a tfonesshape1 100 100 64 1 a depthfactor2 heightfactor2 widthfactor2 shape tensorshape1 200 200 128 1 these factor values above should be an integer and are coded here in that case how can we downsample the input sample for example python a tfonesshape1 100 100 64 1 a depthfactor05 heightfactor05 widthfactor05 shape typeerror float object cannot be interpreted as an integer expected tensorshape1 50 50 32 1 here another scenario where the factor needed to be fractional candidate solutions scipyndimagezoom in pytorch didnt test others such downsampling feature needs to be implemented in lowlevel in the depth part of volumetric data it might be hard to decide the appropriate strategy to drop the slices depending on the domain for example in medical data if we drop the slice blindly we might lose information fyi in ctmri images most of the information appears mainly in the middle range currently a workaround for medical data ctmri were following input data 1 50 50 20 4 desired output 1 25 25 10 4 python a tfonesshape1 50 50 20 4 ashape tensorshape1 50 50 20 4 a2 tfreshapea 1 50 50 204 a2shape tensorshape1 50 50 80 a3 tfimageresizea2 25 25 a3shape tensorshape1 25 25 80 a4 tfreshapea3 1 25 25 20 4 a4shape tensorshape1 25 25 20 4 here picking some middle slices assuming that by this we may get relevant slices how convenient is this may not general a5 a4 515 a5shape tensorshape1 25 25 10 4"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTFLite Tensor name converted by 2.7.0 is much longer than 1.14.0\nsystem information os platform and distribution linux ubuntu 1804 mobile device no tensorflow installed from source or binary binary pip install tensorflow270 tensorflow version 270 python version 3813 bazel version if compiling from source none gcccompiler version if compiling from source none cudacudnn version none gpu model and memory none exact command to reproduce none describe the problem using tensorflow 1140 convert pb model to tflite as follows python import tensorflow as tf graphdeffile pathtomobilenetv1pb inputarrays input outputarrays inputshapes input 1 224 224 3 convert inputarrays outputarrays inputshapes tflitemodel convertconvert with wb as f fwritetflitemodel after update tensorflow to 270 and modify scripts as follows python import tensorflow as tf graphdeffile pathtomobilenetv1pb inputarrays input outputarrays inputshapes input 1 224 224 3 convert inputarrays outputarrays inputshapes tflitemodel convertconvert with wb as f fwritetflitemodel i found tensor name in is much longer than such a long name caused a lot of trouble when comparing the tflite model with the original model however i also noticed that there will be a new attributes in tfliteconverter python convert inputarrays outputarrays inputshapes false tflitemodel convertconvert but the log as follows warning me that old converter is deprecated shell warningabslplease consider switching to the new converter by setting the old converter toco is deprecated is is possible to add an attribute in the new version so that the model conversion name can remain unchanged and the tensor of folder const can be removed"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReplacing Add Layer with Linear Combination of Learnable Weights\nclick to expand issue type feature request the add layer can be expressed as a linear combination of inputs where each coefficient value is 1 i was trying to make a custom layer that performs the same as add except uses trainable coefficients as we assume a coefficient of 1 is optimal unfortunately i was unable to do so on my own specifically the gradients i do not think this would be too hard to implement as all the code is kind of already there just need to calculate gradients and then update source source tensorflow version 27 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour shell the add layer can be expressed as a linear combination of inputs where each coefficient value is 1 i was trying to make a custom layer that performs the same as add except uses trainable coefficients as we assume a coefficient of 1 is optimal unfortunately i was unable to do so on my own specifically the gradients i do not think this would be too hard to implement as all the code is kind of already there just need to calculate gradients and then update standlone code to reproduce the issue shell x relevant log output no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrequest for feature gather and matmul\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate system information tensorflow version you are using 271 are you willing to contribute it yesno yes describe the feature and the current behaviorstate this function can realize that the corresponding weight is taken from the matrix b according to the index given by the matrix c and then multiplied by the matrix a a batch h b num h d c batch out batch d batch num python for i j in enumeratec outi matmulai bj currently this function can be implemented by tfgather then tfmatmul however it will waste a lot of gpu memory due to the need to define an intermediate variable w python w tfgatherb c out tfmatmula w it can also be implemented by one hot matmul however the time complexity of the calculation will be very high python tmp tfonehotc depthnum out tfenisumbhbnnhdbd a tmp b will this change the current api how no who will benefit with this feature this function can be applied to the moe model to achieve the assignment of experts strictly according to the probability of the router avoids the limitations of the expert capacity currently required any other info no"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRFE tensorflow-aarch64==2.6.0 build ?\nsystem information tensorflow version you are using 260 are you willing to contribute it yesno yes describe the feature and the current behaviorstate brainchip akida akd1000 snn neuromorphic metatf sdk support 260 on x8664 they claim support for aarch64 but when creating a virtualenv it fails on aarch64 due to lacking tensorflowaarc64260 build will this change the current api how na who will benefit with this feature customer of brainchip akida who run on arm64 platforms any other info"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntf.image.extract_patches default value for areas outside the input \nrunning by the same padding leads to zeros for areas outside the input there is no way to change the default value and it is best to have this as another parameter for this function this background label should be always zero otherwise this function mess up the labels"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`pfor`/`tf.vectorize_map`: Improve feedback/hints messages when it `fallback_to_while_loop`\nsystem information tensorflow version you are using are you willing to contribute it yesno probably if i can talk with a codeowner of this namepace describe the feature and the current behaviorstate as we are adding a root cause message on the cause we are going internally to rely on fallbacktowhileloop it would be nice to have a more clear feedback string to the user on what kind of action is required eg refactoring his function open a new ticket with a code gist on tf github etc see more at cc wangpengmit will this change the current api how no who will benefit with this feature developers that partially fail to fully tfvectorizemap their functions any other info"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nList of TF ops that tf.vectorized_map supports\nwhere can i get this information which tf operation is a vectorized operation and which one is not"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGeneralise `xla::Map` to functions over arbitrary shapes\nsystem information tensorflow version you are using 28 are you willing to contribute it yesno no describe the feature and the current behaviorstate currently xlamap only allow functions from shape to id like to use functions with arbitrary shapes for example apply a function with shapes 2 3 5 to a tensor 100 4 2 3 to get a 100 4 5 ive not yet thought about how it would work when mapping multiple input tensors at once will this change the current api how it would extend xlamap either internally or as an overload its possible additional information would need to be passed to a more general implementation of map in which an overload may be preferable to maintain backwards compatibility who will benefit with this feature anyone using xla whod like to apply a function over sections of a tensor it would effectively be an alternative to some portion of broadcasting allowing people to use functions that dont allow leading dimensions to tensors with leading dimensions it is particularly useful for me as im working with dependent types and adding leading dimensions is nontrivial and verbose in type signatures any other info it is already possible to do this by indexing into the tensor and iteratively applying the function to the contents then concatenating the results but i expect this is significantly slower than could be achieved within xla i have considered using xlawhile for this but i still expect the slicing and concatenation would still come with a significant performance cost"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nplease publish TensorFlowLiteObjC 2.8\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate system information tensorflow version you are using android 28 ios 27 are you willing to contribute it yesno no describe the feature and the current behaviorstate will this change the current api how who will benefit with this feature any other info"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncapture_tpu_profile on Cloud TPU VM\nhello it seems that capturetpuprofile only works for legacy tpu devices but not for cloud tpu vm i was wondering if and when we can expect to have support for cloud tpu vm at the moment its is impossible to monitor jaxflax tpu workloads as tensorboard instrumentation does not exhibit the right metrics eg utilization of tpu matrix units other related thread for legacy tpu devices thanks"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nXLA tf.bincount support\nsystem information tensorflow version you are using master are you willing to contribute it yesno only if we have a clear path and a reviewer on how to contribute this describe the feature and the current behaviorstate tfbincount isnt supported by xla will this change the current api how no who will benefit with this feature speedup functionsloops that rely on tfbincount any other info how to reproduce it python import tensorflow as tf def return tfmathbincountvalues values tfconstant11232445 0 2 2 1 2 1 python invalidargumenterror detected unsupported operations when trying to compile graph on xlacpujit bincount no registered bincount opkernel for xlacpujit devices compatible with node node bincountbincountnode bincountbincount the op is created at without this we had problems to compile intermediate ms coco recall function in kerascv extra please also note that the cpugpu tf2xla supported ops tables are probably outdated 2018 cc jokereph lukewood"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ngradient_function/gradient_tapes with device annotations\nsystem information tensorflow version you are using 28 are you willing to contribute it yesno yes describe the feature and the current behaviorstate feature request adding option to tfgradients in 1x to tfgradienttape in 2x this feature requestissue was 1st mentioned in almost two years ago by olesalscheider allow me to quickly review the op in which the current behavior still hold in tf 28 is described currently gradienttapegradient is executed on the device of the scope it is called in have a look at the following code with tfgradienttape as tape with tfdevicegpu1 x f1input with tfdevicegpu2 x f2x with tfdevicegpu0 g tapegradientx fvars here all gradient calculations will be carried out by gpu0 and all variables needed for the gradient calculation will also be allocated on gpu0 this is a problem if these temporary variables are too large to fit into the vram of gpu0 please provide a way to execute the backward functions on the device of the corresponding forward function and allocate temporary variables for gradient calculation there this allows to split a large model and distribute it among as many gpus as necessary also olesalscheider provided a pr to achieved such feature and it get merged at the beginning but shortly get rollbacked due to certain performance issues i opened another pr to fit the current master tf28 and build and test it it looks to me the gradient can now be split correctly according to the device annotation will this change the current api how it will allow tfgradienttape to do gradient in the device of the corresponding forward function hence it would be possible to split the training of large models into as many possible gpus as necessary who will benefit with this feature anyone who wants to train large models that do not fit into the vram of a single gpu any other info it looks to me that the original post has gone silence so i raise the issue again here to draw more attentions it is a very import feature for peoples working in large image segmentation tasks some times the input tensor is so large and the model can not even be fitted into a single a100 card moreover i noticed that in the discussion flow in the original post that there are some other work around like split into different tapes i tried but with no luck all gradient calculation still be allocated on gpu0 and moreover splitting tape would be very different for model like unet which has a lot of skipconnections last but not the least i know for a fact that there is the mashtensorflow which propose to do such job but a native tensorflow support would be also very useful for people work on large models"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRuntimeError: Exporting/importing meta graphs is not supported when eager execution is enabled. No graph exists when eager execution is enabled.\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate 20220211 110530792376 i successfully opened dynamic library libcudartso101 traceback most recent call last file 01genquadproposalspy line 82 in file line 92 in restorecnnsess saver meta importscopecornerdet file line 1460 in importmetagraph return file line 1472 in raise meta graphs is not supported when runtimeerror exportingimporting meta graphs is not supported when eager execution is enabled no graph exists when eager execution is enabled system information tensorflow version you are using tensorboard 280 061 tensorboardpluginwit 181 tensorflow 231 tensorflowestimator 230 tensorflowhub 0120 0240 tensorflowjs 3130 cuda 101 cudnn 76 python 38 are you willing to contribute it yesno yes describe the feature and the current behaviorstate will this change the current api how who will benefit with this feature any other info"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOption to avoid caching with bijectors.\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate system information tensorflow version you are using 270 are you willing to contribute it yesno yes describe the feature and the current behaviorstate the current behaviour for is to cache the input to be used if the inverse function is called i would very much like a keyword being able to turn this caching off to ensure the inverse function of the bijector is always called whilst setting the property of isinjective can accomplish this you lose other features will this change the current api how yes a keyword in the definition of the bijector class who will benefit with this feature anyone who wishes to have bijectors where the inverse function is always called rather than the input thats been cached any other info"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGradient for tf.sparse.reduce_max\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate describe the feature and the current behaviorstate tfsparsereducemax do not define grad so it cannot be used in training step will this change the current api how wont change current api just add grad in tfsparsereducemax who will benefit with this feature people using sparsereducemax in training if they have huge sparse matrix and cannot turn to dense array any other info i am working with pointnetlike model and it will take a huge sparse matrix if i turn this sparse matrix to dense it will take 60g memory so i need do global maxpooling using tf sparse reducemax unfortunately it cannot be used in training right now thanks"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\niterating over `tf.Tensor` is not allowed\nplease make sure that this is a bug as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagbugtemplate system information have i written custom code as opposed to using a stock example script provided in tensorflow yes os platform and distribution eg linux ubuntu 1604 mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on mobile device tensorflow installed from source or binary tensorflow version use command below 23 python version38 bazel version if compiling from source gcccompiler version if compiling from source cudacudnn version gpu model and memory you can collect some of this information using our environment capture script you can also obtain the tensorflow version with 1 tf 10 python c import tensorflow as tf printtfgitversion tfversion 2 tf 20 python c import tensorflow as tf tfversionversion describe the current behavior i have a dictionary that i build by accessing only the channel dimensions of an output layer of a convolutional neural network it has a shape 10024246 therefore keys of this dictionary are tuples of tensor shape 6 i want to map these keys to the input of the next layer using the tfmapfn however i am incapable of doing it because the keys of my dictionary are of type tensor and i cannot iterate over them looking for some help thank you describe the expected behavior contributing do you want to contribute a pr yesno briefly describe your candidate solutionif contributing standalone code to reproduce the issue provide a reproducible test case that is the bare minimum necessary to generate the problem if possible please share a link to colabjupyterany notebook other info logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCount number of leaves in the ensemble gradient BoostedTree\nthis is an issue related to the performance of system information tensorflow version you are using 270 are you willing to contribute it yesno yes describe the feature and the current behaviorstate is there any method that returns the number of entire leaves in the built ensemble if the feature already exists would you please introduce it a bit more here if not could we develop it will this change the current api how no who will benefit with this feature users of the tensorflow"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nnormalization should be done using moving averages?\nurls with the issue description of issue what needs changing hello this is a small feature request in the time series tutorial at the normalization section in the 3rd paragraph there is a remark saying and that this normalization should be done using moving averages i am very curious on how a moving average would be used here should a simple moving average for the whole dataset be computed and then on that new datasetma just use the normalization technique that is described in the tutorial the feature i am requesting is something like a remark on how this would be done or maybe a pointer to different tutorial if one exists or some further referencesresearch users could look into"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUsing scipy fsolve or other solvers (e.g. GEKKO) in combination with backpropagation models\ni was wondering if there was any progress or existing methodologies to use existing solvers such as gekko to findupdate certain values in your network eg when using pinn networks on a electrical circuit one might use a variable resistance dependent on one of your network input parameters when this dependency is given by an explicit equation it would be nice to given the inputs be able to use existing solvers as scipys fsolve to get this value and use it further on in the network from my experience in order to be able to use solvers tensors should be converted to numpy elements and used in combination with tfnumpyfunction this way i can use solvers as such however it breaks the chain of gradients and tf can no longer find gradients for certain values and thus no longer train the network system information tensorflow 230 but using some tf1 functionalities from tfcompatv1 no possibility to share existing code but see below for small hypothetical case example start of code from scipyoptimize import fsolve class def initself superppinlayer selfinitkwargs def callself input nn args nnoutput nninput this is a nn already initialized somewhere else with trainable parameters output selffnnoutput input return output the output is then used later on to compare with labeled data as loss function for training def fself nnoutput input r0 input0 r1 input1 v0 input2 def r2eqr2 r0 r1 return npexpr2r1 r1r2 r02 r2 fsolver2eq 0 argsr0 r1 return v0r0 r2 thanks in advance cedric"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[TFLite] Optional Debug Tools can only support log in Desktop Computer\nhi tensorflowers the in minimalcc can only be used on computer system with desktop because it use printf style to output info in optionaldebugtoolscc not the tflitelog in minimallogging the better way supporting more systems besides why not use something like stdstringstream to format info that seems more general"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nI have made wrapper of Tensor \nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate system information tensorflow version you are using are you willing to contribute it yesno latest github release describe the feature and the current behaviorstate graph will this change the current api how nope who will benefit with this feature everyone any other info i have started wrapper of tensorflow using cppflow i need some help with graph it is unclear how it works in c api i am thinking of wrapping c api it works for all swig languages the question is does capi suppot the graph enough to use it or should i wrap the c api"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntf.data.dataset gather element\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate system information tensorflow version you are using tensorflow 27 are you willing to contribute it yesno no describe the feature and the current behaviorstate i want to do something like tfgather on tfdatadataset for example dataset b c d e f g h i choicedataset define a dataset containing 0 1 2 0 1 2 i want it to output a dataset having a b c a b c this is somewhat similar to choosefromdatasets but that method choose from multiple datasets not element in the dataset will this change the current api how add new method to tfdatadataset who will benefit with this feature tensorflow dataset user any other info i am not sure if there is a workaround please correct me if i am wrong"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRequest for RandomIllumination layer in keras\nsomething like this already is possible with imagedatagenerator but with corners in it only applies brightness scale what is needed is a full keras layer that randomize illumination differences spatially across the image or even a single scaling factor to the whole image i think more ideas can be added to something like this if it was implemented properly"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRelease tensorflow-macos wheel compatible with Python 3.9 and x86\ncurrently in version 270 of tensorflowmacos there are only 3 wheels released in pip 2 for arm64 supporting python 3839 and 1 for x86 only supporting python 38 it would be great to have also a wheel for python 39 for the x86 architecture the same thing also applies for tensorflowmetal system information tensorflow version you are using 270 describe the feature and the current behaviorstate see above will this change the current api how no who will benefit with this feature every intel mac user with python 39 any other info"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntf.debugging.assert_type throws error when checking type of RaggedTensor\nplease make sure that this is a bug as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagbugtemplate system information have i written custom code as opposed to using a stock example script provided in tensorflow yes os platform and distribution eg linux ubuntu 1604 ubuntu 18046 lts mobile device eg iphone 8 pixel 2 samsung galaxy if the issue happens on a mobile device na tensorflow installed from source or binary binary tensorflow version use command below 270 python version 390 bazel version if compiling from source na gcccompiler version if compiling from source na cudacudnn version na gpu model and memory na you can collect some of this information using our environment capture script you can also obtain the tensorflow version with 1 tf 10 python c import tensorflow as tf printtfgitversion tfversion 2 tf 20 python c import tensorflow as tf tfversionversion describe the current behavior when calling on a raggedtensor a valueerror typeerror object of type raggedtensor has no len is thrown describe the expected behavior the assertion check should pass if the ragged tensor is the correct type or fail otherwise contributing do you want to contribute a pr yesno no briefly describe your candidate solutionif contributing na standalone code to reproduce the issue provide a reproducible test case that is the bare minimum necessary to generate the problem if possible please share a link to colabjupyterany notebook python import tensorflow as tf a tfraggedconstant1 2 1 tftypetfint32 should pass valueerror typeerror object of type raggedtensor has no len other info logs include any logs or source code that would be helpful to diagnose the problem if including tracebacks please include the full traceback large logs and files should be attached workaround import tensorflow as tf a tfraggedconstant1 2 1 assert adtype tfint32"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupport partial parameter warm-start from pretrained checkpoints in tensorflow v2 (non-estimator mode)\nplease make sure that this is a feature request as per our github policy we only address codedoc bugs performance issues feature requests and buildinstallation issues on github tagfeaturetemplate system information tensorflow version you are using tensorflow 2x are you willing to contribute it yesno no describe the feature and the current behaviorstate warmstarting from an existing checkpoint is an important feature for all kinds of model training thats well supported under tfestimator framework the latter unfortunately seems relegated to second class status in tensorflow 2x since its not eager at least not natively the closest way to achieve warmstart in tf2x seems to be via tftraincheckpoint a more directly approach than that is if implemented well so far however i see that it supports loading all the parameters in a checkpoint altogether but not loading only some of the parameters will this change the current api how possibly maybe provide a kwarg in checkpoint initializer called parameterlist who will benefit with this feature anyone who wants to reuse a pretrained model but not all of its parameters any other info there is a lot of emphasis on eagerness efficiency in tensorflow v2 but in my opinion not sufficient focus on flexibility and directness of usage so far warmstarting is one example update my colleague found an unofficial implementation of flexible warmstart from a checkpoint in the tf2 version of bert here i would recommend adding some official examples along similar lines"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNew dtype: bcomplex32 \nsystem information tensorflow version you are using 27 are you willing to contribute it yesno probably yes describe the feature and the current behaviorstate add bcomplex32 dtype currently only a real like in math real field version is supported bfloat16 will this change the current api how each function that supports the dtype paramter should also support the new bcomplex32 who will benefit with this feature anyone who uses the complex plane and wants a speedup for further calculations on supported hardware such as gpus with compatibility level of 7 and above for example while using fft any other info"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCan I repeat a 1-D tensor in segment form?\naccording to the doc tf has tfsegmentxxx and tfrepeat but can i repeat a 1d tensor in segment form example segment 0 0 0 1 1 value 0 1 2 3 4 1 if repeatcnt 2 2 2 1 1 with tfrepeat i can easily repeat value to 0 0 1 1 2 2 3 4 2 but i want a segment repeat which means segment0 repeat 2 times segment1 repeat 1 time that is to say if repeatcntnew 2 1 and i want to repeat value to 0 1 2 0 1 2 3 4 i mean repeat blocks in a vector 0 1 2 2 3 4 1 are there any tf func or api can help thanks"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nLSTM expansion\nsystem information tensorflow version you are using 13 are you willing to contribute it yesno maybe describe the feature and the current behaviorstate simple lstms have limitations it cannot extract some features ie some mathematical operands conditional logic etc i dont think the lstm advancements cover this this paper kind of shows what logic needs to be part of lstm out of the box can we improve the lstm to include ability to figure out some basic logic like mathematical operands and conditional logic will this change the current api how shouldnt who will benefit with this feature everyone any other info lstm is brokened at the moment pretty rudimentary"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nKeyError: 'min'\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version tf 213 custom code yes os platform and distribution mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version 122 gpu model and memory no response current behavior traceback most recent call last file o2kpy line 11 in kmodel onnxtokerasonnxmodel input1 namepolicyrenumerate verbosetrue file line 175 in onnxtokeras file line 31 in convertclip if paramsmin 0 keyerror min standalone code to reproduce the issue shell from onnx2keras import onnxtokeras import keras import onnx import sys syspathappendrootmr onnxmodel onnxinputs onnxmodelgraphinput print printonnxinputs onnxmodel onnxloadvgg11onnx kmodel onnxtokerasonnxmodel input1 namepolicyrenumerate verbosetrue ssdbmv1torchh5 overwritetrue saveformath5 onnx file can be downloaded at relevant log output shell traceback most recent call last file o2kpy line 11 in kmodel onnxtokerasonnxmodel input1 namepolicyrenumerate verbosetrue file line 175 in onnxtokeras file line 31 in convertclip if paramsmin 0 keyerror min"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAttributeError: Number of inputs is not equal 1 for unsqueeze layer\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version tf 213 custom code yes os platform and distribution mobile device no response python version 3817 bazel version no response gcccompiler version no response cudacudnn version 122 gpu model and memory no response current behavior traceback most recent call last file o2kpy line 11 in kmodel onnxtokerasonnxmodel onnxunsqueeze0 namepolicyrenumerate verbosetrue file line 175 in onnxtokeras file line 210 in convertunsqueeze raise attributeerrornumber of inputs is not equal 1 for unsqueeze layer attributeerror number of inputs is not equal 1 for unsqueeze layer standalone code to reproduce the issue shell please run the below codes to reproduce from onnx2keras import onnxtokeras import keras import onnx import sys syspathappendrootmr onnxmodel onnxinputs onnxmodelgraphinput print printonnxinputs onnxmodel onnxloadvgg11onnx kmodel onnxtokerasonnxmodel onnxunsqueeze0 namepolicyrenumerate verbosetrue textcnntorchh5 overwritetrue saveformath5 onnx file can be downloaded at relevant log output shell traceback most recent call last file o2kpy line 11 in kmodel onnxtokerasonnxmodel onnxunsqueeze0 namepolicyrenumerate verbosetrue file line 175 in onnxtokeras file line 210 in convertunsqueeze raise attributeerrornumber of inputs is not equal 1 for unsqueeze layer attributeerror number of inputs is not equal 1 for unsqueeze layer"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nValueError: Exception encountered when calling layer \"13\" (type Lambda).\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 213 custom code yes os platform and distribution mobile device no response python version 3817 bazel version no response gcccompiler version no response cudacudnn version 122 gpu model and memory no response current behavior html xmlns link idmainfile relmainfile link relfilelist table page margin75in 7in 75in 7in msoheadermargin3in msofootermargin3in font5 colorwindowtext fontsize90pt fontweight400 fontstylenormal textdecorationnone fontfamily等线 msofontcharset134 tr msoheightsourceauto col msowidthsourceauto br td paddingtop1px paddingright1px paddingleft1px msoignorepadding colorblack fontsize110pt fontweight400 fontstylenormal textdecorationnone fontfamily等线 msofontcharset134 textaligngeneral verticalalignmiddle bordernone msopatternauto msoprotectionlocked visible whitespacenowrap msorotate0 xl65 textaligncenter xl66 textaligncenter whitespacenormal ruby rubyalignleft rt colorwindowtext fontsize90pt fontweight400 fontstylenormal textdecorationnone fontfamily等线 msofontcharset134 msochartypenone displaynone valueerror exception encountered when calling layer 13 type lambda dimensions must be equal but are 204 and 206 for node 13add placeholder1 with input shapes 64204204 64206206 call arguments received by layer 13 type lambda • 64 204 204 dtypefloat32 tftensorshapenone 64 206 206 dtypefloat32 • masknone • trainingnone standalone code to reproduce the issue shell just run the following code to reproduce from onnx2keras import onnxtokeras import keras import onnx import sys syspathappendrootmr onnxmodel onnxinputs onnxmodelgraphinput print printonnxinputs onnxmodel onnxloadvgg11onnx kmodel onnxtokerasonnxmodel x namepolicyrenumerate verbosetrue overwritetrue saveformath5 the onnx file can be downloaded at relevant log output shell traceback most recent call last file o2kpy line 11 in kmodel onnxtokerasonnxmodel x namepolicyrenumerate verbosetrue file line 175 in onnxtokeras file line 83 in layersnodename lambdalayerinput0 input1 file line 70 in errorhandler raise from none file line 76 in targetlayer layer tfadd valueerror exception encountered when calling layer layer12 type lambda dimensions must be equal but are 204 and 206 for node layer12add placeholder1 with input shapes 64204204 64206206 call arguments received by layer layer12 type lambda • 64 204 204 dtypefloat32 tftensorshapenone 64 206 206 dtypefloat32 • masknone • trainingnone"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTraining Vanilla Transformer on TPU gives InternalError\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version 2130 custom code yes os platform and distribution linux ubuntu 22042 google colab mobile device colab python version 31012 bazel version colab gcccompiler version colab cudacudnn version colab gpu model and memory colab current behavior training transformer model on tpu gives internal error i have some idea on the error that theres a incompatible tensor ops thats causing the problem but i cant pinpoint it i had already done a bigger model which is using pretrained embeddings and it went off without a hitch i tried to replicate the same but with different tfds dataset if this is already solved please direct me to the relevant links standalone code to reproduce the issue this is the notebook this notebook worked fine thankyou in advance i will respond asap relevant log output shell internalerror traceback most recent call last in 1 modelfit 2 trainds 3 4 epochsepochs 5 1 frames in errorhandlerargs kwargs 68 to get the full stack trace call 69 70 raise from none 71 finally 72 del filteredtb in capturebyvalueself graph tensor name 120 graphconst 121 if graphconst is none 122 graphconst pylint 123 if graphconst is none 124 some eager tensors eg parallel tensors are not convertible to internalerror failed to connect to all addresses last error unknown ipv412700135437 failed to connect to remote host connection refused additional grpc error information from remote target unknownfailed to connect to all addresses last error unknown ipv412700135437 failed to connect to remote host connection refused grpcstatus14 executing noncommunication op originally returned unavailableerror and was replaced by internalerror to avoid invoking tf network error handling logic"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBody function of `while_loop` cannot access the external variable after compilation \nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2150dev20230914 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior the body function of whileloop cannot access the external variable after compilation it will raise the error unboundlocalerror local variable x referenced before assignment however if i run the model without the the model can be executed without any error standalone code to reproduce the issue shell class modeltfkerasmodel def initself supermodel selfinit comment this line it will succeed def callself x def condi return i 10 def bodyi y y tfmathaddy 20 x tfmathmultiplyx 20 return tfmathsubtracti 1 y x i tfconstant10 y tfconstant10 finaly tfwhileloopcond body i y yshape return finaly m model inputshape 12 x tfconstant45 shapeinputshape y mx relevant log output shell unboundlocalerror exception encountered when calling layer model28 type model in user code file line 16 in body x tfmathmultiplyx 20 unboundlocalerror local variable x referenced before assignment call arguments received by layer model28 type model • xtftensorshape1 2 dtypefloat32"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCould not find matching concrete function to call loaded from the SavedModel\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf210 custom code yes os platform and distribution win10 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior how to match data of signature standalone code to reproduce the issue shell saveformattf signaturesnone localmodel ylocalpred ymodelpred modelpredictxtest printylocalpred ymodelpred ymodelpred userinputs nameinputs0 nameinputs1 nameinputs2 useroutputs relevant log output shell could not find matching concrete function to call loaded from the savedmodel got positional arguments 1 total keyword arguments expected these arguments to match one of the following 1 options option 1 positional arguments 1 total tensorspecshapenone 5 dtypetffloat32 nameinputs0 tensorspecshapenone 10 dtypetfint32 nameinputs1 tensorspecshapenone 3 5 dtypetfint32 nameinputs2 keyword arguments"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nValueError: Unable to create dataset (name already exists)\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior epoch 110 11 eta 0s loss 68405 accuracy 03250 valueerror traceback most recent call last in 1 epochsepochs checkpointcall plotlosses 2 frames in makenewdsetparent shape dtype data name chunks compression shuffle fletcher32 maxshape compressionopts fillvalue scaleoffset tracktimes external trackorder dcpl dapl efileprefix virtualprefix allowunknownfilter rdccnslots rdccnbytes rdccw0 161 sid h5screatesimpleshape maxshape 162 163 dsetid h5dcreateparentid name tid sid dcpldcpl dapldapl 164 165 if data is not none and not isinstancedata empty h5pyobjectspyx in h5pyobjectspyx in h5pyh5dpyx in h5pyh5dcreate valueerror unable to create dataset name already exists i want to save each epoch as a checkpoint two weeks back back without any any error each checkpoint will save as a checkpoint but suddenly now getting error standalone code to reproduce the issue shell import matplotlibpyplot as plt from import callback import os checkpointdir modelcheckpointsm1 if not from import earlystopping earlystop patience3 set up the model checkpoint callback checkpointcall monitorvalloss savebestonlytrue saveweightsonlyfalse modemin savefreqepoch epochsepochs checkpointcall relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbazel  test failed with some ctest\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf212 custom code yes os platform and distribution centos76 mobile device no response python version 39 bazel version 530 gcccompiler version 931 cudacudnn version no response gpu model and memory no response current behavior after compiling tensorflow based on the source code bazel test is executed for unit testing some test items are passed but there are many failures and the reasons for the error are as follows so i want to know if im executing the statement incorrectly how should i set it up bazel test c opt configcuda output information exec pagerusrbinless 0 exit 1 executing tests from image image standalone code to reproduce the issue shell bazel test c opt configcuda relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to open file (truncated file: eof = 2568306, sblock->base_addr = 0, stored_eof = 9406464)\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version 2130 custom code no os platform and distribution mac os 1351 mobile device no response python version 3113 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior oserror traceback most recent call last cell in15 line 3 1 create the base model from the pretrained model mobilenet v2 2 imgshape imgsize 3 3 basemodel 4 includetopfalse 5 weightsimagenet file in alpha includetop weights inputtensor pooling classes classifieractivation kwargs 477 weightpath baseweightpath modelname 478 weightspath datautilsgetfile 479 modelname weightpath cachesubdirmodels 480 481 482 elif weights is not none 483 file in kwargs 67 filteredtb 68 to get the full stack trace call 69 70 raise from none 71 finally 72 del filteredtb file h5pyobjectspyx55 in file h5pyh5fpyx106 in h5pyh5fopen oserror unable to open file truncated file eof 2568306 sblockbaseaddr 0 storedeof 9406464 standalone code to reproduce the issue shell create the base model from the pretrained model mobilenet v2 imgshape imgsize 3 basemodel includetopfalse weightsimagenet relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nXLA compiled tf.where with known output shape error (set_shape, tf.concat / tf.stack)\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 213 custom code no os platform and distribution google colab mobile device no response python version 31012 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior output of tfwhere when used inside tffunction with jitcompiletrue can sometimes be used correctly as with sum and sometimes raises shape mismatch error as with concatenation this error is present even if output shape is set manually with setshape the code below runs without jitcompile or with sum instead of tfconcat and only fails if concatenating inside a compiled function note autoclustering solves the issue on the toy example but not on the codebase i am working on standalone code to reproduce the issue colab python import tensorflow as tf def funx y x tfwherex 1 printfshape before unknown xshape 2 printfshape after known xshape return tfconcatxy axis1 concatentation fails return x y sum would succeed x tfconstant00110 01010 10001 10100 01100 dtypetfint32 y 2 dtypetfint64 axis1 funx y tffunctionfunxy tffunctionfun jitcompiletruexy fails as described above relevant log output shell shape before unknown none 2 shape after known 10 2 invalidargumenterror cannot concatenate arrays that differ in dimensions other than the one being concatenated dimension 0 in both shapes must be equal s64252 vs s64101"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWill there a MLP model in the future version?\nissue type feature request have you reproduced the bug with tensorflow nightly no source source tensorflow version 2130 custom code no os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior when building deep learning models like multilayer perceptrons mlps code reusability and conciseness are crucial factors currently using tfkerassequential in tensorflow allows for convenient creation of sequential models however manually adding common operations such as batch normalization or dropout to each layer can lead to code redundancy and an increased burden in terms of coding and maintenance therefore proposing the addition of a feature in tensorflow to directly create mlps with batch normalization and dropout is highly beneficial here are several reasons why this feature would be advantageous for tensorflow users 1 simplified code users wont need to manually add batch normalization and dropout operations to each layer resulting in cleaner more readable and maintainable code 2 reduced error rate manual copypasting of code is errorprone especially as model complexity increases automating the integration of batch normalization and dropout operations can reduce issues arising from code errors 3 increased productivity developers can build and iterate on models more swiftly focusing on design and parameter tuning rather than rewriting the same code segments for every new model 4 education and learning for newcomers to tensorflow this feature can provide a quicker onboarding process lowering the learning curve and enabling them to grasp and apply deep learning concepts faster certainly heres the additional information i also believe that pytorch has implemented mlp functionality quite effectively an example of this can be found in the following url pytorch mlp pytorchs approach to creating mlps provides a good reference for how tensorflow could potentially integrate similar features standalone code to reproduce the issue shell origin model tfkerassequential tfkeraslayersrelu tfkeraslayersdense64 tfkeraslayersrelu tfkeraslayersdense32 tfkeraslayersrelu tfkeraslayersdense10 with mlp model python model tfkerasmlp hiddenchannels128 64 32 10 dropout02 relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nextensions eglQueryDevicesEXT, eglQueryDeviceAttribEXT and eglGetPlatformDisplayEXT not available\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 1131 custom code yes os platform and distribution unbuntu 22 mobile device no response python version python 27 bazel version no response gcccompiler version 940 cudacudnn version 10 gpu model and memory gtx 1060 current behavior hi i got this error when i run dirt model with my tensorflowgpu 1131 20230825 152337711796 f extensions eglquerydevicesext and not available standalone code to reproduce the issue shell import numpy as np import tensorflow as tf import dirt canvaswidth canvasheight 128 128 centrex centrey 32 64 squaresize 16 def getnondirtpixels xs ys tfrangecanvasheight xs tfcastxs tffloat32 05 ys tfcastys tffloat32 05 xinrange tflessequaltfabsxs centrex squaresize 2 yinrange tflessequaltfabsys centrey squaresize 2 return yinrange tffloat32 def getdirtpixels build square in screen space squarevertices tfconstant0 0 0 1 1 1 1 0 dtypetffloat32 squaresize squaresize 2 squarevertices centrex centrey transform to homogeneous coordinates in clip space squarevertices squarevertices 2 canvaswidth canvasheight 1 squarevertices tfzeros4 1 tfones4 1 axis1 return dirtrasterise faces0 1 2 0 2 3 vertexcolorstfones4 1 canvaswidth 1 heightcanvasheight widthcanvaswidth channels1 0 def main if in tfversion and inttfversionsplit0 2 session tfsession with sessionasdefault nondirtpixels getnondirtpixelseval dirtpixels getdirtpixelseval else nondirtpixels dirtpixels getdirtpixelsnumpy if npallnondirtpixels dirtpixels printsuccessful all pixels agree else printfailed pixels dirtpixels if name main main relevant log output shell 20230825 152337181664 i your cpu supports instructions that this tensorflow binary was not compiled to use sse41 sse42 avx avx2 fma 20230825 152337186756 i cpu frequency 2496000000 hz 20230825 152337189184 i xla service 0x24d6bf0 executing computations on platform host devices20230825 152337189205 i streamexecutor device 0 20230825 152337478413 e could not open file to read numa node your kernel may have been built without numa support 20230825 152337478518 i xla service 0x233ae60 executing computations on platform cuda devices20230825 152337478540 i streamexecutor device 0 nvidia geforce gtx 1060 6gb compute capability 61 20230825 152337478666 i found device 0 with properties name nvidia geforce gtx 1060 6gb major 6 minor 1 memoryclockrateghz 17085 pcibusid 000001000 totalmemory 600gib freememory 509gib 20230825 152337478681 i adding visible gpu devices 0 20230825 152337478801 i device interconnect streamexecutor with strength 1 edge matrix 20230825 152337478813 i 0 20230825 152337478817 i 0 n 20230825 152337478968 i could not identify numa node of platform gpu id 0 defaulting to 0 your kernel may not have been built with numa support 20230825 152337479033 i created tensorflow device with 4913 mb memory physical gpu device 0 name nvidia geforce gtx 1060 6gb pci bus id 000001000 compute capability 61 20230825 152337711796 f extensions eglquerydevicesext and not available aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBatch matmul imprecision\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 213 2140dev20230706 custom code yes os platform and distribution linux ubuntu 2004 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version mamba list grep cu cudanvcc 122128 0 nvidia cudatoolkit 1180 h4ba93d112 condaforge nvidiacublascu11 202248 pypi0 pypi nvidiacublascu117 1110125 pypi0 pypi nvidiacudanvrtccu11 202248 pypi0 pypi nvidiacudanvrtccu117 11750 pypi0 pypi nvidiacudnncu11 89425 pypi0 pypi gpu model and memory nvidia geforce rtx 3060 12 gb driver version 5206105 current behavior im trying to do a batch matrix multiply ie ive got a bunch of m x n matrices all in one tensor and i want to do a matrix multiply of each of them with some other matrix however im getting slightly different results than i get from numpy and previous tensorflow versions this script passed for me in 29 one interesting thing is that the value 25 the second dimension of x is significant if i reduce this to 16 or below it passes also if i change the second dimension of c from 2 to 1 it also passes standalone code to reproduce the issue python import numpy as np import tensorflow as tf printffile tffile printfgit version tfversiongitversion printfversion tfversion rng nprandomrandomstate0 x rnguniform1 1 size1 25 5astypenpfloat32 c rnguniform1 1 size5 2astypenpfloat32 y x c x2 nptilex 2 1 1 y2 x2 c for y2i in y2 ysqueeze0 tols dictatol1e7 rtol1e5 z tfmatmulx cnumpy z tfeinsumtqqrtr x c y tols z2 tfmatmulx2 cnumpy z2 tfeinsumtqqrtr x2 c y2 tols relevant log output shell file git version version 2140dev20230706 traceback most recent call last file testbatchpy line 26 in y2 file line 1592 in assertallclose actual desired errmsgstrerrmsg file line 75 in inner return funcargs kwds file line 862 in assertarraycompare raise assertionerrormsg assertionerror not equal to tolerance rtol1e07 atol0 mismatched elements 100 100 100 max absolute difference 000046098 max relative difference 001047752 x array0187503 0005696 0255552 084404 0268836 1250793 y array0187499 0005691 0255404 0844322 0268935 1251033"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTF Quantizer breaks pip package\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version git head custom code no os platform and distribution ubuntu 2004 mobile device na python version 3916 bazel version 610 gcccompiler version 1606 cudacudnn version na gpu model and memory na current behavior the commit added to the pip package but the build fails to set the rpath for in the new so leading to a failure in auditwheel when attempting to repair to make it manylinux2014 compatible standalone code to reproduce the issue shell python3 m auditwheel repair plat manylinux2014aarch64 wheeldir whl relevant log output shell python3 m auditwheel repair plat manylinux2014aarch64 wheeldir whl traceback most recent call last file line 198 in runmoduleasmain file line 88 in runcode file line 6 in sysexitmain file line 59 in main rval argsfuncargs p file line 173 in execute outwheel repairwheel file line 80 in repairwheel raise valueerror valueerror cannot repair wheel because required library could not be located also ldd linuxvdsoso1 0x0000ffffb8af9000 0x0000ffffb6800000 not found libdlso2 0x0000ffffb8923000 libpthreadso0 0x0000ffffb88f2000 libmso6 0x0000ffffb8847000 libstdcso6 0x0000ffffb661b000 libgccsso1 0x0000ffffb8823000 libcso6 0x0000ffffb64a8000 libldlinuxaarch64so1 0x0000ffffb8ac9000 librtso1 0x0000ffffb8809000 compare with ldd linuxvdsoso1 0x0000ffffa40a2000 0x0000ffffa1e00000 0x0000ffffa1c0a000 libdlso2 0x0000ffffa3ee5000 libmso6 0x0000ffffa3e3a000 libpthreadso0 0x0000ffffa3e09000 libstdcso6 0x0000ffffa1a25000 libgccsso1 0x0000ffffa3de5000 libcso6 0x0000ffffa18b2000 libldlinuxaarch64so1 0x0000ffffa4072000 librtso1 0x0000ffffa3dcd000 libtensorflowccso2 0x0000ffff8be00000 libmldtypessoso 0x0000ffffa3d99000 libompso5 0x0000ffff8bcc0000"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/interpreter.py\", line 915, in invoke     self._interpreter.Invoke() RuntimeError: tensorflow/lite/kernels/concatenation.cc:158 t->dims->data[d] != t0->dims->data[d] (1 != 2)Node number 304 (CONCATENATION) failed to prepare.\n1 system information image os platform and distribution linux ubuntu 2004 tensorflow installation 291nv229 2 code import numpy as np import tensorflow as tf def main load the tflite model and allocate tensors interpreter return get input and output tensors inputdetails outputdetails test the model on random input data inputshape inputdetails0shape inputdata dtypenpfloat32 inputdata signatures printsignatures interpreterinvoke return the function gettensor returns a copy of the tensor data use tensor in order to get a pointer to the tensor outputdata printoutputdata if name main main how to get the model i used a library here to get a unet with efficientnetb0 as encoder so you can try to use my script to get the model backbone efficientnetb0 batchsize 1 classes background target others lr 00001 epochs 10 preprocessinput define network parameters nclasses 1 if lenclasses 1 else lenclasses 1 case for binary and multiclass segmentation activation sigmoid if nclasses 1 else softmax create model model smunetbackbone classesnclasses activationactivation"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCheck failed when running tensorflow.python.ops.gen_nn_ops.max_pool_grad_with_argmax\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior specific input combination is caused check failure standalone code to reproduce the issue shell import tensorflow as tf import numpy as np from tensorflowpythonops import gennnops try try with tfdevicecpu arg0tensor tfrandomuniform2 3 3 1 dtypetffloat32 arg0 tfidentityarg0tensor arg1tensor tfrandomuniform2 2 2 1 dtypetffloat32 arg1 tfidentityarg1tensor arg2tensor tfrandomuniform2 2 2 1 minval256 maxval257 dtypetfint64 arg2 tfidentityarg2tensor ksize0 1 ksize1 2 ksize2 2 ksize3 1 ksize strides0 1 strides1 1 strides2 1 strides3 1 strides padding valid includebatchinindex false out except exception as e printerrorstre try with tfdevicegpu0 arg0 tfidentityarg0tensor arg0 tfcastarg0 tffloat32 arg1 tfidentityarg1tensor arg1 tfcastarg1 tffloat32 arg2 tfidentityarg2tensor arg2 tfcastarg2 tfint64 ksize strides except exception as e printerrorstre except exception as e printerrorstre relevant log output shell 20230821 003614553160 f check failed gradoutindex outputstart gradoutindex outputend invalid output gradient index 77 0 18 aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCannot build tensorflow from source\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version latest custom code yes os platform and distribution debian 12 mobile device no response python version python 38 bazel version latest gcccompiler version clang 16 cudacudnn version dont have gpu model and memory dont have current behavior i tried several times still same error searched on google found nothing standalone code to reproduce the issue shell i follow the guide from tensorflowcom but still faced this error please help relevant log output shell myenv bazel build j 2 configopt verbosefailures info options provided by the client inherited common options isatty1 terminalcolumns189 info reading rc options for build from inherited common options info reading rc options for build from build options define define c opt announcerc definegrpcnoarestrue configshortlogs configv2 info reading rc options for build from build options actionenv actionenv actionenv info found applicable config definition buildshortlogs in file info found applicable config definition buildv2 in file definetfapiversion2 info found applicable config definition buildopt in file coptwnosigncompare info found applicable config definition buildlinux in file hostcoptw coptwnoall coptwnoextra coptwnodeprecated coptwnoarraybounds coptwunusedresult coptwswitch coptwerrorswitch defineprefixusr cxxoptstdc17 hostcxxoptstdc17 configdynamickernels info found applicable config definition builddynamickernels in file info analyzed target 648 packages loaded 42257 targets configured info found 1 target info deleting stale sandbox base error compiling failed killed clang failed error executing command from target cd exec env pwdprocselfcwd tf2behavior1 usrlibllvm16binclang ufortifysource fstackprotector wall wthreadsafety wselfassign wnofreenonheapobject fcolordiagnostics fnoomitframepointer g0 o2 dfortifysource1 dndebug ffunctionsections fdatasections stdc0x md mf fpic dllvmonunix1 dhavebacktrace1 dbacktraceheader dltdlshlibextso dllvmpluginextso dllvmenablethreads1 dhavelibpthread1 dhavepthreadh1 dhaveregisterframe1 dhavesetenvr1 dhavestrerrorr1 dhavesysexitsh1 dhaveunistdh1 dgnusource dhavelinkh1 dhavemallinfo1 dhavesbrk1 dllvmnativearchx86 dllvmversionmajor18 dllvmversionminor0 dllvmversionpatch0 dstdclimitmacros dstdcconstantmacros dstdcformatmacros dblake3useneon0 dblake3noavx2 dblake3noavx512 dblake3nosse2 dblake3nosse41 deigenmpl2only dhavesysuioh dtfusesnappy iquote iquote bazeloutk8optbin iquote iquote iquote externalllvmproject iquote iquote externalnsync iquote iquote iquote iquote externalgif iquote iquote externallibjpegturbo iquote iquote iquote iquote iquote iquote externalfft2d iquote iquote externalhighwayhash iquote iquote externalzlib iquote iquote externaleigenarchive iquote iquote externalmldtypes iquote iquote iquote iquote externalsnappy iquote isystem isystem isystem isystem isystem externalnsyncpublic isystem isystem isystem isystem externalgif isystem isystem isystem isystem externalzlib isystem isystem isystem isystem externaleigenarchive isystem isystem externalmldtypes isystem isystem isystem wnoall wnoextra wnodeprecated wnoignoredattributes wnoarraybounds wunusedresult werrorunusedresult wswitch werrorswitch wnosigncompare stdc17 nocanonicalprefixes ddateredacted dtimestampredacted dtimeredacted c o configuration execution platform in file included from in file included from in file included from in file included from warning parsetype overrides a member function but is not marked override mlirtype parser const note overridden virtual function is here virtual type parser const in file included from in file included from in file included from in file included from warning printtype overrides a member function but is not marked override void printtypemlirtype type printer const note overridden virtual function is here virtual void printtypetype dialectasmprinter const target failed to build info elapsed time 3990011s critical path 34316s info 991 processes 3 internal 988 local failed build did not complete successfully"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nlibtensorflowlite_jni.so (offset 0x2f3000):signal 11 (SIGSEGV), code 2 (SEGV_ACCERR), fault addr 0xa59fdbc0\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version custom code yes os platform and distribution andorid 13 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior our process comvttvaipq use tensorflowlite cause process crash build fingerprint revision 1234 abi arm timestamp 20230506 1436470800 pid 14794 tid 28796 name tfservicet comvttvaipq uid 1000 signal 11 sigsegv code 2 segvaccerr fault addr 0xa59fdbc0 r0 00000004 r1 00000020 r2 00000300 r3 a59fdbc0 r4 31a05640 r5 000002f0 r6 31a05740 r7 a59fe4c0 r8 31a056c0 r9 a5674220 r10 a59fe1c0 r11 31a055c0 ip a59fdec0 sp 84db73e8 lr 832ded97 pc 832f08ac backtrace 00 pc 000258ac offset 0x2f3000 standalone code to reproduce the issue shell the google server background statistics process crash information unable to clarify the steps to reproduce the problem relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOverflow bug when running tf.image.resize\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large elements in the input list standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try arg0tensor tfconstant1000000 shape577 700 3 1 dtypetffloat64 arg0 tfidentityarg0tensor arg10 1610637938 arg11 1250999896764 arg1 arg10arg11 out except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 929338090226 with 1164413628 result 1 opresizebilinear name"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOverflow when running tf.compat.v1.linalg.diag\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large elements in the input list standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try diagonal0000 1111 diagonal0001 1112 diagonal000 diagonal0010 1121 diagonal0011 1122 diagonal001 diagonal00 diagonal0100 1211 diagonal0101 1212 diagonal010 diagonal0110 1221 diagonal0111 1222 diagonal011 diagonal01 diagonal0 diagonal00diagonal01 diagonal1000 2111 diagonal1001 2112 diagonal100 diagonal1010 2121 diagonal1011 2122 diagonal101 diagonal10 diagonal1100 2211 diagonal1101 2212 diagonal110 diagonal1110 2221 diagonal1111 2222 diagonal111 diagonal11 diagonal1 diagonal10diagonal11 diagonal diagonal0diagonal1 name diagpart k 1610637938 paddingvalue 0 align rightleft out except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 12885103520 with 1610637940 result 1 opmatrixdiagv3"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOverflow when running tf.compat.v1.tile\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large elements in the input list standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try inputtensor tfrandomuniform370 1 1024 dtypetffloat32 input multiples0 125091515651 multiples1 125091515651 multiples2 125091515651 multiples nametensor tfrandomuniform dtypetfint32 maxval66860669291904 name tfidentitynametensor name tfvariablename out except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 46283860790870 with 125091515651 result 1 node tile optile"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOverflow bug when running tf.raw_ops.ResizeNearestNeighbor\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large list element standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try imagestensor tfconstant256 shape16 4 5 1 dtypetffloat16 images size0 1250999896764 size1 1610637938 size size0size1 aligncorners false halfpixelcenters false name none out except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 18630618048 with 1610637938 result 1"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOverflow bug when running tf.keras.layers.ZeroPadding2D\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large list element standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try padding00 125091515651 padding01 false padding0 padding00padding01 padding10 125091515651 padding11 125091515651 padding1 padding10padding11 padding padding0padding1 argclass arginput0tensor tfrandomuniform3 300 300 192 dtypetffloat32 arginput0 arginput arginput0 out argclassarginput except exception as e printerrorstre relevant log output shell functionnode encountered overflow when multiplying 2501999793529 with 2501999793530 result 1n t node pad oppadn n call arguments received by layer zeropadding2d type zeropadding2dn • inputstftensorshape1 1 2 2 dtypefloat32n"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOverflow bug when running tf.linalg.diag on colab\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large integer list element standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try diagonal0000 1111 diagonal0001 1112 diagonal000 diagonal0010 1121 diagonal0011 1122 diagonal001 diagonal00 diagonal0100 1211 diagonal0101 1212 diagonal010 diagonal0110 1221 diagonal0111 1222 diagonal011 diagonal01 diagonal0 diagonal00diagonal01 diagonal1000 2111 diagonal1001 2112 diagonal100 diagonal1010 2121 diagonal1011 2122 diagonal101 diagonal10 diagonal1100 2211 diagonal1101 2212 diagonal110 diagonal1110 2221 diagonal1111 2222 diagonal111 diagonal11 diagonal1 diagonal10diagonal11 diagonal diagonal0diagonal1 name none k 92233720368 paddingvalue 0 align rightleft out except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 16315257232 with 2039407154 result 1 opmatrixdiagv3"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOverflow bug when running tf.clip_by_value on colab\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large tensor standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try arg0tensor tfrandomuniform2 472 496 4 1 1024 dtypetffloat64 arg0 tfidentityarg0tensor arg1 0 arg2 false out except exception as e printerrorstre relevant log output shell 215514592 notebookapp searching rootjupyter rootlocaletcjupyter usretcjupyter usrlocaletcjupyter etcjupyter for config 215514592 notebookapp looking for jupyterconfig in 215514594 notebookapp looking for jupyterconfig in 215514601 notebookapp looking for jupyterconfig in 215514602 notebookapp looking for jupyterconfig in 215514602 notebookapp looking for jupyterconfig in 215514604 notebookapp looking for in 215514604 notebookapp loaded config file 215514605 notebookapp looking for in 215514597 notebookapp searching rootjupyter rootlocaletcjupyter usretcjupyter usrlocaletcjupyter etcjupyter for config 215514609 notebookapp loaded config file 215514610 notebookapp looking for in 215514610 notebookapp looking for in 215514610 notebookapp looking for in 215514612 notebookapp loaded config file 215514597 notebookapp looking for jupyterconfig in 215514597 notebookapp looking for jupyterconfig in 215514598 notebookapp looking for jupyterconfig in 215514598 notebookapp looking for jupyterconfig in 215514598 notebookapp looking for jupyterconfig in 215514599 notebookapp looking for in 215514600 notebookapp loaded config file 215514601 notebookapp looking for in 215514603 notebookapp loaded config file 215514603 notebookapp looking for in 215514603 notebookapp looking for in 215514603 notebookapp looking for in 215514606 notebookapp loaded config file notebook server cookie secret to of metrics is off since other authentication is serverextension notebook server cookie secret to of metrics is off since other authentication is serverextension notebooks from local directory notebooks from local directory notebook 655 is running controlc to stop this server and shut down all kernels twice to skip notebook 655 is running controlc to stop this server and shut down all kernels twice to skip started name events for closed stream 215556928312 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 215558601992 w tftrt warning could not find 215604276761 w oprequires failed at tileopscc193 invalidargument encountered overflow when multiplying 500366062604 with 125091515651 result exception was never wrapper done defined at most recent call file line 1087 in await stream is handling of the above exception another exception most recent call file line 232 in result file line 1089 in raise events for closed stream 231717631931 w allocation of 19327655268 exceeds 10 of free system restarting kernel 15 keep random 231954827450 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 231958360271 w tftrt warning could not find 232003457377 w allocation of 15342764032 exceeds 10 of free system restarting kernel 15 keep random"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOverflow when running tf.raw_ops.PadV2\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to the large list of element standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try inputtensor tfrandomuniform16 4 4 512 dtypetffloat32 input paddings00 125091515651 paddings01 125091515651 paddings0 paddings00paddings01 paddings10 125091515651 paddings11 125091515651 paddings1 paddings10paddings11 paddings20 125091515651 paddings21 125091515651 paddings2 paddings20paddings21 paddings30 125091515651 paddings31 125091515651 paddings3 paddings30paddings31 paddings constantvalues 0 name none out except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 250183031318 with 250183031306 result 1 node padv2 oppadv2"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOverflow when running tf.image.pad_to_bounding_box on colab\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large list element standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try arg0000 10 arg0001 20 arg0002 30 arg000 arg0010 40 arg0011 50 arg0012 60 arg001 arg00 arg000arg001 arg0100 70 arg0101 80 arg0102 90 arg010 arg0110 100 arg0111 110 arg0112 120 arg011 arg01 arg010arg011 arg0 arg00arg01 arg1 1 arg2 1 arg3 4 arg4 1676240524292489355 out except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 6704962097169957420 with 3 result 1 node pad oppad name"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOverflow when running tf.keras.layers.ZeroPadding2D\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large list elements standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try padding00 125091515651 padding01 false padding0 padding00padding01 padding10 125091515651 padding11 125091515651 padding1 padding10padding11 padding padding0padding1 argclass arginput0tensor tfrandomuniform3 300 300 192 dtypetffloat32 arginput0 arginput arginput0 out argclassarginput except exception as e printerrorstre relevant log output shell errorexception encountered when calling layer zeropadding2d type zeropadding2d functionnode encountered overflow when multiplying 375274547853 with 250183031602 result 1 node pad oppad call arguments received by layer zeropadding2d type zeropadding2d • inputstftensorshape3 300 300 192 dtypefloat32"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOverflow bug when running tf.pad on colab\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large input tensor standalone code to reproduce the issue shell import tensorflow as tf import numpy as np try try with tfdevicecpu arg0tensor tfrandomuniform12 2 256 513 dtypetffloat32 arg0 tfidentityarg0tensor arg1tensor tfrandomuniform4 2 dtypetfint32 maxval54676034958255 arg1 tfidentityarg1tensor out tfpadarg0arg1 except exception as e printerrorstre try with tfdevicegpu0 arg0 tfidentityarg0tensor arg0 tfcastarg0 tffloat32 arg1 tfidentityarg1tensor arg1 tfcastarg1 tfint32 tfpadarg0arg1 except exception as e printerrorstre except exception as e printerrorstre relevant log output shell errorfunctionnode encountered overflow when multiplying 2206572623628733836 with 75929941 result 1 oppad name errorfunctionnode encountered overflow when multiplying 2206572623628733836 with 75929941 result 1 oppad name"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCannot type \"I Accept\" to extract from hexagon_nn_skel\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version hexagonnnskelv12001 custom code no os platform and distribution android mobile device android python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior same as here running the instantly prints license extraction aborted extractsh5 read p no coprocess aborting extraction done without giving time to write i accept neither does accept option work standalone code to reproduce the issue shell adb push datalocaltmp adb shell cd datalocaltmp chmod x accept relevant log output shell limited or its designated affiliate licensee shall be solely responsible to obtain such separate license from apical limited the provision or license of a pkla product kit to licensee does not convey any license or other right under any patents of qualcomm incorporated or snaptrack inc type i accept if you agree to the terms of the license you didnt accept the license extraction aborted extractsh5 read p no coprocess aborting extraction done hnnthdatalocaltmp"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCrash when running tf.compat.v1.keras.layers.MaxPool2D on colab\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior due to large elements in input lists standalone code to reproduce the issue shell results dict import tensorflow as tf import os import numpy as np try poolsize0 1e38 poolsize1 1048576 poolsize poolsize0poolsize1 strides0 2 strides1 2 strides strides0strides1 padding same dataformat none argclass arginput0tensor tfrandomuniform3 74 74 256 dtypetffloat32 arginput0 arginput arginput0 out argclassarginput except exception as e printerrorstre printresults relevant log output shell 142443837 notebookapp searching rootjupyter rootlocaletcjupyter usretcjupyter usrlocaletcjupyter etcjupyter for config 142443838 notebookapp looking for jupyterconfig in 142443840 notebookapp looking for jupyterconfig in 142443842 notebookapp looking for jupyterconfig in 142443842 notebookapp looking for jupyterconfig in 142443842 notebookapp looking for jupyterconfig in 142443843 notebookapp looking for in 142443847 notebookapp loaded config file 142443847 notebookapp looking for in 142443849 notebookapp loaded config file 142443849 notebookapp looking for in 142443849 notebookapp looking for in 142443849 notebookapp looking for in 142443857 notebookapp loaded config file 142444049 notebookapp searching rootjupyter rootlocaletcjupyter usretcjupyter usrlocaletcjupyter etcjupyter for config 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444059 notebookapp looking for in 142444059 notebookapp loaded config file 142444060 notebookapp looking for in 142444060 notebookapp loaded config file 142444060 notebookapp looking for in 142444060 notebookapp looking for in 142444060 notebookapp looking for in 142444061 notebookapp loaded config file notebook server cookie secret to of metrics is off since other authentication is serverextension notebook server cookie secret to of metrics is off since other authentication is serverextension notebooks from local directory notebook 648 is running controlc to stop this server and shut down all kernels twice to skip notebooks from local directory notebook 648 is running controlc to stop this server and shut down all kernels twice to skip started name 142629531813 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 142632617224 w tftrt warning could not find 142636113889 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636787982 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636788362 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636803571 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636803974 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636804329 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000011 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000338 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000550 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000771 w overriding origvalue setting because the environment variable is set original config value was 142640000816 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 142640077428 w allocation of 6093750902 exceeds 10 of free system 142642860963 f check failed size 0 0 vs restarting kernel 15 keep random 142736094812 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 142737142240 w tftrt warning could not find 142741764145 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741816688 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741826117 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741831423 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741832476 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741833383 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743665264 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743667057 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743668052 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743668828 w overriding origvalue setting because the environment variable is set original config value was 142743669432 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 142743701398 w allocation of 6093750902 exceeds 10 of free system 142748308263 f check failed size 0 0 vs restarting kernel 15 keep random 143109645133 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143110714033 w tftrt warning could not find 143112844776 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112892144 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112894009 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112896074 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112897012 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112897897 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114331805 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114332225 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114332548 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114332751 w overriding origvalue setting because the environment variable is set original config value was 143114332800 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 143118149537 i loaded cudnn version 143118151181 f check failed handleget cudnnmaxpoolingmode propagatenans cudnnpropagatenan cudnnnotpropagatenan nd shapedata paddingdata stridesdata cudnnstatussuccess 3 vs restarting kernel 15 keep random 143258023248 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143300925573 w tftrt warning could not find 143422817441 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422920819 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422921484 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422923040 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422923548 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422924029 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424323413 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424324064 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424324360 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424324522 w overriding origvalue setting because the environment variable is set original config value was 143424324601 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 143429102979 i loaded cudnn version 143429104423 f check failed handleget cudnnmaxpoolingmode propagatenans cudnnpropagatenan cudnnnotpropagatenan nd shapedata paddingdata stridesdata cudnnstatussuccess 3 vs restarting kernel 15 keep random 143439499788 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143441797362 w tftrt warning could not find restarted 143459388548 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143501250311 w tftrt warning could not find 143606143899 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606181829 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606182572 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606184389 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606184737 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606185055 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607232416 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607232868 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607233157 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607233367 w overriding origvalue setting because the environment variable is set original config value was 143607233419 i created device with 13692 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 143607261994 w oprequires failed at matrixdiagopcc273 invalidargument encountered overflow when multiplying 12884901888 with 1610612736 result 143657056526 w allocation of 6093750902 exceeds 10 of free system 143703543980 w oprequires failed at matrixdiagopcc273 invalidargument encountered overflow when multiplying 3046875451 with 3046875451 result 143704268280 w allocation of 6093750784 exceeds 10 of free system 143708172313 w oprequires failed at matrixdiagopcc273 invalidargument encountered overflow when multiplying 3046875392 with 3046875392 result 143816953443 i loaded cudnn version 143816953795 f check failed handleget cudnnmaxpoolingmode propagatenans cudnnpropagatenan cudnnnotpropagatenan nd shapedata paddingdata stridesdata cudnnstatussuccess 3 vs restarting kernel 15 keep random 144146795637 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 144147897333 w tftrt warning could not find 144150174067 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 144150217161 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 144150217535 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 145315973272 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 145315977064 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 145315977438 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 145317404160 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 145317405355 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 145317406091 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 145317406821 w overriding origvalue setting because the environment variable is set original config value was 145317407403 i created device with 13692 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 145317447492 w oprequires failed at matrixdiagopcc273 invalidargument encountered overflow when multiplying 9984734776 with 1248091847 result 145600832626 i loaded cudnn version 145600832804 f check failed handleget cudnnmaxpoolingmode propagatenans cudnnpropagatenan cudnnnotpropagatenan nd shapedata paddingdata stridesdata cudnnstatussuccess 3 vs restarting kernel 15 keep random"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCrash when running tf.keras.layers.MaxPooling2D\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution prettynameubuntu 22042 lts nameubuntu versionid2204 version22042 lts jammy jellyfish versioncodenamejammy idubuntu idlikedebian homeurl supporturl bugreporturl privacypolicyurl ubuntucodenamejammy mobile device no response python version 31012 main jun 11 2023 052628 bazel version no response gcccompiler version gcc 1140 cudacudnn version nvcc nvidia r cuda compiler driver copyright c 20052022 nvidia corporation built on cuda compilation tools release 118 v11889 build gpu model and memory t4 current behavior due to the large list of elements standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np try arg00 1e20 arg01 true arg0 arg00arg01 strides0 2 strides1 2 strides strides0strides1 argclass arginput0tensor tfrandomuniform2 17 17 768 dtypetffloat32 arginput0 arginput arginput0 out argclassarginput except exception as e printerrorstre relevant log output shell 142443837 notebookapp searching rootjupyter rootlocaletcjupyter usretcjupyter usrlocaletcjupyter etcjupyter for config 142443838 notebookapp looking for jupyterconfig in 142443840 notebookapp looking for jupyterconfig in 142443842 notebookapp looking for jupyterconfig in 142443842 notebookapp looking for jupyterconfig in 142443842 notebookapp looking for jupyterconfig in 142443843 notebookapp looking for in 142443847 notebookapp loaded config file 142443847 notebookapp looking for in 142443849 notebookapp loaded config file 142443849 notebookapp looking for in 142443849 notebookapp looking for in 142443849 notebookapp looking for in 142443857 notebookapp loaded config file 142444049 notebookapp searching rootjupyter rootlocaletcjupyter usretcjupyter usrlocaletcjupyter etcjupyter for config 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444056 notebookapp looking for jupyterconfig in 142444059 notebookapp looking for in 142444059 notebookapp loaded config file 142444060 notebookapp looking for in 142444060 notebookapp loaded config file 142444060 notebookapp looking for in 142444060 notebookapp looking for in 142444060 notebookapp looking for in 142444061 notebookapp loaded config file notebook server cookie secret to of metrics is off since other authentication is serverextension notebook server cookie secret to of metrics is off since other authentication is serverextension notebooks from local directory notebook 648 is running controlc to stop this server and shut down all kernels twice to skip notebooks from local directory notebook 648 is running controlc to stop this server and shut down all kernels twice to skip started name 142629531813 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 142632617224 w tftrt warning could not find 142636113889 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636787982 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636788362 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636803571 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636803974 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142636804329 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000011 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000338 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000550 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142640000771 w overriding origvalue setting because the environment variable is set original config value was 142640000816 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 142640077428 w allocation of 6093750902 exceeds 10 of free system 142642860963 f check failed size 0 0 vs restarting kernel 15 keep random 142736094812 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 142737142240 w tftrt warning could not find 142741764145 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741816688 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741826117 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741831423 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741832476 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142741833383 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743665264 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743667057 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743668052 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 142743668828 w overriding origvalue setting because the environment variable is set original config value was 142743669432 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 142743701398 w allocation of 6093750902 exceeds 10 of free system 142748308263 f check failed size 0 0 vs restarting kernel 15 keep random 143109645133 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143110714033 w tftrt warning could not find 143112844776 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112892144 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112894009 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112896074 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112897012 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143112897897 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114331805 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114332225 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114332548 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143114332751 w overriding origvalue setting because the environment variable is set original config value was 143114332800 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 143118149537 i loaded cudnn version 143118151181 f check failed handleget cudnnmaxpoolingmode propagatenans cudnnpropagatenan cudnnnotpropagatenan nd shapedata paddingdata stridesdata cudnnstatussuccess 3 vs restarting kernel 15 keep random 143258023248 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143300925573 w tftrt warning could not find 143422817441 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422920819 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422921484 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422923040 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422923548 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143422924029 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424323413 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424324064 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424324360 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143424324522 w overriding origvalue setting because the environment variable is set original config value was 143424324601 i created device with 13664 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 143429102979 i loaded cudnn version 143429104423 f check failed handleget cudnnmaxpoolingmode propagatenans cudnnpropagatenan cudnnnotpropagatenan nd shapedata paddingdata stridesdata cudnnstatussuccess 3 vs restarting kernel 15 keep random 143439499788 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143441797362 w tftrt warning could not find restarted 143459388548 i this tensorflow binary is optimized to use available cpu instructions in performancecritical enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler 143501250311 w tftrt warning could not find 143606143899 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606181829 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606182572 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606184389 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606184737 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143606185055 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607232416 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607232868 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607233157 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 143607233367 w overriding origvalue setting because the environment variable is set original config value was 143607233419 i created device with 13692 mb memory device 0 name tesla t4 pci bus id 000000040 compute capability 143607261994 w oprequires failed at matrixdiagopcc273 invalidargument encountered overflow when multiplying 12884901888 with 1610612736 result 143657056526 w allocation of 6093750902 exceeds 10 of free system 143703543980 w oprequires failed at matrixdiagopcc273 invalidargument encountered overflow when multiplying 3046875451 with 3046875451 result 143704268280 w allocation of 6093750784 exceeds 10 of free system 143708172313 w oprequires failed at matrixdiagopcc273 invalidargument encountered overflow when multiplying 3046875392 with 3046875392 result 143816953443 i loaded cudnn version 143816953795 f check failed handleget cudnnmaxpoolingmode propagatenans cudnnpropagatenan cudnnnotpropagatenan nd shapedata paddingdata stridesdata cudnnstatussuccess 3 vs restarting kernel 15 keep random"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nInteger overflow when running tf.experimental.numpy.identity\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution prettynameubuntu 22042 lts nameubuntu versionid2204 version22042 lts jammy jellyfish versioncodenamejammy idubuntu idlikedebian homeurl supporturl bugreporturl privacypolicyurl ubuntucodenamejammy mobile device no response python version 31012 main jun 11 2023 052628 bazel version no response gcccompiler version gcc 1140 cudacudnn version cudatoolkit1180nvcc nvidia r cuda compiler driver copyright c 20052022 nvidia corporation built on cuda compilation tools release 118 v11889 build gpu model and memory t4 current behavior due to large integer variable standalone code to reproduce the issue shell results dict import tensorflow as tf import numpy as np try try with tfdevicecpu ntensor 3046875451 n tfidentityntensor dtype tfuint16 out except exception as e printerrorstre try with tfdevicegpu0 n tfidentityntensor n tfcastn tfcomplex64 dtype tfuint16 except exception as e printerrorstre except exception as e printerrorstre printresults relevant log output shell errorfunctionnode encountered overflow when multiplying 3046875451 with 3046875451 result 9163294059803098215 opmatrixdiagv3 name diag complexwarning casting complex values to real discards the imaginary part return intselfnumpy errorfunctionnode encountered overflow when multiplying 3046875392 with 3046875392 result 9163294419334397952 opmatrixdiagv3 name diag"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCould not find a version that satisfies the requirement tensorflow-compression~=2.12.0 (from versions: none)\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version fail custom code yes os platform and distribution no response mobile device no response python version 3912 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior i try to pip intsall tensorflowfederated it fail so i build it on source i pip install requirement requirementstxt then happened this error can i know how to solve this problem standalone code to reproduce the issue shell relevant log output shell error could not find a version that satisfies the requirement from versions none error no matching distribution found for"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTrain Simple Audio Recognition - TinyML\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2120 custom code yes os platform and distribution windows 11 mobile device no response python version 31012 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior issue report error in training audio recognition model description i am trying to train a simple audio recognition model as described in the book tinyml i am using google colab to train the model however i encountered errors during both the installation of dependencies and the training process error during install dependencies when attempting to install dependencies using the command pip uninstall y tensorflow tensorflowestimator tensorboard pip install q i encountered the following error error could not find a version that satisfies the requirement from versions 2120 error no matching distribution found for error during training modulenotfounderror error to begin training upon running the training script with tensorflow in the begin training section i received the following error traceback most recent call last file line 81 in import inputdata file line 35 in from import audioops as contribaudio modulenotfounderror no module named tensorflowcontrib observations i suspect that these errors are occurring because the code provided in the book is intended for tensorflow 115 while i am using tensorflow 2120 since tensorflow 115 is no longer supported not sure how i can resolve this please help me to fix this issue standalone code to reproduce the issue shell relevant log output shell error could not find a version that satisfies the requirement from versions 2120 error no matching distribution found for traceback most recent call last file line 81 in import inputdata file line 35 in from import audioops as contribaudio modulenotfounderror no module named tensorflowcontrib"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCrash when running tensorflow.python.ops.nn_ops.fractional_max_pool\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2100 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to feeding large integer value standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import nnops try arg0tensor tfrandomuniform5 20 20 3 dtypetffloat64 arg0 tfidentityarg0tensor arg10 1 arg11 130 arg12 15 arg13 1 arg1 arg10arg11arg12arg13 seed 125091515651 seed2 1 deterministic true out except exception as e printerrorstre relevant log output shell 20230814 220506501205 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230814 220507064824 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507082027 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507082168 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507082457 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 220507083701 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507083818 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507083916 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507144960 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507145099 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507145198 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 220507145279 i created device with 4205 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 fractionalmaxpool from is deprecated and will be removed in a future version instructions for updating seed2 and deterministic args are deprecated use fractionalmaxpoolv2 segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCrash when running tensorflow.python.eager.context.check_alive\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2100 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior probably due to an invalid string argument standalone code to reproduce the issue shell import tensorflow as tf import numpy as np from import context try try with tfdevicecpu arg0 out except exception as e printerrorstre try with tfdevicegpu0 except exception as e printerrorstre except exception as e printerrorstre relevant log output shell 0230814 214355028346 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355045718 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355045863 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355046195 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 214355047241 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355047355 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355047452 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355101589 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355101732 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355101832 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 214355101916 i created device with 4018 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAbort when running tensorflow.python.ops.gen_ctc_ops.ctc_loss\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to large input tensor standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import genctcops try arg0tensor shape2 2 3 dtypetffloat32 arg0 tfidentityarg0tensor arg1tensor shape4 2 dtypetfint64 arg1 tfidentityarg1tensor arg2tensor tfrandomuniform4 minval256 maxval257 dtypetfint32 arg2 tfidentityarg2tensor arg3tensor tfrandomuniform2 minval256 maxval257 dtypetfint32 arg3 tfidentityarg3tensor false ctcmergerepeated true false out except exception as e printerrorstre relevant log output shell 20230814 213656173477 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656190838 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656190979 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656191266 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 213656191900 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656192006 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656192110 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656252143 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656252287 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656252387 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213656252470 i created device with 4025 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 20230814 213656314614 i loaded cudnn version 8600 20230814 213656327748 f check failed handleget cudnnstatussuccess 3 vs 0 aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAbort when running tensorflow.python.ops.nn_ops.conv3d_transpose\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2100 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to feeding invalid list element standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import nnops try arg0tensor tfrandomuniform2 5 6 4 3 dtypetffloat32 arg0 tfidentityarg0tensor arg1tensor tfrandomuniform3 3 3 2 3 dtypetffloat32 arg1 tfidentityarg1tensor arg20 2 arg21 11 arg22 13 arg23 9 arg24 false arg2 strides0 1 strides1 2 strides2 2 strides3 2 strides4 1 strides padding valid out except exception as e printerrorstre relevant log output shell 20230814 213234731642 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234748917 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234749058 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234749350 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 213234750631 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234750742 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234750840 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234804553 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234804756 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234804893 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 213234804979 i created device with 4009 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 20230814 213234866964 i loaded cudnn version 8600 20230814 213234880076 f check failed handleget cudnnstatussuccess 3 vs 0 aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nInternal Assertion Failure when running tensorflow.python.eager.remote.connect_to_remote_host\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to feeding nan input standalone code to reproduce the issue shell import tensorflow as tf import numpy as np from import remote try try with tfdevicecpu arg0 nan out except exception as e printerrorstre try with tfdevicegpu0 except exception as e printerrorstre except exception as e printerrorstre relevant log output shell 20230814 194647563173 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647580413 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647580559 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647580847 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 194647582229 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647582354 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647582453 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647643352 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647643499 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647643600 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647643684 i created device with 4110 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 20230814 194647645827 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647645936 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647646029 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647646141 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647646236 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 194647646304 i created device with 4110 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 20230814 194647654175 e invalidargument could not interpret nan as a hostport pair e0814 194647654333018 18949 completionqueuecc244 assertion failed queuenumitems 0 aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCrash when running tensorflow.python.ops.gen_array_ops.lower_bound\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2100 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to mismatch between input tensors standalone code to reproduce the issue shell import tensorflow as tf import numpy as np from tensorflowpythonops import genarrayops try try with tfdevicecpu arg0tensor tfrandomuniform2 3 dtypetffloat32 arg0 tfidentityarg0tensor arg1tensor tfrandomuniform2 dtypetffloat32 arg1 tfidentityarg1tensor arg2 tfint32 arg3 false out except exception as e printerrorstre try with tfdevicegpu0 arg0 tfidentityarg0tensor arg0 tfcastarg0 tffloat32 arg1 tfidentityarg1tensor arg1 tfcastarg1 tffloat32 arg2 tfint32 except exception as e printerrorstre except exception as e printerrorstre relevant log output shell 20230814 193709497421 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709514487 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709514629 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709514917 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 193709515817 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709515932 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709516035 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709573389 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709573531 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709573629 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 193709573710 i created device with 4043 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 free invalid pointer aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCrash when running tensorflow.python.ops.gen_list_ops.tensor_list_reserve\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to the large integer value standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import genlistops try elementshapetensor tfrandomuniform0 minval256 maxval257 dtypetfint32 elementshape numelements 1250999896764 elementdtype tffloat64 out except exception as e printerrorstre relevant log output shell 20230814 191202093783 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202111206 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202111351 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202111663 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 191202113096 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202113270 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202113369 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202167538 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202167673 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202167772 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 191202167855 i created device with 4163 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAbort when running tensorflow.python.ops.math_ops.sobol_sample\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2100 custom code no os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to empty input value standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import mathops try arg0 10 arg1 50 arg2 dtype none out except exception as e printerrorstre relevant log output shell 20230814 185753081061 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753098644 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753098788 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753099088 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 185753099985 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753100112 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753100209 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753168279 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753168422 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753168524 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 185753168607 i created device with 3574 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 20230814 185753212928 f check failed 1 numelements 1 vs 0must have a one element tensor aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCrash when running tensorflow.python.eager.context.add_function\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2100 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to feeding none value standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from import context try arg0 none out except exception as e printerrorstre relevant log output shell 20230814 180938431471 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230814 180939008742 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939026368 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939026511 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939026801 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 180939027611 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939027718 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939027812 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939086029 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939086174 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939086268 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 180939086349 i created device with 4023 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsegmentation fault when running tensorflow.python.ops.nn_ops.fractional_max_pool\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2110 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to large input tensor standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import nnops try arg0tensor tfrandomuniform5 20 20 3 dtypetffloat64 arg0 tfidentityarg0tensor arg10 40 arg11 15 arg12 15 arg13 1 arg1 arg10arg11arg12arg13 seed 1 seed2 1 deterministic true out except exception as e printerrorstre relevant log output shell 20230814 163531365070 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230814 163531920926 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163531937761 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163531937904 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163531938205 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230814 163531939360 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163531939470 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163531939568 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163532006452 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163532006593 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163532006693 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230814 163532006775 i created device with 4461 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 fractionalmaxpool from is deprecated and will be removed in a future version instructions for updating seed2 and deterministic args are deprecated use fractionalmaxpoolv2 segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnicodeDecodeError when loading model from a path with Chinese characters.\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 2130 custom code yes os platform and distribution windows 11 22h2 mobile device no response python version 311 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior current behavior when i attempt to use to load a saved model from a folder path that contains chinese characters tensorflow throws a unicodedecodeerror this suggests that tensorflow may not be parsing chinese characters correctly in the folder path expected behavior i expect to be able to load the model correctly from any folder path regardless of whether it contains chinese characters or not if there are limitations on the folder name it should be clearly documented or provide a more descriptive error message standalone code to reproduce the issue shell import tensorflow as tf create a simple model model inputshape1 lossmse modelsave模型 模型 is chinese for model now try to load the saved model loadedmodel relevant log output shell traceback most recent call last unicodedecodeerror utf8 codec cant decode byte 0xa1 in position 27 invalid start byte"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSegmentation fault when running tensorflow.python.framework.importer._GatherReturnElements\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2110 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to feeding none value standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from import importer try arg00 a arg0 arg00 arg1 none arg2 none out except exception as e printerrorstre relevant log output shell 0230813 021014149106 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAbort when running\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2110 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to a negative large integer the behavior is bizarre it would be best if you ran multiple times to see the abort standalone code to reproduce the issue shell import tensorflow as tf import numpy as np from tensorflowpythonops import genmathops try try with tfdevicecpu splitstensor tfconstant1000000 shape129 1 1 dtypetffloat16 splits valuestensor shape3456 values weightstensor shape128 27 weights size 3046875451 out except exception as e printerrorstre try with tfdevicegpu0 splits splits tfcastsplits tffloat16 values values tfcastvalues tfuint64 weights weights tfcastweights tfint16 except exception as e printerrorstre except exception as e printerrorstre relevant log output shell 20230813 015836322308 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230813 015837120869 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837139665 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837139841 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837140154 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230813 015837140677 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837140794 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837140896 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837187990 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837188156 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837188267 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 015837188356 i created device with 152 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 errorcant convert negative int to unsigned 20230813 015837207611 i failed to allocate 15281m 160235520 bytes from device cudaerroroutofmemory out of memory 20230813 015837207886 i failed to allocate 13753m 144211968 bytes from device cudaerroroutofmemory out of memory 20230813 015837208138 i failed to allocate 12378m 129790976 bytes from device cudaerroroutofmemory out of memory 20230813 015837213816 f check failed pyerroccurred aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAbort when running tensorflow.python.ops.gen_array_ops.depth_to_space\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2110 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior due to very large integer argument standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import genarrayops try arg0tensor tfrandomuniform3 2 3 4 dtypetffloat32 arg0 tfidentityarg0tensor arg1 2147483647 arg2 nhwc out except exception as e printerrorstre relevant log output shell 0230813 002353644564 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230813 002354491071 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354510564 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354510736 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354511051 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230813 002354511595 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354511717 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354511830 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354572398 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354572634 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354572791 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230813 002354572916 i created device with 153 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 20230813 002354594062 i failed to allocate 15388m 161349632 bytes from device cudaerroroutofmemory out of memory 20230813 002354594484 i failed to allocate 13849m 145214720 bytes from device cudaerroroutofmemory out of memory 20230813 002354600623 f nonokstatus initdimsdimsizes status invalidargument expected a nonnegative size got 2 aborted"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSegmentation fault when running tensorflow.python.ops.list_ops.tensor_list_reserve\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 2130 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior when numelements is very large standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import listops try elementshape0 1 elementshape elementshape0 numelements 1250999896764 elementdtype tffloat32 out except exception as e printerrorstre relevant log output shell 20230812 230556608429 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230812 230557434965 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557454466 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557454644 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557454958 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230812 230557455499 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557455620 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557455724 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557504359 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557504534 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557504649 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 230557504741 i created device with 151 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 20230812 230557518166 i failed to allocate 15144m 158793728 bytes from device cudaerroroutofmemory out of memory segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncheck failure when running tensorflow.python.ops.nn_ops.conv3d_transpose_v2\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2110 custom code no os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior the following input combination causes check failure standalone code to reproduce the issue shell import tensorflow as tf import os import numpy as np from tensorflowpythonops import nnops try arg0tensor tfrandomuniform2 5 6 4 3 dtypetffloat32 arg0 tfidentityarg0tensor arg1tensor tfrandomuniform3 3 3 2 3 dtypetffloat32 arg1 tfidentityarg1tensor arg20 2 arg21 11 arg22 13 arg23 9 arg24 false arg2 arg30 1 arg31 2 arg32 2 arg33 2 arg34 1 arg3 padding valid dataformat ndhwc dilations none out except exception as e printerrorstre relevant log output shell 20230806 065826108204 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230806 065826851251 w could not load dynamic library libnvinferso7 dlerror libnvinferso7 cannot open shared object file no such file or directory ldlibrarypath 20230806 065826851492 w could not load dynamic library libnvinferpluginso7 dlerror libnvinferpluginso7 cannot open shared object file no such file or directory ldlibrarypath 20230806 065826851500 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230806 065827585126 w could not load dynamic library libnvinferso7 dlerror libnvinferso7 cannot open shared object file no such file or directory ldlibrarypath 20230806 065827585372 w could not load dynamic library libnvinferpluginso7 dlerror libnvinferpluginso7 cannot open shared object file no such file or directory ldlibrarypath 20230806 065827585380 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230806 065912781705 f check failed handleget cudnnstatussuccess 3 vs 0"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSegmentation fault when running tensorflow.python.eager.context.check_alive\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code yes os platform and distribution 2204 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version cudatoolkit1180 gpu model and memory no response current behavior probably due to invalid string argument standalone code to reproduce the issue shell import tensorflow as tf import numpy as np from import context try try with tfdevicecpu arg0 out except exception as e printerrorstre try with tfdevicegpu0 except exception as e printerrorstre except exception as e printerrorstre relevant log output shell cudnnlib 20230812 152722605920 w tftrt warning cannot dlopen some tensorrt libraries if you would like to use nvidia gpu with tensorrt please make sure the missing libraries mentioned above are installed properly 20230812 152723511442 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723533020 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723533197 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723533535 i this tensorflow binary is optimized with oneapi deep neural network library onednn to use the following cpu instructions in performancecritical operations avx2 fma to enable them in other operations rebuild tensorflow with the appropriate compiler flags 20230812 152723534136 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723534277 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723534432 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723605501 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723605704 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723605831 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero 20230812 152723605930 i created device with 77 mb memory device 0 name nvidia geforce gtx 1660 ti pci bus id 000001000 compute capability 75 segmentation fault"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTypeError: Unable to serialize 64.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version 213 custom code no os platform and distribution windows 11 mobile device no response python version 3113 bazel version na gcccompiler version na cudacudnn version not using gpu gpu model and memory na current behavior i have been receiving this message when trying to save a variety of tensorflow models since version 211 i have reported it before it appears to be produced by the lack of an ability by tensorfow to serialize the model representations it maintains in memory typeerror unable to serialize 640 to json unrecognized type see the debugger output below for details can i change anything in my models to dodge this logic is there another model saving function i can try standalone code to reproduce the issue shell please email me for code relevant log output shell traceback most recent call last file line 132 in saveformattf file line 149 in savemodel return file line 70 in errorhandler raise from none file line 200 in encode chunks selfiterencodeo oneshottrue file line 258 in iterencode return iterencodeo 0 typeerror unable to serialize 640 to json unrecognized type"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBinaryFocalCrossentropy: alpha does not work\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version tf 213 custom code yes os platform and distribution linux ubuntu 2004 mobile device no response python version 31012 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior computes the loss without using the alpha import tensorflow as tf ytruelist 0 1 0 0 logitslist 16 051 294 18 gamma 2 focalfunc1 alpha025 fromlogitstrue focalloss1 focalfunc1ytruelist logitslist focalfunc2 alpha10 fromlogitstrue focalloss2 focalfunc2ytruelist logitslist focalfunc3 alpha100 fromlogitstrue focalloss3 focalfunc3ytruelist logitslist printfocalloss1 printfocalloss2 printfocalloss3 the results are tftensor06932789 shape dtypefloat32 tftensor06932789 shape dtypefloat32 tftensor06932789 shape dtypefloat32 focalloss1 in the codes should be 051168 standalone code to reproduce the issue shell in above relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNotImplementedError while converting a tensorflow model to coreml using coremltools\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2130 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior i am facing a notimplementederror while trying to convert movinets model to coreml the model is saved in savedmodel format and i am using a tensorflow version equal to 2130 and a version of core ml tools equal to 630 and a 3106 python i dont understand the origin of operation and its meaning any idea whats could be going on here are the steps to reproduce the error 1 download a savedmodel from the following link 2 convert the model using shell import coremltools as ct coremlmodel ctconvertsaveddir converttomlprogram where saveddir is the path to the downloaded model relevant log output shell notimplementederror conversion for tf op not implemented name op input image input unknown input unknown0 input unknown1 input unknown2 input unknown3 input unknown4 input unknown5 input unknown6 input unknown7 input unknown8 input unknown9 input unknown10 input unknown11 input unknown12 input unknown13 input unknown14 input unknown15 input unknown597 input unknown598 input unknown599 attr key tin value list type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat type dtfloat attr key tout value list type dtfloat attr key xlamustcompile value b true attr key collectivemanagerids value list attr key value b true attr key value list i 1 i 2 i 3 i 4 i 5 i 6 i 7 i 8 i 9 i 10 i 11 i 12 i 13 i 14 i 15 i 597 i 598 i 599 i 600 i 601 attr key config value s attr key configproto value s attr key executortype value s attr key f value func name"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTensorflow inference error\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 28 custom code yes os platform and distribution linux centos mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior my model can train normally but there was an error when inference after the training was completedthe model structure code is as follows conv1 bn1 out1 prelusharedaxes12bn1 out2 tfreshapeout1 dp1 lstmout2 dpo1 dense32dp1 dpo2 lso1 lstmdpo2 dpo3 dense2lso1 the error is as follows execution error scale must have the same number of elements as the channels of x got 32 and 2 node may i ask what caused this and if it can be resolved standalone code to reproduce the issue shell no relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to get detailed information about the issue\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2121 custom code no os platform and distribution linux ubuntu 1804 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version cuda 118 cudnn 892 gpu model and memory nvidia a10 current behavior im getting following error while compiling the model with xla oprequires failed at xlaopscc347 invalidargument trying to access resource located in device from device this issue is documented as xla limitation here which seems reasonable but the error message doesnt specify where this issue is coming from is there any way to get more details on which variable is creating this issue standalone code to reproduce the issue shell na relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value num_blocks_2/multihead_attention/conv1d_1/kerne\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 28 custom code yes os platform and distribution linux ubuntu 2004 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior i have trained the carcacontext and attributeaware sequential recommendation via crossattention on video games dataset i saved the session after 1 epoch and try to restore the session since all the architecture was written using the concepts of the session i saved the session using tftrainsaver save method sessionsaver sessionoutputpath epochsstrepoch if not make directory if not exists sessionsaversavesess printfinfo save the model after epochs epoch then i restored session using saver carcamodelmeta saverrestoresess i have tried to perform prediction on new dataset using restored session sess but i have encountered attempting to use uninitialized value error the full error is traceback most recent call last file line 1356 in docall return fnargs file line 1341 in runfn options feeddict fetchlist targetlist runmetadata file line 1429 in calltfsessionrun runmetadata attempting to use uninitialized value node during handling of the above exception another exception occurred traceback most recent call last file carcatrainpy line 1441 in usernum itemnum args itemfeatures userfeatures cxtdict file carcatrainpy line 1317 in predictions modelpredictsess nponesargsmaxlenu seq itemidx seqcxt testitemscxt file carcatrainpy line 976 in predict selftestuser u selfinputseq seq selftestitem itemidx selfistraining false selfseqcxtseqcxt file line 950 in run runmetadataptr file line 1173 in run feeddicttensor options runmetadata file line 1350 in dorun runmetadata file line 1370 in docall raise typeenodedef op message attempting to use uninitialized value node defined at carcatrainpy670 original stack trace for file carcatrainpy line 1441 in usernum itemnum args itemfeatures userfeatures cxtdict file carcatrainpy line 1266 in model modelusernum itemnum args itemfeatures userfeatures cxtsize cxtsize useres true file carcatrainpy line 768 in init file carcatrainpy line 670 in feedforward outputs tflayersconv1dparams file line 324 in newfunc return funcargs kwargs file line 218 in conv1d return layerapplyinputs file line 1479 in apply return selfcallinputs args kwargs file line 537 in call outputs superlayer selfcallinputs args kwargs file line 591 in call selfmaybebuildinputs file line 1881 in maybebuild selfbuildinputshapes file line 165 in build dtypeselfdtype file line 450 in addweight kwargs file line 384 in addweight file line 663 in kwargsforgetter file line 1496 in getvariable file line 1239 in getvariable file line 562 in getvariable file line 514 in truegetter file line 929 in getsinglevariable file line 259 in call return kwargs file line 220 in variablev1call shapeshape file line 198 in previousgetter lambda kwargs kwargs file line 2511 in shapeshape file line 263 in call return clscallargs kwargs file line 1568 in init shapeshape file line 1755 in initfromargs selfsnapshot nameread file line 180 in wrapper return targetargs kwargs file line 86 in identity ret namename file line 4253 in identity identity inputinput namename file line 788 in applyophelper opdefopdef file line 507 in newfunc return funcargs kwargs file line 3616 in createop opdefopdef file line 2005 in init selftraceback tfstackextractstack i have also checked the variables in both the stored session and the session just after training both outputs seem similar i was stuck on this issue for a few days and also tested saving the model using and restoring the model using but not solved the issuecurrentlyi am using tensorflow 114 standalone code to reproduce the issue shell sessionsaver sessionoutputpath epochsstrepoch if not make directory if not exists sessionsaversavesess printfinfo save the model after epochs epoch saver carcamodelmeta saverrestoresess relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n//tensorflow/compiler/mlir/lite/tests:optimize.mlir.test fails\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version git head custom code no os platform and distribution ubuntu 2004 mobile device na python version 3917 bazel version 610 gcccompiler version 1021 cudacudnn version na gpu model and memory na current behavior unit test fails since commit standalone code to reproduce the issue shell bazel test testenvtf2behavior1 definetfapiversion2 jobs75 buildtestsonly relevant log output shell test output for testing 1 tests 1 workers fail mlir tests optimizemlir 1 of 1 test mlir tests optimizemlir failed script run at line 2 tfloptimize run at line 4 checkprefixfold run at line 7 tfllegalizetf tfloptimize checkprefixfusing run at line 9 tfllegalizetf checkprefixnofusing exit code 1 command output stderr error check expected string not found in input check tflbatchmatmularg0 arg1 154253 note scanning from here funcfunc tensor arg1 tensor tensor 15497 note possible intended match here 2 tflbatchmatmularg1 1 adjx true adjy false false tensor tensor tensor input file check file dumpinputhelp explains the following input dump input was 1537 3 tfltranspose2 0 tensor tensor tensor 1538 4 tflgathernd3 1 tensor tensor tensor 1539 5 tflreshape4 cst tensor tensor tensor 1540 return 5 tensor 1541 1542 funcfunc tensor arg1 tensor tensor check36220 x error no match found 1543 cst arithconstant dense tensor check36220 1544 cst0 arithconstant dense tensor check36220 1545 cst1 arithconstant dense tensor check36220 1546 cst2 arithconstant dense tensor check36220 1547 0 tfltransposearg0 cst2 tensor tensor tensor check36220 1548 1 tflreshape0 cst1 tensor tensor tensor check36220 1549 2 tflbatchmatmularg1 1 adjx true adjy false false tensor tensor tensor check36220 check36221 possible intended match 1550 3 tflreshape2 cst0 tensor tensor tensor check36220 1551 4 tfltranspose3 cst tensor tensor tensor check36220 1552 return 4 tensor check36220 1553 check36220 1554 funcfunc tensor arg1 tensor arg2 none tensor check36220 failed tests 1 mlir tests optimizemlir testing time 053s failed 1"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCould not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 2100 custom code yes os platform and distribution windows 11 mobile device na python version 310microsoft store bazel version no response gcccompiler version no response cudacudnn version cuda 112 gpu model and memory rtx 3070 ti 8gb current behavior i installed cuda 112 as recommended for tf 2100 heres the install screenshot at first i thought it was a path issue but after restarting my pc i was able to access exe files in that folder image if the files are in path why cant tensorflow find them many people say to use miniconda so i did but i got the same result other resolved issues were resolved as the ops were using the wrong version of cuda i checked on the website and i can confirm that my version is the required one standalone code to reproduce the issue shell import tensorflow as tf relevant log output shell 20230731 185625098058 w could not load dynamic library cudart64110dll dlerror cudart64110dll not found 20230731 185625098226 i ignore above cudart dlerror if you do not have a gpu set up on your machine 20230731 185626164080 w could not load dynamic library cudart64110dll dlerror cudart64110dll not found 20230731 185626164320 w could not load dynamic library cublas6411dll dlerror cublas6411dll not found 20230731 185626164540 w could not load dynamic library cublaslt6411dll dlerror cublaslt6411dll not found 20230731 185626164818 w could not load dynamic library cufft6410dll dlerror cufft6410dll not found 20230731 185626368828 w could not load dynamic library cusparse6411dll dlerror cusparse6411dll not found 20230731 185626369092 w could not load dynamic library cudnn648dll dlerror cudnn648dll not found"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nJAVA - org.tensorflow.TensorFlowException: Can't parse /<modelPath>/<somePathToFolder>/saved_model.pb as binary proto - JDK 17\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 1150 custom code yes os platform and distribution rhel 8 version 875 mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior has following files 1 assetsvocabtxt 2 savedmodelpb 3 4 i am using java binding code to run the inference libraries i am using are orgtensorflow tensorflow 1150 orgtensorflow libtensorflow 1150 orgtensorflow proto 1150 orgtensorflow libtensorflowjni 1150 tensorflow version 1150 jdk oracle open jdk version 1705 os rhel 8 version 875 describe the current behavior cant parse savedmodelpb as binary proto at method at at at at describe the expected behavior in jdk 11 the code runs while in jdk 17 its throws error the model file is not corrupted same model path file is able to run successfully in jdk 11 standalone code to reproduce the issue shell code import import orgjunittest import import orgtensorflowsession import javaioioexception import import javaniofilepaths public class testclass test public void tfpredictor throws ioexception urisyntaxexception savedmodelbundle b savedmodelbundleload serve session sess bsession"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIssue\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 29 custom code yes os platform and distribution linux ubuntu mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior xyz standalone code to reproduce the issue shell xyz relevant log output shell jkjnk"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nint8 tflite model allocate_tensors() silently stop python process.\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 281 2130 2140dev20230706 custom code yes os platform and distribution windows 11 windows 10 wsl with ubuntu 2004 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior i have converted a resnet18 model from onnx to tflite onnx tf tflite onnx to tf conversion is done by this repo tflite is converted to int8 precision using posttraining integer quantization link netron can display the converted int8 model correctly onnx model tflite model link tflite int8 model link but when i try to do inference calling the method allocatetensors stop the python process without showing any errorwarning if the tflite model is converted with fp32 this issue doesnt happen i have no idea how do to fix this issue or is there any workaround thanks standalone code to reproduce the issue shell tf to tflite conversion import tensorflow as tf import numpy as np savedmodeldir resnet18 tflitemodelpath savedmodeldir tflite converter def for in range100 data nprandomrand1 3 224 224 yield dataastypenpfloat32 tfint8 tfint8 tflitemodel converterconvert save the model with opentflitemodelpath wb as f fwritetflitemodel inference time import tensorflow as tf interpreter printbefore printafter this line not displayed relevant log output shell inference time output tf 2140dev20230706 from is deprecated and will be removed after 20190101 instructions for updating the tensorflow distributions library has moved to tensorflow probability you should update all references to use tfpdistributions instead of tfdistributions registerklinit from is deprecated and will be removed after 20190101 instructions for updating the tensorflow distributions library has moved to tensorflow probability you should update all references to use tfpdistributions instead of tfdistributions before info created tensorflow lite xnnpack delegate for cpu"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n Invalid work group size\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version tf 2100 custom code yes os platform and distribution ubuntu 2004 mobile device qualcomm sm6225 python version 38 bazel version 511 gcccompiler version 940 cudacudnn version no gpu model and memory qualcomm adrenotm qualcomm opencl c 20 adrenotm 610 current behavior use tflite to invoke mobilnetv2 or any model with op softmax on mobile device will encounter an error tflitegpudelegate invoke failed to invalid work group size more details if inferenceforcefp16 is false no error occured if work group size is smaller than 256 no error occured standalone code to reproduce the issue shell same code as tflite invoke on android phone will reproduce this issue relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRNG generators make python abort in python3.11 and tf2.12, conda-forge\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2121 custom code yes os platform and distribution macos 1341c mobile device no response python version 311 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior unable to make random number generators this happens with condaforge python 3113 tensorflow2121 it works fine with pip python 3113 tensorflow 2120 standalone code to reproduce the issue shell import tensorflow as tf g gnormalshape3 relevant log output shell assertion failed f nullptr dynamiccastf nullptr function downcast file line 58 1 18173 abort python"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncannot find explicitly assigned device for op\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 284 custom code no os platform and distribution ubuntu1804 mobile device no response python version no response bazel version 520 gcccompiler version gcc1130 cudacudnn version none gpu model and memory none current behavior model trained use gpu but infer machine dont have gpu device so will meet cannot find assigend device at model load stage here is log e20230724 130227982717 35915 tfmodelcorecc80 failed to load model in cannot assign a device for operation node was explicitly assigned to devicegpu0 but available devices are make sure the device specification refers to a valid device the requested device appears to be a gpu but cuda is not enabled standalone code to reproduce the issue shell no code relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nLSTM loss does not work TPU with bfloat16\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2120 custom code yes os platform and distribution google colab tpu mobile device no response python version 310 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior lstm on tpu works in float32 gives error message in bfloat16 value passed to parameter input has datatype bfloat16 not in list of allowed values float16 float32 float64 standalone code to reproduce the issue shell colab code in this gist run with tpu relevant log output shell typeerror traceback most recent call last in 1 with strategyscope 2 model buildmodel 3 4 modelcompile 5 3 frames in attrdef paramname 54 allowedvalues for x in allowedlist 55 if dtype not in allowedlist 56 raise typeerror 57 fvalue passed to parameter paramname has datatype 58 not in list of allowed values typeerror exception encountered when calling layer lstm4 type lstm value passed to parameter input has datatype bfloat16 not in list of allowed values float16 float32 float64 call arguments received by layer lstm4 type lstm • none 128 dtypebfloat16 • masknone • trainingnone • initialstatenone"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAssertionError: Tried to export a function which references an 'untracked' resource. TensorFlow objects(e.g. tf.Variable)\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 210 custom code yes os platform and distribution no response mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior as you can see in the code below the operation of multiplying attn by temperature at mdta is being performed and the temperature is defined by tfvariable the model using the attention module below runs normally until trainingmodelfit but an assertionerror occurs when saving the model i would appreciate it if you could tell me how to make the temperature variable trackable standalone code to reproduce the issue shell import tensorflowcompatv2 as tf import tensorflow as tf import keras from keras import backend from kerasapplications import imagenetutils from kerasengine import training from keraslayers import versionawarelayers from kerasutils import datautils from kerasutils import layerutils from keraslayers import layer activation relu concatenate conv2d add dense maxpool2d avgpool2d flatten multiply softmax from keraslayers import dropout dense input batchnormalization depthwiseconv2d zeropadding2d layernormalization from tensorflowkeras import backend as k from kerasmodels import model import tensorflowkeras 정상적으로 작동 temperature제외 isort off from import tflogging as logging from import kerasexport baseweightpath kerasexport def mobilenet inputshapenone alpha10 depthmultiplier1 dropout1e3 includetoptrue weightsimagenet inputtensornone poolingnone classes1000 kwargs global layers if layers in kwargs layers kwargspoplayers else layers versionawarelayers if kwargs raise valueerrorfunknown arguments kwargs if not weights in imagenet none or raise valueerror the weights argument should be either none random initialization imagenet pretraining on imagenet or the path to the weights file to be loaded freceived weightsweights if weights imagenet and includetop and classes 1000 raise valueerror if using weights as imagenet with includetop as true classes should be 1000 freceived classesclasses determine proper input shape and default size if inputshape is none defaultsize 224 else if channelsfirst rows inputshape1 cols inputshape2 else rows inputshape0 cols inputshape1 if rows cols and rows in 128 160 192 224 defaultsize rows else defaultsize 224 inputshape inputshape minsize32 weightsweights if channelslast rowaxis colaxis 0 1 else rowaxis colaxis 1 2 rows inputshaperowaxis cols inputshapecolaxis if weights imagenet if depthmultiplier 1 raise valueerror if imagenet weights are being loaded depth multiplier must be 1 freceived if alpha not in 025 050 075 10 raise valueerror if imagenet weights are being loaded alpha can be one of 025 050 075 or 10 only freceived alphaalpha if rows cols or rows not in 128 160 192 224 rows 224 loggingwarning inputshape is undefined or nonsquare or rows is not in 128 160 192 224 weights for input shape 224 224 will be loaded as the default if inputtensor is none imginput inputshapeinputshape else if not imginput shapeinputshape else imginput inputtensor numheads 4 expansionfactor 3 x convblockimginput 32 alpha strides2 2 x transformerblockx numheads expansionfactor x depthwiseconvblockx 64 alpha depthmultiplier blockid1 x transformerblockx numheads expansionfactor x depthwiseconvblock x 128 alpha depthmultiplier strides2 2 blockid2 x transformerblockx numheads expansionfactor x depthwiseconvblockx 128 alpha depthmultiplier blockid3 x transformerblockx numheads expansionfactor x depthwiseconvblock x 256 alpha depthmultiplier strides2 2 blockid4 x transformerblockx numheads expansionfactor x depthwiseconvblockx 256 alpha depthmultiplier blockid5 x transformerblockx numheads expansionfactor x depthwiseconvblock x 512 alpha depthmultiplier strides2 2 blockid6 x transformerblockx numheads expansionfactor x depthwiseconvblockx 512 alpha depthmultiplier blockid7 x transformerblockx numheads expansionfactor x depthwiseconvblockx 512 alpha depthmultiplier blockid8 x transformerblockx numheads expansionfactor x depthwiseconvblockx 512 alpha depthmultiplier blockid9 x transformerblockx numheads expansionfactor x depthwiseconvblockx 512 alpha depthmultiplier blockid10 x transformerblockx numheads expansionfactor x depthwiseconvblockx 512 alpha depthmultiplier blockid11 x transformerblockx numheads expansionfactor x depthwiseconvblock x 1024 alpha depthmultiplier strides2 2 blockid12 x transformerblockx numheads expansionfactor x depthwiseconvblockx 1024 alpha depthmultiplier blockid13 x transformerblockx numheads expansionfactor if includetop x x layersdropoutdropout namedropoutx x layersconv2dclasses 1 1 paddingsame nameconvpredsx x layersreshapeclasses namereshape2x weights x layersactivation namepredictions x else if pooling avg x elif pooling max x globalmaxpooling2dx ensure that the model takes into account any potential predecessors of inputtensor if inputtensor is not none inputs else inputs imginput create model model trainingmodelinputs x namemobilenet02fs alpha rows load weights if weights imagenet if alpha 10 alphatext 10 elif alpha 075 alphatext 75 elif alpha 050 alphatext 50 else alphatext 25 if includetop modelname mobilenetsdtfh5 alphatext rows weightpath baseweightpath modelname weightspath datautilsgetfile modelname weightpath cachesubdirmodels else modelname mobilenetsdtfnotoph5 alphatext rows weightpath baseweightpath modelname weightspath datautilsgetfile modelname weightpath cachesubdirmodels bynametrue elif weights is not none bynametrue return model class mdtakeraslayerslayer important the channels must be zero when divided by numheads def initself numheads supermdta selfinit selfnumheads numheads selftemperature tfvariable1 for in rangeselfnumheads shapenone selfnumheads 1 1 trainabletrue def buildself inputs n h w c n h w c output of mdta feature should be added to input feature x b h w c inputsshape layers qkv conv2dfiltersc3 kernelsize1 usebiasfalse qkvconv conv2dc3 kernelsize3 paddingsame groupsc3 usebiasfalse projectout conv2dfiltersc kernelsize1 usebiasfalse temperature tfvariable1 for in rangeselfnumheads shapenone selfnumheads 1 1 trainabletrue forward q k v numorsizesplits3 axis1 divide the of channels into heads learn separate attention map q tfreshapeq 1 selfnumheads cselfnumheads h w n numheads cnumheads hw k tfreshapek 1 selfnumheads cselfnumheads h w v tfreshapev 1 selfnumheads cselfnumheads h w q k tfnnl2normalizeq axis1 tfnnl2normalizek axis1 cxc attention map instead of hwxhw when numheads1 attn tfmatmulq k transposebtrue attn multiplyattn temperature attn softmaxaxis1attn out tfmatmulattn v shape tfshapeoutk for k in range4 batch numheads cnumheads hw out tfreshapeout shape0 h w shape1shape2 out projectoutout attnv n numheads cnumheads hw return out def callself inputs return selfbuildinputs class gdfnkeraslayerslayer def initself supergdfn selfinit selfexpansionfactor 2 def buildself inputs n h w c n h w c with expansionfactorr output of gdfn feature should be added to input feature x b h w c inputsshape hiddenchannels intc selfexpansionfactor channel expansion layers projectin conv2dhiddenchannels 2 kernelsize1 usebiasfalse conv conv2dhiddenchannels 2 kernelsize3 paddingsame groupshiddenchannels 2 usebiasfalse projectout conv2dc kernelsize1 usebiasfalse forward x projectininputs n h w 2cr x convx n h w 2cr x1 x2 tfsplitx numorsizesplits2 axis1 n h w cr n h w cr gating the elementwise product of 2 parallel paths of linear transformation layers out relux1 x2 n h w cr out projectoutout n h w cr return out def callself inputs return selfbuildinputs def numheads expansionfactor n h w c n h w c shape tfshapeinputsk for k in range4 b h w c inputsshape0 inputsshape1 inputsshape2 inputsshape3 assert c numheads 0 norm1 layernormalization default axis1 attn mdtanumheads norm2 layernormalization ffn gdfn add mdta output feature inputsnorm1 norm1tfreshapeinputs 1 hw c inputsnorm1 tfreshapeinputsnorm1 1 h w c inputs inputs attninputsnorm1 add gdfn output feature inputsnorm2 norm2tfreshapeinputs 1 hw c inputsnorm2 tfreshapeinputsnorm2 1 h w c x inputs ffninputsnorm2 return x def convblockinputs filters alpha kernel3 3 strides1 1 channelaxis 1 if channelsfirst else 1 filters intfilters alpha x conv2d filters kernel paddingsame usebiasfalse stridesstrides nameconv1 inputs x nameconv1bnx return relu60 nameconv1relux def depthwiseconvblock inputs pointwiseconvfilters alpha depthmultiplier1 strides1 1 blockid1 channelaxis 1 if channelsfirst else 1 pointwiseconvfilters alpha if strides 1 1 x inputs else x zeropadding2d 0 1 0 1 nameconvpadd blockid inputs x depthwiseconv2d 3 3 paddingsame if strides 1 1 else valid stridesstrides usebiasfalse nameconvdwd blockid x x batchnormalization axischannelaxis nameconvdwdbn blockid x x relu60 nameconvdwdrelu blockidx x conv2d pointwiseconvfilters 1 1 paddingsame usebiasfalse strides1 1 nameconvpwd blockid x x batchnormalization axischannelaxis nameconvpwdbn blockid x return relu60 nameconvpwdrelu blockidx def dropoutrate numclass if inputshape224 224 3 weights imagenet else weights none basemodel includetopfalse inputshapeinputshape basemodeltrainable true x basemodeloutput headlayer activationrelu activationsoftmax predictions headlayerx this is the model we will train model outputspredictions printmodel return model inputshape 768 768 3 x inputinputshape model 03 6 out modelx savepath dmodelmdtah5 metricsacc modelsavesavepath relevant log output in the vscodeterminal shell assertionerror tried to export a function which references an untracked resource tensorflow objects eg tfvariable captured by functions must be tracked by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly see the information below function name captured tensor trackable referencing this tensor internal tensor tensor181720 shape dtyperesource during handling of the above exception another exception occurred in the jupyternoetebook shell valueerror traceback most recent call last in 1 metricsacc 2 in errorhandlerargs kwargs 68 to get the full stack trace call 69 70 raise from none 71 finally 72 del filteredtb in encodeself o 197 exceptions arent as detailed the list call should be roughly 198 equivalent to the pysequencefast that join would do 199 chunks selfiterencodeo oneshottrue 200 if not isinstancechunks list tuple 201 chunks listchunks in iterencodeself o oneshot 255 selfkeyseparator selfitemseparator selfsortkeys 256 selfskipkeys oneshot 257 return iterencodeo 0 258 259 def default encoder indent floatstr valueerror unable to serialize 4 1 1 dtypetffloat32 trainabletrue aliasidnone to json because the typespec class has not been registered"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCould not load dynamic library 'libcublasLt.so.12'; dlerror: libcublasLt.so.12: cannot open shared object file: No such file or directory\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2130 custom code no os platform and distribution linux ubuntu 2310 mobile device no response python version 311 bazel version no response gcccompiler version no response cudacudnn version 11801893281cuda121 gpu model and memory nvidia geforce gtx 960m 4096mib current behavior running the mobilenet from keras included by tensorflow leads to the following error could not load library libcublasltso12 error libcublasltso12 cannot open shared object file no such file or directory abgebrochen speicherabzug geschrieben standalone code to reproduce the issue shell python c from import mobilenet import numpy as np m mobilenet relevant log output shell could not load library libcublasltso12 error libcublasltso12 cannot open shared object file no such file or directory abgebrochen speicherabzug geschrieben"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTensorFlow distributed training works for at most 2 GPUs\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version 2120 custom code yes os platform and distribution linux ubuntu 2204 mobile device no response python version 3916 bazel version no response gcccompiler version no response cudacudnn version cuda 118 cudnn 860163 gpu model and memory no response current behavior i have 8 nvidia h100s on this system below is the output of nvidiasmi image the following code works as intended if gpus includes at most 2 gpus image in the relevant log output section i have the error log from running the code with 3 gpus in the gpus list please let me know if you need any additional information standalone code to reproduce the issue shell import tensorflow as tf gpus gpu0 gpu1 gpu2 strategy with strategyscope model inputshape1 modelcompilelossmse optimizersgd dataset 1repeat100batch16 modelfitdataset relevant log output shell 20230717 232831469519 i onednn custom operations are on you may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders to turn them off set the environment variable tfenableonednnopts0 20230717 232831516738 i this tensorflow binary is optimized to use available cpu instructions in performancecritical operations to enable the following instructions avx2 avx512f avx512vnni avx512bf16 avxvnni amxtile amxint8 amxbf16 fma in other operations rebuild tensorflow with the appropriate compiler flags 20230717 232831972313 w tftrt warning could not find tensorrt 20230717 232835178825 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232835181183 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232835183528 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232835185905 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232835188234 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232835190559 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232835192895 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232835195198 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836609484 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836610685 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836611908 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836613166 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836614370 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836615584 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836616799 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836617975 w tensorflow was not built with cuda kernel binaries compatible with compute capability 90 cuda kernels will be jitcompiled from ptx which could take 30 minutes or longer 20230717 232836680264 i created device with 78938 mb memory device 0 name nvidia h100 80gb hbm3 pci bus id 000019000 compute capability 90 20230717 232836682112 i created device with 78938 mb memory device 1 name nvidia h100 80gb hbm3 pci bus id 00003b000 compute capability 90 20230717 232836683772 i created device with 78938 mb memory device 2 name nvidia h100 80gb hbm3 pci bus id 00004c000 compute capability 90 20230717 232836685499 i created device with 78938 mb memory device 3 name nvidia h100 80gb hbm3 pci bus id 00005d000 compute capability 90 20230717 232836687179 i created device with 78938 mb memory device 4 name nvidia h100 80gb hbm3 pci bus id 00009b000 compute capability 90 20230717 232836688884 i created device with 78938 mb memory device 5 name nvidia h100 80gb hbm3 pci bus id 0000bb000 compute capability 90 20230717 232836690581 i created device with 78938 mb memory device 6 name nvidia h100 80gb hbm3 pci bus id 0000cb000 compute capability 90 20230717 232836692292 i created device with 78938 mb memory device 7 name nvidia h100 80gb hbm3 pci bus id 0000db000 compute capability 90 20230717 232839806560 i devicecpu0 debug info executor start aborting this does not indicate an error and you can ignore this message invalidargument you must feed a value for placeholder tensor placeholder1 with dtype float and shape 1 node placeholder1 20230717 232839806723 i devicecpu0 debug info executor start aborting this does not indicate an error and you can ignore this message invalidargument you must feed a value for placeholder tensor placeholder0 with dtype float and shape 1 node placeholder0 20230717 232839807452 w auto sharding policy will apply data sharding policy as it failed to apply file sharding policy because of the following reason found an unshardable source dataset name tensordataset2 op tensordataset input placeholder0 input placeholder1 attr key toutputtypes value list type dtfloat type dtfloat attr key cardinality value i 1 attr key metadata value s n017tensordataset0 attr key outputshapes value list shape dim size 1 shape dim size 1 experimentaltype typeid tftproduct args typeid tftdataset args typeid tftproduct args typeid tfttensor args typeid tftfloat args typeid tfttensor args typeid tftfloat 20230717 232839823305 i devicecpu0 debug info executor start aborting this does not indicate an error and you can ignore this message invalidargument you must feed a value for placeholder tensor placeholder1 with dtype float and shape 1 node placeholder1 20230717 232839823469 i devicecpu0 debug info executor start aborting this does not indicate an error and you can ignore this message invalidargument you must feed a value for placeholder tensor placeholder1 with dtype float and shape 1 node placeholder1 20230717 232840010671 i devicecpu0 debug info executor start aborting this does not indicate an error and you can ignore this message invalidargument you must feed a value for placeholder tensor placeholder1 with dtype float and shape 1 node placeholder1 20230717 232840010843 i devicecpu0 debug info executor start aborting this does not indicate an error and you can ignore this message invalidargument you must feed a value for placeholder tensor placeholder0 with dtype float and shape 1 node placeholder0 20230717 232848599915 i xla service 0x7fe600008ff0 initialized for platform cuda this does not guarantee that xla will be used devices 20230717 232848599956 i streamexecutor device 0 nvidia h100 80gb hbm3 compute capability 90 20230717 232848599964 i streamexecutor device 1 nvidia h100 80gb hbm3 compute capability 90 20230717 232848599971 i streamexecutor device 2 nvidia h100 80gb hbm3 compute capability 90 20230717 232848599977 i streamexecutor device 3 nvidia h100 80gb hbm3 compute capability 90 20230717 232848599983 i streamexecutor device 4 nvidia h100 80gb hbm3 compute capability 90 20230717 232848599988 i streamexecutor device 5 nvidia h100 80gb hbm3 compute capability 90 20230717 232848599994 i streamexecutor device 6 nvidia h100 80gb hbm3 compute capability 90 20230717 232848600003 i streamexecutor device 7 nvidia h100 80gb hbm3 compute capability 90 20230717 232848636269 e could not create cudnn handle 20230717 232848636335 e possibly insufficient driver version 535543 20230717 232848649063 e could not create cudnn handle 20230717 232848649131 e possibly insufficient driver version 535543 20230717 232848711026 i loaded cudnn version 8600 20230717 232848712282 e internal retcheck failure dnn nullptr begin stack trace const xlaautotuneresults const const const stduniqueptr xlabackend const bool const absllts20220623span const const absllts20220623span const const const const const const stdvector const const tslmutex const const const stdvector const const xlalocalexecutable stdfunction stdfunction const end stack trace 20230717 232848712483 w oprequires failed at xlaopscc362 internal retcheck failure dnn nullptr 20230717 232848712506 i debug info executor start aborting this does not indicate an error and you can ignore this message internal retcheck failure dnn nullptr node 20230717 232848727426 e internal retcheck failure dnn nullptr begin stack trace const xlaautotuneresults const const const stduniqueptr xlabackend const bool const absllts20220623span const const absllts20220623span const const const const const const stdvector const const tslmutex const const const stdvector const const xlalocalexecutable stdfunction stdfunction const end stack trace 20230717 232848727590 w oprequires failed at xlaopscc362 internal retcheck failure dnn nullptr 20230717 232848727609 i debug info executor start aborting this does not indicate an error and you can ignore this message internal retcheck failure dnn nullptr node 20230717 232848728128 e could not create cudnn handle 20230717 232848728185 e possibly insufficient driver version 535543 20230717 232848740946 w falling back to the cuda driver for ptx compilation ptxas does not support cc 90 20230717 232848740965 w used ptxas at ptxas 20230717 232848742906 e could not create cudnn handle 20230717 232848742961 e possibly insufficient driver version 535543 20230717 232848770994 i compiled cluster using xla this line is logged at most once for the lifetime of the process 20230717 232848806579 e internal retcheck failure dnn nullptr begin stack trace const xlaautotuneresults const const const stduniqueptr xlabackend const bool const absllts20220623span const const absllts20220623span const const const const const const stdvector const const tslmutex const const const stdvector const const xlalocalexecutable stdfunction stdfunction const end stack trace 20230717 232848806809 w oprequires failed at xlaopscc362 internal retcheck failure dnn nullptr 20230717 232848818268 e internal retcheck failure dnn nullptr begin stack trace const xlaautotuneresults const const const stduniqueptr xlabackend const bool const absllts20220623span const const absllts20220623span const const const const const const stdvector const const tslmutex const const const stdvector const const xlalocalexecutable stdfunction stdfunction const end stack trace 20230717 232848818437 w oprequires failed at xlaopscc362 internal retcheck failure dnn nullptr 20230717 232848858099 i debug info executor start aborting this does not indicate an error and you can ignore this message internal retcheck failure dnn nullptr node traceback most recent call last file line 8 in modelfitdataset file line 70 in errorhandler raise from none file line 52 in quickexecute tensors devicename opname graph execution error detected at node defined at most recent call last file line 8 in modelfitdataset file line 65 in errorhandler return fnargs kwargs file line 1685 in fit tmplogs file line 1284 in trainfunction return stepfunctionself iterator file line 1268 in stepfunction outputs argsdata file line 1250 in file line 1245 in applygradtoupdatevar return var idselfvarkeyvar node detected at node defined at most recent call last file line 8 in modelfitdataset file line 65 in errorhandler return fnargs kwargs file line 1685 in fit tmplogs file line 1284 in trainfunction return stepfunctionself iterator file line 1268 in stepfunction outputs argsdata file line 1250 in file line 1245 in applygradtoupdatevar return var idselfvarkeyvar node detected at node defined at most recent call last file line 8 in modelfitdataset file line 65 in errorhandler return fnargs kwargs file line 1685 in fit tmplogs file line 1284 in trainfunction return stepfunctionself iterator file line 1268 in stepfunction outputs argsdata file line 1250 in file line 1245 in applygradtoupdatevar return var idselfvarkeyvar node 3 root errors found 0 internal retcheck failure dnn nullptr node 1 internal retcheck failure dnn nullptr node 2 internal retcheck failure dnn nullptr node 0 successful operations 0 derived errors ignored"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nThe return value when LayerNormalization takes zero vectors as input\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version tf2120 custom code yes os platform and distribution macos mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior output tftensor 0 0 0 0 0 0 0 0 0 0 0 0 shape3 4 dtypefloat32 tftensor nan nan nan nan nan nan nan nan nan nan nan nan shape3 4 dtypefloat32 tftensor 0 0 0 0 0 0 0 0 0 0 0 0 shape3 4 dtypefloat32 document epsilon is used to avoid division by zero errors but when layernormalization takes a zero vector as input it returns nan and batchnormalization returns 0 （psepsilon is documented as a small floatingpoint numberin our experiments we found that epsilon works with larger floatingpoint numbersis this a bit vague） standalone code to reproduce the issue shell standalone code import tensorflow as tf data tfzerosshape3 4 printdata layer1 epsilon0 output1 layer1data printoutput1 layer2 epsilon0 output2 layer2data printoutput2 relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`tf.math.reduce_sum`'s `name` property doesn't change in `model.compile`\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version tf 213 custom code no os platform and distribution linux ubuntu 18046 lts mobile device no response python version 310 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior out 05 tffloat32 axis1 keepdimstrue namefinal model outputsposition out modelsummary tfmathreducesum tfoplambda none 1 0 tfcast00 standalone code to reproduce the issue shell input layersinputshape3 position layersdense5 sigmoid namepositioninput out 05 tffloat32 axis1 keepdimstrue namefinal model outputsposition out modelsummary relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncan't save compiled model as .tf\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2130 custom code yes os platform and distribution mac mini m1 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory m1 gpu and 8gb ram current behavior cant save compile model as a tf file standalone code to reproduce the issue shell import tensorflow as tf class def initself dmodel f05 warmupsteps4000 superinit selfdmodel dmodel selfdmodel tfcastselfdmodel tffloat32 selfwarmupsteps warmupsteps selff f def callself step step tfcaststep dtypetffloat32 arg1 tfmathrsqrtstep arg2 step selfwarmupsteps 15 return selff tfmathminimumarg1 arg2 def getconfigself config dmodel selfdmodel warmupsteps selfwarmupsteps f selff return config model tfkerassequential tfkeraslayersdense10 learningrate customschedule1024 optimizer beta109 beta2098 epsilon1e5 modelcompile optimizeroptimizer lossmse metricsaccuracy modelsavemodeltf relevant log output shell traceback most recent call last file line 40 in modelsavemodeltf file line 70 in errorhandler raise from none file line 199 in encode chunks selfiterencodeo oneshottrue file line 257 in iterencode return iterencodeo 0 typeerror unable to serialize 10240 to json unrecognized type"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSegmentation fault  \nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior python trainpy x datatrain2xnpy y datatrain2ynpy standalone code to reproduce the issue shell segmentation fault but i use tensorflow2120 this problem does not occur relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nThe required input dimension and type changed after conversion of SAC algorithm\n1 system information os platform and distribution linux ubuntu 2204 tensorflow installation pip package tensorflow library tensorflow 2121 2 code most of them i followed the sac minitaur tutorial here but with some modification to fit with my environment also with additional function to convert to tflite 3 failure after conversion the observation spec reduced and changed from shape 5 float32 to shape1 int32 in this conversion observation spec dtypedtypefloat32 nameobservation minimum00 maximum10 reward spec arrayspecshape dtypedtypefloat32 namereward action spec dtypedtypefloat32 nameaction time step timestep discount array1 dtypefloat32 observation array009387773 045744053 08837498 084389937 05 dtypefloat32 reward array0 dtypefloat32 steptype array0 dtypeint32 step 0 averagereturn 0000758 averageepisodelength 120449997 step 100 loss 029556670784950256 step 200 loss 042344561219215393 step 300 loss 04886786639690399 step 400 loss 05600587129592896 step 500 loss 06421032547950745 step 600 loss 07184216380119324 step 700 loss 0785315752029419 step 800 loss 08600273728370667 step 900 loss 09031595587730408 step 1000 averagereturn 1299191 averageepisodelength 115500000 step 1000 loss 0990966796875 policy saved at convert to tflite input shape arg0discount tensorspecshapenone dtypetffloat32 name0discount arg0observation tensorspecshapenone 5 dtypetffloat32 name0observation arg0reward tensorspecshapenone dtypetffloat32 name0reward arg0steptype tensorspecshapenone dtypetfint32 name0steptype info created tensorflow lite xnnpack delegate for cpu input details name action0steptype0 index 0 shape array1 dtypeint32 shapesignature array1 dtypeint32 dtype quantization 00 0 scales array dtypefloat32 zeropoints array dtypeint32 quantizeddimension 0 sparsityparameters name action0discount0 index 1 shape array1 dtypeint32 shapesignature array1 dtypeint32 dtype quantization 00 0 scales array dtypefloat32 zeropoints array dtypeint32 quantizeddimension 0 sparsityparameters name action0observation0 index 2 shape array1 5 dtypeint32 shapesignature array1 5 dtypeint32 dtype quantization 00 0 scales array dtypefloat32 zeropoints array dtypeint32 quantizeddimension 0 sparsityparameters name action0reward0 index 3 shape array1 dtypeint32 shapesignature array1 dtypeint32 dtype quantization 00 0 scales array dtypefloat32 zeropoints array dtypeint32 quantizeddimension 0 sparsityparameters output details name index 92 shape array1 1 dtypeint32 shapesignature array1 1 dtypeint32 dtype quantization 00 0 scales array dtypefloat32 zeropoints array dtypeint32 quantizeddimension 0 sparsityparameters input data 0 input shape 1 output data 06 the converted model has less dimension input and different input type required"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAttributeError: module 'tensorflow_datasets' has no attribute 'load'\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version 2100 os platform and distribution windows 11 mobile device no response python version 31012 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior i cannot access ucf101 and download tensorflow 210 python 31112 tensorflowdatasets 492 standalone code to reproduce the issue shell import tensorflowdatasets ucf101 relevant log output shell attributeerror module tensorflowdatasets has no attribute load"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntf.data train model worse than numpy data\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version tf 210 custom code yes os platform and distribution linux ubuntu 2204 mobile device no response python version 38 bazel version no response gcccompiler version no response cudacudnn version 120 gpu model and memory no response current behavior 1 used tfdata train model best val loss is 014 and the code is image traindataset1 traindataset2 traindataset traindataset2 testdataset1 testdataset2 testdataset testdataset2 batchsize 256 shufflebuffersize 1000 traindataset testdataset model modelinputs inputs outputs s2s modelcompileloss mse optimizeradam metricsmape earlystopping patience4 modelfittraindataset epochs20 batchsize256 validationdata testdataset 2 used numpy array train model best val loss is 010 the code is image model modelinputs inputs outputs s2s modelcompileloss mse optimizeradam metricsmape earlystopping patience4 nparrayytrain epochs20 batchsize256 validationdata nparrayytest 3 val loss worse more standalone code to reproduce the issue shell tfdata bugs at version 210 relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsite/en/guide/create_op.md example code has memory leak\nissue type documentation bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version tf 265 custom code yes os platform and distribution linux centos 76 mobile device linux centos 76 python version 37 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior in the demo code tensor outputtensor was allocated but the memory was not free include using namespace tensorflow class zerooutop public opkernel public explicit context opkernelcontext void context override grab the input tensor const tensor inputtensor contextinput0 auto input inputtensorflat create an output tensor tensor outputtensor null oprequiresokcontext inputtensorshape outputtensor auto outputflat outputtensorflat set all but the first element of the output tensor to 0 const int n inputsize for int i 1 i n i outputflati 0 preserve the first input value if possible if n 0 outputflat0 input0 standalone code to reproduce the issue shell repeatedly call the zerooutop youll see the memory continue to increase relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntf.image.adjust_gamma outputs incorrect error message for string input\nissue type bug have you reproduced the bug with tensorflow nightly yes source source tensorflow version 2120 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior when giving tfimageadjustgamma a string inputs it outputs misleading error messages valueerror failed to convert a numpy array to a tensor unsupported object type float standalone code to reproduce the issue shell import tensorflow as tf t tfconstant dtypetfstring i tfimageadjustgammat gamma01 relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDistributedDatasetInterface is not an attribute of input_lib - engine\\\\data_adapter.py\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version 213 custom code no os platform and distribution no response mobile device no response python version 3109 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior im new to machine learning and i was setting up this network with just one layer with only one neuron inside it just to see how it works setting up went fine the error occured when i asked it to predict im not sure what exactly happend but apparently a non existent attribute was passed to isinstance in the file line 1699 ive replaced by the wrong one by the one suggested and worked as expected standalone code to reproduce the issue shell import numpy as np import tensorflow as tf from import dense input from import sequential from import sigmoid import logging xtrain nparray0 1 2 3 4 5 ytrain nparray0 0 0 1 1 1 model sequential inputshape1 dense1 activationsigmoid name l1 modelsummary setting the weights and bias of the neuron logisticlayer modelgetlayerl1 setw nparray2 setb nparray45 setb performance test a1 this line caused the error printa1 alog setb printalog relevant log output shell line 1699 in isdistributeddataset return isinstanceds attributeerror module has no attribute did you mean"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMy customized OP gives incorrect outputs on GPUs since `tf-nightly 2.13.0.dev20230413`\nissue type bug have you reproduced the bug with tensorflow nightly yes source binary tensorflow version 213 custom code yes os platform and distribution fedora 36 mobile device no response python version 3114 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior i have a complex program based on tensorflow with several customized ops these ops were created following yesterday tf 2130 was released but after i upgraded to 2130 i found that one of my customized op gives incorrect results on gpus and still has the correct outputs on cpus then i tested many tfnightly versions and found that tfnightly 2130dev20230412 works but tfnightly 2130dev20230413 fails so the situation is shown in the following table version cpu gpu tensorflow 2120 correct correct tensorflow 2130 correct incorrect tfnightly 2130dev20230412 correct correct tfnightly 2130dev20230413 correct incorrect id like to know what changed between april 12th and 13th related to the customized ops this can be a breaking change to downstream applications or an internal bug thanks here is a quick link for commits between april 12th and 13th standalone code to reproduce the issue shell indeed the reason is still unclear to me so it is hard to create a minimal example the code of our customized ops is relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPython 3.7.0 is incompitable with tensorflow 2.11.0 \nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version 2110 custom code yes os platform and distribution windows 10 educion mobile device no response python version 370 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior image python 370 throws an exception that it cannot import ordereddict from typings the fix was downgrading from tensorflow 2110 to tensorflow 2100 orderd dict is supported starting from python 372 by default pip installs 2110 for python 370 which is not supported the doc states that 370 is supported standalone code to reproduce the issue shell 1 install python 370 2 pip install tensorflow2110 3 inside python shell type import tensorflow as tf 4 exception will rise relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntf.data Dataset: Warning when caching validation set. \"You should use `dataset.take(k).cache().repeat()` instead.\"\nissue type bug have you reproduced the bug with tensorflow nightly no source source tensorflow version tf 290 custom code yes os platform and distribution ubuntu 2204 lts mobile device no response python version 395 bazel version no response gcccompiler version no response cudacudnn version gpu model and memory nvidia a100sxm480gb current behavior whenever i use the cache function on my tfdata validation dataset i get the warning below when i use the cache only and without the validation set no warning appears standalone code to reproduce the issue shell dataset tftensorspecshapes0 dtypetffloat32 tftensorspecshapes1 dtypetffloat32 valdataset tftensorspecshapes0 dtypetffloat32 tftensorspecshapes1 dtypetffloat32 dataset valdataset strategy with strategyscope m unet28builds0 epochsargsep stepsperepoch spevalidationsteps relevant log output shell 20230703 134714532355 w the calling iterator did not fully read the dataset being cached in order to avoid unexpected truncation of the dataset the partially cached contents of the dataset will be discarded this can happen if you have an input pipeline similar to you should use instead"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNot correct result from tf.split()\nissue type bug have you reproduced the bug with tensorflow nightly no source binary tensorflow version tf 2829210 custom code no os platform and distribution both on mac and on ubuntu mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behavior tryng to split a four axes tensor i got some unexpected zeros in the splitted tensors this behaviour is not presented in the tf 212 is an old bug standalone code to reproduce the issue shell import tensorflow as tf vectfones176831400 printsplitted zeros have occured in the tensor relevant log output shell no"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n` #include \"include/float8.h\"  // from @ml_dtypes` is missing\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source source tensorflow version 2140 custom code yes os platform and distribution mobile device no python version 38 bazel version na gcccompiler version nr cudacudnn version nr gpu model and memory nr current behaviour create a testcc include compile it with flags provided by tensorflow getcompileflags dglibcxxusecxx11abi1 stdc17 getlinkflags g wlrorigin wlrpathorigin stdc17 dndebug shared testcc o tmptestso fpic dglibcxxusecxx11abi1 stdc17 iusrinclude iusrlocalcudainclude o2 the result is in file included from from from from from from from from from fatal error includefloat8h no such file or directory 19 include includefloat8h from mldtypes it is probably caused by this pr either should have include from mldtypes or getcompileflags should include standalone code to reproduce the issue shell as above relevant log output shell as above"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nModel running on CPU when using NNAPI even with NnApiDelegate.Options().useNnapiCpu = false\nclick to expand issue type bug have you reproduced the bug with tf nightly no source binary tensorflow version tensorflowlite 2120 custom code yes os platform and distribution no response mobile device google pixel 7 python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour i am running the openai whisper tiny model on android using the tensorflow lite nnapi delegate it seems to be running on the cpu instead of the hardware accelerator on the google pixel 7 even though false is set standalone code to reproduce the issue shell false relevant log output shell w access denied finding property romediatekplatform w access denied finding property rochipname w access denied finding property rohardwarechipname i created tensorflow lite xnnpack delegate for cpu"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNoClassDefFoundError: GpuDelegateFactory$Options not found\nclick to expand issue type bug have you reproduced the bug with tf nightly false source source tensorflow version tf212 custom code yes os platform and distribution android 12 mobile device android 12 python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour the gpu is not being used correctly standalone code to reproduce the issue shell implementation implementation interpreteroptions options new interpreteroptions gpudelegate file file new interpreter interpreter new interpreterfile options relevant log output shell eandroidruntime fatal exception main process pid 13553 failed resolution of at at at at at at at at at at at at at at method at at caused by didnt find class on path dexpathlistzip file systemlib64 systemsystemextlib64 at at at at at at at at at at at at at at at at at method at at"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTF2.13 Breaks register_keras_serializable\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source pypi tensorflow version tf2130rc2 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour when building tf addons for tf213 were noticing that our ability to register custom keras objects as serializable has been broken class def initself units kwargs superinitunits kwargs standalone code to reproduce the issue shell here it is shown as working in tf212 here it breaks in tf213 relevant log output shell valueerror unknown layer mydense please ensure you are using a and that this object is included in the scope see for details"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError to run tf\nclick to expand issue type bug have you reproduced the bug with tf nightly no source source tensorflow version 210 custom code yes os platform and distribution windowsx 11 mobile device no response python version 3109 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour when i try to run tensorflow import him i get this error image standalone code to reproduce the issue shell import tensorflow as tf relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nXLA unit tests fail to build on gcc\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source source tensorflow version git head custom code no os platform and distribution ubuntu 2004 mobile device na python version 3813 bazel version 610 gcccompiler version 1021 cudacudnn version na gpu model and memory na current behaviour 3 unit tests fail to build and one fails with error standalone code to reproduce the issue shell bazel test relevant log output shell error compiling failed exit 1 gcc failed error executing command from target cd exec env cachebuster20220325 pwdprocselfcwd tf2behavior1 dt10usrbingcc md mf deigenmpl2only dhavesysuioh dtfusesnappy iquote iquote iquote externaleigenarchive iquote iquote iquote iquote externalnsync iquote iquote iquote iquote iquote iquote externalsnappy iquote iquote iquote iquote iquote iquote iquote iquote iquote iquote externalzlib iquote iquote externalbazeltools iquote isystem externaleigenarchive isystem isystem externalnsyncpublic isystem isystem isystem isystem isystem isystem isystem isystem isystem isystem isystem isystem isystem isystem externalzlib isystem ddateredacted dtimestampredacted dtimeredacted fpie ufortifysource dfortifysource1 fstackprotector wall fnoomitframepointer nocanonicalprefixes dndebug g0 o2 ffunctionsections fdatasections wnoall wnoextra wnodeprecated wnoignoredattributes wnoarraybounds wunusedresult werrorunusedresult wswitch werrorswitch mtunegeneric marcharmv8a o3 stdc17 sysrootdt10 c o configuration execution platform in member function virtual void error call of overloaded tileassignment is ambiguous 3488 tileassignment 2 in file included from from from from from note candidate 173 explicit dims note candidate 172 explicit iota iotastdmoveiota and more"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTF Lite Converter produces outputs in an incorrect order when multiple outputs are present\n1 system information os platform and distribution eg linux ubuntu 1604 linux ubuntu 2004 tensorflow installation pip package or built from source pip tensorflow library version if pip package or github sha if built from source 2140dev20230622 2 code this is the minimized code to reproduce the issue python import tensorflow as tf import numpy as np x1 tfconstant1 shape11 class modeltfkerasmodel def initself supermodel selfinit def callself x1 x2 tfeye1 x3 tfeye2 x4 tfeye1 return x2 x3 x4 m model expectedvalue mx1 converter tflitemodel converterconvert def inputdata interpreter inputdetails outputdetails for i in rangeleninputdata inputdatai interpreterinvoke outputdata for i in return outputdata actualvalue outputs printfexpected output1 expectedvalue0numpy printflite output1 actualvalue0 print printfexpected output2 expectedvalue1numpy printflite output2 actualvalue1 print printfexpected output3 expectedvalue2numpy printflite output3 actualvalue2 wrong order output ir 3 failure after conversion output incorrect order expected output1 1 lite output1 1 expected output2 1 0 0 1 lite output2 1 expected output3 1 lite output3 1 0 0 1 lite ir subgraph0 maint0 t1 t1 t2 tensors of subgraph0 shapesignature1 1 typefloat32 t1partitionedcall0 shape1 1 typefloat32 ro 4 bytes buffer 2 data1 t2partitionedcall1 shape2 2 typefloat32 ro 16 bytes buffer 3 data1 0 0 1 tf lite converter produces wrong outputs in the lite ir the ouput should be t1 t2 t1 instead of t1 t1 t2"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfloat8 (both e4m3fn and e5m2) missing from numbertype\nissue type bug have you reproduced the bug with tf nightly no source binary tensorflow version 2120 custom code yes os platform and distribution mobile device no response python version 396 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour fp8 datatypes are missing from knumbertypes in and also missing from tfcallfloattypesm in this causes simple ops like slice transpose split etc to raise notfounderror standalone code to reproduce the issue python import tensorflow as tf from import dtypes a tfconstant12345678 23456789 34567891 45678912 56789123 67891234 dtypedtypesfloat16 printa afp8 tfcasta dtypesfloat8e4m3fn printafp8 b afp812 b tftransposeafp8 1 0 relevant log output could not find device for node node stridedslice tdtfloat8e4m3fn beginmask0 ellipsismask0 endmask0 newaxismask0 shrinkaxismask0 all kernels registered for op stridedslice devicexlacpujit index in dtint32 dtint16 dtint64 t in dtfloat dtdouble dtint32 dtuint8 dtint16 930109355527764061 dthalf dtuint32 dtuint64 dtfloat8e5m2 dtfloat8e4m3fn devicecpu t in dtuint64 devicecpu t in dtint64 devicecpu t in dtuint32 devicecpu t in dtuint16 devicecpu t in dtint16 devicecpu t in dtuint8 devicecpu t in dtint8 devicecpu t in dtint32 devicecpu t in dthalf devicecpu t in dtbfloat16 devicecpu t in dtfloat devicecpu t in dtdouble devicecpu t in dtcomplex64 devicecpu t in dtcomplex128 devicecpu t in dtbool devicecpu t in dtstring devicecpu t in dtresource devicecpu t in dtvariant devicecpu t in dtqint8 devicecpu t in dtquint8 devicecpu t in dtqint32 devicedefault t in dtint32 opstridedslice name stridedslice could not find device for node node transpose tpermdtint32 all kernels registered for op transpose devicexlacpujit tperm in dtint32 dtint64 t in dtfloat dtdouble dtint32 dtuint8 dtint16 930109355527764061 dthalf dtuint32 dtuint64 dtfloat8e5m2 dtfloat8e4m3fn devicecpu t in dtuint64 devicecpu t in dtint64 devicecpu t in dtuint32 devicecpu t in dtuint16 devicecpu t in dtint16 devicecpu t in dtuint8 devicecpu t in dtint8 devicecpu t in dtint32 devicecpu t in dthalf devicecpu t in dtbfloat16 devicecpu t in dtfloat devicecpu t in dtdouble devicecpu t in dtcomplex64 devicecpu t in dtcomplex128 devicecpu t in dtbool devicecpu t in dtstring devicecpu t in dtresource devicecpu t in dtvariant optranspose"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nandroid gpu delegate Failed to build program executable\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source source tensorflow version 210 or 211 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour a bug happened i test gpu delegate on oppo r9 will reture error value error failed to build program executable build program failure3526 error opencl extension clkhr3dimagewrites is not supported pragma opencl extension clkhr3dimagewrites enable error compiler frontend failed error code 58 error falling back to opengl error tflitegpudelegate init openglbased api disabled error tflitegpudelegate prepare delegate is not initialized error node number 100 tflitegpudelegatev2 failed to prepare error restored original execution plan after delegate application failure tflite gpu delegate create failed2 standalone code to reproduce the issue shell oppo r9 is produced in 2016 year relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nget_file raises exception if the content-length is unknown\nclick to expand issue type bug have you reproduced the bug with tf nightly no source binary tensorflow version 2110 custom code no os platform and distribution ubuntu 22042 lts mobile device no response python version 3106 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour calling getfile on a url that doesnt indicate the contentlength causes an exception standalone code to reproduce the issue shell import tensorflow as tf origin printp relevant log output shell downloading data from 8192unknown 0s 0ussteptraceback most recent call last file homekentenvmlsrcf3py line 3 in file line 300 in getfile urlretrieveorigin fpath dlprogbar file line 86 in urlretrieve for chunk in chunkreadresponse reporthookreporthook file line 78 in chunkread reporthookcount chunksize totalsize file line 294 in call file line 252 in update bar 7dunknown current typeerror d format a real number is required not nonetype"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSome parameters are missing type descriptions\nclick to expand issue type documentation bug have you reproduced the bug with tf nightly yes source source tensorflow version tf 2120 custom code yes os platform and distribution no response mobile device no response python version no response bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour html xmlns link idmainfile relmainfile link relfilelist table page margin75in 7in 75in 7in msoheadermargin3in msofootermargin3in font5 colorwindowtext fontsize90pt fontweight400 fontstylenormal textdecorationnone fontfamily等线 msofontcharset134 tr msoheightsourceauto col msowidthsourceauto br td paddingtop1px paddingright1px paddingleft1px msoignorepadding colorblack fontsize110pt fontweight400 fontstylenormal textdecorationnone fontfamily等线 msofontcharset134 textaligngeneral verticalalignbottom bordernone msopatternauto msoprotectionlocked visible whitespacenowrap msorotate0 ruby rubyalignleft rt colorwindowtext fontsize90pt fontweight400 fontstylenormal textdecorationnone fontfamily等线 msofontcharset134 msochartypenone displaynone api lack of type desciption params tfsparsebincount values tfkeraslayersinput tensor inputtensor tfmathaddn inputs inputtensor tfdevice devicename identifier metrics tfexpanddims input inputtensor tfsignalframe signal ytrue 、 ypred ytrue 、 ypred ytrue 、 ypred tfkeraslosseslogcosh ytrue 、 ypred inputtensor ytrue 、 ypred expectedcardinality ytrue 、 ypred tflossessquaredhinge ytrue 、 ypred x、y、sampleweight x tfnndepthtospace input tfgathernd params tfzeroslike input inputtensor metrics tfstack values tfensureshape x tfroll input x tflinalgsetdiag input、diagonal、k tfmathbincount arr、weights tfconcat values inputtensor ytrue 、 ypred tfrandomcategorical logits x x tfpad tensor gain inputtensor tfrepeat input image tfsplit value y tfscatternd updates input bands、rhs tfoneslike input tfnestflatten structure x input image devices tfsize input tfimageresize images tftile input inputtensor ytrue 、 ypred gain image tfraggedrange starts、limits、deltas tfreshape tensor tflosseslogcosh ytrue 、 ypred inputtensor tfnnmoments x inputtensor image ytrue 、 ypred controlinputs images tfimagergbtoyiq images inputtensor tfraggedbooleanmask data、mask tfimagerandomhue image tfimageadjustgamma image tfistensor x gain tfmathpolyval coeffs、x tfioserializetensor tensor image tfonehot indices tflinalgdiagpart input、paddingvalue、 image tfbooleanmask tensor、mask tftranspose a tfimageflipupdown image ytrue 、 ypred tfbroadcastto input value ytrue 、 ypred image image x inputtensor tfidentity input tfgather params inputtensor tfkeraslayersmasking maskvalue ytrue 、 ypred tflinalgbandpart input ytrue 、 ypred image tfimagetranspose image tfstopgradient input tfstringsbytessplit input ytrue 、 ypred image inputtensor ytrue 、 ypred tfnnembeddinglookup params tfmathreducevariance inputtensor data tfnnl2normalize x ytrue 、 ypred inputtensor identifier gain tfdivide x、y tfmathtopk input ytrue 、 ypred image ytrue 、 ypred inputtensor tfclipbyvalue t tftypespecfromvalue value ytrue 、 ypred tensor、indices tfequal x、y images image tfimagergbtohsv images tfconverttotensor value ytrue 、 ypred x tfslice input tfimageadjusthue image tfmathargmax input tfreversesequence input ytrue 、 ypred ytrue 、 ypred tfsqueeze input tfmathequal x、y tfmathdivide x、y tfunstack value inputtensor inputtensor x inputtensor x ytrue 、 ypred ytrue 、 ypred ytrue 、 ypred ytrue 、 ypred ytrue 、 ypred inputtensor x tfimageflipleftright image inputtensor tfmathreducemin inputtensor inputtensor tfmathnotequal x、y tfimagerot90 image inputtensor image inputtensor inputtensor ytrue 、 ypred tfsparsecross inputs ytrue 、 ypred image standalone code to reproduce the issue shell many parameters are not for any type of value so the allowed types should be clearly marked in the document relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTensorboard histogram onehot operation causing ResourceExhauseError: OOM\nclick to expand issue type bug have you reproduced the bug with tf nightly yes source source tensorflow version 28 custom code yes os platform and distribution linux ubuntu 2004 mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour im trying to train a vgg16 model im using a sample dataset of 4000 300x300 images in 14 classes and running my code on a google vm using an nvidia l4 gpu with 20gb of memory i am running python 37 tf version 211 and cuda version 121 my data is stored in gcs when i run the model with the following tensorboard callback tensorboardcallback histogramfreq1 i get this error at the end of the first epoch 20230614 195121248476 w allocator mklcpu ran out of memory trying to allocate 2297gib rounded to 24662507520requested by op onehot if the cause is memory fragmentation maybe the environment variable will improve the situation functionnode oom when allocating tensor with shape10276044830 and type double on by allocator mklcpu oponehot the error traces back to the tensorboard histogram object traceback most recent call last in 1 fit model 2 history modelfittrainds validationdatavalds epochs5 in errorhandlerargs kwargs 68 to get the full stack trace call 69 70 raise from none 71 finally 72 del filteredtb in histogramname data step buckets description 198 tensorlazytensor 199 stepstep 200 201 202 in callself 64 elif selftensor is none 65 selftensor 66 selftensor selftensorcallable 67 return selftensor 68 in lazytensor 192 193 def lazytensor 194 return bucketsdata buckets 195 196 return tfsummarywrite in bucketsdata bucketcount 291 292 293 return tfcondisempty whenempty whennonempty in whennonempty 288 289 return tfcond 290 hassinglevalue whensinglevalue whenmultiplevalues 291 292 in whenmultiplevalues 257 see for details 258 onehots tfonehot 259 clampedindices depthbucketcount dtypetffloat64 260 261 bucketcounts tfcast functionnode oom when allocating tensor with shape10276044830 and type double on by allocator mklcpu oponehot interestingly it seems to be calling tfonehot and blowing up the gpu memory with a massive tensor regardless of whether i train the model with integer labels and spare categorical cross entropy or if i train it with one hot labels and cross entropy i dont really understand what the tensor contains because its dimensions neither relate to the number of training examples or classes that i am using standalone code to reproduce the issue shell tensorboardcallback histogramfreq1 i get this error at the end of the first epoch 20230614 195121248476 w allocator mklcpu ran out of memory trying to allocate 2297gib rounded to 24662507520requested by op onehot if the cause is memory fragmentation maybe the environment variable will improve the situation functionnode oom when allocating tensor with shape10276044830 and type double on by allocator mklcpu oponehot relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntf.test.gpu_device_name() leads to soft lockup and unusable system\nclick to expand issue type bug have you reproduced the bug with tf nightly no source binary tensorflow version 2120 custom code yes os platform and distribution linux ubuntu 2004 mobile device no response python version 3816 conda 114 bazel version no response gcccompiler version no response cudacudnn version 114 gpu model and memory nvidia t4 current behaviour we found that running tftestgpudevicename leads to a soft lockup and an unresponsive system i apologise in advance i dont know much about tensorflow but several of my coworkers do and im in charge of maintaining infrastructure we have a virtual server for computeintensive tasks where we train models and work with large datasets yesterday at about 7 local time i found that i couldnt ssh into the server so i had to wait for it to forcibly restart the server at around 13 local time the server was back up and i looked through the kernel logs to find that there was a soft lockup kernel bug this means that the server was still running but some process wasnt releasing the cpu for more than 20 seconds which meant that no other process could fulfill its tasks not even half an hour later and the server locked up again i got a message from a coworker who suspected that they were at fault for the server locking up because they started running a very computeintensive python script on the server last night they opened a python shell and typed in these two lines and watched the server lock up in real time py import tensorflow as tf printdefault gpu i provided the relevant log output below it required another hard reset from it to get the server back into a working state after the server restarted again i had another look at the kernel logs and found that the reported errors were the same which means i have reason to believe that running tftestgpudevicename consistently leads to a soft lockup on our infrastructure as mentioned previously we run our computations on a virtual server the hypervisor is vmware were running on a nvidia t4 gpu with nvidia drivers in version 4706301 these drivers were provided to us by it installing another version for some reason isnt possible and i prefer not to mess with that the coworker installed tensorflow in a conda environment using pip since were running on a virtual server we depend on it in case things go very wrong this means our means of reproducing this issue are somewhat limited if the server locks up we have to wait up to a couple hours for our service desk to escalate this issue enough so that it restarts the server we cannot afford downtimes like these since we rely on the server for our computations im happy to provide any logs from previous runs but if possible i would like to not share them on github in their entirety since they might contain confidential info standalone code to reproduce the issue shell import tensorflow as tf printdefault gpu device relevant log output shell output from running the function in a python shell python3 python 3816 default mar 2 2023 032146 gcc 1120 anaconda inc on linux type help copyright credits or license for more information import tensorflow as tf 20230615 133449940226 i could not find cuda drivers on your machine gpu will not be used 20230615 133450367115 i could not find cuda drivers on your machine gpu will not be used 20230615 133450368678 i this tensorflow binary is optimized to use available cpu instructions in performancecritical operations to enable the following instructions avx2 fma in other operations rebuild tensorflow with the appropriate compiler flags 20230615 133452102738 w tftrt warning could not find tensorrt printdefault gpu 20230615 133505586532 i successful numa node read from sysfs had negative value 1 but there must be at least one numa node so returning numa node zero see more at 20230615 133505587485 w cannot dlopen some gpu libraries please make sure the missing libraries mentioned above are installed properly if you would like to use gpu follow the guide at for how to download and setup the required libraries for your platform skipping registering gpu devices message from syslogds050009088 at jun 15 133532 kernel 176957689 watchdog bug soft lockup cpu6 stuck for 22s python34167 output from journalctl jun 15 133505 s050009088 kernel nvidiauvm loaded the uvm driver major device number 238 jun 15 133505 s050009088 kernel cut here jun 15 133505 s050009088 kernel trying to vfree nonexistent vm area 00000000f9521180 jun 15 133505 s050009088 kernel warning cpu 6 pid 4167 at mmvmallocc2245 vunmap0x1ff0x210 jun 15 133505 s050009088 kernel modules linked in nvidiauvmoe veth xtnat xttcpudp xtconntrack xtmasquerade nfconntracknetlink nfnetlink xfrmuser xfrmalgo iptablenat nfnat nfconntrack nfdefragipv6 nfdefragipv4 xtaddrtype iptablefilter bpfilter brnetfilter bridge stp llc aufs overlay vsock dmmultipath scsidhrdac scsidhemc scsidhalua binfmtmisc nvidiadrmpoe nvidiamodesetpoe intelraplmsr nvidiapoe vmwballoon intelraplcommon inputleds intelpowerclamp joydev rapl serioraw vmwvmci machid schfqcodel msr ramoops reedsolomon efipstore iptables xtables autofs4 btrfs zstdcompress raid10 raid456 asyncraid6recov asyncmemcpy asyncpq asyncxor asynctx xor raid6pq libcrc32c raid1 raid0 multipath linear vmwgfx crct10difpclmul crc32pclmul ttm ghashclmulniintel drmkmshelper syscopyarea aesniintel sysfillrect cryptosimd sysimgblt mptspi cryptd fbsysfops gluehelper psmouse mptscsih drm mptbase ahci i2cpiix4 vmxnet3 scsitransportspi jun 15 133505 s050009088 kernel libahci pataacpi jun 15 133505 s050009088 kernel cpu 6 pid 4167 comm python3 tainted p oe 540150generic 167ubuntu jun 15 133505 s050009088 kernel hardware name vmware inc vmware virtual platform440bx desktop reference platform bios 600 11122020 jun 15 133505 s050009088 kernel rip 0010vunmap0x1ff0x210 jun 15 133505 s050009088 kernel code ff e8 d5 fc ff ff eb bf 48 89 fe 48 c7 c7 a0 6d b8 8e e8 36 ba 82 00 0f 0b eb b4 4c 89 ee 48 c7 c7 c8 6d b8 8e e8 23 ba 82 00 0b eb a1 66 66 2e 0f 1f 84 00 00 00 00 00 66 90 0f 1f 44 00 00 jun 15 133505 s050009088 kernel rsp 0018ffffab66c32b7c00 eflags 00010286 jun 15 133505 s050009088 kernel rax 0000000000000000 rbx 0000000000000001 rcx 0000000000000006 jun 15 133505 s050009088 kernel rdx 0000000000000007 rsi 0000000000000096 rdi ffff8ce3bfb9c8c0 jun 15 133505 s050009088 kernel rbp ffffab66c32b7c28 r08 00000000000006d2 r09 286565726676206f jun 15 133505 s050009088 kernel r10 286565726676206f r11 6978656e6f6e2029 r12 0000000000000000 jun 15 133505 s050009088 kernel r13 ffff8ce22c348000 r14 ffff8ce22c349000 r15 0000000000000027 jun 15 133505 s050009088 kernel fs 00007fbf935e31800000 jun 15 133505 s050009088 kernel cs 0010 ds 0000 es 0000 cr0 0000000080050033 jun 15 133505 s050009088 kernel cr2 000000000435c3d0 cr3 0000001e50400001 cr4 00000000003606e0 jun 15 133505 s050009088 kernel call trace jun 15 133505 s050009088 kernel vfree0x220x60 jun 15 133505 s050009088 kernel vfree0x2c0x40 jun 15 133505 s050009088 kernel osfreemem0x1b0x30 nvidia jun 15 133505 s050009088 kernel nvidia jun 15 133505 s050009088 kernel nv000647rm0xdc0x160 nvidia jun 15 133505 s050009088 kernel warning kernel stack frame pointer at 0000000068b18731 in python34167 has bad value 00000000f3874266 jun 15 133505 s050009088 kernel unwind stack type0 mask0x2 graphidx0 jun 15 133505 s050009088 kernel 00000000c0e190e6 ffffab66c32b7c40 0xffffab66c32b7c40 jun 15 133505 s050009088 kernel 0000000074c2bd79 ffffffff8da6e972 vfree0x220x60 jun 15 133505 s050009088 kernel 00000000ea3bef41 0000000000000200 0x200 jun 15 133505 s050009088 kernel 00000000d32e6150 ffffab66c32b7c58 0xffffab66c32b7c58 jun 15 133505 s050009088 kernel 00000000e4c2b257 ffffffff8da6e9dc vfree0x2c0x40 jun 15 133505 s050009088 kernel 000000008b622c26 ffff8ce22c348000 0xffff8ce22c348000 jun 15 133505 s050009088 kernel 00000000b443bda0 ffffab66c32b7c68 0xffffab66c32b7c68 jun 15 133505 s050009088 kernel 0000000004f89fc7 ffffffffc068ccdb osfreemem0x1b0x30 nvidia jun 15 133505 s050009088 kernel 0000000058382150 ffffab66c32b7c98 0xffffab66c32b7c98 jun 15 133505 s050009088 kernel 000000007fb1b873 ffffffffc068edfc nvidia jun 15 133505 s050009088 kernel 00000000629b0f28 ffff8ce395ff60c8 0xffff8ce395ff60c8 jun 15 133505 s050009088 kernel 000000003a4ac7ef 0000010004400000 0x10004400000 jun 15 133505 s050009088 kernel 000000005e9a76c9 0000000000000200 0x200 jun 15 133505 s050009088 kernel 000000005fe4a88b 00000000aa000000 0xaa000000 jun 15 133505 s050009088 kernel 0000000068b18731 ffff8ce3b3e92fb0 0xffff8ce3b3e92fb0 jun 15 133505 s050009088 kernel 00000000bd345bcf ffffffffc101e8dc nv000647rm0xdc0x160 nvidia jun 15 133505 s050009088 kernel 0000000089f90db7 ffff8ce395ff60c8 0xffff8ce395ff60c8 jun 15 133505 s050009088 kernel 00000000c99c1977 ffff8ce39726c0c0 0xffff8ce39726c0c0 jun 15 133505 s050009088 kernel 000000009060a662 0000000000000008 0x8 jun 15 133505 s050009088 kernel 0000000043ee1352 ffffffffc101f3a3 nv000723rm0xa430xa90 nvidia jun 15 133505 s050009088 kernel 0000000064b64c73 0000000000000000 jun 15 133505 s050009088 kernel 0000000030c878cd ffff8ce3b35bc000 0xffff8ce3b35bc000 jun 15 133505 s050009088 kernel 00000000e60fac70 ffffffffc101f316 nv000723rm0x9b60xa90 nvidia jun 15 133505 s050009088 kernel 0000000065747b0c ffff8ce3b3e90000 0xffff8ce3b3e90000 jun 15 133505 s050009088 kernel 0000000063da2df1 ffff8ce3a658b800 0xffff8ce3a658b800 jun 15 133505 s050009088 kernel 0000000008c0ac4e ffffab66c32b7e48 0xffffab66c32b7e48 jun 15 133505 s050009088 kernel 0000000057ee515b ffff8ce3b35b9400 0xffff8ce3b35b9400 jun 15 133505 s050009088 kernel 000000006c5468b7 0000000000000027 0x27 jun 15 133505 s050009088 kernel 0000000065281df3 ffffffffc1025204 rmioctl0x540xb0 nvidia jun 15 133505 s050009088 kernel 00000000b419e233 000000388da5fdb5 0x388da5fdb5 jun 15 133505 s050009088 kernel 000000006f1b29a3 ffff8ce39726c0c0 0xffff8ce39726c0c0 jun 15 133505 s050009088 kernel 00000000465f1196 8000000000000027 0x8000000000000027 jun 15 133505 s050009088 kernel 0000000024eadd83 0000000000001047 0x1047 jun 15 133505 s050009088 kernel 00000000e74dc1ab 00000000000007e9 0x7e9 jun 15 133505 s050009088 kernel 00000000f6d262ce 003d08dcf6746300 0x3d08dcf6746300 jun 15 133505 s050009088 kernel 00000000400760c5 003d08dde4df8b00 0x3d08dde4df8b00 jun 15 133505 s050009088 kernel 00000000c7874ca7 003d08e3f2980f00 0x3d08e3f2980f00 jun 15 133505 s050009088 kernel 00000000946d2608 003d08dd6da9f700 0x3d08dd6da9f700 jun 15 133505 s050009088 kernel 000000007a9cecb7 0000000000000000 jun 15 133505 s050009088 kernel 000000000e6b2400 0000000000000200 0x200 jun 15 133505 s050009088 kernel 0000000022df682d 0000002000000006 0x2000000006 jun 15 133505 s050009088 kernel 0000000005972aee 0000000000001047 0x1047 jun 15 133505 s050009088 kernel 00000000f3ab8670 0000000000000000 jun 15 133505 s050009088 kernel 0000000043395ee6 0000000000000001 0x1 jun 15 133505 s050009088 kernel 0000000090b81e91 0000000000000000 jun 15 133505 s050009088 kernel 00000000ce75a231 ffff8ce39726c0c0 0xffff8ce39726c0c0 jun 15 133505 s050009088 kernel 00000000336aa9c4 0000000000000038 0x38 jun 15 133505 s050009088 kernel 0000000016e174a9 ffff8ce3b35b9400 0xffff8ce3b35b9400 jun 15 133505 s050009088 kernel 00000000c453e6ee ffff8ce3a658b800 0xffff8ce3a658b800 jun 15 133505 s050009088 kernel 00000000ca8fc06a 0000000000000000 jun 15 133505 s050009088 kernel 0000000027388a61 ffffffffc068268f nvidia jun 15 133505 s050009088 kernel 000000001f100b3c ffff8ce3b3e90000 0xffff8ce3b3e90000 jun 15 133505 s050009088 kernel 00000000d70e2948 00007ffd116cef60 0x7ffd116cef60 jun 15 133505 s050009088 kernel 000000009e15ae1f ffff8ce3b35b9498 0xffff8ce3b35b9498 jun 15 133505 s050009088 kernel 000000002d53d487 00007ffd00000027 0x7ffd00000027 jun 15 133505 s050009088 kernel 000000002ea37e99 0000000000000000 jun 15 133505 s050009088 kernel 00000000723c86e7 0000000000000003 0x3 jun 15 133505 s050009088 kernel 000000004b070af4 3c5520dc9b31e900 0x3c5520dc9b31e900 jun 15 133505 s050009088 kernel 00000000260adce7 ffff8ce3a37b1e01 0xffff8ce3a37b1e01 jun 15 133505 s050009088 kernel 00000000f3ab64dd ffff8ce3a37b1e00 0xffff8ce3a37b1e00 jun 15 133505 s050009088 kernel 000000009250db0d ffff8ce3a46feaa0 0xffff8ce3a46feaa0 jun 15 133505 s050009088 kernel 000000001a439626 00007ffd116cef60 0x7ffd116cef60 jun 15 133505 s050009088 kernel 00000000d28c869f ffff8ce3a37b1e00 0xffff8ce3a37b1e00 jun 15 133505 s050009088 kernel 00000000264cc6e1 ffffab66c32b7e58 0xffffab66c32b7e58 jun 15 133505 s050009088 kernel 00000000c9cdb9ef ffffffffc069191b nvidia jun 15 133505 s050009088 kernel 00000000dc15a7de ffffab66c32b7ed8 0xffffab66c32b7ed8 jun 15 133505 s050009088 kernel 000000009b8c3053 ffffffff8dae8e77 dovfsioctl0x4070x670 jun 15 133505 s050009088 kernel 00000000f2d02675 0000010004400000 0x10004400000 jun 15 133505 s050009088 kernel 00000000c52e1241 0000000000000000 jun 15 133505 s050009088 kernel 0000000027ba7e88 ffffab66c32b7e78 0xffffab66c32b7e78 jun 15 133505 s050009088 kernel 00000000aaf3e429 ffffab66c32b7e78 0xffffab66c32b7e78 jun 15 133505 s050009088 kernel 00000000fd0b1f6d 3c5520dc9b31e900 0x3c5520dc9b31e900 jun 15 133505 s050009088 kernel 0000000051d890d1 0000000000000031 0x31 jun 15 133505 s050009088 kernel 000000001e5b54d6 0000000000200000 0x200000 jun 15 133505 s050009088 kernel 00000000bf7d038a 0000000000000000 jun 15 133505 s050009088 kernel 00000000a021b6f5 3c5520dc9b31e900 0x3c5520dc9b31e900 jun 15 133505 s050009088 kernel 00000000382d5bbd ffff8ce3a37b1e01 0xffff8ce3a37b1e01 jun 15 133505 s050009088 kernel 000000005691996c 0000000000000006 0x6 jun 15 133505 s050009088 kernel 000000002b0a9fae 00000000c0384627 0xc0384627 jun 15 133505 s050009088 kernel 00000000ed0791ed 00007ffd116cef60 0x7ffd116cef60 jun 15 133505 s050009088 kernel 00000000944e63ee ffff8ce3a37b1e00 0xffff8ce3a37b1e00 jun 15 133505 s050009088 kernel 00000000b8133399 ffffab66c32b7f18 0xffffab66c32b7f18 jun 15 133505 s050009088 kernel 000000006b019d54 ffffffff8dae9147 ksysioctl0x670x90 jun 15 133505 s050009088 kernel 0000000025959ce7 3c5520dc9b31e900 0x3c5520dc9b31e900 jun 15 133505 s050009088 kernel 0000000019e92101 0000000000000000 jun 15 133505 s050009088 kernel 000000002801fc84 ffffab66c32b7f58 0xffffab66c32b7f58 jun 15 133505 s050009088 kernel 0000000060185eb1 0000000000000000 jun 15 133505 s050009088 kernel 000000007c1db1b7 ffffab66c32b7f28 0xffffab66c32b7f28 jun 15 133505 s050009088 kernel 0000000084b8d84e ffffffff8dae918a x64sysioctl0x1a0x20 jun 15 133505 s050009088 kernel 000000009b8e8f5f ffffab66c32b7f48 0xffffab66c32b7f48 jun 15 133505 s050009088 kernel 00000000f2da7b14 ffffffff8d804fd7 dosyscall640x570x190 jun 15 133505 s050009088 kernel 00000000942f1f70 0000000000000000 jun 15 133505 s050009088 kernel 00000000f56a3750 ffffffff8e4000a4 jun 15 133505 s050009088 kernel 0000000018f467fe 00007ffd116ceed0 0x7ffd116ceed0 jun 15 133505 s050009088 kernel 00000000831b89bf 00000000648af769 0x648af769 jun 15 133505 s050009088 kernel 000000000597aba6 00007ffd116cef88 0x7ffd116cef88 jun 15 133505 s050009088 kernel 00000000a139f77e 0000000000000006 0x6 jun 15 133505 s050009088 kernel 000000006612db4e 00000000c0384627 0xc0384627 jun 15 133505 s050009088 kernel 00000000ab55bfe9 00007ffd116cef60 0x7ffd116cef60 jun 15 133505 s050009088 kernel 000000000b644430 0000000000000246 0x246 jun 15 133505 s050009088 kernel 00000000d2d8779b 0000000000000000 jun 15 133505 s050009088 kernel 00000000725ab6b6 00007ffd116cef88 0x7ffd116cef88 jun 15 133505 s050009088 kernel 000000000399d500 00007ffd116cef60 0x7ffd116cef60 jun 15 133505 s050009088 kernel 00000000c0a877c1 ffffffffffffffda 0xffffffffffffffda jun 15 133505 s050009088 kernel 00000000fb645881 00007fbf936f83ab 0x7fbf936f83ab jun 15 133505 s050009088 kernel 00000000f6cd2602 00007ffd116cef60 0x7ffd116cef60 jun 15 133505 s050009088 kernel 000000006fc36d91 00000000c0384627 0xc0384627 jun 15 133505 s050009088 kernel 00000000e5058b78 0000000000000006 0x6 jun 15 133505 s050009088 kernel 000000002777ac42 0000000000000010 0x10 jun 15 133505 s050009088 kernel 00000000d68cb82a 00007fbf936f83ab 0x7fbf936f83ab jun 15 133505 s050009088 kernel 0000000077e7b064 0000000000000033 0x33 jun 15 133505 s050009088 kernel 0000000037ef3830 0000000000000246 0x246 jun 15 133505 s050009088 kernel 00000000fcba1669 00007ffd116ceec8 0x7ffd116ceec8 jun 15 133505 s050009088 kernel 00000000ea0caaa1 000000000000002b 0x2b jun 15 133505 s050009088 kernel nv000723rm0xa430xa90 nvidia jun 15 133505 s050009088 kernel nv000723rm0x9b60xa90 nvidia jun 15 133505 s050009088 kernel rmioctl0x540xb0 nvidia jun 15 133505 s050009088 kernel nvidia jun 15 133505 s050009088 kernel nvidia jun 15 133505 s050009088 kernel dovfsioctl0x4070x670 jun 15 133505 s050009088 kernel ksysioctl0x670x90 jun 15 133505 s050009088 kernel x64sysioctl0x1a0x20 jun 15 133505 s050009088 kernel dosyscall640x570x190 jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel end trace be1a4a9ea080b7b8 the following logs are then repeatedly printed leading to the soft lockup jun 15 133505 s050009088 kernel bug bad page state in process python3 pfn1e301a6 jun 15 133505 s050009088 kernel pageffffd052f8c06980 refcount0 mapcount0 index0x1 jun 15 133505 s050009088 kernel shmemaops namedevzero jun 15 133505 s050009088 kernel flags 0x17ffffc0000000 jun 15 133505 s050009088 kernel raw 0017ffffc0000000 dead000000000100 dead000000000122 ffff8ce230f6e0d8 jun 15 133505 s050009088 kernel raw 0000000000000001 0000000000000000 00000000ffffffff 0000000000000000 jun 15 133505 s050009088 kernel page dumped because nonnull mapping jun 15 133505 s050009088 kernel modules linked in nvidiauvmoe veth xtnat xttcpudp xtconntrack xtmasquerade nfconntracknetlink nfnetlink xfrmuser xfrmalgo iptablenat nfnat nfconntrack nfdefragipv6 nfdefragipv4 xtaddrtype iptablefilter bpfilter brnetfilter bridge stp llc aufs overlay vsock dmmultipath scsidhrdac scsidhemc scsidhalua binfmtmisc nvidiadrmpoe nvidiamodesetpoe intelraplmsr nvidiapoe vmwballoon intelraplcommon inputleds intelpowerclamp joydev rapl serioraw vmwvmci machid schfqcodel msr ramoops reedsolomon efipstore iptables xtables autofs4 btrfs zstdcompress raid10 raid456 asyncraid6recov asyncmemcpy asyncpq asyncxor asynctx xor raid6pq libcrc32c raid1 raid0 multipath linear vmwgfx crct10difpclmul crc32pclmul ttm ghashclmulniintel drmkmshelper syscopyarea aesniintel sysfillrect cryptosimd sysimgblt mptspi cryptd fbsysfops gluehelper psmouse mptscsih drm mptbase ahci i2cpiix4 vmxnet3 scsitransportspi jun 15 133505 s050009088 kernel libahci pataacpi jun 15 133505 s050009088 kernel cpu 6 pid 4167 comm python3 tainted p w oe 540150generic 167ubuntu jun 15 133505 s050009088 kernel hardware name vmware inc vmware virtual platform440bx desktop reference platform bios 600 11122020 jun 15 133505 s050009088 kernel call trace jun 15 133505 s050009088 kernel dumpstack0x6d0x8b jun 15 133505 s050009088 kernel badpagecold0x800xb1 jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel tlbflushmmu0x3a0x140 jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel warn0x9d0xe0 jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel unmapvmas0x790xf0 jun 15 133505 s050009088 kernel unmapregion0xbc0x160 jun 15 133505 s050009088 kernel domunmap0x2aa0x500 jun 15 133505 s050009088 kernel mmapregion0x2480x650 jun 15 133505 s050009088 kernel dommap0x3b40x5c0 jun 15 133505 s050009088 kernel vmmmappgoff0xcb0x120 jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel fput0x130x20 jun 15 133505 s050009088 kernel ksysioctl0x770x90 jun 15 133505 s050009088 kernel x64sysmmap0x330x40 jun 15 133505 s050009088 kernel dosyscall640x570x190 jun 15 133505 s050009088 kernel jun 15 133505 s050009088 kernel rip 00330x7fbf936fc8e6 jun 15 133505 s050009088 kernel code 00 00 00 00 f3 0f 1e fa 41 f7 c1 ff 0f 00 00 75 2b 55 48 89 fd 53 89 cb 48 85 ff 74 37 41 89 da 48 89 ef b8 09 00 00 00 0f 05 3d 00 f0 ff ff 77 62 5b 5d c3 0f 1f 80 00 00 00 00 48 8b 05 71 jun 15 133505 s050009088 kernel rsp 002b00007ffd116cf078 eflags 00000206 origrax 0000000000000009 jun 15 133505 s050009088 kernel rax ffffffffffffffda rbx 0000000000000032 rcx 00007fbf936fc8e6 jun 15 133505 s050009088 kernel rdx 0000000000000000 rsi 0000000000200000 rdi 0000010004400000 jun 15 133505 s050009088 kernel rbp 0000010004400000 r08 00000000ffffffff r09 0000000000000000 jun 15 133505 s050009088 kernel r10 0000000000000032 r11 0000000000000206 r12 00000000044be5e0 jun 15 133505 s050009088 kernel r13 0000000000000001 r14 00000000047d97c0 r15 000000000430b450 eventually the watchdog reports the soft lockup checking the pid against the one from the process that ran tftestgpudevicename shows that it mustve caused this lockup jun 15 134645 s050009088 kernel watchdog bug soft lockup cpu6 stuck for 22s python34167"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntf.data.Dataset.map does not support randomization\nclick to expand issue type bug have you reproduced the bug with tf nightly didnt try source binary tensorflow version tf 2110 custom code yes os platform and distribution macos python version python 38 it seems like tfdatadatasetmap does not support randomization from numpy for the sample code it gives constant output from the randint function call but if you switch the function from numpyrandomrandint to tfrandomuniform toggle the comment then you get good randomization behavior i am wondering if this is expected standalone code to reproduce the issue shell a key i value nprandomrandom for i in range5 dictoflist orientlist keys dictoflistkeys dataset tfdatadatasetzip tuple for key in keys dataset datasetmaplambda x key xi for i key in enumeratekeys for i in range2 for b in dataset printbefore map i b def testfunctionx fkey low0 high100 xf tfrandomuniformshape minval1 maxval5 dtypetfint32 this is randomized xf highhigh this is not randomized return x dataset for i in range2 for b in dataset printafter map i b relevant log output shell before map 0 key value before map 0 key value before map 0 key value before map 0 key value before map 0 key value before map 1 key value before map 1 key value before map 1 key value before map 1 key value before map 1 key value after map 0 key value after map 0 key value after map 0 key value after map 0 key value after map 0 key value after map 1 key value after map 1 key value after map 1 key value after map 1 key value after map 1 key value"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFunctional Bug：Could not interpret serialized activation function\nclick to expand issue type bug have you reproduced the bug with tf nightly no source source tensorflow version tf2120 custom code yes os platform and distribution macos mobile device no response python version 39 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour output could not interpret serialized activation function tensorconv1abiasadd0 shapenone 224 224 64 dtypefloat32 document activation activation function to use if you dont specify anything no activation is applied see kerasactivations standalone code to reproduce the issue py x kernelsize3 strides1 paddingsame py x kernelsize3 strides1 activationserialize paddingsame relevant log output no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nImage Segmenter | tflite-suuport | AttributeError: type object 'SegmentationOptions' has no attribute 'OutputType'\nclick to expand issue type documentation bug have you reproduced the bug with tf nightly yes source source tensorflow version tflitesupport 010a1 custom code no os platform and distribution macos ventura 134 mobile device no response python version 387 bazel version no response gcccompiler version no response cudacudnn version no response gpu model and memory no response current behaviour the syntax provided for using image segmenter did not execute in python environment possible fix the line segmentationoptions should have been segmentationoptions standalone code to reproduce the issue shell relevant log output shell traceback most recent call last file imagesegmenterpy line 8 in segmentationoptions attributeerror type object segmentationoptions has no attribute outputtype"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhen saving new file with some content in a readonly directory VSCode creates an empty file instead\ntype bug 1 use the following settingsjson file filesreadonlyinclude true 2 create temporary file with some content in editor image 3 save file somewhere on the computer image 4 the file created by vscode is empty this is a bug image vs code version code 1822 20230914t055525390z os version windowsnt x64 10022621 modes unsupported system info itemvalue cpus12th gen intelr coretm i51235u 12 x 2496 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1569gb 678gb free process argv screen readerno vm0 extensions none ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscorecescf30445987 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 2e4cg34230602488 f6dab26930613381 a9j8j15430646983 03d3595930757346 9b8hh23430694863 fixshowwlkth30771522 i26e353130792625 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572 pythonmhint130842940 dsvsc01530845448"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCan't use icon contributed using TTF file \ndoes this issue occur when all extensions are disabled yes vs code version 1822 os version macos monterey 123 steps to reproduce 1 created a ttf font file using select any icon and font character i have selected g 2 update the packagejson to include the ttf file icons myiconid description my icon default fontpath checkttf fontcharacter g 3 create status bar item with text myiconid text 4 the icon needs to show up but the character g shows up instead image attached my font file glyphterfontzip expected to show image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfocus cell output with ctrl+down does not visually select the output\nfound testing for 1 run a cell to get output 2 press ctrldown to focus the output bug visually it looks like the cell container is focused"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nterminal accessible view opens unexpectedly\n1 create a terminal 2 quickly use altf1 3 bug the terminal accessible view opens dynamic prompt data is shown"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nClarify what `always` means\nthe comment for always just says always trigger code actions on save but thats not true because format on delay isnt a trigger reason this should be mentioned explicitly because other folks are confused also the settingname syntax could be used to link to the required setting"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nclear persistent tasks when task reconnection is disabled\nwhen one disables task reconnection the persistent tasks should get cleared"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nComment widget jump to max height when switching editors\ntesting 194011"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n'Focus Session' button shows in debug toolbar in command center\nwhen there are multiple debug sessions the dropdown action item shows in the debug toolbar here as a button that doesnt do anything you can see it in the gif in we could just hide that item when this setting is set"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nComments accessibility help nits\ntesting 194012 the following commands are inconsistently treated in the accessibility help menu 1 run the command go to previous commenting range which is currently not triggerable via keybinding should just be listed as go to previous commenting range aligning with go to next commenting range also should be triggerable via a keybinding 2 run the command focus sticky scroll to focus the currently nested scopes it is currently not triggerable by a keybinding should just be listed as focus sticky scroll image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nScrolling is blocked when mouse is on review comment\ntesting 194011 i am able to see the text size grow fine with the existing comment but realized scrolling freezesblocked when my mouse cursor is on the comment section when i move the mouse cursor to the actual document itself i am able to scroll back and forth in the document fine but scrolling seems to be stuck when cursor is in the comment block for example place the mouse cursor in the black comment section and try scrolling up and down the document scrolling will freeze however having mouse cursor in outside the comment section in this case the green section will not freeze the scrolling img width736 altscreenshot 20230926 at 2 18 04 pm src"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTop tab border wrong size with Pinned Tab Sizing shrink when scrolling/wrapping\ntesting 193991 enable and make a pinned editor dirty notice how the blue color appears over the entire tab bar image vs in stable image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWrapping tabs needs a smaller threshold for disabling wrapping when 2 rows show\ntesting 193991 see here image when many tabs are wrapping and height is little at once point we disable wrapping to make room for the editor i think this limit now needs to account for when 2 tab rows are showing"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nActive pinned tab has no separation to other tab row\ntesting 193991 with the default light modern theme and this layout image see how the active tab in the first row shows no border to the bottom row i think i would have expected the border to go through here"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNavigating to previous comment thread with shift+alt+f9 does not work on Linux\ntesting 194012 the accessibility help says this should work but it does not appear to do anything"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDon't observe any result from Run Recent Command\ntesting 193852 testing on windows 11 altf1 opens terminal accessibility help dialog correctly image explore options decide i want to try run recent command controlaltr altf2 to open terminal accessible view opens correctly image try controlaltr redquestionmark i dont observe anything happen but maybe im misunderstanding what should happen or how i should set this command up"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMissing background color when showing inline chat inbetween \nopen inline chat on a mid sized methodfunction the whole function gets included by the chat extension bug the background color isnt contiguous img width963 altscreenshot 20230926 at 16 15 59 src"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCan not set breakpoint in .c files\ntesting 194071 i have the dwarf extension installed but i can not set breakpoint in c files should dwarf contribute the ability to set breakpoints in c files or am i missing something"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSCM Sync: File change shows `COMMIT^`\ntesting 194016 although technically correct we should use the actual commits short hash not the parent syntax for left side image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMake max comment area height depend on editor height?\ntesting 194011 the constant max height works well with large editors when the editor area is small the comment can overgrow it maybe the max height could be constant unless the editor is very small"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuick diff decorations not rendering at all or rendering the wrong state\ndiff decorations are disappearing when switching to another file and back recording 20230926 at 11 46 09"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGo to prev/next commands keybindings are not working in terminal\ntesting 193852 image option downup arrow in terminal is not navigating between commands these are working only in accessibility view in terminal the keybindings are cmd downup arrow"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSettings Sync gets stuck at \"Turning on Settings Sync...\" after turning it off\ndoes this issue occur when all extensions are disabled yes report issue dialog can assist with this vs code version version 1830insider user setup commit date 20230925t104126295z electron 2582 electronbuildid 23977753 chromium 11405735289 nodejs 18150 v8 11418329electron0 os version os windowsnt x64 10023550 steps to reproduce 1 turn on settings sync 2 do not select anything to sync leave all checkboxes unchecked and click on sign in to sync 3 sign in used my gh account insiders 4 get a notification that settings sync is on 5 go back to the gear turn off settings sync result image the only way out of this is to restart vs code reload window doesnt fix it once you do that it appears to be turned off everything is normal again"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Accessibility] Take out \"Exit this dialog (Escape).\" from terminal accessible view\ntype bug tested with terminal created in editor area at the bottom of the terminal buffer accessible view there is an instruction exit this dialog escape users may not want to hear this instruction all the time please consider removing this instruction when verbosity setting is off vs code version code insiders 1830insider 20230925t104126295z os version windowsnt x64 10022621 modes system info itemvalue cpus11th gen intelr coretm i51145g7 260ghz 8 x 2611 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1571gb 473gb free process argv crashreporterid screen readeryes vm0 extensions 91 extensionauthor truncatedversion androiddevextade132 aiprmlangaip002 bookmarksale1341 openscadant121 spellrightban30118 zoterolatexbna041 doxdocgencsc140 vscodeeslintdba242 vscodedenoden3231 gitlenseam1430 editorconfigedi0164 codespacesgit1153 copilotgit1115437 remotehubgit0600 cslpreviewigo022 easysnippetinu063 latexworkshopjam9140 lilypondsyntaxjea011 schemejea020 googlesearchkam001 vslilypondlhl173 zoterombl0110 gitgraphmhu1300 vscodedockerms1261 flake8ms202360 pythonms2023160 jupyterkeymapms112 remotesshms01064 remotessheditms0860 remotewslms0814 azurereposms0360 cmaketoolsms11531 cpptoolsms1175 powershellms202360 vslivesharems105883 autodocstringnjp061 pandocciternot0103 shinypythonpos014 shinyuieditorpos043 quartoqua11000 rdebuggerrde054 javared1221 vscodexmlred0261 rred281 multicommandryu160 vscodedeeplsoe106 abcmusicsof040 luasum370 cmaketwx0017 errorlensuse3130 vscodearduinovsc060 vscodemavenvsc0420 grammarlyznc0221 1 theme extensions excluded ab experiments vsliv69530137379 vsins82930139715 vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vstes62730244334 vslsvsres30330308271 pythontb30258533 vshan82030294714 vscod805cf30301675 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230404738 py29gd226330784851 vsclangdf30492506 c4g4892830535728 dsvsc01230540252 pynewext5430618038 a9j8j15430646983 ecj1e33230687743 fixshowwlkth30771523 i26e353130792625 pythonidxpt30768918 pythonnoceb30776497 asynctok30821568 dsvsc01330777762 dsvsc01430777825 diffeditorv230786206 dsvsc01530821418"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSCM sync view actions are contributed to all views\nscm sync view refresh command image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDebug controls in command center appear and rightaway disappear on window reload\n1 reload vscode window given you have setting to put debug controls in the command center 2 bug notice how the command center includes debug controls and then right away disappear see version version 1830insider commit date 20230922t093118274z electron 2581 electronbuildid 23779380 chromium 11405735289 nodejs 18150 v8 11418329electron0 os darwin arm64 2260"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProfile icon missing\ntype bug in yesterdays insider i changed the icon for my documentation profile atfer the update today its gone reloading the window didnt help img width177 altimage src vs code version code insiders 1830insider 20230922t093118274z os version darwin arm64 2260 modes remote os version linux x64 5801039azure"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nnext/previous commenting range command doesn't work\nim on a mac setting it to be optionf10 works though"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Accessibility] alt+UpArrow and alt+DownArrow does not work as expected in terminal buffer accessible view\ntype bug cc meganrogge 1 create a terminal in editor area 1 type echo hello echo world in the terminal 1 press altf2 to open accessible view 1 press altuparrow and altdownarrow to see if it moves between executed commands notes altdownarrow unexpectedly opens a new terminal view vs code version code insiders 1830insider 20230921t053438227z os version windowsnt x64 10022621 modes system info itemvalue cpus11th gen intelr coretm i51145g7 260ghz 8 x 2611 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1571gb 533gb free process argvcrashreporterid screen readeryes vm0 extensions 91 extensionauthor truncatedversion androiddevextade132 aiprmlangaip002 bookmarksale1341 openscadant121 spellrightban30118 zoterolatexbna041 doxdocgencsc140 vscodeeslintdba242 vscodedenoden3231 gitlenseam1430 editorconfigedi0164 codespacesgit1153 copilotgit1115430 remotehubgit0600 cslpreviewigo022 easysnippetinu063 latexworkshopjam9140 lilypondsyntaxjea011 schemejea020 googlesearchkam001 vslilypondlhl173 zoterombl0110 gitgraphmhu1300 vscodedockerms1261 flake8ms202360 pythonms2023160 jupyterkeymapms112 remotesshms01064 remotessheditms0860 remotewslms0814 azurereposms0360 cmaketoolsms11531 cpptoolsms1175 powershellms202360 vslivesharems105883 autodocstringnjp061 pandocciternot0103 shinypythonpos014 shinyuieditorpos043 quartoqua1980 rdebuggerrde054 javared1221 vscodexmlred0261 rred281 multicommandryu160 vscodedeeplsoe106 abcmusicsof040 luasum370 cmaketwx0017 errorlensuse3130 vscodearduinovsc060 vscodemavenvsc0420 grammarlyznc0221 1 theme extensions excluded ab experiments vsliv69530137379 vsins82930139715 vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vstes62730244334 vslsvsres30330308271 pythontb30258533 vshan82030294714 vscod805cf30301675 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230404738 py29gd226330784851 vsclangdf30492506 c4g4892830535728 dsvsc01230540252 pynewext5430618038 a9j8j15430646983 ecj1e33230687743 fixshowwlkth30771523 i26e353130792625 pythonidxpt30768918 pythonnoceb30776497 asynctok30821568 dsvsc01330777762 dsvsc01430777825 diffeditorv230786206 dsvsc01530821418"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ngoto symbol cell decorations do not persist for multiple symbols in a single cell\nsteps to reproduce 1 create a notebook with a markdown cell that has multiple headers eg header sub header 3 show the preview for the markdown cell shiftenter 4 open symbols quickpick ctrlshifto and arrow down through the symbols list bug cell decoration appears for the first item but then is removed for the second"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfocusing a task terminal tab removes its status\n1 run a task like vs code build 2 click on the terminal tab for one of the task terminals 3 bug the status is gone"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuick diff should not run in diff editor\ni think we had it disabled there image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIssue Reporter doesn't have a placeholder in the Extension drop down\nimage this is needed for accessibility"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Accessibility] ctrl+DownArrow in editor-type terminal buffer creates a new terminal view\ntype bug reproducible steps 1 terminal create new terminal in editor area 1 type echo hello and hit enter 1 press altf2 to open accessible terminal buffer 1 in the accessible terminal buffer press ctrldownarrow to see if your focus goes back to the terminal input area notes pressing ctrldownarrow unexpectedly creates a new terminal view vs code version code insiders 1830insider 20230919t085635775z os version windowsnt x64 10022621 modes system info itemvalue cpus11th gen intelr coretm i51145g7 260ghz 8 x 2611 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1571gb 570gb free process university of illinois urbanadesktopsourcer crashreporterid screen readeryes vm0 extensions 91 extensionauthor truncatedversion androiddevextade132 aiprmlangaip002 bookmarksale1341 openscadant121 spellrightban30118 zoterolatexbna041 doxdocgencsc140 vscodeeslintdba242 vscodedenoden3220 gitlenseam1430 editorconfigedi0164 codespacesgit1153 copilotgit1112422 remotehubgit0600 cslpreviewigo022 easysnippetinu063 latexworkshopjam9140 lilypondsyntaxjea011 schemejea020 googlesearchkam001 vslilypondlhl173 zoterombl0110 gitgraphmhu1300 vscodedockerms1260 flake8ms202360 pythonms2023160 jupyterkeymapms112 remotesshms01064 remotessheditms0860 remotewslms0813 azurereposms0360 cmaketoolsms11531 cpptoolsms1175 powershellms202360 vslivesharems105883 autodocstringnjp061 pandocciternot0103 shinypythonpos014 shinyuieditorpos043 quartoqua1980 rdebuggerrde054 javared1221 vscodexmlred0261 rred281 multicommandryu160 vscodedeeplsoe106 abcmusicsof040 luasum370 cmaketwx0017 errorlensuse3130 vscodearduinovsc060 vscodemavenvsc0420 grammarlyznc0221 1 theme extensions excluded ab experiments vsliv69530137379 vsins82930139715 vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vstes62730244334 vslsvsres30330308271 pythontb30258533 vshan82030294714 vscod805cf30301675 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230404738 py29gd226330784851 vsclangdf30492506 c4g4892830535728 dsvsc01230540252 pynewext5430618038 a9j8j15430646983 ecj1e33230687743 fixshowwlkth30771523 i26e353130792625 pythonidxpt30768918 pythonnoceb30776497 asynctok30821568 dsvsc01330777762 dsvsc01430777825 diffeditorv230786206 dsvsc01530821418"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`treeView.message = undefined` should not block `viewsWelcome` from appearing\ndoes this issue occur when all extensions are disabled yes report issue dialog can assist with this vs code version 1822 os version macos 1352 steps to reproduce 1 use vscode treeview with a viewswelcome make sure the treeview is empty 2 set the treeviewmessage to undefined 3 the viewwelcome is not shown a minimal reproducible example is accessible on here expected behaviour setting the treeviewmessage to undefined should make vscode consider the message as empty and show the viewswelcome"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd placeholder to terminal change icon and color\nimage image feedback from tylerleonhardt not daniel"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMoved Code False Positive\ndescription this shouldnt be reported as moved code image playground example monaco editor playground repro click on use latest dev to verify a future bugfix another example"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAADSTS500202 Pass-thru error trying to sign-in with  an MSA using 'microsoft' auth provider on github.dev\nthe below code works fine in vs code desktop and in but fails on if using an msa account when i signin using my corp account ie microsoftcom is also works fine ts logdebugquerying for account workspaces authenticate and retrieve tenants the user has azure resources for for the msa case you need to query the tenants first and get the underlying azuread tenant for the guest msa see const firstauth await microsoft scopesarmmgmt createifnone true note doesnt even get to this line so the above must throw if firstauth logerrorno authentication session returned return below is the debug level output from the microsoft authentication channel 20230917 100828202 info reading sessions from secret storage 20230917 100828202 info got 0 stored sessions 20230917 100828203 info getting sessions for all scopes 20230917 100828203 info got 0 sessions for all scopes 20230917 100828203 info getting sessions for the following scopes email offlineaccess openid profile 20230917 100828203 info got 0 sessions for scopes email offlineaccess openid profile 20230917 100902899 info getting sessions for the following scopes email offlineaccess openid profile 20230917 100902899 trace no session found with idtoken scopes using fallback scope list of 20230917 100902899 info got 0 sessions for scopes email offlineaccess openid profile 20230917 100905852 info logging in for the following scopes email offlineaccess openid profile 20230917 100908990 info exchanging login code for token for scopes email offlineaccess openid profile 20230917 100909369 error error exchanging code for token for scopes email offlineaccess openid profile error user account emailhidden from external identity provider livecom is not supported for api version 20 microsoft account passthru users and guests are not supported by the tenantindependent endpointrntrace id id 20230917 using exactly the same code with the same msa account but working on or vs code desktop it works fine and the log shows 20230917 103557937 info reading sessions from secret storage 20230917 103557937 info got 0 stored sessions 20230917 103557937 info getting sessions for all scopes 20230917 103557937 info got 0 sessions for all scopes 20230917 103557937 info getting sessions for the following scopes email offlineaccess openid profile 20230917 103557938 info got 0 sessions for scopes email offlineaccess openid profile 20230917 103603229 info getting sessions for the following scopes email offlineaccess openid profile 20230917 103603229 info got 0 sessions for scopes email offlineaccess openid profile 20230917 103605259 info logging in for the following scopes email offlineaccess openid profile 20230917 103608863 info exchanging login code for token for scopes email offlineaccess openid profile 20230917 103609472 info exchanging login code for token for scopes email offlineaccess openid profile succeeded 20230917 103609473 info setting token for scopes email offlineaccess openid profile 20230917 103609474 info login successful for scopes email offlineaccess openid profile 20230917 103609474 info token available from cache for scopes email offlineaccess openid profile expires in 4713999 milliseconds 20230917 103609475 info stored token for scopes email offlineaccess openid profile 20230917 103609479 info getting sessions for the following scopes email offlineaccess openid profile 20230917 103609480 info refreshing token for scopes email offlineaccess openid profile 20230917 103609981 info setting token for scopes email offlineaccess openid profile 20230917 103609982 info token refresh success for scopes email offlineaccess openid profile 20230917 103609983 info got 1 sessions for scopes email offlineaccess openid profile if interested the extension im using is published at and you can see the code for it at does this issue occur when all extensions are disabled yesno report issue dialog can assist with this"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNotebook list view height changes after toggling the panel off/on\n1 open a notebook where two cells take up more than the scrollable region 2 navigate between the two cells note how far down the region scrolls 3 toggle the panel offon 4 navigate between the two cells again bug the scroll placement is different because listviewrenderheight returns a different value recording 20230915 at 09 51 19"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBackup file system provider can not do buffered write\ndoes this issue occur when all extensions are disabled yesno report issue dialog can assist with this vs code version 183insiders os version macos i was verifying and found that large file piece tree buffers are still merged before write turns out that backup is always doing dowriteunbuffered since its using fileuserdataprovider which doesnt have capability so it always runs and unfortunately unbuffered write always concatenates all buffers first img width977 altimage src"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSince latest update, each time debugging, annoying popup\ntype bug i dont use github with vscode since the latest update each time i click the open browser devtools button while debugging a site i get the following popup dialog and have to click cancel the extension local tunnel port forwarding wants to sign in using github ive searched for the extension and am not finding it vs code version code 1821 20230908t084505575z os version windowsnt x64 10022621 modes system info itemvalue cpus12th gen intelr coretm i912900k 24 x 3187 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system6370gb 5120gb free process argv screen readerno vm50 extensions 17 extensionauthor truncatedversion vscodeeslintdba242 classicasphtmljtj013 betterfoldingmoh051 vscodedockerms1260 alms117863928 isortms2023101 pythonms2023160 vscodeiconsvsc1250 phpdebugxde1330 phppackxde103 screenshot 20230914 054336"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError messages from linters overlapping with chatprompt message\ni have linters to ensure files have the right header when i created the empty ts file i get the linter error as well as chat prompt however when i add an empty line you can see the caht prompt does not appear and linter error is in the second line screenshot 20230914 at 13 12 33 screenshot 20230914 at 13 12 27"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDebug stop button doesn't work after restarting session\nstart debugging python not js because restart is handled inside the adapter click restart click stop nothing happens this is from similarly to we reuse the debugsession when restarting then these get disposed and never readded maybe i cant really fix this until is properly fixed cc jrieken"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nLog files created should be created under the log home folder of the process by default\na logger file created in the window renderer process should create the log file scoped to that window for example following should create the view log file under the current window ts name view if a component wants to create the logger shared across windows one should provide the log file while creating the logger as follows ts logidlog id logid name loggername"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntask status bar says `Building...` even after task statuses have been applied\nonly happens for tasks that have been reconnected"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`RPCProtocol._remoteCall` leaks a listener\nthis handler for token cancellation is never disposed found it with the help of the new commands from to track disposables in the app opening and closing editors"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCopy and pasting issues\ntype bug when im copying and pasting text from onenote into vs code editor it comes up like this alt textimagepng how do i correct this vs code version code 1820 20230906t220707438z os version windowsnt x64 10019045 modes extensions 59 extensionauthor truncatedversion bettercommentsaar302 linkcheckmdbla031 docsbuilddoc041 docsimagesdoc101 docslintingdoc0013 docsmarkdowndoc102 docsmetadatadoc109 docspreviewdoc103 docsyamldoc101 gitlenseam1430 pythonsnippetsfrh102 codespacesgit1151 remotehubgit0600 gogol0391 terraformhas2272 vscodedockerms1260 mssqlms1201 isortms2023101 pythonms2023160 jupyterkeymapms112 remotesshms01063 remotessheditms0860 remotewslms0813 powershellms202360 remoteexplorerms041 remoteserverms143 vslivesharems105883 vslivesharepackms040 autodocstringnjp061 vscodeyamlred1140 vscodeiconsvsc1250 7 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vswsl49230256859 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes263cf30335440 vscorecescf30445987 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vscccc30803845 2e4cg34230602488 8954411730613380 a2ce337530757347 57b7757930736110 fixshowwlkth30771522 i26e353130792625 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572 dsvsc015cf30829746"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUI Overlap With `window.nativeTabs: false`, `window.commandCenter: true`, and Tab per Project\ntype bug 1 have windownativetabs false and windowcommandcenter true 2 open a project 3 open a new tab ie on macos command shift n 4 open a new project in that tab ie on macos control r then select one 5 notice overlap of command center atop tabs screenshot dark mode vs code command center and tab per project screenshot light mode screenshot 20230911 at 12 40 44 pm vs code version code 1820 universal 20230906t220941364z os version darwin arm64 2260 modes system info itemvalue cpusapple m2 8 x 24 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avg2 3 3 memory system2400gb 012gb free process argvcrashreporterid crashreporterid crashreporterid crashreporterid crashreporterid crashreporterid screen readerno vm0 extensions 34 extensionauthor truncatedversion yaml2jsonahe005 iconscarbonant026 djangohtmlbib130 postcsscss109 mustachedaw111 vscodeeslintdba242 gitlenseam1430 vscodehtmlcssecm1131 editorconfigedi0164 vscodeenviro010 vscodeeditcsvjan082 minifyalljos2100 twiglanguage2mbl092 rainbowcsvmec370 pythonms2023160 colorhighlightnau250 autodocstringnjp061 vscodeyamlred1140 jinjahtmlsam0200 simplersttro153 vscodemdxuni140 3 theme extensions excluded ab experiments vsliv368cf30146710 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes263cf30335440 vscoreces30445986 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vscaat30438848 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vsccc30803844 282f872430602487 f6dab26930613381 a9j8j15430646983 03d3595930757346 ecj1e33230736112 f8hc823830694864 fixshowwlkth30771522 i26e353130792625 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572 dsvsc01530829745"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUpdate to 1.82.0, VSCode takes more time to kill processes after quit\ntype bug in this video i quit vscode at 7 seconds but it dock icon was killed at 12 seconds vs code version code 1820 20230906t220941364z os version darwin x64 2250 modes system info itemvalue cpusintelr coretm i51038ng7 cpu 200ghz 8 x 2000 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avg3 3 3 memory system3200gb 1343gb free process argvcrashreporterid screen readerno vm0 extensions 2 extensionauthor truncatedversion astrovscodeast233 ab experiments vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdc30486549 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vsccc30803844 2e4cg34230602488 f6dab26930613381 2i9eh26530646982 0bi6i64230831757 fixshowwlkth30771522 i26e353130792625 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv130821571 dsvsc01530829745"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTerminal link underline flickers and is re-evaluated when the buffer changes (but not on the current line)\nrepro 1 run vscode tests 2 scroll up 3 hover a link bug it will flicker and be difficult to ctrlcmdclick not sure yet if this is upstream or vscode"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTerminal DOM renderer: Selection background is drawn incorrectly when unfocused\nupstream"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCannot connect to the server after update\nthe updated version is version 1820 universal os darwin arm64 2210 the issue is cannot reconnect please reload the window but as i reload the window it shows waiting for port forwarding to be ready update i uninstalled the extension wsl and it solves the problem update per 192740 changing the ssh extension to the prerelease version can also help"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nToggle collapse unchanged regions button is showing on every editor\neven ones without changes shouldnt it only show it diffs"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError traces show unrendered HTML `href` that makes them hard to read\nenvironment data vs code version 1820 jupyter extension version available under the extensions sidebar v1017 python extension version available under the extensions sidebar v2023160 os windows mac linux distro and version linux debian 12 python andor anaconda version conda 2373 python 311 type of virtual environment used na venv virtualenv conda conda jupyter server running local steps to reproduce 1 open an interactive jupyter window 2 execute some python code that would trigger an exception in a library example python from sklearnlinearmodel import logisticregression expected behaviour should show me a readable error trace like it does in regular terminalbased python and regular jupyter actual behaviour shows me an error trace in which each line that references a line of code from an external library shows up with what looks like unrendered html tags image and doesnt let me change the presentation format anymore for the cell outputs like it used to do in the past"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Bug]: Sash to expand diff editor appears to be shorter than full height\ndoesnt seem to happen with other editors img width1066 altscreenshot 20230908 at 13 18 05 src"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRegression: Port forwarding fails while working with remote SSH\nthis is the 4th time this issue has occurred and fixed then regressed within the last 4 months such frequent major bugs make vscode really unstable to use does this issue occur when all extensions are disabled yes version 1820 user setup commit date 20230906t220707438z electron 2580 electronbuildid 23503258 chromium 11405735289 nodejs 18150 v8 11418329electron0 os windowsnt x64 10019045 steps to reproduce see 1 connect to a remote ssh host via remote explorer 2 start a server on 00003000 3 port forward it 4 try to access it on the current pc error logs in shared window could be irrelevant since i get the log below on both 1812 and 1811 but no issue is faced on 1181 20230908 120350235 error uncaught exception in sharedprocess cannot read properties of undefined reading then typeerror cannot read properties of undefined reading then at vs vs at vq vs at cvalue vs at bw vs at bx vs at bfire vs at messageportmainte vs at messageportmainemit nodeevents51328 at 20230908 120351522 error uncaught exception in sharedprocess cannot read properties of undefined reading then typeerror cannot read properties of undefined reading then at vs vs at vq vs at cvalue vs at bw vs at bx vs at bfire vs at messageportmainte vs at messageportmainemit nodeevents51328 at 20230908 120352335 error uncaught exception in sharedprocess cannot read properties of undefined reading then typeerror cannot read properties of undefined reading then at vs vs at vq vs at cvalue vs at bw vs at bx vs at bfire vs at messageportmainte vs at messageportmainemit nodeevents51328 at launchjson version 020 configurations name nextjs debug serverside type nodeterminal request launch command npm run dev name nextjs debug clientside type chrome request launch url name nextjs debug full stack type nodeterminal request launch command npm run dev serverreadyaction pattern started server on url https uriformat s action debugwithchrome sourcemaps true image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRegresion: Terminal group relative size not preserved\ndoes this issue occur when all extensions are disabled yesno report issue dialog can assist with this vs code version stable and from sources os version steps to reproduce 1 open terminal panel 2 split terminal and resize 3 reload window 4 bug terminal relative sizes are not preserved"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUpdater wastes large amount of disk space logging once per second while waiting for VS Code to close\ntype bug the vs code update process appears to write to log files named tempsetup log date numbertxt it appends a new line once every second as it waits for a running instance of vs code to be closed heres a snippet from a current file on my machine 20230907 140942549 application is still running waiting 20230907 140943552 application is still running waiting 20230907 140944555 application is still running waiting 20230907 140945558 application is still running waiting 20230907 140946560 application is still running waiting i basically always have vs code running and sometimes dont close it for weeks at a time and just found that i had over 200mb of log files mostly filled with lines like the above vs code version code 1811 20230809t222242175z os version windowsnt x64 10019044 modes"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nConsider changing dim usage in test terminal\nthis now results in 12 the minimum contrast requirements which is a soft accessibility issue it seems like these messages are special vscode messages which use special formatting in the real terminal"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTest view output needs a space separator between messages\nthese 2 dont have a space or new line between them image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTest Results view misses separator between editor and list\ntheres no separator line between the two components image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBuild task status indicator not reappearing on window reload\nsteps to reproduce 1 i use the default build task in vscode on a multi root workspace 2 i see a 2 appearing in the status bar indicating the 2 runs see pic 1 3 i reload the window 4 everything is fine 5 i open 2 more terminals see pic 2 6 i hide the panel 7 i reload window bug there is no more a 2 in my status bar 1 image image 2 image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nThemes warn on unknown theme key activityBarItem.profilesBackground\nimage"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProcessing artifacts fails with error about blob already existing\ncreating asset size 7710698 sha1 sha256 errorblob quality blobname already exists not publishing again error blob insider already exists not publishing again at main at"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNull error in sticky scroll test\nwhen running the sticky scroll unit tests the following error was noticed uncaught in promise typeerror cannot read properties of null reading coordinatesconverter source 180"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPasting is not selecting the newly pasted text\nthis happens after a regular ctrlv image its very easy to reproduce 버전 1820insider user setup 커밋 날짜 20230901t110840414z electron 2580 electronbuildid 23503258 chromium 11405735289 nodejs 18150 v8 11418329electron0 os windowsnt x64 10022621"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTerminal cursor doesn't reflect that the terminal is focused\ndoes this issue occur when all extensions are disabled yes description terminal has focus but the cursor displayed doesnt look like it does its not filled white actual expected with stable 1811 steps to reproduce i dont have any but i can repro even with a new vscode window without any workspace folders version version 1820insider commit date 20230901t111322523z electron 2580 electronbuildid 23503258 chromium 11405735289 nodejs 18150 v8 11418329electron0 os darwin arm64 2260 cant seem to repro with 1811 stable within my vscode integrated terminal zsh version zsh 59 x8664appledarwin220 its weirdly x8664 even though im on arm64 but it seems ok"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`vscode.TreeView.dispose` doesn't clean up in the renderer\ni went after some later callers of disposableregister see devdiscuss and i noticed that uses the disposable of its container object not one specific to the tree view id its likely a theoretical bug but it seems that extensions calling dispose of their view dont achieve anything and that repeated create calls for the same id could leak some memory"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIs moved code range correct?\nhediet not sure if it a bug report or question but i notcied that moved lines range is not correct image why it is written that lines are moved from 1621 shouldnt they be marked as moved from 1620 the same question is about moved to"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPre launch task doesn't run if similar task is already running in different workspace folder\ndoes this issue occur when all extensions are disabled yes report issue dialog can assist with this vs code version 1820insider os version macos ventura 135 issue description if the prelaunchtask for a debug configuration in workspace a is already running in workspace b the task is not started in workspace a vs code thinks the prelaunchtask is already running even though its running in a different workspace folder the expected behavior is to launch the task in the workspace folder containing the debug configuration seems similar to ive created a repository which reproduces the bug the repo contains two node express hello world apps and corresponding launchtasksjson configs for debugging the apps the debug config is a simple launch program and each has a prelaunchtask that runs tsc watch as a background task with a problem matcher steps to reproduce 1 clone 2 open the workspace file in vs code img width232 altimage src 3 run npm install in each workspace folder each workspace folder contains a hello world express server 4 run the npm watch task in workspace1 img width618 altimage src 5 launch launch program workspace2 from the debug menu it will not run the prelaunchtask and it will not work img width442 altimage src"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuick Chat layout issue on resize\non the latest insiders on windows 1 open quick chat 2 close it 3 zoom in or out of the editor 4 open quick chat again 5 bug layout issue"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nImprove consistency, lessen redundancy of accessibility help dialog text\nas a result of the discussion in 191672 we should format each command description and keybinding more consistently and limit redundancy"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nInvoking choice from `Show CodeLens Commands For Current Line` may require multiple Enters or clicks\ntype bug 1 set true 2 open a ts file 3 put cursor on a line that has an n references codelens above it 4 open command palette and run show codelens commands for current line 5 press enter to try and run the selected only entry n references bug nothing happens until you press enter a second time or more results of using a mouseclick to try and run the codelens from the quickpick is the same first click does nothing and a second click is required this also happens in 1811 so it is not a 182 regression vs code version code insiders 1820insider 20230831t053359698z os version windowsnt x64 10022621 modes"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrenderSideBySideInlineBreakpoint invalid default value\nimage"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAfter the command is localized, it cannot be searched by keywords.\nadd issue description here version 1811 commit user agent mozilla50 macintosh intel mac os x 10157 applewebkit53736 khtml like gecko chrome115000 safari53736 embedder vscodedev bug3 steps 1 open vscodedev or vs code app 2 switch to a language other than the default for example simplified chinese 3 search command by shortcut key for example search toggle some matching commands will appear 4 but i search the keyword directly incomplete command keyword nothing will be matched"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[serve-web] In-app Github sign-in link rotates ports and cannot be preset with --port, breaking SSH local forwarding\nsummary the signin link for github in vscode running through serveweb rotates ports in the 54xxx range breaking any preset port forwarding for users connecting via ssh this occurs regardless of any port option set with port taken from my comment in 168492 does this issue occur when all extensions are disabled yes vs code version insiders 1820 os version mac os 133 steps to reproduce 1 connect to the device hosting code via ssh with local port forwarding for port 8000 enabled 2 on the remote device launch serveweb with codeinsiders serveweb 3 open a browser window and navigate to the url given by serveweb 4 turn on settings sync showing a github signin url note the port is different than the default requiring you to reconnect and add a new forwarded port expected behavior setting the port with port should a also determine the port used for signin or b be a separate option so that ssh port forwarding does not require updating ssh config and reconnecting each time you need to sign in"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTerminal buffer is not updating information\ntype bug in the insiders version i noticed that the buffer is no longer automatically reflecting terminal information for example when executing the mvn clean install command in my project the information of the build that starts to run is updated from time to time in the buffer sometimes it is only necessary to give a tab to go to the terminal and give a shift tab that i have the information updated while the build is running and printing various information in the insiders version this update no longer occurs i have to keep pressing alt f2 but i couldnt be sure if i still have all the updated information vs code version code insiders 1820insider 20230830t053347972z os version windowsnt x64 10022621 modes remote os version linux x64 system info itemvalue cpusintelr coretm i58365u cpu 160ghz 8 x 1896 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system3172gb 1144gb free process argvcrashreporterid screen readeryes vm0 itemvalue remotewsl ubuntu oslinux x64 cpusintelr coretm i58365u cpu 160ghz 4 x 1896 memory system1562gb 522gb free vm0 extensions 22 extensionauthor truncatedversion remotewslms0810 gitlenseam202383005 copilotgit1106367 vscodedockerms1260 javared1210 vscodemavenvsc0420 ab experiments vsliv69530137379 vsins82930139715 vsliv36830146709 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 pythontb30258533 vshan82030294714 vscod80530301674 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230404738 py29gd226330784851 vsclangdf30492506 c4g4892830535728 dsvsc012cf30540253 pynewext5430618038 2i9eh26530646982 0bi6i64230823812 ecj1e33230687743 fixshowwlkth30771523 i26e353130792625 gsofa30797620 pythonidxpt30768918 pythonnoceb30776497 dsvsc01330777762 dsvsc01430777825 diffeditorv230786206 dsvsc01530821418"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPort forwarding log has formatting issues\ntesting 191540 on linux there are ansi escape sequences as well as empty lines 20230830 111219936 info forwarding starting cli 20230830 111219997 info forwarding 20230830 111219 debug no code server tunnel found creating new one 20230830 111219997 info forwarding \u001b2m20230830 111219 trace found token in keyring 20230830 111223233 info forwarding \u001b0m20230830 111223 info creating tunnel with the name 20230830 111223233 info forwarding \u001b2m20230830 111223 trace found token in keyring 20230830 111226235 info forwarding \u001b0m\u001b2m20230830 111226 trace found token in keyring 20230830 111227197 info forwarding \u001b0m20230830 111227 debug starting tunnel to server 20230830 111227199 info forwarding \u001b2m20230830 111227 trace found token in keyring 20230830 111228872 info forwarding \u001b0m20230830 111228 debug connected to tunnel endpoint base tunnelendpoint connectionmode tunnelrelay hostid hostpublickeys porturiformat some tunneluri some portsshcommandformat somessh tunnelsshcommand somessh sshgatewaypublickey none hostrelayuri clientrelayuri 20230830 111228872 info forwarding \u001b2m20230830 111228 trace found token in keyring 20230830 111228873 error forwarding 20230830 111229498 info forwarding \u001b0m20230830 111229 info forwarding port 8000 at private 20230830 111246702 error forwarding 20230830 111246702 info forwarding \u001b2m20230830 111246 trace found token in keyring 20230830 111247371 info forwarding \u001b0m20230830 111247 info forwarding port 3000 at private 20230830 111440594 error forwarding image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuick Text Search: Duplicate results when file is open\ntesting 191499 open the vscode repo open command palette type findtheme pick the first entry in the file opens again open command palette type findtheme you see duplicated results image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProgressive rendering freezes sometimes\nimage i thought i noticed this happening from time to time after we made changes to how rendering works but in this case with my test extension its pretty obvious i will investigate"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAlign quick question code block style with chat view\ntesting 191496 not sure why we would the backgrounds different image image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbad input box styling in quick chat UI\nimage im not sure how i got to this point but resizing the window just makes it worse image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIcons in Accessible view don't seem right\ntesting 191345 image the bell icon for manage extension does not seem correct here gear icon might be better the shown next and show previous should swap places and i would expect x to be at the end"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nConfusing accessibility help message in an editor\n1 open settingsjson 2 run open accessibility help 3 see this message 4 i dont really understand what disable the aria hint label to open this means image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nI cannot click on the left hand side to expand:\ni cannot click on the left hand side to expand image also is the hover color themable originally posted by bpasero in"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDim unfocused setting link does not work\nforked off from the link in settings does not work image im pretty sure im following this reference exactly though config is defined here"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nConsider to revert dynamic grow from scroll when reopening\ntesting 191496 i think that growing quick chat when you scroll is an interesting idea but i would reset the size back to how it was when you reopen quick chat because its harder to manage the size to make it small again you cannot just scroll to get back where you were"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPort forwarding attempts wrong path to tunnel binary on linux\ntesting 191540 1 use latest snap installation of insiders 2 attempt to forward a port and after sign in flow see the notification with following error img width727 altscreenshot 20230829 at 22 53 14 src 3 path should have been"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMoved code widget does not get highlighted when is moved over cursor\ntesting 191508 steps to reproduce 1 create two copies of the same lines one of this copy will be connected with arrow 2 select the connected copy and past some symbols so that arrow jumps to another copy 3 remove those symbols so the arrow jumps again over the block where cursor is located 4 bug now the moved lines frame is located so that the cursor is inside of it but it is not highlighted untill the cursor is moved example"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWelcome editor does not dim\ntesting 191527 image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSettings editor does not fully dim\ntesting 191527 image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nClicking \"Compare\" in another moved section doesn't compare\ntesting 191508 1 move 2 blocks of code 2 click compare on one of them 3 scroll to the other block and click compare on that 4 i would expect the compare the move to the second block but instead it just untoggles the compare recording 20230829 at 08 57 45 monaco editor playground repro"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMissing jsdoc for `GlobalEnvironmentVariableCollection`\nthe type lacks a leading jsdoc comments the getscoped function lacks a return annotation"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nClicking on search result sets the selection in the cell and not in the output\ntesting 191488 open enable true search for 1 2 3 4 5 click on a result in 0208sortingipynb observe the selection is set on the input code and not on the output version 1820insider commit date 20230829t054832218z electron 2550 electronbuildid 23084831 chromium 11405735289 nodejs 18150 v8 11418329electron0 os darwin arm64 2260"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNotification and notification buttons lack border radius\n1 if the notification content is sufficiently long insufficient height is allocated for the action buttons to grow consequently they appear cramped and lack border radius 2 when a notification is focused the focus border radius is truncated image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`ctrl+upArrow` doesn't open accessible buffer on windows\n1 enable screen reader mode 2 focus a terminal 3 ctrluparrow 4 bug the accessible buffer isnt entered this is because its getting sent to the shell adding it to commands to skip shell fixes this reported by jooyoungseo"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to ssh to remote host\ntype bug note i was unable to create a bug report after i choose the an extension option in the dropdown in the help report issue window as it does not show any of my extensions i do have extensions for whatever reason the bug report does not show them after installing 1820 insiders i started to get the following error message failed to connect to the remote extension host server error message server exited without writing socket original channel closed and could not fetch remote environment when i use an older version via regular vscode this issue does not happen vs code version code insiders 1820insider 20230828t053552131z os version windowsnt x64 10019044 modes connection to ssh devlablinepulseca could not be established message server exited without writing socket original channel closed system info itemvalue cpusintelr coretm i78665u cpu 190ghz 8 x 2112 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1572gb 699gb free process argvcrashreporterid screen readerno vm0 connection to ssh devlablinepulseca could not be established message server exited without writing socket original channel closed extensions none ab experiments vsliv69530137379 vsins82930139715 vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 pythontb30258533 vshan82030294714 vscod80530301674 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230404738 py29gd226330784851 vsclangdf30492506 c4g4892830535728 dsvsc01230540252 pynewext5430618038 vscrp30624060 2i9eh26530646982 ecj1e33230687743 fixshowwlkth30771523 i26e353130792625 gsofa30797620 pythonidxpt30768918 pythonnoceb30776497 dsvsc01330777762 dsvsc01430777825 diffeditorv230786206 dsvsc01530821418"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAvoid unnecessary virtual scroll bar area refreshing during typing \nvs code version 1800 os version windows 11 22h2 226212134 steps to reproduce 1 open a text file turn on developer tools rendering paint flashing 2 type a few characters without changing line observe the screen refresh areas with each character typing the virtual scroll bar area is updated expected because there is no line change id expect the scroll bar area shouldnt update impact i think this behavior leads to issue 164503 which causes underlying chromium to combine and refresh the entire whole editor screen this kind of behavior is not optimized for remote desktop experience such as dev box"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nToggling Command Center does not resize the title bar\ntoggling the command center works but the title bar height is stuck until the window is resized i also noticed some issues where i had to click twice to open the command center once enabled the command center input then disappears while the command center quick pick opens"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Accessibility] Accept suggestion button disappeared in the latest Accessible View\ntype bug press altf2 on any inline suggestion and press shifttab key where you can find related action buttons such as go to symbols go to nextprevious suggestion there is no accept suggestion button anymore vs code version code insiders 1820insider 20230825t053334878z os version windowsnt x64 10022621 modes system info itemvalue cpus11th gen intelr coretm i51145g7 260ghz 8 x 2611 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1571gb 766gb free process university of illinois urbanadesktopemailmd crashreporterid screen readeryes vm0 extensions 89 extensionauthor truncatedversion androiddevextade132 bookmarksale1341 openscadant121 spellrightban30116 zoterolatexbna041 doxdocgencsc140 vscodeeslintdba242 vscodedenoden3200 gitlenseam1421 editorconfigedi0164 codespacesgit11416 copilotgit1105358 remotehubgit0600 cslpreviewigo022 easysnippetinu063 latexworkshopjam9134 lilypondsyntaxjea011 schemejea020 googlesearchkam001 vslilypondlhl173 zoterombl0110 gitgraphmhu1300 vscodedockerms1260 flake8ms202360 pythonms2023140 jupyterkeymapms112 remotesshms01051 remotessheditms0860 remotewslms0810 azurereposms0360 cmaketoolsms11531 cpptoolsms1174 powershellms202360 vslivesharems105883 autodocstringnjp061 pandocciternot0103 shinypythonpos012 shinyuieditorpos043 quartoqua1940 rdebuggerrde054 javared1210 vscodexmlred0261 rred281 multicommandryu160 vscodedeeplsoe106 abcmusicsof040 luasum370 cmaketwx0017 errorlensuse3130 vscodearduinovsc060 vscodemavenvsc0420 grammarlyznc0221 1 theme extensions excluded ab experiments vsliv69530137379 vsins82930139715 vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vstes62730244334 vslsvsres30330308271 pythontb30258533 vshan82030294714 vscod805cf30301675 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230404738 py29gd226330784851 vsclangdf30492506 c4g4892830535728 dsvsc01230540252 pynewext5430618038 a9j8j15430646983 ecj1e33230687743 fixshowwlkth30771523 i26e353130792625 gsofa30797620 pythonidxpt30768918 pythonnoceb30776497 asynctok30821568 dsvsc01330777762 dsvsc01430777825 diffeditorv230786206 dsvsc01530821418"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nmacOS: Window menu does not show opened windows in some cases\nsteps to reproduce 1 have 2 windows opened eg one on vscode and an empty window 2 quit 3 start 4 verify 2 windows open bug the window menu only shows 1 window for me image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Accessibility] Cannot clear terminal buffer using shortcut key\ntype bug if you assign a keybinding for clear terminal command and press the key in the accessible terminal buffer it does not work keybindings json key ctrll command when terminalfocus note ctrll only works in terminal input not terminal buffer vs code version code insiders 1830insider 20230928t053400540z os version windowsnt x64 10022621 modes system info itemvalue cpus11th gen intelr coretm i51145g7 260ghz 8 x 2611 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1571gb 602gb free process argvcrashreporterid screen readeryes vm0 extensions 92 extensionauthor truncatedversion androiddevextade132 aiprmlangaip002 bookmarksale1341 openscadant121 spellrightban30118 zoterolatexbna041 doxdocgencsc140 vscodeeslintdba242 vscodedenoden3250 gitlenseam1430 editorconfigedi0164 codespacesgit1154 copilotgit1117446 remotehubgit0600 cslpreviewigo022 easysnippetinu063 latexworkshopjam9140 lilypondsyntaxjea011 schemejea020 vscodebardjim0010 googlesearchkam001 vslilypondlhl173 zoterombl0110 gitgraphmhu1300 vscodedockerms1261 flake8ms202360 pythonms2023160 jupyterkeymapms112 remotesshms01064 remotessheditms0860 remotewslms0815 azurereposms0360 cmaketoolsms11531 cpptoolsms1175 powershellms202360 vslivesharems105883 autodocstringnjp061 pandocciternot0103 shinypythonpos014 shinyuieditorpos050 quartoqua11000 rdebuggerrde054 javared1221 vscodexmlred0261 rred281 multicommandryu160 vscodedeeplsoe106 abcmusicsof040 luasum370 cmaketwx0017 errorlensuse3140 vscodearduinovsc060 vscodemavenvsc0420 grammarlyznc0221 1 theme extensions excluded ab experiments vsliv69530137379 vsins82930139715 vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vstes62730244334 vslsvsres30330308271 pythontb30258533 vshan82030294714 vscod805cf30301675 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230404738 py29gd226330784851 vsclangdf30492506 c4g4892830535728 dsvsc01230540252 pynewext5430618038 a9j8j15430646983 ecj1e33230687743 fixshowwlkth30771523 i26e353130792625 pythonidxpt30768918 pythonnoceb30776497 asynctok30821568 dsvsc01330777762 dsvsc01430777825 diffeditorv230786206 dsvsc01530821418 pythoncet030848247"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHave the \"Ask Chat\" button in the Command Palette default to the ChatView\noriginally this option which can be seen if you have a chat provider installed like copilot chat image would open the query in quick chat however i got feedback that quick chat may be too hard for newer users of vs code and that instead it should open in chat view but there should be a setting to change this behavior to quick chat we should do this"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Accessibility] ctrl+k, ctrl+shift+n does not open actionable notification items\ntype bug the recently added keybinding ctrlk ctrlshiftn does not seem to do what screen reader users want if there are some notification items that require user interactions pressing this key does not move user focus to the actionable notification item list linking this keybinding to command seems more reasonable for the accessibility purpose vs code version code insiders 1830insider 20230921t053438227z os version windowsnt x64 10022621 modes system info itemvalue cpus11th gen intelr coretm i51145g7 260ghz 8 x 2611 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1571gb 613gb free process argvcrashreporterid screen readeryes vm0 extensions 91 extensionauthor truncatedversion androiddevextade132 aiprmlangaip002 bookmarksale1341 openscadant121 spellrightban30118 zoterolatexbna041 doxdocgencsc140 vscodeeslintdba242 vscodedenoden3231 gitlenseam1430 editorconfigedi0164 codespacesgit1153 copilotgit1115430 remotehubgit0600 cslpreviewigo022 easysnippetinu063 latexworkshopjam9140 lilypondsyntaxjea011 schemejea020 googlesearchkam001 vslilypondlhl173 zoterombl0110 gitgraphmhu1300 vscodedockerms1261 flake8ms202360 pythonms2023160 jupyterkeymapms112 remotesshms01064 remotessheditms0860 remotewslms0814 azurereposms0360 cmaketoolsms11531 cpptoolsms1175 powershellms202360 vslivesharems105883 autodocstringnjp061 pandocciternot0103 shinypythonpos014 shinyuieditorpos043 quartoqua1980 rdebuggerrde054 javared1221 vscodexmlred0261 rred281 multicommandryu160 vscodedeeplsoe106 abcmusicsof040 luasum370 cmaketwx0017 errorlensuse3130 vscodearduinovsc060 vscodemavenvsc0420 grammarlyznc0221 1 theme extensions excluded ab experiments vsliv69530137379 vsins82930139715 vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vstes62730244334 vslsvsres30330308271 pythontb30258533 vshan82030294714 vscod805cf30301675 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230404738 py29gd226330784851 vsclangdf30492506 c4g4892830535728 dsvsc01230540252 pynewext5430618038 a9j8j15430646983 ecj1e33230687743 fixshowwlkth30771523 i26e353130792625 pythonidxpt30768918 pythonnoceb30776497 asynctok30821568 dsvsc01330777762 dsvsc01430777825 diffeditorv230786206 dsvsc01530821418"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndebug: surface StackFrame moduleId in the debug CALL STACK UI\ngo debug adapter delve has been using the fully qualified go function names as the stack frame names these names include the full package path eg examplecomfoobar and the function name eg pkgacoolfuncname and many users requested to shorten the names presented in the call stack view for example one way to handle this is to shorten the name by dropping the full package path for example our contributor is proposing to control this by adding a new launch config setting i think it makes sense to show the function name but i wonder if we can still carry the package info module in other languages stackframe has the moduleid field the current vs code doesnt seem to utilize this field at all how about utilizing the moduleid field and surfacing it in the ui i think the tooltip shown when hovering over the stackframe name is a good option screenshot with a small change in callstackviewts and a delveside change screenshot 20230914 at 6 36 33 pm one concern is it will be surprising for other language debug adapters that use the moduleid field already for other purposes cc suzmue stefanhaller aarzilli"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nindentSize API finalization\nthis api adds indentsize as a property to texteditoroptions"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWindows is ignore terminal titles unless they look like paths\nfrom noelabrahams in ive been trying to programmatically set the title of a bash terminal without success and glad that i chanced upon this issue here is the repro system windows 11 git bash installed vscode version 1820 vscode workspace settings image bashrc shell echo en 0330new terminal titlea the title of the bash terminal window remains stubbornly unchanged as bash myworkspacefolder im assuming this issue will fix my use case thanks this section is setting it to undefined we want to keep the path trimming behavior above but only when it looks like a path"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAllow the debug toolbar to show in the command center\ntoday the debug toolbar can be hidden floating around or be docked inside the viewlet this is about adding it to the command center implemented by via debugtoolbarlocation commandcenter"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupport icons for Profiles\nsupport icons for profiles"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdopt accessible view in terminal\nthis change should be seamless for screen reader users and well want to test it thoroughly to ensure that"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTheme names should have transated name and untranslated name like the command palette\nsee in the list below dark no localization kimbie 어둡게 only dark translated 다크 모던 all translated with loan words daku modeon image ideally this would act like commands where we provide the original if they differ image"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMoved Code Should Scan Previous/Next Lines\ndescription these moves could be one image and this move could be bigger image playground example monaco editor playground repro 1 monaco editor playground repro 2 click on use latest dev to verify a future bugfix"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Accessibility] Consider removing \"terminal.integrated.tabFocusMode\"\ntype feature request now that tabindex is removed from the terminal buffer area i was wondering if would be still useful if not please consider removing this option to officially deprecate this vs code version code insiders 1820insider 20230831t173455916z os version windowsnt x64 10022621 modes"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd support for grouping root workspace folders\nid like to nest workspace folders like this json folders name e2e folders name app1 path name app2 functionally the folders can act the same as if the list were flat but just in ui the nested structure is shown my immediate need would also be solved by but ive used this feature a bit in visual studio to group shared library projects where for other reasons the folder structure on disk needed to be different"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Improvement] Icons to expand and contract the hidden lines should be placed on top of each other in the diff view\nthe icon to expand the hidden lines is to the right of the editor gutter the icon to contract the hidden lines is to the left of the editor gutter perhaps these icons could be positioned in the same spot so that the user can contract the hidden lines after the last expansion without moving the mouse"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMake comment editor expandable\nthe editor in the comment widget doesnt get any larger when the content doesnt fit this makes editing long comments painful image"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMake QuickChat styles closer to QuickPick\nthis was done across multiple prs to eventually get to this experience image"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[css] text-wrap: balance is css(unknownProperties)\ndoes this issue occur when all extensions are disabled yesno report issue dialog can assist with this vs code version 1811 os version ventura 135 img width480 altscreenshot 20230828 at 14 05 44 src steps to reproduce 1 write textwrap balance 2 observer error"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd `preserveInput` for quick search\nthere is currently a way to preserve the input for quick open and the command palette but not for quick search add a setting for this"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGo to next change doesn't show in command palette in diff editors\nsteps to reproduce 1 open a git change in the scm view 2 try using move to next change in the command to navigate to a diff in the file bug move to next change doesnt show in the command palette only in the toolbar i see the command in normal text files related 136059"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupport binding to a unix domain socket instead of a TCP address in serve-web\nit doesnt look like this new cli supports serving on a unix domain socket could we please get that added in too like in were going to need it in order to handle auth in a proxy im happy to open a new issue for that if you need originally posted by leifwalsh in"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDiff Editor: Don't align just whitespace\nimage repro"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nExplore RelatedInformation Provider\nthis would replace semanticsimilarity proposal ts copyright c microsoft corporation all rights reserved licensed under the mit license see licensetxt in the project root for license information declare module vscode export enum symbolinformation 1 commandinformation 2 searchinformation 3 settinginformation 4 interface type weight number todo symbols and search export interface extends type command string export interface extends type setting string export type export interface string token cancellationtoken providerresult export interface string token cancellationtoken providerresult export namespace ai export function string types token cancellationtoken thenable export function provider disposable export function string provider disposable"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDiff Editor v2: setting for number of untouched lines around unchanged regions\nthere is now verification steps set it to a value eg 7 open a diff where there are many unchanged lines and verify that the distance between a changed line and the closest collapsed code block is at least as many lines as specified"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nquick text search: show open files first\nrelated to since quick picks dont support streaming results via callback the quick text search seems a bit slow if we show some synchronous results from open editors ahead of time using the fastandslowpicks it might give the user something initial to look at"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[themes] follow `window.autoDetectColorScheme` when switching profiles\ndoes this issue occur when all extensions are disabled yes report issue dialog can assist with this vs code version 1811 os version windows11 23h2 226312191 steps to reproduce 1 switching to the default profile 2 switching the windows to dark theme 3 switching to the other profile but the vs code remains the light theme"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nShow Extension Dependents\ni just discovered that the net install tool for extension authors was installed without my interaction i had no idea where this came from or why it was suddenly added it wasnt until i tried to uninstall it that i saw a warning that the c extension depends on it i had no other way of knowing please add a tab to the extension info page to show what extensions depend on a given extension it would also be great to see what a given extension depends on i never noticed the dependencies tab on extensions until i was looking into this issue and now its very strange that there isnt the reverse for installed dependencies"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndiff giving more priority to blank lines\ndoes this issue occur when all extensions are disabled yesno report issue dialog can assist with this version 1811 user setup commit date 20230809t222242175z os windowsnt x64 10019045 steps to reproduce 1 open two newblank editors 2 compare both the editors open editors ctrlk e select both shiftupdown right click compare selected 3 paste this on one side and that on the other mind the empty lines 4 now on that side try to make it match the left side by say removing one empty line from starting or putting before async this and that this async def handlerequest keyvals requestmatchinfo return async def fetchnamerequest pass async def insertnamerequest pass that async def handlerequest keyvals requestmatchinfo return wrong diff result after the step 4 given above ie on increasing similarity it detects common part correctly"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDim terminal text should have half the minimum contrast ratio\nsee for an example of why this is an issue repro set a high minimum contrast ratio in settings run echo e x1b31mnormal x1b312mdimx1b0m bug provided the minimum contrast ratio is not too high the colors should differ actual image expected image"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSide by side Compare (diffs) should leverage editor groups instead of nested \"subgroups\"\ndevelopers often work with two editor groups side by side when switching between editing and comparing your changes to the existing code the ux is not great i prefer to use sidebyside diffs rather than inline when opening a compare the sidebyside compare editor is squeezed into whichever editor group is active which means the before and after sides of the compare editor end up with 14 of the total available editor width even on a 5k monitor this is cramped img width972 altimage src so i end up merging all of the editor groups when i close the compare and switch back to editing ive lost my editor organization would it be possible for split compares to just open two linked editors the left and right editors would have their own tabs in sidebyside editor groups activatingclosing one would activateclose the other scrolling would still be linked between the two etc this could have other advantages for example breadcrumbs and stickiness today is only supported for the right half of the compare editor even though these features are leftaligned if two adjoining groups dont exist a new group could be added with some kind of transient flag such that it goes away when it becomes empty if the user explicitly moves something into that group it maybe clears that flag"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrenderSideBySide: never | auto | always\ninstead of rendersidebyside boolean we could have rendersidebyside never auto always as a downside when a user switches from the inline view to the side by side view they probably switch to rendersidebyside never and not auto even though never does not make much sense"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNotebook toolbar foreground color cannot be modified by custom styles:\nthe unavailable foreground color has been marked with a red arrow please see the image expected behavior notebook toolbar foreground color can be modified through custom styles unexpected behavior notebook toolbar foreground color cannot be modified through custom styles vs code version 181 182 os version windows10"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nConsider adding `ctrl/cmd+shift+.` as go to symbol keybinding in accessible view\ncc jooyoungseo"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Accessibility] Add a custom setting always moving focus to terminal buffer after sending selection to terminal\ntype feature request for screen reader users terminal buffer is the great landing area where they can verify executed commands currently the focus always moves to terminal input when we use the following command terminal run selected text in active terminal given the immediate need of accessing the terminal buffer for screen reader users please add a custom setting to always move focus in terminal buffer area instead of the terminal input this will greatly improve the accessibility navigability and alertability for screen reader users vs code version code insiders 1820insider 20230804t053509023z os version windowsnt x64 10022621 modes"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUpdate search results after enter pressed in files to include/exclude text fields.\nwhen the user has a high debounce delay and changes the files to includeexclude text fields it can take a couple of seconds for the search results to update this could be fixed by giving the user the option to skip this delay by pressing enter this already happens with the search text field it seams like calling triggerquerychange after the user presses enter in one of the fields would fix this problem maybe somewhere in setsearchparameters line 1329 at"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupport public/private port toggle in tunnel forwarding\nderekbekoe while testing via the instructions in i noticed that switching port visibility has no effect and the port stays private public visibility would be helpful for scenarios such as testing webhooks also there are a few vs code repos but hopefully this is an appropriate one to file this cc connor4312"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRich content results for naive output in closed notebooks\ncurrently we show rich content results for inputs in closed notebooks it would be nice to show some output results info before we enable this experimental feature for insiders since some people might want to search in outputs even if its not fully a rich content result"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMenu bar unnecessarily changes to hamburger when window width is reduced\nthis feels similar to 152906 but thats marked as closed i dont like the hamburger menu i want to always see the normal menu bar it already supports overflowing but for some reason as soon as the go menu overflows it seems to be entirely replaced by the hamburger i dont understand why this is when theres already an overflow and i would prefer it to just move more items into the overflow the hamburger adds an extra click to get to the file menu which is almost always the menu im using the mouse for ive tried changing various settings including setting menu bar visibility to visible but nothing seems to fix this except disabling command center but i feel like that shouldnt be necessary because a theres an overflow for the menu and b the command center appears to basically just be a mouse hit target so could probably shrink in size"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Feature] Collapse Region In Sticky Scroll\nin the sticky scroll section it would be nice to be able to collapse those regions this would allow us to move to the next region more quickly when were finished with the current one"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRender terminal cursor in the webgl canvas\nincoming change from xtermjs to verify check all combinations of moving the cursor around in the terminal a bit and ensure they work"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Accessibility] Add keybindings going between terminal input and output buffer back and forth just like Copilot Chat view\ntype feature request currently to navigate between terminal input and output users are required to use the tab and shifttab keys while this does offer a method for moving around its not an ideal solution the tab cycle can include other tabbable elements which may not be relevant to the users immediate needs i would like to point out the new navigation model introduced in the copilot chat view this new navigation system is both efficient and userfriendly by pressing ctrluparrow while in the chat input users focus is shifted directly to the chat output regardless of how many times the ctrluparrow key is pressed to return to the chat input from the output view users simply press ctrldownarrow by implementing a similar system for navigating between terminal input and output vscode could greatly improve the user experience the intuitive and userfriendly design of the copilot chat views navigation system makes it a perfect candidate to be extended into other areas of vscode ui i believe many screen reader users would appreciate this change as it would streamline their interactions with the terminal input and output buffer vs code version code insiders 1810insider 20230728t120804472z os version windowsnt x64 10022621 modes"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n\"Restart running task\" command shouldn't show quick pick if there's only one task to restart\n"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd snippets as a language\ntheres a good community grammar for snippets at which would improve our snippets experience we could include this as one of our built in languages"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAllow specifying prompt prefix via Environment variable collection\ntypescript export interface a string that will be prepended to the existing prompt in the terminal keep it short and only use it if its really needed as it modifies all terminals even those not related to the extension note this only applies if shell integration is enabled promptprefix string the idea is to use shell integration to apply this parameter this can be used by python extension to indicate an environment is activated in powershell or fish where there is no other way to set the prompt"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMouse click shortcut to split view right\nsublime text 4 has a great feature that allows us to simply ctrl left click on an editor tab to split view that tab with the currently selected open editor tab right now the only way to do this in vs code is by right clicking the tab and selecting split right to demonstrate what im asking for lets say we currently have 3 open editors file 1 file 2 and file 3 lets say the currently selected open editor tab is file 1 what id like to do now is to split right file 2 in order to do this with vs code i must right click file 2 and select split right what id like is the ability to do this exact same scenario by simply holding ctrl left clicking file 2s tab vs code v1801 os windowsnt x64 10019045"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCommands do not work in single question mode\ntesting 188542 looks like they are not supported image"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSettings editor doesn't respect ctrl+up and ctrl+down\ntesting 188536 not sure if the settings editor is intended to support this but it seems very similar to the other places that do support it"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd tunnel activation event\nwith extensions can now contribute tunnel factories however extensions doing this need to get activated on startupfinished to be shown there itd be nice if there was some kind of tunnel activation event that would only pick up when a tunnel or requested or perhaps if the ports view is interacted with to avoid this mentioned in"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAllow terminal quick fix providers to call vscode commands\ncurrently quick fixes can run a command in the terminal or open a uri to fix with copilot we need to run a command which will then do the work in order to suggest the result which could take some time"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDisable autosave while debugging\ni would like to be able to disable autosave while debugging its a problem if you are using hot reload"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpen Preview to support spawning new tabs\ncurrently when opening for example a markdown file in preview the vs code editor only uses the first tab to present the markdown as shown below animation it would be nice to make it possible to open multiple files in preview mode and spawn new window tabs"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDiff Editor v2: hide unchanged code command\nin the new diff editor you can hide unchanged code but theres no way to fold or unfold all regions at once they all come folded but you must unfold each region manually and must also fold them back it would be nice to have a command to unfold all regions at once just like with code image theres no need for all code folding functionalities but at least fold and unfold all would be very useful"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[json] set a user agent when attempting to retrieve `$schema` JSON Schemas\ndoes this issue occur when all extensions are disabled yesno report issue dialog can assist with this vs code version 1792 os version darwin x64 2250 steps to reproduce 1 start a webserver at serving a single schema at foojson containing required bar the precise contents dont really matter 2 open a file barjson and paste in json schema 3 place the cursor between the quotes just after the trailing slash 4 type foojson and look at the webserver logs observing no user agent was sent"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nadd accessible view hint to aria label for hovers\nwe can pretty easily do this for editor hovers but im not sure how straightforward this will be to apply to the aria labels of extension contributed ones via the context view service"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\npressing enter on deleted lines should take me to old file\nverification steps open diff editor press f7 to open accessible diff viewer select a deleted line and press enter verify focus is in original editor press f7 again select a modified line and press enter verify focus is in modified editor"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTurning off debug settings Focus Editor On Break, Focus Window On Break, or set the Open Debug to neverOpen,  doesn't work \ntype bug i have mainjs and import it to maindebugjs in maindebugjs i have a breakpoint either by clicking the breakpoint dot or by the debugger line in launchjson i set js program maindebugjs if i open mainjs and hit f5 then when the debugger hit the breakpoint on maindebugjs the editor will automatically switch to that file is there a way to set this off in the setting i have tried to turn of focus editor on break focus window on break and set the open debug to neveropen but it still switches vs code version code 1801 20230712t172207651z os version windowsnt x64 10022621 modes system info itemvalue cpusintelr coretm i510210u cpu 160ghz 8 x 2112 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system784gb 053gb free process argvcrashreporterid screen readerno vm0 extensions 39 extensionauthor truncatedversion bookmarksale1341 htmlplaybia0010 regexchr040 vscodeeslintdba242 githistorydon0620 gitlenseam1411 runonsaveeme020 urlencodefle110 ftpsimplehum076 vscodegraphvizjoa006 jsonmee012 isortms2023101 pythonms2023120 jupyterkeymapms112 remotewslms0802 powershellms202360 quokkavscodewal10547 yautohotkeyyed113 ab experiments vsliv368cf30146710 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vswsl49230256859 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscorecescf30445987 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vscaac30438847 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 282f872430602487 8954411730613380 a9j8j15430646983 vsctsb30748421 03d3595930757346 fixshowwlkth30771522 i26e353130792625 pythonidxpt30784022 pythonnoceb30776495 h7j2d46530786200 h0f3276830792100 dsvsc01330789517"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nadopt `next/previous` in chat response accessible view\nuseful so a screen reader user doesnt have to escape the view navigate to the next element and reopen the view this is possible now in notifications and should also be possible for notebook output cc amunger"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhile editing multiline using ctrl + d if a right import suggestion is accepted, it will only effect on the first occurrence's spelling.\ndoes this issue occur when all extensions are disabled not sure while editing multiline using ctrl d if a right import suggestion is accepted it will only affect on the first occurrences spelling report issue dialog can assist with this vs code version 1801 os version windows 11 steps to reproduce 1 for example in a file i have a variable type called userservice and i want to change it to customuserservice and there are at least two mentions of it the type 2 i select both of them using ctrl d and start typing customuserservice notice the small letter u and s in the name after that i ctrl it for suggestions and when i accept the suggestion it will update the spelling of the first occurrence only and will leave the subsequent occurrences just like that"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nThe dismissed search results appear after search term changes even a letter\nwhen i use multifile search by ctrlshiftf i may use the dismiss button but after adding another letter to the term the dismissed item shows up again i started not using this functionality the dismiss button any more because it shows up right after a new letter proposed solution can you please add the dismissed items to files to exclude part after clicking on dismiss button or the dismissed items can stay dismissed until whole word gets deleted or changes this may require another button to stop dismissing"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDiff editor shows funny word alignments\ncompare the two versions of the file the word alignment is confusing img width1101 altscreenshot 20230717 at 14 19 08 src monaco editor repro"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFirefox: Support opening local files and folders\nas stated in the docs opening local folders in vscodedev requires the file system access api support of the browser according to file system access api browser compatibility as of 20230314 firefox 111 added support for the file system access api so could the support for firefox be added"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAllow trusting the session instead of the folder\nthere needs to be a way to trust just once for the current open editor i dont want to have to maintain a list of trusted folders originally posted by teohhanhui in"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSelectable Soft Dependencies\nable to select what dependencies should not install while installing an extension"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDiff Editor: Show Progress Indicator\nto verify open the diff editor and notice that a progress indicator appears when diffing big files appears after 1s of waiting codeossjxdqvgxkik"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFallback to release version if the pack/dependency extension does not have compatible pre-release\nfallback to release version if the packdependency extension does not have compatible prerelease"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nParent Function Identifier on \"Go To References\" Window\nin the image below i have functions 1 and 2 they are found inside different functions p1 and p2 – parent functions id like to see the proper parent function name on the top bar at the end of the file path and before references 5 when i have a reference focused image"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSurface dev tunnel usage limits more clearly\ncheck dev tunnel limits asynchronously when we try to connect to a tunnel and show a modal notification if theyre exceeded have a show usage limits command for users to monitor their limits link to documentation both places with more information"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nImage preview on hover \nit would be awesome to have optional image previews for eg jpeg and png images when hovering over these files in the explorer or the quick open promt this would allow to find images faster not just by their name but also visually"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhen chosen to install pre-release install the latest release version if there is no compatible pre-release version available\n1 install vs code 180 2 install copilot chat prerelease 3 get this error message img width460 altimage src 4 install copilot chat stable 5 try to switch to prerelease 6 bug extension description view optimistically switches to prerelease view but i am still on stable img width857 altimage src"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd an explicit toggle for terminal bracketed paste mode support\nthe subshell experience can have problems without a toggle"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCTRL+P on selected text must fill search input \"Search file by name...\", such as happens in CTRL+F\nim working on a legacy huge project that has many files references inside other files and its not able to be clickable to navigate in because its using a different aproach to import files so to navigate inside the referenced file i have to copy the file name and then press ctrlp to open search input then i paste the copied file name its good for small changes but when im doing big changes its can be a few exhausting the suggested behavior is like happens with ctrlf select the file name any text then press ctrlp and the search input must be fullfilled with the selected text with the searchs results already selected the first match to hit enter and navigate into the selected file"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMoved code polishing\ntasklist tasks 185498 191255 moved out 185957 186337"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Feature] auto unfold code when navigate symbols\nimage"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nImprove Run and Debug\nhi i wonder whether it would be possible to improve output in run and debug pane and make it more devfriendly i could not find any similar issuefeature request on this though i might have missed shortly background of the feature request i come from another php ide phped by nusphere which uses own php debugger client server module not xdebug the debugging output is much more developerfriendly than in vscode i am not using phped anymore on new projects because it has memory issues and no development or new features last few years vscode works much better but debugging experience cannot really compare to phpeds i could not find any extension that would make debugging output more friendly so here is what i would love to have vscode improved in pane run and debug note this strictly applies to phpxdebug since i do not have experience with other languages possibility to move run and debug into bottom of screen to allow wider layout possibility to have separate tabs for locals variables globals immediate evaluation call stack formatting variables into a table with 3 columns name value type see screen bellow less cluttered output better readablelegible eg change font size less padding increasedecrease line height possibility to sort variables by name eg modes notsorted asc desc highlight changed values between 2 breakpoints or against previous debug step if there already exists such an extension please provide link if not how difficult would it be to implement features above how much time would it take i would be willing to pay for it if someone could provide costs estimate screenshot vscode debug output vs phped output img src img src"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReplace preview: add \"jump to this line\" feature\nim in the middle of global findandreplace with 1000 changes to make but i want to manually edit one of the lines that is about to get changed in this instance i am trying to review all usage of title case and switch to sentence case in the replace preview window it would be nice if i can right click and jump to this line this would open the original file at that line so that i could edit that line however i want img width1289 altscreenshot 20230706 at 16 40 48 src"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSuggestion window styling/snippet styling\ncan we get suggestion styling the suggestion windows on the right where is the description i am new to the github sorry for messing up if this feature already exists could you give me a link or examples image here you type the code and the suggestion pops up and when you open description i saw some styling for the suggestion box but not for the description box would be nice to be able to change text color size font weight very general formatting when writing snippets"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nInformation on updates prior to using \"Restart to Update\"\nit would be great if users could know what changes an update will apply to vscode before we choose restart to update a link to a whats new or some log would probably suffice img width313 altimage src"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAllow search to be sorted by shortest match.\nwhen using a regex search in a project its often likely that the shortest match is the one closest to what you need it would be nice if there was some way to make this a search option in the ctrlshiftf menu"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPull new CSS grammar for colors, lengths, etc.\nthis issue will describe the changes pulled in by prs on vscodecss this updates highlighting for colors gradients and colormix function length units math functions and adding the property to verify that this is working paste this string into a css file css body backgroundimage lineargradient to right in oklch longer hue red 0 100 h1 fontsize 10vb textdecorationline underline 30px shape width calc10px pow5 2 height 100px backgroundcolorfff if youre using the default dark theme then it should look like this img width236 altimage src in particular make sure that that hue is the same color as longer and oklch 10vb is all one color like how you would see 10px is the same color as the other properties pow is formatted as a css function like calc is"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDeveloper Tools Settings Sync\nimage the button doesnt do anything why not integrate it into vscodes existing settings sync i do have a lot of preferences set there so itd be helpful since i frequently have to diagnose lots of extensions in the same way across machines"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd command to manually trigger Proxy Login dialog\nthe problem my company has a proxy password that changes daily because vscode caches the proxy password if vscode is left open past midnight it loses the ability to access the internet this causes a variety of issues including inability to install extensions xhr failed errors etc the current workaround is to quit and reopen vscode but this is a sledgehammer where a scalpel would suffice proposed solution i would like to propose the addition of a command to the command palette that manually triggers the proxy login dialog proxyauthhandler"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAllow better extension of the search UI\ni was trying to build out some features to extend the search results ui since it is a very natural place for the work i was doing in general there were two limitations i encountered 1 that has been flagged and delayed and 1 that has not 1 context menu actions or additional action buttons like replace are not able to be added being able to add context menu actions to search can enable workflows that are more context specific to that result but possibly more intelligent for instance being able to right click a result and look at the quick actions for that result inline what if we wanted to add an option for each result to process it in some way say convert it to a functional component from a class component if we could have a way to specify when a result matches some criteria show this additional action it would be awesome enabling the context menu would also achieve this 2 replacements are 11 with find it would be very powerful if you could instead suggest a custom replacement for each found result in the api when triggering the command you are allowed to pass a replace value this value has all the power of the uis replace field but is pretty limiting when trying to build a stronger tool here it would be awesome if you could provide one of the following as well pass a replacement function tsx replace string async current string string this function could be executed when rendering the ui for the replacement and would allow a custom replacement to be computed from the original this means you could have all the power of javascript to compute these replacements instead of being limited to only regex style computations you could load the file into an ast and make a decision for instance allow reuse of the existing search ui if you allowed instead for the extension to just provide a list of results it would keep a similar ui experience but provide similar power tsx query type custom representation ast query results match file filets line 24 start 0 end 1 replacement foo triggersearch true preservecase true true isregex true iscasesensitive false matchwholeword false filestoinclude tstsx this could be made even more powerful if you actually let extension developers leverage the search functionality in the extension as well something like tsx matches match query type custom representation ast query results matchesmapv triggersearch true preservecase true true isregex true iscasesensitive false matchwholeword false filestoinclude tstsx"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCustomBuiltinExtensions FromLocations will not automatically load the correct `package.nls.{locale}.json`\nthe code here when loading the extension through does not pass packagenlsuris parameters is it because it cannot read all nlsrelated file lists for matching"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nadd accessible view provider for inline chat response\ncc jooyoungseo panel chat responses can be read char by char line by line via altf2 we should do the same for the inline chat response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWorst usability in \"Preventing dirty writes\". Please fix it ()\nhello i hope you rate it right away that if the usability is terrible that this is a product defect because it makes the product no longer reasonably useful does this issue occur when all extensions are disabled yes report issue dialog can assist with this vs code version 1792 system setup os version windowsnt x64 10019045 steps to reproduce 1 create a situation in which vs code offers the annoying preventing dirty writes mode 2 select yes so that vs code allows you to merge changes now the problems start for probably more than 99 of the users 1 it is terribly difficult to see what content is displayed in the left and right windows this is the most important use case for any merge process users can see at a glance without having to scan the screen which data he can see but vs code displays this information in small printed text because its not obvious which data is on the left right side it happens again and again that users merge the wrong way around and they ask where is the backup 3 this is a shame basic merge commands are missing of course one often uses the command to merge all changes to the left or to the right but because vs code allows to navigate between the individual changes it also means that sometimes customers want to merge individual changes in one direction but those commands are missing or somewhere hidden 5 if something fails where is the backup it can happen that someone synchronizes the data in the wrong direction due to a mistake therefore it should be configurable and enabled by default that a backup is created automatically or that the merge process asks whether a backup should be created 6 please allow us to disable this new feature preventing dirty writes in the end in the last decade ive never once had the problem of a dirty write and when i ask our many dozens of engineers they felt the same way vs code solves a problem that pretty much only occurs in very rare special situations but vs code now forces users to merge data every now and then even though it was never necessary before please allow to reenable the old mode where everything worked perfectly thanks a lot kind regards thomas"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nToggle Inline Diff not discoverable in inline chat\nfollowup to i spent quite some time messing with the inline chat preview mode setting to get the diff to appear without success it didnt occur to me to look in the discard dropdown for the toggle inline diff action since i dont associate diffing with discarding have we considered surfacing this another way maybe as a separate icon or through a keybinding with some helper text below the result"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd Context Key for when cursor is at end of line in cell\nhaving the same issue as this post i decided to try to create my own keybindings within jupyter vscode in order to replicate the behavior of the old jupyter interface regarding the effect of downarrow 1 when the cursor is not at the bottom of a cell move the cursor down 2 when the cursor is at the bottom of a cell but not at the end of the line move cursor to the end of the line 3 when the cursor is at the bottom of a cell and at the end of the line move to the next cell in order to do this however i need to use a when clause context to detect when the cursor is at the end of a line i cant seem to find such a context key there is however bottom which i believe detects if the cursor is at the bottom of a cell"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFeature Request: Show Code Variations\nin this type of feature if i select a block of code it will display different and optimized variation to execute a particular block of code for example basic javascript code for mapping javascript const inputarray 1 2 3 4 5 const outputarray for let i 0 i inputarraylength i const mappedvalue inputarrayi 2 optimized javascript code variation javascript const inputarray 1 2 3 4 5 const outputarray inputarraymapvalue value 2"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nExtend serverReadyAction to support startDebugging with provided DebugConfiguration \nserverreadyaction only seems to support name for starting a new browser debug session this feature request is to extend it to support a new entry called config that will be used for the call eg jsonc name type object markdowndescription default name launch browser type edge request launch properties"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDifference Review, Improve Voice Over\ntesting 186213 maybe this is related to but as i tried it i got different results from that mode but it never seemed to read what i expected i enable screenreader mode and voiceover and every time i press f7 this is what it reads i dont really know what the first part is telling me and also it says 7 lines changed but this was a file with 2 change chunks each with just one changed line so no idea where it is getting 7 img width662 altimage src"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n\"Collapse unchanged regions\" looks disabled\ntesting 186213 img width273 altimage src should use a toggle state instead or a new icon you can see it looks the same as the other disabled action"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd Accessibility View and Accessibility Help Menu for Copilot Inline Suggestions\ntesting 186214 if you already have an issue for future plans feel free to close this one i think the copilot inline ghost text suggestions could also profit from the accessibility view currently users are depending on the copilot view on the side which might get deprecated in the future and i think we need a native solution for this so intellicode also profits i am not sure how exactly to integrate this with the inline suggestion hover a potential start would be whenever there is an inline suggestion we play an audio cue as we do today and a user can open accessibility view to inspect the exact suggestion fyi hediet"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nInform SR users about `Open Accessible View`\nmaybe as an aria hint for hovers and in the chat accessibility help menu"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupport trailing colon in --goto\nitd be useful if code goto file12 works with a trailing comma thisd be useful because many tools add a comma after filelinecol for example clang srcmainrs11 error unknown type name fn gcc srcmainrs11 error unknown type name ‘fn’ ld ldsrcmainrs file format not recognized treating as linker script bash srcmainrs line 1 syntax error near unexpected token awk awk srcmainrs1 filename fnr1 fatal function main not defined make srcmainrs1 missing separator stop and so on"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nadd compare feature on tab menu\ncan add compare feature on tab menu image image image"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFiletype specific autosave\nin my project i have a mixture of javascript and python files the javascript files are connected to an autoreloading react app thus i would like to retain autosave on them the python files control a running server also autoreload however making a change to the python file takes longer so i would like to control the saving of those more directly is it possible to have filesautosave be settable on a filetype granularity"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAllow to disable editor group maximize on double click\noccasionally a mouse click turns into a double click which is hard to avoid but i dont want to maximize the editing group and have to get it back every time i accidentally maximize it i cant find the relevant settings in the settings i hope this feature can be turned off thank you very much"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTab sizing option fixed\ntype feature request i am very happy that you introduced this feature for quickly closing many tabs however with fixed width the tabs become so small that it is hard to distinguish files with the same first 3 or 4 characters can you also add a minimum width setting this would allow each developer to set a minimum width based on their file naming convention eg if they have many files starting with the first 6 characters they can set the minimum to see at least 8 or 9 characters thank you vs code version code 1792 20230614t085704379z os version windowsnt x64 10019045 modes"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[FR] Search editor syntax highlighting based on extensions\ncurrently the search editor uses a fixed list to do syntax highlighting which cannot be dynamically changed based on which extensions are installed it would be nice to support that ref"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nKeyboard shortcut to move tabs left and right\nim a very visual person and i work better when i drag similar tabs together i can do that using the cursor but id love to be able to do that using the keyboard ideally there would be keyboard shortcuts to move a tab to the left to the right to the further left side to the further right side basically id love to be able to do in vscode what i can do in chrome using this extension"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMove off of Keytar\nwith nodekeytar now archived and unmaintained we need a path forward for securely storing secrets and additionally reflect the fact that we do not need to follow the shape of keytar anymore on desktop we will take advantage of electrons safestorage api we will also get rid of vscodeencrypt because it would be providing no benefit in this new world additionally we will remove the keytarshim that has been in the product this was the solution to secrets before the secretstorage api outlined are the steps to get this done tasklist tasks x implement new encryptionservice secretstorageservice services with a migration story use new services for extension secretstorage api x write new docs for troubleshooting keyring issues update remote docs x notify top x extensions of keytarshim that we will remove it x make discussion post"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nStarted VS-Code\ntype bug arch linux trying to get vscode to find yarn berry packages for intellisense vs code version code oss 1820 20230911t163045959z os version linux x64 653arch11 modes system info itemvalue cpusintelr coretm i55350u cpu 180ghz 4 x 2700 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode disabledoffwebgl enabledwebgl2 enabledwebgpu disabledoff load avg5 4 3 memory system766gb 361gb free process argvunitylaunch screen readerno vm0 desktopsessionplasma xdgcurrentdesktopkde xdgsessiondesktopkde xdgsessiontypex11 extensions 9 extensionauthor truncatedversion vscodezipfsarc240rc5 bettertomlbun032 editorconfigedi0166 pythonms2023160 romerom0280 volarvue1815 2 theme extensions excluded"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError: EBUSY: resource busy or locked\nfiled to save “html file” unable to write file ‘diskfolderhtmlfile’ busy or locked open ‘diskfolderhtmlfile’ suddenly this error occured when i make change in the code and save"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrunning a selection of code is not working while it runs when the program is executed\ntype performance issue i am using python ide when i run some part of my code i get errors like nameerrors syntaxerrors but when the program is run as a whole the code executes as it should how do i fix it id like to keep running portions of the program without necessarily executing the whole program section of code a intinputenter number a b intinputenter number b sum 0 if a b ab ba start a while start b sum start start1 printfthe sum between a and b is sum vs code version code 1822 20230914t055525390z os version windowsnt x64 10019045 modes system info itemvalue cpusintelr coretm i56300u cpu 240ghz 4 x 2496 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system742gb 234gb free process argvcrashreporterid screen readerno vm0 process info cpu mem mb pid process 0 96 5476 code main 0 28 2468 crashpadhandler 0 73 5008 filewatcher 1 0 91 5388 sharedprocess 0 182 5652 window 1 ● countup problemspy pythonexercises visual studio code 0 160 6212 gpuprocess 0 38 7908 0 85 8420 ptyhost 0 7 1904 conptyagent 0 68 4900 0 7 6452 conptyagent 0 69 7176 noexit command try vs catch 0 11 3184 0 7 7584 conptyagent 0 69 10752 noexit command try vs catch 0 149 11400 extensionhost 1 0 157 13348 electronnodejs vs codecodeexe nodeipc clientprocessid11400 0 92 13844 window 2 issue reporter workspace info window ● countup problemspy pythonexercises visual studio code folder pythonexercises 5 files file types py3 gitignore1 conf files extensions 3 extensionauthor truncatedversion pythonms2023160 ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscorecescf30445987 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 282f872430602487 8954411730613380 0bi6i64230841073 03d3595930757346 fixshowwlkth30771522 i26e353130792625 pythonnoceb30805159 asynctok30821568 dsvsc01330795093 dsvsc01430804076 diffeditorv130821571 dsvsc01530845448 tasklist tasks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nInlay hints do not show when using Workspace TypeScript version\ndoes this issue occur when all extensions are disabled yes report issue dialog can assist with this vs code version 1822 os version macos 1352 steps to reproduce 1 have a vscodesettingsjson with json typescripttsdk 2 command palette typescript select typescript version choose between workspace default vs code version when default ts version is selected 522 img width289 altimage src when workspace ts is selected 408 img width265 altimage src however ts definitely knows what type it is since when i hover over it displays the type correctly img width258 altimage src"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNon existent issue with URL mapping\nscreenshot 20230926 114624 screenshot 20230926 114642 screenshot 20230926 114748 type bug vsc is currently giving me 404 messages when i run the development server despite me correctly mapping out the urls to the relavant pages your piece of shit software of giving me error 404 webpage not found messages end of my teather with your product sort it out vs code version code 1822 20230914t055525390z os version windowsnt x64 10022621 modes system info itemvalue cpusintelr coretm i59400f cpu 290ghz 6 x 2904 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1595gb 806gb free process argvcrashreporterid screen readerno vm0 extensions 22 extensionauthor truncatedversion compilemql4kei001 mqltoolsli202 pythonms2023160 azureaccountms0115 cmaketoolsms11531 cpptoolsms1175 liveserverms049 powershellms202360 mq4ner104 mqlovercppnic003 bitmagicyaz0015 1 theme extensions excluded ab experiments vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vstes62730244334 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 py29gd2263cf30792227 vsclangdc30486549 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 2e4cg34230602488 8954411730613380 2i9eh26530646982 03d3595930757346 fixshowwlkth30771522 i26e353130792625 pythonidxpt30805730 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572 dsvsc01530845448"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPython input() function does not read input (SSH Remote VM)\nim using vs code to ssh into a remote vm when running python scripts in the terminal window that request input eg query inputnenter a query it does not read the provided input but waits forever"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMSYS2 UCRT64 terminal profile can't integrate under TERMINAL tab\ndoes this issue occur when all extensions are disabled yesno yes report issue dialog can assist with this vs code version 1822 os version microsoft windows 10 家庭中文版 steps to reproduce 1 installed msys2 2 adding following in settingsjson javascript ucrt64 path dprogram filesmsys64ucrt64exe ucrt64 3 click ucrt64 in terminal profiles dropdown image 4 the ucrt64 terminal run but not under the terminal tab image"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to resolve your shell environment: Unexpected exit code from spawned shell (code 9, signal null)\nimg width533 altimage src im facing this issue in viscose on my mac i have removed nodeoptions from the zshrc file still the error isnt going away need fix asap"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nmusic store database\ntype bug details about customerscity amount and most preferred employee vs code version code 1822 20230914t055525390z os version windowsnt x64 10022621 modes restricted system info itemvalue cpusamd ryzen 3 3250u with radeon graphics 4 x 2595 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system595gb 058gb free process store database analysis project on postgresql crashreporterid screen readerno vm0 extensions none ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes263cf30335440 vscorecescf30445987 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 py29gd226330792226 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 2e4cg34230602488 f6dab26930613381 a9j8j15430646983 03d3595930757346 fixshowwlkth30771522 i26e353130792625 pythonidxpt30805730 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572 dsvsc015cf30829746"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nmarkdown format problem\ncan you add specific icon to avoid plugin or anything else aiming at formating autoly deleting the space at the end of linei need double space at the end of line to elegant line break anyhting elseif theres another way to elegant line break gracefullyplease tell me"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbreakpoints not working on vscode extension development\ntype bug im developing an extension for vscode and breakpoints dont work i can set them without any problem but when i launch f5 it just wont stop on them i have tried disabling all the extensions and it still happens related to vs code version code 1822 20230914t055525390z os version windowsnt x64 10022621 modes system info itemvalue cpus11th gen intelr coretm i711800h 230ghz 16 x 2304 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system3179gb 1712gb free process argvcrashreporterid screen readerno vm0 extensions 40 extensionauthor truncatedversion codesnapadp134 ngtemplateang1618 cssremcip311 continuecon00394 vscodeeslintdba242 gitlenseam1430 fetchclientgan130 todotreegru00226 angular2joh1601 vscodepeacockjoh422 gitgraphmhu1300 isortms2023101 pythonms2023160 liveserverms049 vslivesharems105883 javared1221 vscodexmlred0261 vscodeyamlred1140 partialdiffryu143 errorlensuse3130 vscodemavenvsc0420 vscodeiconsvsc1250 1 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscorecescf30445987 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vsclangdc30486549 c4g4892830535728 dsvsc01230540252 pynewext5430695312 3biah62630602489 8954411730613380 a9j8j15430646983 03d3595930757346 fixshowwlkth30771522 i26e353130792625 pythonnoceb30805159 synctok30821570 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572 dsvsc015cf30829746"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nintellisense \ntype bug when i press tab to complete the line of code like const btn didnt finish the hole line with brackets vs code version code 1820 20230906t220707438z os version windowsnt x64 10022621 modes unsupported system info itemvalue cpus11th gen intelr coretm i711800h 230ghz 16 x 2304 gpu status2dcanvas enabledonopengl disabledoffwebgl unavailablesoftware load avgundefined memory system3171gb 2031gb free process argvcrashreporterid screen readerno vm67 extensions 130 extensionauthor truncatedversion codesnapadp134 ngtemplateang1618 browseliteant032 viteant025 musicplayerarj103 blackboxbla1166 autoalignbla0013 exerunnerbra021 phpserverbra302 codeiumcod1288 postcsscss109 vsphpclassgendam011 vscodejqdan120 dartcodedar3722 flutterdar3720 vscodeeslintdba242 cssminifydie0113 chatgptcodedog013 jquerysnippetsdon001 vscodehtmlcssecm1131 autoclosetagfor0514 autorenametagfor0110 coderunnerfor0120 vscodemysqlfor041 cypressrunnergf200 remotehubgit0600 cppsnippetshar0015 vuesnippetshol104 csssnippetsjoy104 codebackgroundkat280 prettyphplkr0428 jsonmee012 fluenticonsmig0018 vscodedockerms1261 csharpms212 isortms2023101 pythonms2023160 jupyterkeymapms112 azurereposms0360 cmaketoolsms11531 cpptoolsms1175 liveserverms049 powershellms202360 veturoct0373 laravelbladeone1340 convertcssinjspau113 vscodecsspeekpra441 vscodeyamlred1140 liveserverrit579 backgroundsha1212 vscodecyhelpershe122 indenticatorsir070 jsjsxsnippetssky1101 musictimesof2243 cssautoprefixspo017 autoimportste154 tabninevscodetab3160 vscodepetston1250 cmaketwx0017 volarvue1813 quokkavscodewal10564 enowsc2353 qfwsc68122 phpdebugxde1330 phppackxde103 materialthemezhu3160 classnametocsszit007 10 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vswsl492cf30256860 vstes62730244334 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscoreces30445986 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 3biah62630602489 f6dab26930613381 a9j8j15430646983 03d3595930757346 fixshowwlkth30771522 i26e353130792625 pythonidxpt30805730 pythonnoceb30805159 synctok30821570 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572 dsvsc015cf30829746"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to save file\ntype bug failed to save appcomponenthtml insufficient permissions select retry as admin to retry as administrator vs code version code 1822 20230914t055525390z os version windowsnt x64 10019045 modes system info itemvalue cpusintelr coretm i55200u cpu 220ghz 4 x 2195 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system792gb 071gb free process argvdangular projectsproclient crashreporterid screen readerno vm0 extensions 9 extensionauthor truncatedversion ngtemplateang1618 autorenametagfor0110 coderunnerfor0120 copilotgit1113423 liveserverrit579 ab experiments vsliv368cf30146710 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdc30486549 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 3biah62630602489 8954411730613380 a9j8j15430646983 03d3595930757346 fixshowwlkth30771522 i26e353130792625 pythonnoceb30805159 asynctok30821568 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572 dsvsc01530829745"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCode not working correctly for a specific number 3\ntype bug include using namespace std void frequencyint arr int n int count 1 for int i 0 i n i if arri arri 1 count else cout arri count endl count 1 int main int n4 int arrn 1233 frequencyarr n return 0 above is the code to print frequency of each element of sorted array for the test case int n4 int arrn1233 output ps cusershimanshu cd if g gfgcpp o gfg if gfg 1 1 2 1 the vs code is not giving right output else everywhere it working fine and also for the test case int n4 int arrn1244 output ps cd if g gfgcpp o gfg if gfg 1 1 2 1 4 2 it is working fine vs code version code 1822 20230914t055525390z os version windowsnt x64 10022621 modes system info itemvalue cpus11th gen intelr coretm i51135g7 240ghz 8 x 2419 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system777gb 070gb free process argvcrashreporterid screen readerno vm40 extensions 16 extensionauthor truncatedversion autorenametagfor0110 coderunnerfor0120 copilotgit1111404 pythonms2023160 jupyterkeymapms112 cpptoolsms1175 liveserverrit579 ab experiments vsliv368cf30146710 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscoreces30445986 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 py29gd2263cf30792227 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vscccc30803845 282f872430602487 8954411730613380 2i9eh26530646982 962ge76130835153 a2ce337530757347 fixshowwlkth30771522 i26e353130792625 pythonidxpt30805730 pythonnoceb30805159 asynctok30821568 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572 dsvsc01530829745"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nreact \ntype feature request react is not installed vs code version code 1822 20230914t055525390z os version windowsnt x64 10019045 modes"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProblem with \"unused variable\"\ntype bug sometimes there is such an error when reopening it may not happen again idx declared but not used vs code version code 1822 20230914t055120981z os version linux x64 515083generic modes system info itemvalue cpusintelr coretm i59300h cpu 240ghz 8 x 2400 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode disabledoffwebgl enabledwebgl2 enabledwebgpu disabledoff load avg1 1 0 memory system760gb 456gb free process argvunitylaunch crashreporterid screen readerno vm0 xdgsessiontypex11 extensions 39 extensionauthor truncatedversion commonclo0015 doxdocgencsc140 gdbdebugdam107 gogol0391 todotreegru00226 vscodedrawiohed166 plantumljeb2175 vscodedockerms1260 isortms2023101 pythonms2023160 jupyterkeymapms112 remotesshms01064 remotessheditms0860 remotewslms0813 cmaketoolsms11531 cpptoolsms1175 remoteexplorerms041 vslivesharems105883 cratesser062 cmaketwx0017 vscodelldbvad1100 debugweb0261 1 theme extensions excluded ab experiments vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes263cf30335440 vscorecescf30445987 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vsccc30803844 282f872430602487 8954411730613380 962ge76130835153 fixshowwlkth30771522 i26e353130792625 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572 dsvsc01530829745"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncursor control\ntype performance cursor speed is very high it scroll the whole page at once it is very difficult to navigate because the whole page is scroll at once and im unable to scroll a single line or double line vs code version code 1821 20230908t084505575z os version windowsnt x64 10019045 modes system info itemvalue cpusintelr coretm i36006u cpu 200ghz 4 x 1992 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system791gb 286gb free process crashreporterid screen readerno vm0 extensions 7 extensionauthor truncatedversion ngtemplateang1618 csdevkitms0410 csharpms2210 vskeybindingsms021 liveserverrit579 ab experiments vsliv36830146709 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vstes51630244333 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscorecescf30445987 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 py29gd226330792226 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vsccc30803844 3biah62630602489 8954411730613380 962ge76130835153 03d3595930757346 fixshowwlkth30771522 i26e353130792625 pythonidxpt30805730 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv130821571 dsvsc01530829745"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nopen a file in a new tab\ndoes this issue occur when all extensions are disabled yesno report issue dialog can assist with this vs code version os version steps to reproduce 1 when i double click a file to open it in a new tab its not 2 then i go back in navigation history the elder file replaced by the new one is opened again in a new tab i tried to do a quick video with camtasia and then recording the problem disappears thinkingface im using the fact to open new files in the same project when rightclicking on a file and not opening a new project default behavior i dont know if its linked but just to tell"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsvg path is not working\ntype bug whenever i paste svg code in vs code then svg path is not coming an decrypted code coming in vs code while pasting please help me and resolve my problem as soon as possible vs code version code 1821 20230908t084505575z os version windowsnt x64 10022621 modes unsupported system info itemvalue cpusamd ryzen 5 5500u with radeon graphics 12 x 2096 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system739gb 103gb free process plts crashreporterid screen readerno vm0 extensions 35 extensionauthor truncatedversion vscodedjangobat1110 javaruncao114 vscodehtmlcssecm1131 beautifyhoo150 isortms2023101 pythonms2023160 jupyterkeymapms112 remotesshms01064 remotessheditms0860 remoteexplorerms041 autodocstringnjp061 javared1220 liveserverrit579 backgroundsha1212 vscodegradlevsc3127 vscodemavenvsc0420 vscodeiconsvsc1250 jinjawho008 ab experiments vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes263cf30335440 vscorecescf30445987 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdc30486549 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vscccc30803845 3biah62630602489 8954411730613380 vscrpc30673769 a9j8j15430646983 0bi6i64230835152 03d3595930757346 fixshowwlkth30771522 i26e353130792625 pythonnoceb30805159 asynctok30821568 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572 dsvsc01530829745"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncommand line --help does not show cli help\ntype bug hello vs code crew signofthehorns found the documentation shows one shall type code help to get help for the command line interface but this seems broken what i get is vs codecode help vs code unable to move the cache access is denied 0x5 unable to create cache and then a new vs code window opens the short h works just the same way expected the cli options are printed no window opens no confusing errors vs code version code 1821 20230908t084505575z os version windowsnt x64 10022621 modes system info itemvalue cpusintelr coretm i71065g7 cpu 130ghz 8 x 1498 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1574gb 650gb free process argvcrashreporterid screen readerno vm0 extensions 9 extensionauthor truncatedversion vscodeofficecwe316 perforcemjc4157 hexeditorms1912 materialthemezhu3160 1 theme extensions excluded ab experiments vsliv368cf30146710 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscoreces30445986 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vsccc30803844 282f872430602487 8954411730613380 962ge76130835153 03d3595930757346 fixshowwlkth30771522 i26e353130792625 pythonidxpt30805730 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572 dsvsc015cf30829746"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nmodules\ntype feature request i installed the external module pandas using pip install pandas command in terminal in problems its showing import pandas could not be resolved pylance vs code version code 1811 20230809t222242175z os version windowsnt x64 10019045 modes"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nterminal issue\ntype performance issue why is my terminal not running my python code vs code version code 1820 20230906t220707438z os version windowsnt x64 10022621 modes system info itemvalue cpusamd 3020e with radeon graphics 2 x 1200 gpu status2dcanvas disabledoffopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system594gb 127gb free process vs codecodeexe crashreporterid screen readerno vm0 process info cpu mem mb pid process 3 141 19240 code main 0 181 1124 window 3 demopy visual studio code 0 86 3328 ptyhost 0 69 2348 noexit command try vs catch 0 7 6180 conptyagent 0 7 9856 conptyagent 0 7 10192 conptyagent 0 72 14660 noexit command try vs catch 0 61 18112 noexit command try vs catch 0 123 7008 gpuprocess 0 94 8056 sharedprocess 0 28 8140 crashpadhandler 0 87 11300 filewatcher 3 0 136 13468 extensionhost 1 0 138 10176 electronnodejs vs codecodeexe nodeipc clientprocessid13468 0 154 16248 window 1 demopy visual studio code 0 148 17360 extensionhost 3 0 166 15432 electronnodejs vs codecodeexe nodeipc clientprocessid17360 0 73 17532 filewatcher 1 0 49 17804 2 91 18732 window 4 issue reporter workspace info extensions 2 extensionauthor truncatedversion pythonms2023160 ab experiments vsliv368cf30146710 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vsdfh931cf30280410 vshan82030294714 vstes26330335439 vscorecescf30445987 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 py29gd2263cf30792227 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vscccc30803845 3biah62630602489 8954411730613380 a2ce337530757347 7ij3880630736111 fixshowwlkth30771522 i26e353130792625 pythonidxpt30805730 pythonnoceb30805159 synctok30821570 dsvsc01330795093 dsvsc01430804076 diffeditorv130821571 dsvsc015cf30829746"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncoke project wrong checking error\ncs50 coke project checking is giving wrong results i think my program is correct but checking shows error however those errors were directed to next prompts even though the project asks for next prompt version 1820 commit user agent mozilla50 windows nt 100 win64 x64 applewebkit53736 khtml like gecko chrome116000 safari53736 edg1160193862 embedder codespaces"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nerror while Compiling/running c code\ntype bug include include include int main const int min 1 const int max 5 int guess int guesses int answer srandtime0 answer rand max min do printfenter your guess scanfdguess ifguess answer printftoo highn else if guess answer printftoo lown else printfcorrect you got thisn guesses whileguess answer printfn printfanswer dnanswer printftries dnguesses printf return 0 the result must provide me with the answer and the total amount of triesguesses i get the answer printed correctly but the number of tries isnt accurate i tried running the same code on online compilers to see if my code had some problem the online compilers gave me the correct answer and the number of tries but there seems to be something wrong with vscode when it comes to the tries part vs code version code 1820 20230906t220707438z os version windowsnt x64 10022621 modes system info itemvalue cpusamd ryzen 5 4600h with radeon graphics 12 x 2994 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1542gb 557gb free process argvcrashreporterid screen readerno vm0 extensions 5 extensionauthor truncatedversion coderunnerfor0120 cmaketoolsms11531 cpptoolsms1175 cmaketwx0017 2 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes263cf30335440 vscorecescf30445987 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 py29gd226330792226 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vscccc30803845 282f872430602487 8954411730613380 vscrpc30673769 0bi6i64230831757 03d3595930757346 fixshowwlkth30771522 i26e353130792625 pythonidxpt30805730 pythonnoceb30805159 asynctok30821568 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572 dsvsc01530829745"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nzsh: killed \ntype bug i have this problem in my terminal on my mac and in the terminal on visual studio code when i type python3 and python3 version it gives me zsh killed im new to coding and it didnt do this before im not sure how to fix it img width697 altscreenshot 20230907 at 12 06 07 pm src vs code version code 1811 universal 20230809t222033924z os version darwin arm64 2260 modes system info itemvalue cpusapple m2 8 x 24 gpu status2dcanvas enabledmetal enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avg2 2 2 memory system800gb 005gb free process argvcrashreporterid screen readerno vm0 extensions 7 extensionauthor truncatedversion pythonms2023140 jupyterkeymapms112 ab experiments vsliv36830146709 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vswsl492cf30256860 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vsdfh931cf30280410 vshan82030294714 vstes263cf30335440 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vsclangdc30486549 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vsccc30803844 2e4cg34230602488 f6dab26930613381 0bi6i64230823812 a2ce337530757347 fixshowwlkth30771522 i26e353130792625 pythonidxpt30805730 pythonnoceb30805159 synctok30821570 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572 dsvsc01530829745"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nzoom challenge\ndoes this issue occur when all extensions are disabled yesno report issue dialog can assist with this vs code version os version steps to reproduce 1 2 vsc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError in calculating 5 cube to check weather 153 is armstrong number or not\ntype bug i wrote a code to check weather 153 is a armstrong number or notit is an armstrong number as per a question in vs code when i print cube of every digit using pow it show 5 cube as 124 instead of 125while same code run perfectly on devc software but other cubes are correct code is provided below for your ease to confirm my problem include include int main int i153aans0n0 ai whilea0 npowa103 printfcube of each digits ndn ansn a10 ifians printfndans return 0 vs code version code 1811 20230809t222242175z os version windowsnt x64 10023536 modes system info itemvalue cpus11th gen intelr coretm i31115g4 300ghz 4 x 2995 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system775gb 119gb free process argvcrashreporterid screen readerno vm0 extensions 9 extensionauthor truncatedversion coderunnerfor0120 ccpprunnerfra810 pythonms2023140 cmaketoolsms11531 cpptoolsms1175 cmaketwx0017 vscodelldbvad192 1 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vswsl492cf30256860 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vsdfh931cf30280410 vshan82030294714 vstes263cf30335440 vscoreces30445986 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 py29gd226330792226 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vsccc30803844 282f872430602487 f6dab26930613381 03d3595930757346 fixshowwlkth30771522 i26e353130792625 pythonidxpt30805730 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nComing out of program\ntype bug my code automatically comes out after taking only one input vs code version code 1811 20230809t222242175z os version windowsnt x64 10022621 modes system info itemvalue cpus12th gen intelr coretm i712650h 16 x 2688 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1568gb 586gb free process argvcrashreporterid screen readerno vm0 extensions 33 extensionauthor truncatedversion blackboxbla1097 vscodehtmlcssecm1131 editorconfigedi0164 coderunnerfor0120 chatgptvscodegen008 isortms2023101 pythonms2023140 jupyterkeymapms112 remotewslms0810 cmaketoolsms11531 cpptoolsms1175 javared1210 tabninevscodetab388 cmaketwx0017 vscodemavenvsc0420 2 theme extensions excluded ab experiments vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vstes51630244333 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 py29gd2263cf30792227 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vsccc30803844 2e4cg34230602488 f6dab26930613381 962ge76130823813 a2ce337530757347 fixshowwlkth30771522 i26e353130792625 pythonidxpt30805730 pythonnoceb30805159 asynctok30821568 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ni can't run the code\ntype bug when i try to run my come vs shows timed out waiting launcher to connect i search for all info in internet but nothing helped vs code version code 1792 20230614t085704379z os version windowsnt x64 629200 modes system info itemvalue cpusamd ryzen 5 5600h with radeon graphics 12 x 3294 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1386gb 820gb free process argvcrashreporterid screen readerno vm0 extensions 6 extensionauthor truncatedversion gcexcelviewergra4258 json2csvkha001 pythonms2023140 atomkeybindingsms330 vscodeiconsvsc1250 ab experiments vsliv36830146709 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vswsl49230256859 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 py29gd2263cf30792227 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vsccc30803844 3biah62630602489 8954411730613380 vscrpc30673769 a9j8j15430646983 0bi6i64230823812 a2ce337530757347 57b7757930736110 fixshowwlkth30771522 i26e353130792625 pythonidxpt30805730 pythonnoceb30805159 asynctok30821568 dsvsc01330795093 dsvsc01430804076 diffeditorv130821571"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMarkdown files doesn't show as expected\ntype feature request im testing intellij after using vs code for a year and ive noticed that mdfiles display more like i expect in intellij thats a pitty both are not opimal though since marked lists are not very visible i intellij and absent in vs code example x write the press release update the website contact the media definition lists definition vs code version code 1811 20230809t222242175z os version windowsnt x64 10022621 modes"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nextension name too lang cause UI not good\nsee this picturewhen extension name too lang ，ui seems image"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsame program, different outputs\ntype bug include include using namespace std int main coutenter a number int n cinn int i0bit0binary0 coutn whilen0 bitn1 to store a number in same order binary bitpow10ibinary i nn1 cout in binary is binaryendl lets take n7 then the output should be 111 but on visual studio this program gives it to be 110 i copied the same program and ran it on some online c compiler and got the desired output ie 111 vs code version code 1811 20230809t222242175z os version windowsnt x64 10022621 modes system info itemvalue cpus12th gen intelr coretm i51235u 12 x 2496 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1573gb 792gb free process argvcrashreporterid screen readerno vm0 extensions 14 extensionauthor truncatedversion coderunnerfor0120 cmaketoolsms11531 cpptoolsms1175 javared1210 cmaketwx0017 vscodemavenvsc0420 1 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscoreces30445986 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vsccc30803844 2e4cg34230602488 f6dab26930613381 2i9eh26530646982 0bi6i64230823812 03d3595930757346 fixshowwlkth30771522 i26e353130792625 gsofb30804716 pythonidxpt30805730 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsettings.json\nwithout noticing i removed something in the code in settingsjson and it now shows incorrect type expected null ln4 col 5 and as a beginner in coding i have no idea how to correct that help me please i just need the original to copy and paste it back 1 2 filesautosave onfocuschange true javascript node java cd dir javac filename java filenamewithoutext c cd dir gcc filename o filenamewithoutext zig zig run cpp cd dir g filename o filenamewithoutext objectivec cd dir gcc framework cocoa filename o filenamewithoutext php php python python u perl perl perl6 perl6 ruby ruby go go run lua lua groovy groovy powershell powershell executionpolicy bypass file bat cmd c shellscript bash fsharp fsi csharp scriptcs vbscript cscript nologo typescript tsnode coffeescript coffee scala scala swift swift julia julia crystal crystal ocaml ocaml r rscript applescript osascript clojure lein exec haxe haxe cwd run filenamewithoutext rust cd dir rustc filename racket racket scheme csi script ahk autohotkey autoit autoit3 dart dart pascal cd dir fpc filename d cd dir dmd filename haskell runghc nim nim compile verbosity0 hintsoff run lisp sbcl script kit kitc run v v run sass sass style expanded scss scss style expanded less cd dir lessc filename fortranfreeform cd dir gfortran filename o filenamewithoutext fortranmodern cd dir gfortran filename o filenamewithoutext fortranfixedform cd dir gfortran filename o filenamewithoutext fortran cd dir gfortran filename o filenamewithoutext sml cd dir sml filename command prompt true vb cd dir vbc nologo filename vbs cscript nologo scala scala jl julia cr crystal ml ocaml zig zig run exs elixir hx haxe cwd run filenamewithoutext rkt racket scm csi script ahk autohotkey au3 autoit3 kt cd dir kotlinc filename includeruntime d java jar kts kotlinc script dart dart pas cd dir fpc filename pp cd dir fpc filename d cd dir dmd filename hs runhaskell nim nim compile verbosity0 hintsoff run csproj dotnet run project fsproj dotnet run project lisp sbcl script kit kitc run v v run vsh v run sass sass style expanded cu cd dir nvcc filename o filenamewithoutext ring ring sml cd dir sml filename"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIntellisense\ntype performance issue in my laptop the intellisense is not working even after re installing it from the website vs code version code 1811 20230809t222242175z os version windowsnt x64 10019045 modes system info itemvalue cpusintelr coretm i58250u cpu 160ghz 8 x 1800 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1587gb 664gb free process argvcrashreporterid screen readerno vm0 process info cpu mem mb pid process 0 106 20940 code main 0 45 1376 0 164 1380 extensionhost 1 0 79 7832 electronnodejs vs codecodeexe nodeipc clientprocessid1380 0 80 23284 electronnodejs vs codecodeexe vs nodeipc clientprocessid1380 0 86 28004 electronnodejs vs codecodeexe nodeipc clientprocessid1380 0 80 6460 filewatcher 1 0 27 9312 crashpadhandler 0 101 14484 sharedprocess 1 182 22828 gpuprocess 0 96 26052 ptyhost 0 6 2044 conptyagent 0 84 2496 noexit command try vs catch 0 84 19892 noexit command try vs catch 0 6 22692 conptyagent 0 6 26924 conptyagent 0 84 28048 noexit command try vs catch 0 195 26472 window 1 ● appjs practice visual studio code 1 92 28824 window 2 issue reporter workspace info window ● appjs practice visual studio code folder practice 30 files file types js10 json3 png2 css2 gitignore1 ico1 html1 txt1 md1 svg1 conf files packagejson1 extensions 11 extensionauthor truncatedversion vscodehtmlcssecm1131 autorenametagfor0110 vscodecsspeekpra441 liveserverrit579 openinbrowsertec200 vscodeiconsvsc1250 ab experiments vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vswsl49230256859 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes263cf30335440 vscoreces30445986 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vsclangdc30486549 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vsccc30803844 2e4cg34230602488 f6dab26930613381 a9j8j15430646983 03d3595930757346 fixshowwlkth30771522 i26e353130792625 gsofa30804715 pythonidxpt30805730 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv230821572"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nmultiple file does not open in new tab\ntype feature request when a file is open then if i wanna open a new file it replace the tab with older one not in the new tab vs code version code 1811 20230809t222242175z os version windowsnt x64 10022621 modes"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAll multi-cursors now disappear when navigating by word\ntype bug take any test with multiple lines use ctrlshiftaltdown to create a multicursor one per line navigating by character leftright works as expected all cursors navigate navigating by line updown or homeend also works as expected and all cursors do it navigating by word ctrlleftright doesnt all cursors but one disappear as soon as you do this this just started happening out of the blue possibly after an update i dont know just came back from vacation vs code version code 1810 20230802t123713485z os version windowsnt x64 10022621 modes connection to ssh ttdrazzle could not be established canceled system info itemvalue cpusamd ryzen 9 7950x 16core processor 32 x 4491 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system12714gb 8480gb free process argvcrashreporterid screen readeryes vm0 connection to ssh ttdrazzle could not be established canceled extensions 26 extensionauthor truncatedversion xmldot251 gitlenseam1421 x8664assemblyfre010 todotreegru00226 vscodegraphvizjoa006 tdpcodemic102304707 csharpms20376 sarifviewerms341 remotesshms01020 remotessheditms0860 remotewslms0810 cmaketoolsms11531 cpptoolsms1174 remoteexplorerms041 remoteserverms143 vslivesharems105883 windbgdebugrez034 cmaketwx0017 ab experiments vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vswsl49230256859 vstes62730244334 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes263cf30335440 vscoreces30445986 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 py29gd2263cf30792227 vscaat30438848 vsclangdc30486549 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vscccc30803845 282f872430602487 f6dab26930613381 a9j8j15430646983 03d3595930757346 fixshowwlkth30771522 i26e353130792625 gsofa30804715 pythonidxpt30805730 pythonnoceb30805159 asynctok30810527 dsvsc01330795093 dsvsc01430804076 diffeditorv130810525"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nJava compilation error\ntype bug java compilation error vs code version code 1811 20230809t222242175z os version windowsnt x64 10022631 modes system info itemvalue cpus11th gen intelr coretm i31115g4 300ghz 4 x 2995 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system780gb 143gb free process argvcrashreporterid screen readerno vm0 extensions 20 extensionauthor truncatedversion autorenametagfor0110 vscodejavacgeo0246 remotewslms0810 powershellms202360 javared1210 liveserverrit579 p5vscodesam1214 vscodemavenvsc0420 reactsnippetsxab240 ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes263cf30335440 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vscaac30438847 vsclangdc30486549 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vsccc30803844 3biah62630602489 8954411730613380 03d3595930757346 fixshowwlkth30771522 i26e353130792625 gsofb30804716 pythonidxpt30805730 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv130812748"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to detect if there is a snippets list in the editor?\nhow to detect if there is a snippets list in the editor as user type keystrokes by meaning snippets list i mean dropdown menu in the picture thanks i am building a completion provider which want to trigger only when there is no dropdown suggestions list how to achieve it screenshot 20230821 at 4 39 57 pm"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAbout Winerror 87\nwhen i import eel lib on my python code it keeps shown me this error on eelstartindexhtml is there a problem with my code or its a bug"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntransform function not working\ntype bug i am using css transform function which is not working vs code version code 1811 20230809t222242175z os version windowsnt x64 10019045 modes system info itemvalue cpusamd ryzen 5 2500u with radeon vega mobile gfx 8 x 1996 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system696gb 231gb free process argvcrashreporterid screen readerno vm0 extensions 11 extensionauthor truncatedversion tailwindshadesbou005 vscodehtmlcssecm1131 sqltoolsmtx0280 liveserverrit579 ayutea105 1 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vswsl492cf30256860 vstes62730244334 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vsclangdc30486549 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vsccc30803844 282f872430602487 8954411730613380 2i9eh26530646982 03d3595930757346 7ij3880630736111 fixshowwlkth30771522 i26e353130792625 gsofa30804715 pythonnoceb30805159 synctok30815622 dsvsc01330795093 dsvsc01430804076 diffeditorv130812748"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProblema com salvar as comfigurações do vscode\ntype bug eu instalai a extensão dracula porém quando eu fecho o vscode ela simplesmente sai e eu tenho que reabilitar ela vs code version code 1811 20230809t222242175z os version windowsnt x64 10022621 modes system info itemvalue cpusamd ryzen 3 5400u with radeon graphics 8 x 2595 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system731gb 132gb free process crashreporterid screen readerno vm0 extensions 6 extensionauthor truncatedversion codesnapadp134 colorhighlightnau250 indentrainbowode831 1 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vswsl492cf30256860 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscorecescf30445987 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vscaac30438847 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vscccc30803845 2e4cg34230602488 f6dab26930613381 2i9eh26530646982 fixshowwlkth30771522 i26e353130792625 gsofa30804715 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv130812748"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n#include path error \ntype bug my include path error is coming again and again kindly resolve my issue i have just done everything changing its include path like everything which i can do form my side now pls help me to resolve this issue vs code version code 1811 20230809t222242175z os version windowsnt x64 10019045 modes system info itemvalue cpus11th gen intelr coretm i31115g4 300ghz 4 x 2995 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system773gb 182gb free process argvcrashreporterid screen readerno vm0 extensions 7 extensionauthor truncatedversion exerunnerbra021 coderunnerfor0120 iciemik100 cmaketoolsms11531 cpptoolsms1173 cmaketwx0017 1 theme extensions excluded ab experiments vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes263cf30335440 vscoreces30445986 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vsccc30803844 282f872430602487 8954411730613380 2i9eh26530646982 03d3595930757346 fixshowwlkth30771522 i26e353130792625 gsofa30804715 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv230812749"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nhow can i close the auto save i want to control saving?\nadd issue description here version 1811 commit user agent mozilla50 windows nt 100 win64 x64 applewebkit53736 khtml like gecko chrome115000 safari53736 edg11501901203 embedder codespaces"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nin my vs code t is not working whenever i enter t key vs code give an error by saying the key combination (T,T) is not command please help me\ndoes this issue occur when all extensions are disabled yesno report issue dialog can assist with this vs code version os version steps to reproduce 1 2 tasklist tasks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n> sign has accidentally replaced $ sign at cursor in terminal window of vs code. How can I get $ sign back at cursor\nadd issue description here version 1811 commit user agent mozilla50 windows nt 100 win64 x64 applewebkit53736 khtml like gecko chrome115000 safari53736 embedder codespaces"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nissues in c++ program running\ni am running c program and i it not running properly i have tried run in terminal only it is not running at all fix this"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBUG in in-built function pow (power function).\ntype bug hello developers hope you are doing well so while solving my class asignment problem i have found bug in following program as i am getting unexpected output for certain value that is for input 5 for other values it is working fine but on entering input 5 it is printing unexpected output code include include int powerint a int main int a 5 int k powera printfpow is d k int powerint a int b powa2 return b vs code version code 1811 20230809t222242175z os version windowsnt x64 10022000 modes system info itemvalue cpus11th gen intelr coretm i51135g7 240ghz 8 x 2419 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system776gb 094gb free process argvcrashreporterid screen readerno vm0 extensions 13 extensionauthor truncatedversion exerunnerbra021 isortms2023101 pythonms2023140 cmaketoolsms11531 cpptoolsms1163 indentrainbowode831 cmaketwx0017 1 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vswsl49230256859 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes263cf30335440 vscorecescf30445987 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 py29gd226330792226 vscaac30438847 vsclangdc30486549 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vsccc30803844 3biah62630602489 8954411730613380 03d3595930757346 fixshowwlkth30771522 i26e353130792625 gsofb30804716 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076 diffeditorv130812748"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\narmstrong3.c\nwe have written the needed data into your clipboard because it was too large to send please paste type performance issue include include int main int n rem p s 0 printfnenter number scanfd n p n while n0 rem n 10 s s powrem3 n n10 if s p printfnd is a armstrong number p else printfnsum d s printfnnot a armstrong number return 0 the output is showing me 152 and i even tried the same source code on other ides they worked well and gave me expected output as 153 please solve this issue i talked to my friend and he experienced the same thing why is this happening vs code version code 1811 20230809t222242175z os version windowsnt x64 10022621 modes system info itemvalue cpus11th gen intelr coretm i511300h 310ghz 8 x 3110 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1579gb 822gb free process argvcrashreporterid screen readerno vm0 process info cpu mem mb pid process 0 115 21172 code main 0 87 7764 window 2 issue reporter 0 227 9584 gpuprocess 0 193 10200 extensionhost 1 0 28 2768 cuserstushal 0 11 4256 0x4 0 4 21020 cuserstushal 0 16 5448 cuserstushal 2768 0 11 13588 0x4 0 77 10040 electronnodejs cuserstushal vs codecodeexe cuserstushal nodeipc clientprocessid10200 0 618 22280 cuserstushal addmodulesallsystem addopens addopens addopens dfileencodingutf8 xxuseparallelgc xxgctimeratio4 xmx1g xms100m xlogdisable jar cuserstushal configuration cuserstushal data cuserstushal 0 43 12392 0 204 14128 window 1 armstrong3c untitled workspace visual studio code 0 28 16176 crashpadhandler 0 91 18868 sharedprocess 0 82 21340 electronnodejs cuserstushal vs codecodeexe cuserstushal vs msvscodecppdbg 0 79 19640 filewatcher 1 0 79 22100 ptyhost 0 71 1404 noexit command try cuserstushal vs catch 0 8 20564 conptyagent workspace info window armstrong3c untitled workspace visual studio code folder coding 190 files file types c155 exe13 py2 cpp1 class1 java1 conf files extensions 31 extensionauthor truncatedversion vscodedjangobat1100 vscodehtmlcssecm1131 autoclosetagfor0514 autorenametagfor0110 coderunnerfor0120 pythonms2023140 jupyterkeymapms112 cmaketoolsms11531 cpptoolsms1163 autodocstringnjp061 javared1210 liveserverrit579 cmaketwx0017 vscodemavenvsc0420 jinjawho008 1 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes263cf30335440 vscorecescf30445987 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 py29gd226330792226 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vsccc30803844 2e4cg34230602488 f6dab26930613381 03d3595930757346 pythoncmv30756943 fixshowwlkth30771522 i26e353130792625 gsofb30804716 pythonidxpt30805730 pythonnoceb30805159 dsvsc01330795093 dsvsc01430804076"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncant run my code properly \ntype feature request respected mamsir i am humbly requesting kindly fix my vs code via any online connecting souces like anydesk its showing openlaunchjson kindly help me out i am stuck in this loop for this i will be forever thankful to you guys vs code version code 1811 20230809t222242175z os version windowsnt x64 10022621 modes"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCustom view container menu action contribute \ni want to be able to add actions to custom view container ive tried json commands command testcommandid title test command icon zap viewscontainers activitybar id custiomviewcontainer title test title icon zap menus viewtitle command testcommandid when view custiomviewcontainer group navigation command testcommandid when true group navigation non of this works however i am able to add command for built in containers json menus scmtitle command testcommandid when true group navigation"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug in CodeSpace\ntype bug in codespace jupyter template when i create a new jupyter template and run the first python clock in it shows an error modulenotfounderror no module named lzma caused by the second line import torchvision vs code version code 1810 20230802t123713485z os version windowsnt x64 10022000 modes system info itemvalue cpusamd ryzen 7 4800u with radeon graphics 16 x 1797 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1537gb 907gb free process argvcrashreporterid screen readerno vm0 extensions 12 extensionauthor truncatedversion codespacesgit11415 jupyterkeymapms112 remotesshms01020 remotessheditms0860 remotewslms0810 cpptoolsms171 remoteexplorerms041 ab experiments vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscorecescf30445987 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vscccc30803845 3biah62630602489 f6dab26930613381 a9j8j15430646983 vsctsb30748421 pythoncmv30756943 fixshowwlkth30771522 i26e353130792625 gsofa30804715 pythonidxpt30805730 pythonnoceb30805159 e537b57730795824 dsvsc01330795093 dsvsc01430804076"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsubscribing to the response of CLI command \ni am developing an extension and there is a cli command which subscribes to server and keep listening to it until stopped manually i want to use this command to implement a feature in the extension so that it will keep listening to the server and whenever there is some event happened on server side it will give a response and we can read it and use it this command will get fired as soon as the extension activates and will stop when extension deactivates i tried executing with spawn but it executed the command as there was not response at that time from the cli command it got exit how can i implement this"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nImport\ntype bug i have installed polars but it is not importing in the code says module not found error vs code version code 1810 20230802t123713485z os version windowsnt x64 10022621 modes system info itemvalue cpusintelr coretm i78550u cpu 180ghz 8 x 1992 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1590gb 795gb free process argvcrashreporterid screen readerno vm0 extensions 34 extensionauthor truncatedversion matlabcoderunbra102 dockerexplorerfor017 dockerrungeo110 matlabgim302 composerika080 mongodbvscodemon110 vscodedockerms1260 isortms2023101 pythonms2023140 jupyterkeymapms112 remotewslms0810 vslivesharems105877 dockercomposep1c050 saspvp001 saslspsas110 sasjsforvscodesas251 matlabcompletesla111 octavedebugtia003 wordupcodewor032 phpdebugxde1330 ab experiments vsliv36830146709 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 py29gd226330792226 vsclangdc30486549 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vscccc30803845 3biah62630602489 f6dab26930613381 a9j8j15430646983 vsctsb30748421 03d3595930757346 fixshowwlkth30771522 i26e353130792625 gsofa30804715 pythonnoceb30805159 e537b57730795824 dsvsc01330795093 dsvsc01430804076"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTest Results tab in VS Code keep popping up even if closed after each test run\ntype bug context playwright version1362 operating system mac nodejs version v2040 visual studio code version version 1810 commit date 20230802t123828722z electron 22318 electronbuildid 22689846 chromium 10805359215 nodejs 16171 v8 10816825electron0 os darwin arm64 2260 playwright for vscode extension version v1015 when running a test the tab with test results always popsup this started happening with recent vs code update no matter what i do it keeps poppingup before it was never showed up if not on demand vs code version code 1810 20230802t123828722z os version darwin arm64 2260 modes system info itemvalue cpusapple m1 pro 10 x 24 gpu status2dcanvas enabledmetal enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avg4 4 5 memory system3200gb 040gb free process argvcrashreporterid screen readerno vm0 extensions 27 extensionauthor truncatedversion atlascodeatl304 gitlenseam1420 coderunnerfor0120 rainbowcsvmec370 playwrightms1015 remotesshms01020 remotessheditms0860 remotewslms0810 azureaccountms0115 powershellms202360 remoteexplorerms041 remoteserverms140 vslivesharems105877 vscodeyamlred1140 iconstal370 colonizevms222 gistfsvsl041 ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vsdfh931cf30280410 vshan82030294714 vstes26330335439 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 py29gd226330792226 vsclangdc30486549 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vsccc30803844 2e4cg34230602488 8954411730613380 a9j8j15430646983 vsctsb30748421 03d3595930757346 7ij3880630736111 pythoncmv30756943 fixshowwlkth30771522 i26e353130792625 gsofa30804715 pythonidxpt30805730 pythonnoceb30805159 e537b57730795824 dsvsc01330795093 dsvsc01430804076 image"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ni want to put my name in output\ntype feature request i want to my name in output in default vs code version code 1810 20230802t123713485z os version windowsnt x64 10022621 modes"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProblems with the Fetch API\ntype bug i am not sure if this is really a problem with vs code or not i use the fetch api in javascript when i run the fetch directly in javascript with a chrome browser i have no problems the fetch api executes fine a very important point is that i dont see an options request being sent however when i run the same fetch using exactly the same javascript using vs code i do see an options being sent even worse the fetch under javascript under chrome under vs code does not wait for the options to complete the fetch just fails with a failed to fetch error i dont understand this why should vs code make any difference what am i doing wrong what additional information should i provide how should this problem be debugged this is not a question this is probably a bug vsc has a behavior that native javascript does not either vsc should be fixed or some sort of circumvention should be devised vs code version code 1810 20230802t123713485z os version windowsnt x64 10019045 modes system info itemvalue cpusintelr coretm i74702hq cpu 220ghz 8 x 2195 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode unavailableoffvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1591gb 505gb free process argvfolderuri crashreporterid screen readerno vm0 extensions none ab experiments vsliv368cf30146710 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vstes62730244334 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscoreces30445986 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vsccc30803844 282f872430602487 f6dab26930613381 vsctsb30748421 03d3595930757346 fixshowwlkth30771522 i26e353130792625 gsofb30804716 pythonidxpt30805730 pythonnoceb30805159 e537b57730795824 dsvsc01330795093 dsvsc01430804076"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProblems with the Fetch API\ntype bug i am not sure if this is really a problem with vs code or not i use the fetch api in javascript when i run the fetch directly in javascript with a chrome browser i have no problems the fetch api executes fine a very important point is that i dont see an options request being sent however when i run the same fetch using exactly the same javascript using vs code i do see an options being sent even worse the fetch under javascript under chrome under vs code does not wait for the options to complete the fetch just fails with a failed to fetch error i dont understand this why should vs code make any difference what am i doing wrong what additional information should i provide how should this problem be debugged vs code version code 1810 20230802t123713485z os version windowsnt x64 10019045 modes system info itemvalue cpusintelr coretm i74702hq cpu 220ghz 8 x 2195 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode unavailableoffvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1591gb 579gb free process argvfolderuri crashreporterid screen readerno vm0 extensions 10 extensionauthor truncatedversion copilotgit1100306 pythonms2023140 jupyterkeymapms112 liveserverms049 liveserverrit579 ab experiments vsliv368cf30146710 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vstes62730244334 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscoreces30445986 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vsccc30803844 282f872430602487 f6dab26930613381 vsctsb30748421 03d3595930757346 fixshowwlkth30771522 i26e353130792625 gsofb30804716 pythonidxpt30805730 pythonnoceb30805159 e537b57730795824 dsvsc01330795093 dsvsc01430804076"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nwebpages didn't load in chrome\ntypeurl performance issue when i run the htmlcssjs code it shows again and again localhost8080 localhost refused error i cant load my webpages i feel great if you reply me vs code version code 1810 20230802t123713485z os version windowsnt x64 10022631 modes system info itemvalue cpus11th gen intelr coretm i31115g4 300ghz 4 x 2995 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system765gb 254gb free process argvcrashreporterid screen readerno vm0 process info cpu mem mb pid process 1 90 17104 code main 0 109 2988 extensionhost 1 0 113 8616 electronnodejs cprogram filesmicrosoft vs codecodeexe maxoldspacesize3072 cprogram filesmicrosoft vs enabletelemetry cancellationpipename locale en usenodeipc 0 79 14660 electronnodejs cprogram filesmicrosoft vs codecodeexe cprogram filesmicrosoft vs enabletelemetry typesmaplocation cprogram filesmicrosoft vs 0 119 9260 electronnodejs cprogram filesmicrosoft vs codecodeexe maxoldspacesize3072 cprogram filesmicrosoft vs servermode partialsemantic cancellationpipename locale en usenodeipc 0 80 5360 sharedprocess 1 218 6808 window 1 appjs js visual studio code 0 74 6920 filewatcher 1 0 26 11284 crashpadhandler 1 84 12132 window 2 issue reporter 1 166 15848 gpuprocess 0 42 15856 workspace info window appjs js visual studio code folder js 2 files file types js1 html1 conf files extensions 4 extensionauthor truncatedversion autoclosetagfor0514 coderunnerfor0120 remotewslms0810 liveserverrit579 ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vswsl49230256859 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vscccc30803845 3biah62630602489 8954411730613380 2i9eh26530646982 vsctsb30748421 03d3595930757346 fixshowwlkth30771522 i26e353130792625 gsofb30804716 pythonidxpt30805730 pythonnoceb30805159 e537b57730795824 dsvsc01330795093 dsvsc01430804076"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nerror \ntype bug user microsoft windows versión 100226211992 c microsoft corporation todos los derechos reservados s booting puma rails 706 application starting in development run binrails server help for more startup options sigusr2 not implemented signal based restart unavailable sigusr1 not implemented signal based restart unavailable sighup not implemented signal based logs reopening unavailable puma starting in single mode version 500 ruby 313p185 codename spoony bard min threads 5 max threads 5 environment development exiting initialize only one usage of each socket address protocolnetwork addressport is normally permitted bind2 for 127001 port 3000 errnoeaddrinuse from new from addtcplistener from block in addtcplistener from each from addtcplistener from block in parse from each from parse from loadandbind from run from run from run from start from start from block in perform from 90in tap from perform from run from invokecommand from dispatch from perform from invoke from from require from require from binrails4in vs code version code 1802 20230727t204028909z os version windowsnt x64 10022621 modes system info itemvalue cpusintelr coretm i79750h cpu 260ghz 12 x 2592 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1588gb 885gb free process crashreporterid screen readerno vm0 extensions 22 extensionauthor truncatedversion railspartialaki034 codespacesgit11414 remotehubgit0600 beautifyhoo150 railssnippetshri108 vscodepeacockjoh422 remotewslms0802 azurereposms0360 liveserverms049 indentrainbowode831 sqliteviewerqwt025 rubyreb0281 liveserverrit579 docxreadersha100 vscodeiconsvsc1240 vscoderubywin0280 ab experiments vsliv368cf30146710 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscorecescf30445987 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdc30486549 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vsccc30803844 282f872430602487 8954411730613380 2i9eh26530646982 vsctsb30748421 9b8hh23430694863 fixshowwlkth30771522 i26e353130792625 gsofb30804716 pythonnoceb30805159 e537b57730795824 dsvsc01330795093 dsvsc01430804076"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCan't connect emulators\ntype bug i have tries all posible answers but no luck path reinstallation etc i cant test my apps i have windows 10 home edition vs code version code 1810 20230802t123713485z os version windowsnt x64 10019045 modes system info itemvalue cpusintelr coretm i54210u cpu 170ghz 4 x 2394 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1191gb 688gb free process argvcrashreporterid screen readerno vm0 extensions 4 extensionauthor truncatedversion dartcodedar3700 flutterdar3700 emulatedie160 gitlenseam1411 ab experiments vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vswsl492cf30256860 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes263cf30335440 vscorecescf30445987 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 py29gd226330792226 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vscccc30803845 2e4cg34230602488 8954411730613380 a9j8j15430646983 vsctsb30748421 03d3595930757346 pythoncmv30756943 fixshowwlkth30771522 i26e353130792625 gsofb30804716 pythonidxpt30805730 pythonnoceb30805159 e537b57730795824 dsvsc01330795093 dsvsc01430804076"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTrying to get to SRCPF on PUB400\ntype bug im getting an odd error trying to access my srcpfs on pub400 getting cpf2207 not authorized to ise object ileditor in library qsys type lib can anyone assist vs code version code 1802 20230727t204028909z os version windowsnt x64 10022621 modes system info itemvalue cpus12th gen intelr coretm i51245u 12 x 2496 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1569gb 615gb free process argvcrashreporterid screen readerno vm0 extensions 17 extensionauthor truncatedversion ibmilanguagesbar0614 cobolbit9723 vscoderpgfreebri0026 ibmisnippetsfor100 copilotgit199289 codeforibmihal202 vscodedb2ihal033 vscoderpglehal0193 ibmidebugibm100 vscodeclleibm111 errorlensuse3120 ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vswsl49230256859 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscoreces30445986 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdc30486549 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vsccc30803844 3biah62630602489 8954411730613380 a9j8j15430646983 vsctsb30748421 03d3595930757346 2436559830736109 pythoncmv30756943 fixshowwlkth30771522 i26e353130792625 pythonnoceb30797650 e537b57730795824 dsvsc01330795093 dsvsc014cf30797590"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFailed to install the app.\ndoes this issue occur when all extensions are disabled yes report issue dialog can assist with this vs code version 1632 os version windowsnt x64 10019045 steps to reproduce 1 create a project regardless of reaction native cli expocli ex npx createexpoapp myapp 2 run the project on the android emulator ex expo start a run on emulator if you run an android app project in the current visual studio the emulator will run properly but the app installation will continue to fail is there any additional configuration that i should set currently i have set the home environment variable even though it runs normally in android studio it doesnt run only in visual studio code i dont think i can make a java machine properly can you help me i also posted an issue on the react native collar but i didnt get any help im attaching the link together just in case this is my error npx reactnative runandroid info starting js server daemon not running starting now at tcp5037 daemon started successfully info launching emulator info successfully launched emulator info installing the app unrecognized option xmx64m error could not create the java virtual machine error a fatal exception has occurred program will exit error failed to install the app make sure you have the android development environment set up error command failed gradlewbat appinstalldebug unrecognized option xmx64m error a fatal exception has occurred program will exit at makeerror at at at async runonalldevices at async commandhandleaction info run cli with verbose flag for more details"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncode-oss configure display language is invalid\ndoes this issue occur when all extensions are disabled yesno report issue dialog can assist with this vs code version 1801 os version windowsnt x64 10022621 about info version 1801 user setup commit unknown date 20230731t100118853z electron 22314 electronbuildid undefined chromium 10805359215 nodejs 16171 v8 10816825electron0 os windowsnt x64 10022621 steps to reproduce 1 build vscode source yarn gulp vscodewin32x64 2 install chinese extensionzhcn 3 configure display language and select to zhcnreload its still englistes 4 same as yarn gulp the argvjson had set locale to zhcn image"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSnippet Requires extra tab to move to next placeholder\ntype bug this is my snippets file place your global snippets here each snippet is defined under a snippet name and has a scope prefix body and description add comma separated ids of the languages where the snippet is applicable in the scope field if scope is left empty or omitted the snippet gets applied to all languages the prefix is what is used to trigger the snippet and the body will be expanded and inserted possible variables are 1 2 for tab stops 0 for the final cursor position and 1label 2another for placeholders placeholders with the same ids are connected example print to console scope javascripttypescript prefix log body consolelog1 2 description log output to console cdrl scope html prefix cdrl body 3 description insert href for cdrls fldr scope html prefix fldr body 1 t tt t description creates a new folder steps to reproduce 1 create a new text file and chose html as the language 2 type cdrl press tab snippet is displayed 3 press tab on 1st placeholder to select pdf 4 type 01 press tab to move to 3rd placeholder 5 type test1 and press tab then enter to go to new line 6 repeat steps 2 4 must enter a second tab to move to 3rd placeholder if you repeat this process again but use 02 instead of 01 it will work fine unless you have used 02 before this wasnt an issue in the may or june 2023 release but started during the july 2023 release i verified using the insiders version with no extentions loaded just to note i have folders named a001 a047 that have new files added monthly so i use this snippet often vs code version code insiders 1810insider 20230728t120804472z os version windowsnt x64 10019043 modes system info itemvalue cpusintelr coretm i73770 cpu 340ghz 8 x 3392 gpu status2dcanvas enabledonopengl enabledvideoencode unavailableoffvulkan disabledoffwebgl enabledwebgl2 unavailableoffwebgpu enabled load avgundefined memory system3192gb 2075gb free process argvcrashreporterid screen readerno vm0 extensions none ab experiments vsliv69530137379 vsins82930139715 vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 pythontb30258533 vshan82030294714 vscod80530301674 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230404738 py29gd226330784851 vsclangdf30492506 c4g4892830535728 dsvsc012cf30540253 pynewext5430618038 2i9eh26530646982 2436559830687740 fixshowwlkth30771523 i26e353130792625 gsofa30797620 pythonidxpt30768918 pythonnoceb30776497 e537b57730772214 h0f3276830792099 dsvsc01330777762 dsvsc01430777825 diffeditorv230786206"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nnot executing code\ntype bug please make it correct sometimes my c program is compiled and executed but sometimes it dont neither compiled and executed vs code version code 1802 20230727t204028909z os version windowsnt x64 10022621 modes system info itemvalue cpus12th gen intelr coretm i51240p 16 x 2112 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1571gb 813gb free process argvcrashreporterid screen readerno vm0 extensions 5 extensionauthor truncatedversion nodesnippetschr133 vscodeeslintdba242 coderunnerfor0120 ab experiments vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vswsl492cf30256860 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes263cf30335440 vscorecescf30445987 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 py29gd226330792226 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 2e4cg34230602488 8954411730613380 a9j8j15430646983 vsctsb30748421 03d3595930757346 pythoncmv30756943 fixshowwlkth30771522 i26e353130792625 pythonnoceb30797650 e537b57730795824 dsvsc01330795093 dsvsc01430797589"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCan we activate vs code extension through activation event by reading url from particular file\ndoes this issue occur when all extensions are disabled yesno report issue dialog can assist with this vs code version os version steps to reproduce 1 we a config file inside folder git 2 we need to read the url inside that file and activate the extension"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nClick on file tab shows folder of file\nhey guys good job but im missing the use case of the subject maybe on the pane git is open i continue to code and want to check other files of one active file so i would like to click on the tab of the file and then the filepane should open and the active folder is the one i clicked on maybe it makes sense to offer this feature as an option and to explain it with clicked the first time on it best robert"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTabs showing green line above them.\nproblemwithvscode does this issue occur when all extensions are disabled yesno this occurs regardless of whether all the extensions are disabled i dont think its an extension issue report issue dialog can assist with this vs code version 1801 os version 10022621 build 22621 microsoft windows 11 home steps to reproduce i dont know what caused it i just opened it today and it looked like this now"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMongoDB Atlas\ni plan to work on a project in github codespaces however i cannot find any good documentation on how to connect an expressjs application to mongodb atlas can anyone help version 1801 commit user agent mozilla50 macintosh intel mac os x 10157 applewebkit53736 khtml like gecko chrome114000 safari53736 embedder codespaces"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nprogram not running \ntype bug showing bellow erorr again and again undefined reference to winmain16 collect2exe error ld returned 1 exit status vs code version code 1801 20230712t172207651z os version windowsnt x64 10022621 modes system info itemvalue cpus12th gen intelr coretm i51240p 16 x 2112 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1571gb 713gb free process argvcrashreporterid screen readerno vm0 extensions 13 extensionauthor truncatedversion exerunnerbra021 dscodegptdan2114 coderunnerfor0120 pythonms2023120 jupyterkeymapms112 cmaketoolsms11434 cmaketwx0017 vscodelldbvad192 1 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vswsl49230256859 vstes62730244334 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscorecescf30445987 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdc30486549 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 282f872430602487 8954411730613380 vsctsb30748421 03d3595930757346 fixshowwlkth30771522 i26e353130792625 pythonidxpt30784022 pythonnoceb30776495 e537b57730786199 h0f3276830792100 dsvsc013cf30789518"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError comes node.jc file not found \ntype bug include isotream using namespace std int main count 5 2 endl return 0 i am a beginner i start code c and save this file with cpp format but when i got to run file error come nodejc not found vs code version code 1801 20230712t172207651z os version windowsnt x64 10019045 modes system info itemvalue cpusamd ryzen 7 3700x 8core processor 16 x 3593 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1595gb 825gb free process argvcrashreporterid screen readerno vm0 extensions 4 extensionauthor truncatedversion cmaketoolsms11434 cpptoolsms1163 cmaketwx0017 1 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vswsl492cf30256860 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vsdfh931cf30280410 vshan82030294714 vstes26330335439 vscorecescf30445987 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 py29gd226330792226 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vsccc30610678 3biah62630602489 pyind77930671433 8954411730613380 2i9eh26530646982 vsctsb30748421 pythonms3530701012 03d3595930757346 pythoncmv30756943 fixshowwlkth30771522 bgfeh91530780428 pythonidxpt30784022 e537b57730786199 dsvsc01330789517 dsvsc01430791935"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nimport pptx not working\ntype feature request why cant i install pptx on vscode to do my powerpoint presentations vs code version code 1801 20230712t172207651z os version windowsnt x64 10019045 modes"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nExplorer has disappeared and the shortcut key (Ctrl+Shift+E) in View menu is also gone\nexplorer has disappeared and the shortcut key ctrlshifte in view menu is also gone as shown below img width357 altimage src the context menu mouse right click of the activity bar also does not have the explorer option img width269 altimage src img width319 altimage src please advise how i can get the explorer back"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\njavascript, websocket\ntype bug hello how are you iam am programmer and i am having a issue what i cant solve on my own anymore its probably too offtopic and i still count good people helping a vegan out i logic to work with code excellent software no problems at all working on linux lite 64 ubuntu i do program a computer game browser based java backend and javascript frontend webgl for rendering right now iam writing the interface and having a issue with one of the fundamental functions of javascript hopefully you have some experience with websockets if not then i might have to ask google next usualy the payloadlength is calculated by the send method of the websocket object unfortunetily the byte representation of the payload length does never match the length of the submitted string you at microsoft are very smart people i like you alot and if you have some idea how to solve that i would very appreciate that for a experienced programmer the string is sent by the indexjs and received by the class transmissions building the websocket there before creating a seperate object for it everything else is working fine it is that project if my imagination work than thank you in advance bill kind regards indetale marcel otte vs code version code 1801 20230712t172225257z os version linux x64 515076generic modes system info itemvalue cpusintelr coretm i5 cpu m 460 253ghz 4 x 2534 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode disabledoffwebgl enabledwebgl2 enabledwebgpu disabledoff load avg0 1 1 memory system743gb 557gb free process argvcrashreporterid screen readerno vm0 desktopsessionxfce xdgsessiontypex11 extensions 2 extensionauthor truncatedversion javared1200 ab experiments vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscoreces30445986 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 py29gd2263cf30789497 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 2e4cg34230602488 pyind77930671433 8954411730613380 a9j8j15430646983 vsctsb30748421 pythonms3530701012 03d3595930757346 fixshowwlkth30771522 bgfeh91530780428 pythonidxpt30784022 pythonnoceb30776495 e537b57730786199 dsvsc013cf30789518"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTask definition does not work\ndoes this issue occur when all extensions are disabled yesno report issue dialog can assist with this vs code version os version steps to reproduce 1 2"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsetting \"workbench.editorAssociations\" not work\ntype bug i just installed office viewer plugin from market after setting ，“md”s first use plugin，it not work。 so i try to setting “md” to the original vscode preview，and it not work， everytime i open a markdown file，always open in raw editoreverything can not change that vs code version code 1800 20230704t150602407z os version windowsnt x64 10019045 modes system info itemvalue cpusamd ryzen 7 4800h with radeon graphics 16 x 2895 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1537gb 550gb free process argve笔记本officewordmd crashreporterid screen readerno vm44 extensions 39 extensionauthor truncatedversion bettercommentsaar302 shellbbe030 doxdocgencsc140 vscodeofficecwe316 gitlenseam1401 coderunnerfor0120 latexworkshopjam9123 kitekit01470 rainbowcsvmec370 csharpms1260 isortms2023101 pythonms2023120 jupyterkeymapms112 remotesshms01020 remotessheditms0860 remotewslms0802 cmaketoolsms11434 cpptoolsms1163 remoteexplorerms041 javared1200 vscodeyamlred1130 latexsupporttor3100 cmaketwx0017 vscodemavenvsc0410 1 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscorecescf30445987 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vsclangdc30486549 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vscccc30610679 282f872430602487 pyind77930671433 8954411730613380 2i9eh26530646982 vsctsb30748421 pythonms3530701012 fixshowwlkth30771522 bgfeh91530780428 pythonidxpt30784022 e537b57730786199"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFrequently closes itself\ntype performance issue im trying to build a website writing some html css files and it keeps on closing vs code version code 1800 20230704t150602407z os version windowsnt x64 10022621 modes system info itemvalue cpusintelr coretm i51035g1 cpu 100ghz 8 x 1190 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system778gb 254gb free process argvcrashreporterid screen readerno vm0 process info cpu mem mb pid process 0 94 7112 code main 0 27 1180 crashpadhandler 0 87 3564 window 2 issue reporter 0 160 8280 extensionhost 1 0 79 15124 electronnodejs vs codecodeexe vs nodeipc clientprocessid8280 0 124 10832 sharedprocess 0 182 13840 gpuprocess 0 76 14980 ptyhost 0 79 15196 filewatcher 1 0 193 15680 window 1 detecthtml untitled workspace visual studio code 0 43 16280 workspace info window detecthtml untitled workspace visual studio code folder newfolder 8 files file types py3 pyc2 ipynb1 txt1 conf files folder 13 files file types html8 ipynb1 js1 css1 conf files extensions 30 extensionauthor truncatedversion vscodedjangobat1100 djangohtmlbib130 doxdocgencsc140 vscodehtmlcssecm1131 coderunnerfor0120 gcexcelviewergra4257 vscodedockerms1252 isortms2023100 pythonms2023120 jupyterkeymapms112 remotesshms01020 remotessheditms0860 remotewslms0802 cmaketoolsms11434 cpptoolsms1163 remoteexplorerms041 liveserverrit579 cmaketwx0017 2 theme extensions excluded ab experiments vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vsdfh931cf30280410 vshan82030294714 vstes263cf30335440 vscoreces30445986 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 vscaat30438848 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 3biah62630602489 pyind77930671433 f6dab26930613381 vsctsb30748421 pythonms3530701012 03d3595930757346 57b7757930736110 pythoncmv30756943 f8hc823830694864 fixshowwlkth30771522 bgfeh91530780428 pythonidxpt30784022 h7j2d46530786200"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ni3wm vscode cannot open appimage formate browser like edge,chrome\nwhen i sync github vscode just have open browser but my system not have install browser i use appimage format browser i cannot load vscode sync or i install firefoxesr and it can not open too it always jump to new tab"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\npip can't be installed\ntype bug i cant able to install pip package in terminal i have tried several ways but failed vs code version code 1800 20230704t150602407z os version windowsnt x64 10022621 modes system info itemvalue cpusamd ryzen 5 5500u with radeon graphics 12 x 2096 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system733gb 142gb free process argvcrashreporterid screen readerno vm0 extensions 2 extensionauthor truncatedversion pythonms2023120 ab experiments vsliv368cf30146710 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscoreces30445986 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 py29gd2263cf30784848 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 282f872430602487 pyind77930671433 8954411730613380 2i9eh26530646982 vsctsb30748421 pythonms3530701012 a2ce337530757347 fixshowwlkth30771522 bgfeh91530780428 pythonidxpt30784022"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTS Server fatal error:  UNC host '172.25.30.27' access is not allowed\ntype bug please fill in the sections below to help us diagnose the issue typescript version 504 steps to reproduce crash 1 2 3 ts server log redexclamationmark server logging disabled to help us fix crashes like this please enable logging by setting json verbose after enabling this setting future crash reports will include the server log ts server error stack server semantic error errunchostnotallowed unc host 172253027 access is not allowed at objectwatchfile nodefs234214 at fswatchfileworker cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at pollingwatchfile cprogram filesmicrosoft vs at watchfile2 cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at fswatch cprogram filesmicrosoft vs at objectwatchfile2 as watchfile cprogram filesmicrosoft vs at watchfile cprogram filesmicrosoft vs at objectwatchfile cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at flatmap cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at updateopen cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at cprogram filesmicrosoft vs at process cprogram filesmicrosoft vs at processemit nodeevents51328 at emit at vs code version code 1782 20230510t143926248z os version windowsnt x64 10022621 modes sandboxed yes system info itemvalue cpus12th gen intelr coretm i71260p 16 x 2496 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system3170gb 950gb free process argvcrashreporterid screen readeryes vm0 extensions 10 extensionauthor truncatedversion iniforvscodedav004 vscodehtmlcssecm1131 inifmtlkr015 ncgcodeml20141 sqltoolsmtx0280 logboosternvi007 vscodexmlred0250 ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 py29gd226330773603 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 282f872430602487 pyind77930671433 8954411730613380 vsctsb30748421 pythonms3530701012 03d3595930757346 pythoncmv30756943 fixshowwlkth30771522 dh2dc71830770000 pythonidxpt30772539 pythonnoceb30773526 e537b57730772215"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n#include <cs50.h>\nadd issue description here version 1792 commit user agent mozilla50 windows nt 100 win64 x64 applewebkit53736 khtml like gecko chrome114000 safari53736 embedder codespaces"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntkinter\ntype feature request why is not defined tk vs code version code 1792 20230614t085704379z os version windowsnt x64 10019045 modes"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIntellisense font is incredibly small.\ndoes this issue occur when all extensions are disabled yes report issue dialog can assist with this vs code version 1792 os version fedora 38 638200fc38x8664 device framework laptop 2256x1504 steps to reproduce 1 open vscode 2 write some code such that vscode can provide a suggestion 3 press ctrl space to open intellisense 4 observe the intellisense font is incredibly small screenshot from 20230703 095240"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMy terminal is splitting a file name into seperated parts and then showing directory not found.\ntype bug say my file name is hello worldc when i run it on my terminal its showing gccexe error hello no such file or directory gccexe error worldc no such file or directory gccexe error world no such file or directory gccexe fatal error no input files compilation terminated what to do vs code version code 1792 20230614t085704379z os version windowsnt x64 10019045 modes system info itemvalue cpusintelr coretm i76500u cpu 250ghz 4 x 2592 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system789gb 160gb free process argvcrashreporterid screen readerno vm0 extensions 5 extensionauthor truncatedversion coderunnerfor0120 cmaketoolsms11434 cpptoolsms1163 cmaketwx0017 1 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vsdfh93130280409 vshan82030294714 vstes263cf30335440 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 py29gd226330776702 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vsccc30610678 2e4cg34230602488 pyind77930671433 f6dab26930613381 vsctsb30748421 pythonms3530701012 a2ce337530757347 ecj1e33230736112 fixshowwlkth30771522 bgfeh91530780428 e537b57730772215"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCommande \"./hello\" ne fonctionne pas\ngood morning i need support because when i type de commande hello the notification i receive is permission denied please help me"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd a method to switch between open windows\ndevelopers often need to keep multiple vs code windows open at the same time providing a method to switch between the open windows would be greatly useful the method can be a ui to show open windows eg like open editors a keyboard shortcut"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCant see terminal text\ndoes this issue occur when all extensions are disabled yesno report issue dialog can assist with this vs code version os version image what is happening its been a week haha ive tried all kinds of terminal but same issue image"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNeed a quick way to run or debug the last test I ran\ni often repeatedly run or debug a test as i work on it id like a quick way to run or debug the last test i ran ideally something i can assign to a single keystroke currently i have to find the tests first line in my code in the testing panel or in test results"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncan not run any code on vs code\ntype performance issue i am new to vs code and i can not run any of my code on vs code so please help me out as this is so irritating vs code version code 1792 universal 20230614t085852392z os version darwin arm64 2210 modes system info itemvalue cpusapple m1 8 x 24 gpu status2dcanvas enabledmetal enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avg1 2 2 memory system800gb 012gb free process argvcrashreporterid screen readerno vm0 process info cpu mem mb pid process 14 139 1960 code main 1 66 1963 gpuprocess 0 33 1965 0 246 1966 window 1 mainc — pythonnpy 0 49 1976 ptyhost 0 90 1977 sharedprocess 0 0 2021 binps ax o 0 49 1978 filewatcher 1 0 115 1979 extensionhost 1 0 25 1983 0 98 2014 window 2 issue reporter workspace info window mainc — pythonnpy folder pythonnpy 12 files file types json2 c1 plist1 python1 conf files launchjson1 tasksjson1 extensions 7 extensionauthor truncatedversion vscodehtmlcssecm1131 coderunnerfor0120 cmaketoolsms11433 cpptoolsms1163 liveserverrit579 cmaketwx0017 1 theme extensions excluded ab experiments vsliv368cf30146710 vsreu68530147344 python38330185418 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 py29gd226330776702 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 vscccc30610679 282f872430602487 pyind77930671433 8954411730613380 2i9eh26530646982 vsctsb30748421 pythonms3530701012 03d3595930757346 pythoncmv30756943 fixshowwlkth30771522 dh2dc71830776458 pythonidxpt30772539 pythonnoceb30776495"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nVSCode JS issue: JSDoc Intellisense behavior in array variables are weird after version 1.79.0+\ntype bug type a string b string let arr a abc b def intellisense not working here it works normally for the first element but start to show intellisense of array at reduce instead of normal behavior a b it works fine at version 1781 vs code version code 1792 20230614t085704379z os version windowsnt x64 10022621 modes system info itemvalue cpus12th gen intelr coretm i912900f 24 x 2419 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system3186gb 1680gb free process argvcrashreporterid screen readerno vm0 extensions 3 extensionauthor truncatedversion gitlenseam1401 gitgraphmhu1300 ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vsdfh93130280409 vshan82030294714 vstes26330335439 vscoreces30445986 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa593cf30376535 pythonvs93230410667 py29gd226330773603 vsclangdc30486549 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vscccc30610679 3biah62630602489 pyind77930671433 f6dab26930613381 a9j8j15430646983 vsctsb30748421 pythonms3530701012 a2ce337530757347 pythoncmv30756943 fixshowwlkth30771522 gsof230774497 dh2dc71830770000 pythonidxpt30772539"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIntellisense for MongoDB doesnt working!\ntype bug well i am working on project using mongodbatlas and i created regular model and controller for it it was working in modelbut when i started typing functions in controller it stopsalso i tried everything like updates for vsc extensions deleting models packages and restarting vsc still doesnt working please help me vs code version code 1792 20230614t085704379z os version windowsnt x64 10019045 modes"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd keyboard shortcut for \"Select Language Mode\"\nthe little thing in the bottomright corner where you can select language mode would be a useful candidate for adding a keyboard shortcut it doesnt even have to have a real shortcut by default but in my case i would find it very useful to have the ability to assign a shortcut to it heres an example workflow where it would come in handy i find myself doing this a lot and wish there were a way to add a shortcut 1 graph some code from somewhere a sql query from slack or a graphql query from the network tab or some yaml printed from a debug log and copypaste it into a new tab in vscode 2 vscode doesnt correctly figure out what language the code is in 3 go to the bottom right corner click the sometimes very small button to select language mode this is the part i want a keyboard shortcut for 4 select the correct language 5 hit altshiftf to format the code and youre done basically these steps allow you to take code from some random source where its probably unformatted and may not be syntaxhighlighted and allow you to format inspect it in vscode if step 3 above were able to be automated via a keyboard shortcut it would make this process quite a bit more ergonomic what do you think if theres already a way to do this im open to hearing it as of right now i open keyboard shortcuts and search for select language mode but nothing pops up so it appears that a new keyboard shortcut needs to be added"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProblem with VSC\nimg20230622205601 does this issue occur when all extensions are disabled yesno report issue dialog can assist with this vs code version os version steps to reproduce 1 hello i have a problem with vsc today i saw that when i write code in react plugins turn off i will not format the code well the program does not tell me the names of components when writing the code thank you in advance for your help 2 img20230622211443 img20230622205601"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRemoved keybinding not trigger global hotkey\ndoes this issue occur when all extensions are disabled yes report issue dialog can assist with this vs code version 1792 os version win 11 steps to reproduce 1 remove keybinding f1 image 2 press f1 to trigger my global screenshot hotkey snipaste app default hotkey but it is not work keyboard troubleshooting"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAddEventListener not calling function\ntype bug i am currently doing a tutorial with a game logic the game has buttons which are meant to call on specific functions however upon writing function function remains blank in color indictacting it has not been declared vs code version code 1792 20230614t085704379z os version windowsnt x64 10019045 modes system info itemvalue cpusintelr coretm i57200u cpu 250ghz 4 x 2712 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system785gb 359gb free process argvcrashreporterid screen readerno vm0 extensions 42 extensionauthor truncatedversion linkcheckmdbla031 gitignorecod090 vscodeeslintdba240 docsbuilddoc041 docsimagesdoc100 docslintingdoc0013 docsmarkdowndoc101 docsmetadatadoc109 docspreviewdoc102 docsyamldoc100 githistorydon0620 gitlenseam1401 autoclosetagfor0514 autorenametagfor0110 dotenvmik101 pythonms2023101 jupyterkeymapms112 cpptoolsms1154 vslivesharems105873 vscodeyamlred1130 liveserverrit579 easysassspo006 vscodeiconsvsc1240 quokkavscodewal10546 ab experiments vsliv368cf30146710 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vswsl492cf30256860 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdc30486549 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 282f872430602487 pyind77930671433 f6dab26930613381 vsctsb30748421 pythonms3530701012 03d3595930757346 pythoncmv30756943 fixshowwlkth30771522 bgfeh91530769767 dh2dc71830770000 pythonidxpt30772539"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nnpm start is not starting my react app again i dont know if i mistakenly delete something\ntype performance issue help me restore the deleted files on my project because npm start is not starting my application again vs code version code 1792 20230614t085704379z os version windowsnt x64 10019045 modes system info itemvalue cpusintelr pentiumr cpu n3710 160ghz 4 x 1600 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system385gb 065gb free process argvcrashreporterid screen readerno vm0 process info cpu mem mb pid process 3 82 2332 code main 0 30 7408 ptyhost 0 6 7232 consolewindowhost windows internal process 0 69 10352 noexit command try vs catch 0 3 7524 crashpadhandler 0 42 7600 sharedprocess 3 85 8300 window 4 issue reporter 0 115 9904 gpuprocess 0 61 10656 extensionhost 3 0 58 2584 electronnodejs vs codecodeexe maxoldspacesize3072 vs servermode partialsemantic cancellationpipename locale en usenodeipc 0 58 8936 electronnodejs vs codecodeexe vs nodeipc clientprocessid10656 0 104 12104 electronnodejs vs codecodeexe maxoldspacesize3072 vs enabletelemetry cancellationpipename locale en usenodeipc 0 39 10900 electronnodejs vs codecodeexe vs enabletelemetry typesmaplocation vs 0 12 12040 0 153 12620 window 3 homejsx arcjs workspace visual studio code 0 24 12948 filewatcher 3 workspace info window homejsx arcjs workspace visual studio code folder arcjs 131 files file types png23 css15 jpg15 jsx15 js7 json5 webp5 txt3 map3 ico2 conf files packagejson1 extensions 4 extensionauthor truncatedversion dartcodedar3660 flutterdar3660 ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vsdfh93130280409 vshan82030294714 vstes26330335439 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 vscccc30610679 282f872430602487 pyind77930671433 8954411730613380 a9j8j15430646983 vsctsb30748421 pythonms3530701012 03d3595930757346 fixhidewlkth30730051 e440d66430770001"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nLocalhost Error\ntype bug i am aways getting localhost refused to connect error on my laptop whenever i am trying to make a html file on vs code terminal to use java script vs code version code 1792 20230614t085704379z os version windowsnt x64 10019045 modes system info itemvalue cpusintelr coretm i75600u cpu 260ghz 4 x 2594 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system769gb 181gb free process argvcrashreporterid screen readerno vm0 extensions 11 extensionauthor truncatedversion dartcodedar3660 isortms2023911661018 pythonms2023101 jupyterkeymapms112 sqltoolsmtx0271 1 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vslsvsres30330308271 vserr24230382549 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscod80530301674 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc012cf30540253 pynewext5430695312 282f872430602487 pyind77930671433 8954411730613380 a9j8j15430646983 vsctsb30748421 pythonms3530701012 a2ce337530757347 pythoncmv30756943 fixhidewlkth30730051 dh2dc71830770000"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nEu quero setar o arquivo a ser executado quando clicar em play.\nimage"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbug -- File Saving Error\ndoes this issue occur when all extensions are disabled yesno report issue dialog can assist with this vs code version 1791 universal os version macos steps to reproduce 1 save the file 2 get error img width447 altscreenshot 20230615 at 8 20 29 am src"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMarkdown preview doesn't work\ntype bug step 1 try to open any md file step 2 try to show markdown preview by any of the available command result markdown preview doesnt work expected result markdown preview should according to vscode work out of the box things i tried apart from trying to use default set of commands i found on the vscode documentation and on the internet i tried reinstalling various third party extension for markdown preview i restarted vscode itself and my pc as well vs code version code 1791 20230612t161405102z os version windowsnt x64 10019045 modes system info itemvalue cpusamd ryzen 5 4600h with radeon graphics 12 x 2994 gpu status2dcanvas enabledonopengl enabledrawdraw enabledvideoencode enabledvulkan disabledoffwebgl enabledwebgl2 enabledwebgpu enabled load avgundefined memory system1536gb 1063gb free process argvcrashreporterid screen readerno vm0 extensions 85 extensionauthor truncatedversion vscodesqliteale0141 tailwinddocsaus200 vscodedjangobat1100 doxdocgencsc140 dartcodedar3660 flutterdar3660 vscodeeslintdba240 gitlenseam1400 vscodehtmlcssecm1131 copilotgit189156 gcexcelviewergra4257 ionicion1454 ionidefsharpion754 wslpathkgr010 magicpythonmag110 documentmin221 vscodedockerms1251 csharpms1259 isortms202280 pythonms2023101 jupyterkeymapms112 remotesshms01020 remotessheditms0860 remotewslms0795 cmaketoolsms11433 cpptoolsms1154 liveserverms048 powershellms202360 remoteexplorerms040 remoteserverms121 vslivesharems105873 sqltoolsmtx0271 autodocstringnjp061 gccmdpha001 sqliteviewerqwt025 rdebuggerrde054 liveserverrit579 nodepackswe0116 vscodedjaneirothe142 pdftom122 cmaketwx0017 jinjawho008 vuewsc1026 phpdebugxde1321 vueznc0120 3 theme extensions excluded ab experiments vsliv36830146709 vsreu68530147344 python383cf30185419 vspor87930202332 vspor70830202333 vspor36330204092 vstes62730244334 vslsvsres30330308271 vserr242cf30382550 pythontb30283811 vsjup51830340749 vshan82030294714 vstes26330335439 vscod805cf30301675 binariesv61530325510 bridge070830335490 bridge072330353136 vsaa59330376534 pythonvs93230410667 vsclangdf30486550 c4g4892830535728 dsvsc01230540252 pynewext5430695312 282f872430602487 pyind77930671433 f6dab26930613381 vsctsb30748421 pythonms3530701012 a2ce337530757347 fixshowwlkth30730052 dh2dc71830763024"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n#F\n"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n#F\n"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\na native token protocol\nplease describe the feature youd like to see added a native token protocol can be implemented on btc a utxobased blockchain structure with a native token method which i call dye coins 1 the transaction output class needs to add a new field called color 2 the block header needs to add a new field called color 3 the validation of ordinary transactions needs to add additional validation logic 4 the validation of coinbase transactions needs to add additional validation logic 5 the validation of blocks needs to add new validation logic specific logic is as follows 1 after the transaction output has the color tag field there are only two results 0 all 0 indicates not marked non0 indicates marked 2 to verify that a normal transaction noncoinbase is valid additional validation logic needs to be added specifically it means that the input and output of all transactions must be traversed to ensure that the output values of all colors are less than or equal to the input values of the corresponding colors 3 miners need to verify that all or some of the normal transactions in the transaction pool that need to be packaged meet 2 and calculate the difference between all the corresponding colors in all these transactions as utxo can be single or multiple added to the coinbase output 4 a coinbase transaction is a special transaction that essentially has no input and only output in addition to the utxo generated by the block miner fee the coinbase transaction itself has a certain number of native token rewards 5 the structure of a coinbase transaction that does not participate in color marking is as follows assuming that the current block reward is 50 white coins and the transaction output generated by the miner fee contains 10 red coins 10 green coins and 10 white coins when constructing a coinbase transaction 3 red coin outputs 3 red coin outputs total 10 can be output 2 green coin outputs 2 green coin outputs total 10 and 1 white coin output output quantity is equal to 60 6 the structure of a coinbase transaction that participates in color marking is as follows assuming that the current block reward is 50 white coins and the transaction output generated by the miner fee contains 10 red coins 10 green coins and 10 white coins when constructing a coinbase transaction 3 red coin outputs 3 red coin outputs total 10 can be output 2 green coin outputs 2 green coin outputs total 10 and the remaining 60 white coins will be dyed yellow as a single output or multiple outputs however 60 white coins cannot be dyed yellow 30 blue and white coins can only be dyed the same color and a color that has not appeared before how to determine if the color exists will be mentioned later otherwise the transaction will fail 7 next the miner will pack all the transactions to generate the merkle tree and assign the color value of the dye in the coinbase transaction to the color field in the block header and then start proof of work to generate the block 8 after the miner generates the block it will broadcast the block to the entire network 9 other miners will verify the validity of the block this includes verifying the validity of each transaction especially the coinbase transaction it must be ensured that the only color that can be dyed in the coinbase transaction is one color not that there is only one color of output and that this color has never appeared before it can be obtained by traversing all the block headers or caching all the colors locally otherwise the transaction will fail if there is no dyeing meaning that the output of the coinbase transaction does not produce a new color utxo and the number of utxo tokens of other colors does not increase the traversal process can be skipped 10 verify whether the color value in the block header 0 if no dyeing is equal to the new color value in the coinbase transaction if equal the block is valid the block is added to the blockchain and the next block is mined if not equal the block is invalid and the block is rejected 11 note there is no inflation problem here because inflation can be achieved simply by adding one more color utxo for example green and red are marked as us dollars if interested pls contact me is your feature related to a problem if so please describe it no response describe the solution youd like no response describe any alternatives youve considered no response please leave any additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd Bech32.cpp LocateErrors case to check for minimum length.\nplease describe the feature youd like to see added add a bech32 string too short case to bech32cpp locateerrors to reduce ambiguity and collisions with invalid separator position case is your feature related to a problem if so please describe it error representation when calling locateerrors within is ambiguous and incorrect in some cases because of a missing bech32 string to short case not having a too short case causes a fall though into the conditions of invalid separator position missing separator describe the solution youd like simply add a check for a minimum bech32 string size after or during the check for the maximum size which is already implemented cascading effects of this would be seen in decodedestination if was patched to not consider bech32 invalid then attempt to base58decode it becuase of the incorrect hrp for the current chain referenced in pr describe any alternatives youve considered you could case this into other logic on a case by case basis in code example make a speical case inside decodedestination to display the correct error message to the user by if locateerrors returns invalid separator position missing separator then you check to see if the string is to short please leave any additional context as an aside there is already a check for string length greater than 90 max len in both 10a06t81qzzfhee produce invalid separator position 0 the former is non conformant to bip173 due not even having enough chars to represent a base32 string and the second genuinely has a wrong separator position"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd maxrelaytxfee\nplease describe the feature youd like to see added just an example this feature request is not related to mutinynet in any way lets suppose the miner wants to recycle coins and shrink the total number of utxos by making an allfee transaction and eventually mining it any other miner would be happy to mine such a transaction if it is relayed to the network is your feature related to a problem if so please describe it no response describe the solution youd like add maxrelaytxfee parameter similar to its min equivalent which is present at least since 9d14e689c8 later it became a configurable the value could be in percentage of the amount sent an absolute number like the other similar configurables use may be less helpful here when tho point is to stop broadcasting mostly allfee transactions describe any alternatives youve considered the usual way how utxos work is that they retain their full history back to the block from whose coinbase they come please leave any additional context in case of largescale recycling maybe the chainstate can get back below 6 gib at the moment it is 63 gib big also the ordinals theory may require some rethinking"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nchange wording\nplease describe the feature youd like to see added if you have chosen to limit block chain storage pruning the historical data must still be downloaded and processed but will be deleted afterward to keep your disk usage low change to if you have chosen to limit block chain storage pruning the historical data will be downloaded processed and deleted to keep your disk usage low is your feature related to a problem if so please describe it no response describe the solution youd like no response describe any alternatives youve considered no response please leave any additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUse semantic analysis in lint-logs.py\nplease describe the feature youd like to see added currently testlintlintlogspy tries to parse the c manually which is prone to flaws for example it does not support expressions that span more than one line and would be happy if there is n anywhere on the single line it checks for example cpp bclogleveldebug this is fine but lintlogspy will report errorn cpp bclogleveldebug not okn but will be reported as ok cpp bclogleveldebug even more continued no newline but is ok cpp logprintlevel inside comment causes an error is your feature related to a problem if so please describe it lintlogspy requires to either write everything on line line or add continued comment describe the solution youd like it should be possible to use libclang to properly parse the c code then the check should be something like for each call to logprintlevel get the third argument it should be a string its last two chars should be and n describe any alternatives youve considered no response please leave any additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOption to prevent sleep\nplease describe the feature youd like to see added there should be option to start core which enable system to sleep only when net act is disabled is your feature related to a problem if so please describe it no response describe the solution youd like to notify the system that your application is busy use the describe any alternatives youve considered constant disk activity about 5 mbsec occasionally it may drop to a smaller value but in general this 50 mbsec activity continues for very long periods of time creating a customized power plan is also not option because that would affect system even when core is not running more hours would be better and best of all would be if you can run your node continuously please leave any additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrpc: Allow importing wallets by data instead of by filename\nplease describe the feature youd like to see added right now we can only import wallets by filename this means you can only execute that rpc if you are executing it from the system where the bitcoin node is running but it could be that you are sending the rpc request from outside the node in that case you dont have access to the file system so it would be handy to allow passing the content of a wallet dump file instead and also allowing dumping the content not in a file but in the rpc result it might be a good idea to check for other cases where the same is being done"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nConsider Removing Message Signing\nsigning arbitrary messages with bitcoin private keys was always a bit strange it was designed to handle only the narrow case of singlesig keys and isnt welldefined for new address types worse it doesnt allow for signing messages with more arbitrary scripts and its not clear what the semantics for such things would be sadly the message signing feature is now being abused to verify wallets as a part of withdraw flows this prevents bitcoin users from using anything but an incredibly narrow set of scripts in many cases only p2pkh not even modern script formats and definitely not multisig rather than trying to rework it to avoid these things breaking bitcoin it seems like itd be much better to simply remove the message signing logic entirely if someone comes along with a proposal that considers a broader set of scripts and a more sensible design that could be considered"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMillisecond log timestamp (option)\nplease describe the feature youd like to see added for some events like two blocks at the same height being announced by multiple peers at the same time its nice to have millisecond precision on the log entries is your feature related to a problem if so please describe it eg one of the forkmonitor nodes saw two blocks at height 782129 within the same second other nodes saw those blocks in the opposite order describe the solution youd like something like which would second by default with millisecond as an option log entries would look like 20230322t155329z describe any alternatives youve considered a more fancy solution would allow a custom date formatter please leave any additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFeature request: alert PR author in case of CI failure\nwould be nice to have a means of quickly getting alerted about the ci failing on a pr you authored its a bit cumbersome to keep an eye out on it manually and a freshly created pr typically gets more eyes on it so having it in failing state is a bit of a waste of everyones time creating this issue after brief irc discussion i think the main requirements are be able to opt out or easily ignorehide only get a single notification per run not for every single job failing lowtouch easy to maintain some potential approaches i see 1 use github actions as recommended by cirrus ci documention eg heres a sample email workflow can we get this to work so the pr author is notified 2 use bitcoingit irc bot to dm the nickname that corresponds to the pr authors github nickname people with a different username on irc and github would not get notifications to optout i think users could simply use ignore bitcoingit 3 use drahtbot to tag the author as assignee when ci fails and remove them as assignee upon force push havent come up with an elegant way for people to optout of this but arguably its also the least intrusive option and eg could be filtered on the mailbox level"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd support for sighash flags in PSBT (like SINGLE|ANYONECANPAY)\nis your feature request related to a problem please describe when using bitcoin cores gui to sign a psbt that has a utxo with it throws following error specified sighash value does not match value stored in psbt describe the solution youd like id like it to successfully sign psbts containing describe alternatives youve considered the current nonidea workaround is to use the console window as described here additional context example psbt taken from"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfeature: lock inscriptions automatically\nbitcoin core is used a lot for inscriptions but they could be spent accidentally so lets freeze it we could not do it in past but meshcollider helped fix it in lets lock inscriptions with by default it to help users"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndecodescript could infer miniscript from given script in \"segwit\" context\ni was playing around with a probablytoocute script for ln channel smart contract and was looking for something to decide for me if miniscript can infer the structure of the script fe decodescript asm opsize 32 opequalverify ophash160 opequalverify opchecksigverify 1 desc type nonstandard p2sh segwit asm 0 desc hex address type witnessv0scripthash p2shsegwit since its evaluated at top level for desc it cannot get any meaningful structure from it perhaps in segwit it could try infering the miniscript in the segwit context"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nExpose addrman size info via RPC \nif 26847 gets merged addrman will maintain counts of addresses stored on the new tried tables broken down by network this is useful information for monitoring the state of our addrman when we run it with different network configs on mainnet currently when running a node we can get a rough estimate into this information using the cli argument addrinfo however this is just an estimate because it uses the rpc endpoint getnodeaddresses which calls through to addrmangetaddr although this logic path skips the addr caching logic we apply for results propagated to the p2p network it still applies some logic to filter results for example it removes addresses that meet the isterrible attributes it also doesn’t distinguish between the new and tried tables so i recommend we expose the raw counts to provide a better picture of addrman’s workings especially since addrman network integrations are particularly hard to test via our automated tooling we can breakdown the counts by network new vs tried there are a few different options for how we can expose this information i expect this feature to primarily be used by bitcoin core contributors or superusers that understand bitcoind’s inner workings thus i suggest we expose it as a new hidden rpc that enables exposing the information to devs without having to guarantee a stable rpc interface over future versions the name of the rpc can be something generic like addrmaninfo to allow for future extensions for other debugging information for more historic context around bitcoin cli’s addrinfo and conversation about cli vs rpc see 21595 if we do end up implementing a new rpc endpoint we could consider reworking the cli to use these values directly rather than trying to compute them with partial information"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPathing Guide for Installation using macOS\nis your feature request related to a problem please describe yes one common problem with software setups is the pathing is corrupted proper pathing is one of the most important parts of getting started with any new software because if the path is depreciated the software will not properly run this is the problem i am currently working on with bitcoin i downloaded the software but am unable to interact with the network in bitcoincli getblocktemplate rules segwit out zsh command not found bitcoincli describe the solution youd like ideally there would be clear instructions on how to install and get started using bitcoin software that did not require extensive knowledge of software systems architecture and pathing a great installation method would automatically install the software along the right path to prevent the pathing problem a generalized solution would be really good providing a clear guide to solving the pathing problem on any machine describe alternatives youve considered ive researched solving the problem in the bitcoin forum and on stackoverflow however because this common problem is so unique to each local machine a clear or generalized solution is hard to develop one specific solution i tried from my research was to add additional context to the command in curl user username databinary jsonrpc 10 id curltest method getblocktemplate params rules segwit h contenttype textplain out curl 7 failed to connect to 127001 port 8332 connection refused however the command resulted in a connection refusal i found a possible solution in the bitcoin forum but the problem with the proposed solution is that there is no bitcoinconf file in the main bitcoin repository i found a config folder in the src directory but there is no bitcoinconf file additional context i am running on macos thank you in advance for your attention and advice"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nErlay status in getpeerinfo\nwhen running with txreconciliation added in 23443 but off by default and hidden under helpdebug its currently rather tedious to see which of your peers have this enabled it basically involves loooking at the p2p log it would be nice to have erlay status under getpeerinfo"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nInclude estimated time to synchronize blockchain in bitcoind\nis your feature request related to a problem please describe no describe the solution youd like currently the estimated time to synchronize to the bitcoin blockchain is only shown in the qt gui it would be useful to display the estimated remaining time to synchronize to the blockchain via the bitcoin daemons logs as well describe alternatives youve considered display estimated time in the bitcoin daemon synchronizing logs"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsetminrelayfee\ni think this is something within my ability to add is your feature request related to a problem please describe the ability to change minrelaytxfee without restarting describe the solution youd like i would like the ability to set the relayfee by a bitcoincli rpc call setminrelayfee amount set the transaction fee rate in btckvb for this wallet overrides the global setminrelayfee config parameter can be deactivated by passing 0 as the fee in that case automatic default min fee will be used arguments 1 amount numeric or string required the transaction fee rate in btckvb result truefalse boolean returns true if successful examples bitcoincli setminrelayfee 000001 curl user myusername databinary jsonrpc 10 id curltest method setminrelayfee params 000001 h contenttype textplain describe alternatives youve considered additional context i encountered this while hooking up a lightning network node my relay fee was too high from bad conf settings and was blocking funding transactions i wasnt able to change this value and had to restart bitcoind instead of just making an rpc call"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndumpprivkey doesn't work in descriptor wallet\nin a descriptor wallet it returns this type of wallet does not support this command instead of the private key even though the wallet doesnt store the key directly it obviously knows how to build it since it can spend the funds so it should do that and return it there are just too many cases where a private key needs to be dumped and it shouldnt be a nightmare of rpc calls and 3rd party scripts to try to get it that just doesnt make sense usabilitywise just a common case point for us for example we still use p2shsegwit for our users since too many places still dont support bech32 and pretty regularly people still send ltc to our btc addresses smh i know and we need to easily be able to dump the key to recover it for them"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrpc: `listunspent` doesn't return immature coinbase outputs\nis your feature request related to a problem please describe i need to know all the utxos i have in my wallet including the immature ones when using listunspent the immature coinbases are not returned ❯ bitcoincli listtransactions address category immature amount 5000000000 label vout 0 confirmations 1 generated true blockhash blockheight 102 blockindex 0 blocktime 1658995253 txid walletconflicts time 1658995253 timereceived 1658995253 bip125replaceable no ❯ bitcoincli listunspent describe the solution youd like what do you think of adding a default to false parameter to listunspent if you think itd be useful i can start working on this myself describe alternatives youve considered at the moment im calling listtransaction and adding to the utxo list every immature output i see this works just fine but having the includeimmature parameter would make the code a bit cleaner and it would save one rpc call"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd EnsureWalletIsUnlocked to rescanblockchain RPC?\nit seems that it would otherwise silently skip the rescan for prebackup used keys that are still waiting to be generated into the keypool see also 11249"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProgress for opening wallet\nwhile there is progress for importing private keys and rescanning there is good reason to also add progress for wallet opening now you need to look into debuglog and trace it for progress so adding a progress bar for opening wallet it is rescan in the end would be a very nice feature"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAllow groups of accounts to access the RPC cookie file\ncontext i have multiple accounts on the same box that need to run clients of bitcoind in particular its lnd and electrs bitcoind itself runs in a separate account i have other accounts that i dont want to have access to bitcoin eg grafana graphscharts web ui so the cookie file can be shared amount the relevant accounts via a group on the file system a group read permissions can be set on each file i call the group bitcoinclients i setup a directory where new files will inherit the bitcoinclients group and will be created with the urwgro permission this means bticoin account can write the file bitcoinclinets group can read it and no one else has access is your feature request related to a problem please describe the problem is that when bitcoind is restarted it drops the group read permission on the cookie file so clients in other unix accounts cant read the file describe the solution youd like there should be a config that allows controlling permissions of the cookie file just a boolean that sets the read permissions on the group would be sufficient describe alternatives youve considered i setup a chronos workaround but i bet more people will have to reinvent this wheel as the cookie file gets wider adoption additional context cookie file has more security over userpassword auth userpassword auth is being deprecated in favor of the cookie file"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ngettransaction does not contain the field \"abandoned\" for abandoned receiving tx\nin specter a user can abandon an receiving tx that was evicted from the mempool for example because it was double spent the tx is marked via abandontransaction as abandoned in bitcoin core however gettransaction and listtransactions do not return the field abandoned even though this is visible in the gui image consequence specter cannot get the abandoned information from bitcoin rpc and will fetch the abandoned tx back again via listtransactions after it was deleted in specter describe the solution youd like always return the abandoned field in and not only in this special case that should then automatically solve gettransaction via describe alternatives youve considered if specter cant get the information about abandoned tx from bitcoin it would have to keep an internal list that is possible but redundant and can lead to many edge cases steps to reproduce wallet a send 1 btc to wallet b rbf wallet a replace tx with rbf to send all funds to wallet a wallet b abandon tx because no longer in mempool wallet b gettransaction will not show the abandoned field"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nExport a watch wallet only (with descriptors and without private keys) for an air gap setup\nis your feature request related to a problem please describe for long time ive seen users looking for a way to do an air gap setup with bitcoin core since there were no easy way people tend to go with other solutions such as armory electrum which offers an easy and friendly way to do it since bitcoin core v 220 and with the command listdescriptors it can be done easily offline pc create a wallet with descriptorstrue export descriptors with listdescriptors online pc create a wallet without privatekeys descriptorstrue and importdescriptors to have a functional watch only wallet for receiving funds and create unsigned transactions describe the solution youd like instead of creating two wallets one offline and a watch only and manually have to exportimport descriptors the wallet containing the private keys could offer an option like exportwatchonly that would generate a watchwalletdat without private keys and all descriptors already imported making very easy and user friendly the process to create an air gap setup"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCI, tracing: run tracepoint interface tests in the CI\nthe first tracepoint tests were merged in 24358 however they are skipped in the ci ive already done some experiments running them in the ci in however i havent been successful with it yet the main issue was the limited capabilities inside the cirrusci docker container an option would be to ask cirrusci for help another would be to run this part in a vm if its not to much overhead"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nEnable consistency checks by default with `--enable-debug`\nnow that most consistency checks have been made a runtime option instead of configure option see commit it could make sense to enable them on enabledebug otherwise they are only run when explicitly passed the runtime setting"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIsStandard should check the witnessprogram is a valid point on the field\nis your feature request related to a problem please describe a v1 taproot witness program must be a valid point on secp256k1 otherwise it is essentially a black hole describe the solution youd like add a check in isstandard that will check the witnessprogram in the case where witnessv1 is returned if the witness program is not the x value of a valid point return false"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nedit src/index/base.cpp\nis your feature request related to a problem please describe txindex sync message will print more than exactly twice a minute because currenttime and lastlogtime are in seconds it jitters by one second describe the solution youd like change with makes the message appear twice exactly a minute0 in for consistency probably as well in among others but im not interested in analyzing implications of changing that line 174 describe alternatives youve considered i suppose theres a way to change this by using millisec resolution in these time variables additional context thanks 0"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCI testing with minimum supported versions\nit would be nice if we could get a ci that always tests our minimum supported versions maybe we can use guix for it"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFeature request: automatically upgrade legacy to HD wallet\nsince bitcoin core 017 the startup option upgradewallet has been available allowing users to upgrade old legacy wallets to hd wallets however many users with nonhd wallets are yet to upgrade their wallet to reduce complexity and or various issues related to nonhd wallets i am wondering if it may be a good idea to require users to upgrade two different ways of implementing this off the top of my head when all addresses in a keypool are marked used automatically upgrade wallet and notify user to make a backup on startup upgrade wallet and notify user to make a backup are there any reasons for why bitcoin core doesnt already do this"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[RPC] Removal of signmessage and verifymessage\nthose two features are present for a long in bitcoin core but has been scarcely used over the years however this is going to change with aopp who directly link at this code in the protocols implementation"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProof of Advanced Delegation\nif we remove the consensus protocol blockchain and mining what do we get were left with what satoshi nakamoto had before he added the consensus protocol no blockchain no mining just the transaction history with nothing to protect it from double spend attacks here i present what i call proof of advanced delegation pad pad eliminates double spends by spending them in advance when an output is created the transaction that spends it is created too and its txid is embedded in the output before it gets published the output of the last transaction is not yet spent so it remains unpublished beginning with an arbitrary transaction in the ledger a its output is a1 the unpublished transaction that spends it is b and its output is b1 to make a payment the sender 1 creates a new transaction c that splits b1 between two new outputs c1 payment and c2 change 2 generates the txid of c and embeds it in b1 3 creates another transaction e that spends c2 and embeds its txid in c2 4 publishes transactions b advanced delegation 5 sends transaction c with sigs to the receiver in secret the receiver then 1 sees transaction b on the network which validates and binds it to transaction c 2 creates two new transactions of his own d and f d spends c1 and f spends d1 3 publishes c and d as a pair and saves f until hes ready to spend it since every published output is bound to the txid of the unpublished transaction that spends it there is no opportunity to double spend them therefore no consensus mechanism is required"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfuzz: prototype for cross-language differential fuzzing\nsince differential fuzzing is strongest when different programming languages are involved i’d like to fuzz cpp code against python code solution use sockets to establish a tcp clientserver connection server a python file which listens and accepts client communications from the fuzz target performs the required operations in python and sends back the computed python output as a response back to the client client a fuzzing harness which can send requests to the python server to perform certain operations receives python output computed in the server file and compares cpp output with the python output to see if they match since this requires a slight architectural change in the fuzzing harness to allow python subprocesses i’d like to know if this solution is acceptable additional context i’ve implemented a prototype which performs crosslanguage differential fuzzing of chacha20 on this branch and would love to hear opinionsfeedback on how to proceed test instructions 1 start server python3 srctestfuzzscriptpy 2 run the fuzz test srctestfuzzfuzz"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nadd ability to remove (dust) UTXOs\nis your feature request related to a problem please describe problem i have a lot of 0 sat utxos after flooding the testnet lol describe the solution youd like an rpc call to remove utxos for example bitcoincli removeutxos with an argument to remove everything with less than the specified amount describe alternatives youve considered making a new wallet sending coins from the old one to the new one remove the old wallet additional context"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nImprove Test Framework Time With Run Order Directive\nif you could leave a directive in one of the commits in your tree eg runpriority featureblahpy and we could use that to instruct the ci to run that test first that would be pretty helpful in speeding up ci if theres a particular eg new or impacted test that should see failures before others it wont help with passing but it could help with fail fast"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nallow positional and named arguments in `bitcoin-cli`\nis your feature request related to a problem please describe bitcoincli sendtoaddress 01 true false 0 unset true 1 true or bitcoincli named sendtoaddress amount01 verbosetrue describe the solution youd like bitcoincli sendtoaddress 01 verbosetrue add the ability to use positional and named arguments in one rpc call"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMake rescans faster\nthis issue aggregates ideas for making wallet rescans substantially faster using compact block filters when available could substantially speed up wallet rescans although it is not clear to me how this might work for nondescriptorbased legacy wallets currently 20664 proposes to add an rpc that will use compact block filters to scan for blocks relevant to a given script descriptor this gives a listing of blocks that correspond to the descriptor but the user then has to do something with that list of blocks to find transactions relevant to their wallet it would be nice to integrate scanblocks use of block filters opaquely into rescanblockchain wallet rescanning so that if block filters are available the faster method of consulting them could be used instead of scanning the entire chain or forcing the user to do something more roundabout with the output of scanblocks from sipa regarding faster rescanning i think there is some lowerhanging fruit like a rescanning all wallets at startup in parallel rather than one by one and b building a set of scriptpubkeys to look for and using that for legacy wallet rescanning instead of calling ismine for each especially with achow101s migratetodescriptor code i think there should be a way of computing that set for legacy wallets too possible changes integrate compact block filter usage into rescanblockchain to allow faster rescans when the compact block index is available otherwise falling back to the standard scanning method a first approach could possibly use filters only when dealing with a nonlegacy descriptor wallet currently proposed in allow pruned nodes with the block filter index to rescan quickly by getting a list of relevant blocks to the wallet requesting the download of blocks and then parsing the blocks for relevant transactions rescanning all wallets at startup in parallel instead of onebyone building a set of scriptpubkeys to look for when using a legacy wallet based on achow101s migratetodescriptor code"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nadd benchmark to test large scale of hardware\nim not sure if there are any benchmarks that could be easily used to test large scale of hardware wrt type of bottleneck cpussd bound i recall i saw something on twitter mentioned by sipa but not sure now what it was about benching cpus rams and ssds is my daily job and ive been wanting to have some bitcoin related benchmarks in my suite last month i was rebenching 14 cpus and i wish i had relevant data on their performance in bitcoin software it would be best if we could have such benchmarks as part of and so we could bench all kind of hardware and different versions of bitcoin core with single command that way we could have a lot of open data which im sure could be useful to development"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntracing: include tracepoints in GUIX builds\nthere has been light conceptual agreement on including the usdt based tracepoints in bitcoin core release builds this for example enables user to hook into production deployments if they need to binaries dont have to be switched out this is possible because we dont do expensive computations only for the tracepoints and the tracepoints are nops when not used there is a slight chance that the guix build on the current master already includes the tracepoints i have not done an guix build on a branch with the tracepoints merged yet this can be tested on a bitcoind binary using one of the methods mentioned in the tracing documentation section listing avaliable tracepoints if not present making the systemtap headers syssdth available during the guix build should build bitcoind with the tracepoints"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReturn fee in `getrawtransaction`\nsimilar to how the fee is returned in getblock 18771 it should be returned in getrawtransaction useful skills understanding of undo data the rpc interface and the functional tests want to work on this issue for guidance on contributing please read contributingmd before opening your pull request"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRPC: support fee bumping with external inputs\nexternal inputs are currently only supported for initial transaction creation functions extend solvingdata arguments as necessary to support fee bumping wallet transactions with nonwallet inputs"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOther platform support for Linux syscall sandboxing\nnow that 20487 is merged it would be nice if syscall sandboxing was extended to the other linux platforms that have release binaries as well x x8664linuxgnu armlinuxgnueabihf aarch64linuxgnu riscv64linuxgnu powerpc64linuxgnu powerpc64lelinuxgnu"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPlumb \"too-long-mempool-chain\" to RPC error for send/sendtoaddress\nis your feature request related to a problem please describe if coin selection fails as part of send or sendtoaddress the error message returned to the rpc client is insufficient funds even if the actual cause is due to toolongmempoolchain this is likely to alarm users unnecessarily as they will believe this means their funds have permanently vanished rather than being temporarily inaccessible describe the solution youd like if coin selection fails due to toolongmempoolchain the send and sendtoaddress methods should pass that error back to the rpc client instead of insufficient funds describe alternatives youve considered it would be even nicer from a ux standpoint if the limit on mempool chain length were removed but aiui thats a dos vector so is not going to happen additional context apparently this is already done for sendrawtransaction the discussion in is relevant it appears that the pr was withdrawn for reasons unrelated to my request"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAuto-generate MSVC version information\nright now bumping the version involves updating the version in two places configureac in multiple places—see for example commit i think it should be doable to parse the information from configureac in msvcautogenpy so that this is no longer something errorprone that has to be done manually if you do this also update the release process useful skills python msvc want to work on this issue for guidance on contributing please read contributingmd before opening your pull request"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfuzz: Invoking python interpreter from a C++ file\nim interested in reimplementing a python version of the new aead and fuzzing it against the c implementation however since it involves invoking a python interpreter from inside a c file im confused on how to proceed possible approaches 1 using pipes to call the python script from the c file 2 using pybind11 to create the python c interface idea from this pr however the python to c code for the aead wouldnt be very readable here would method 1 be ok id love to hear your thoughts on how to proceed"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrpc: Add level 3 verbosity to getblock RPC call (#21245 modified)\nauthor of 21245 expressed time issues in the original pr given that 21245 has received a lot of review i have decided to open this new pull request with modifications required to get ack from lukejr and a few nits of mine original pr description display the prevout in transaction inputs when calling getblock level 3 verbosity this pr affects the existing restblock api by adding a prevout fields to tx inputs this is mentioned in the change to the release notes i added some functional tests that checks that the rpc call still works when txundo cant be found doesnt display the value or scriptpubkey of the previous output when at a lower verbosity level this completes the issue 18771 possible improvements i can include even this commit to this pr if deemed useful or i can leave it for a followup pr see for more context examples examples of the getblock output with various verbose levels note that contains only 2 transactions see verbose level 0 bash bitcoincli testnet getblock 0 verbose level 1 bash bitcoincli testnet getblock 1 verbose level 2 bash bitcoincli testnet getblock 2 verbose level 3 bash bitcoincli testnet getblock 3 rest bash curl h contenttypetextplain and my everyday obsessive checking of my email inbox whether the pr moves forward edit laanwj removed at symbol from message and large example output to prevent it from all ending up in the commit message"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrpc/wallet: add simulaterawtransaction RPC\nnote this was originally titled add rpc this command iterates over the inputs and outputs of the given transactions and tallies up the balance change for the given wallet this can be useful eg when verifying that a coin join like transaction doesnt contain unexpected inputs that the wallet will then sign for unintentionally i originally proposed this to elements and it was suggested that i propose this upstream there is an alternative 22776 to instead add this info to getbalances when providing an optional transaction as argument"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfuzz: investigate test adequacy (unit and fuzz) via mutation testing\nmarcofalke practicalswift im starting some mutation analysis using a couple of questions at random i picked txverifycpp as a file with high coverage that is likely critical where any missed nonequivalent mutants should be carefully investigated is this a good choice to get the workflow going on is there any mapping from fuzz targets to code expected to be covered i can run all targets of course but knowing which ones might possibly detect txverifycppmutants would be helpful"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncreatewallet with external signer always picks the first external signer, regardless of how many are connected\nis your feature request related to a problem please describe while testing 220rc2 external signer feature i noticed that if multiple hw wallets are connected to the computer createwallet will always pick the first one without alerting the user in any way this led to the following unexpected behavior 1 attach a trezor and create a wallet using bitcoincli createwallet 2 attach a coldcard while the trezor is still connected and create a second wallet with bitcoincli createwallet both wallets were created fine with no errors but on further inspection i realized both wallets were connected to the trezor despite having different names this is related to 22635 describe the solution youd like ideally if multiple external signers are returned from enumeratesigners and i then try to create a wallet i would want createwallet to fail and warn me there are multiple external signers additionally an option to specify the fingerprint of the device would be useful but i think simply failing would be sufficient for now describe alternatives youve considered granted this is a rare case where a user would have multiple hws connected while creating a single sig wallet so perhaps just documenting that you should only have one connected at a time is a viable solution"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nnetinfo: display addr_{processed, rate_limited, relay_enabled} and relaytxes data\nupdate cli netinfo to display the getpeerinfo addrprocessed addrratelimited addrrelayenabled and relaytxes data with autoadjusting column widths srcbitcoincli netinfo help txn time since last novel transaction received from the peer and accepted into our mempool in minutes the peer requested we not relay transactions to it relaytxes is false addrp total number of addresses processed excluding those dropped due to rate limiting we do not relay addresses to this peer addrrelayenabled is false addrl total number of addresses dropped due to rate limiting screenshot from 20210822 143140"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSub wallet for dirty coins\nis your feature request related to a problem please describe unable to spend unconfirmed utxo 100 the combination of these two things affects privacy which is discussed in detail here describe the solution youd like image we are already marking used addresses as grey in can improve this by marking red for addresses used twice or more for receiving bitcoin grey color for addresses used once once we have dirty coins received bitcoin twice or more they should be locked automatically dump private keys associated with the addresses and import them in a new wallet subwallet for dirty coins not sure if there should be a sub wallet for each address or all dirty coins go in one sub wallet describe alternatives youve considered use other wallets additional context this will improve following things 1 no wallet fingerprinting 2 keep things separate 3 manage forced address reuse in a better way 4 neither utxos being confirmed nor value for will matter anymore the user can decide how to spend dirty coins in future either use all in one transaction or do coinjoin or something else looking for concept acks and discussion about this solution so that implementation can be planned if enough people agree to add this feature thanks harding for suggesting idea about subwallets in"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNulldata treated as nonstandard\nbitcoind returns nonstandard addresses from scripts started from opreturn eg in first 300 kiloblocks bktxvout 2297121291 257727911 257727931 2833965961 296195120 299571102 as an example vout 2297121291 block height 229712 tx 129 vout 1 json value 000000000 n 1 scriptpubkey asm opreturn opdup ophash160 opequalverify opchecksig hex type nonstandard"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nwallet: add destination (output) and bump fee\nthis would allow ad hoc transaction batching when a wallet transaction is unconfirmed id like to be able to add an additional destination output bip 125 requires that such a transaction also increases the fee rate one approach would be to create a new wallet rpc addoutput which takes a transaction hash address amount and fee rate difference a better approach imo would be to add a new argument extraoutputs to bumpfee and psbtbumpfee this would have the same format as outputs in send two complications come to mind 1 if the original transaction used we dont store that information see also 11122 so either a the user has to provide that array again for us to subtract the additional fee correctly or b the extra fee is paid entirely from change 2 if the previous transaction confirms rather than the new one the user has to figure this out and manually craft a new transaction"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nEnable reading of pchCommand before Complete()\ni always found it useful to be able to see what message was incoming from another node as soon as the header had been received but since 16202 it no longer appears to be possible to discern the pchcommand until the complete message has been received is there a way to determine the message as soon as the header has been received this could be useful functionality in order to be able to reduce bandwidth and for logging and debugging"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBroadcast a transaction to specific nodes\nis your feature request related to a problem please describe there is no argument in sendrawtransaction to mention the peers describe the solution youd like add an argument in sendrawtransaction that accepts one or more addresses for nodes describe alternatives youve considered additional context note that the transaction will be sent unconditionally to all peers so using this for manual rebroadcast may degrade privacy by leaking the transactions origin as nodes will normally not rebroadcast nonwallet transactions already in their mempool rebroadcast thing mentioned above will be fixed in however this option will still be useful"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDevelop watch-only wallet\nis your feature request related to a problem please describe im trying to create a watch only wallet on bitcoinqt with bitcoin core describe the solution youd like passwordpin protected qrcode capability"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nStyle Guide Enum Bool Thoughts\nin many places we use bool parameters to denote some effect i suggest that throughout the codebase we make an effort to where feasibletouched replace these with enum class its a bit more verbose but its already a norm to do f confusing bool true and it would be nice if our compiler helped us out further it makes it easier should later code extend the functionality to add moredifferent options in order to reduce clutter we could make a macro boolenumargument enabledname disabledname not high importance so i dont think we should make a project out of it but i was looking at some code recently where it would have been nice con we dont need more structs"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to tell compilers to not drop the lock stack when using Assume/Assert?\nit would be nice if there was a way to tell compilers not to drop the lock stack and thus issue warnings when accessing a symbol that needs a lock inside assumeassert hit by at least ajtowns jnewbery me"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd mitigation for disk fill via logging attacks\nshort version it would be nice if we could render disk fill via logging vulnerabilities unexploitable by introducing a mitigation like the one suggested in the up for grabs pr 19995 that pr was concept acked by naumenkogs laanwj and jnewbery but unfortunately closed due to lack of time volunteers welcome long version a disk fill attack is an attack where an untrusted party such as a peer is able to cheaply make your node log to disk excessively the excessive logging may fill your disk and thus make your node crash either cleanly best case if disk fill rate is relatively slow or uncleanly worst case if disk fill rate is relatively fast it is easy to accidentally introduce a disk fill vulnerability all it takes is a logprintf in a code path which is easily and cheaply triggered by a remote attacker it would be nice if we could kill this vulnerability bug class by introducing a general mitigation mechanism which would remove the ability exploit such such a misplaced logprintf our first line of defence would obviously be to never misplace a logprintf but realistically logging mistakes happen and thats where mitigations kick in as a second line of defence one possible mitigation was suggested in pr 19995 which received concept acks from naumenkogs laanwj and jnewbery the reviewers came up with some good ideas for improvements which need to be implemented unfortunately i dont have time to implement those changes myself but if someone is looking for up for grabs prs then 19995 would be a very good choice it is seldom one gets the chance to kill an entire vulnerability bug class id be glad to review and help out the solution suggested in the referenced pr is one of many possible solutions but regardless of which solution we choose i think we need some disk fill attack mitigation to kill this bug class once and for all"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncontrib: Current systemd usage doesn't allow for dependencies\nthe current systemd service does not allow gracefully for services to depend on bitcoind all dependent units will be launched immediately regardless of current status so if it is to work at all they need an inefficient polling loop in the service file the service type is specified as typeforking but we dont heed the behavior specified from the systemdservice5 man page if set to forking it is expected that the process configured with execstart will call fork as part of its startup the parent process is expected to exit when startup is complete and all communication channels are set up a possible solution is 21007 which adds daemonwait so that the control is only returned to the parent process when startup is complete in combination with typeforking i think this achieves the proper functionality to start dependent units only when rpc functionality is working with that the only change to the service file needed would be to use daemonwait instead of daemon an alternative would be to implement support for typenotify and do readyness notification through sdnotify but i opted for daemonwait because it seems more generally useful the advantage of using a native notification mechanism however would be that it is still possible to have logging through stdout to the journal the drawback that it introduces an optional dependency on libsystemd"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSolve for %51 attact\nis your feature request related to a problem please describe yes this problem is security problem for pow consensus protocol describe the solution youd like solution is basic the new consensus algorithm safe proof of work blocks will have a two hash block and miner select from random first hash mining or second hash mining this is changed all mining proccess and add into the hash the merkle root of the blocks of the blockchain the miners wants to add if first hash blocks merkler root not equal second hash blocks merkle root all nodes and miners restart process describe alternatives youve considered if you want to know more you can check the my github repository onuratakanspow i published with mozilla public license"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nguix: Prints \"g++: not found\" when building depends\nsteps to reproduce start a guix build on a system without gcc binsh 1 gcc not found binsh 1 gcc not found binsh 1 g not found binsh 1 g not found env no such file or directory env no such file or directory env no such file or directory env no such file or directory found macos sdk at using make entering directory binsh 1 gcc not found binsh 1 gcc not found binsh 1 g not found binsh 1 g not found binsh 1 gcc not found binsh 1 gcc not found binsh 1 g not found binsh 1 g not found make1 entering directory binsh 1 gcc not found binsh 1 gcc not found binsh 1 g not found binsh 1 g not found env no such file or directory env no such file or directory env no such file or directory env no such file or directory make1 leaving directory make1 entering directory binsh 1 gcc not found binsh 1 gcc not found binsh 1 g not found binsh 1 g not found binsh 1 gcc not found binsh 1 gcc not found binsh 1 g not found binsh 1 g not found make1 leaving directory make1 entering directory binsh 1 gcc not found binsh 1 gcc not found binsh 1 g not found binsh 1 g not found binsh 1 x8664w64mingw32gcc not found binsh 1 x8664w64mingw32gcc not found binsh 1 x8664w64mingw32g not found binsh 1 x8664w64mingw32g not found make1 leaving directory make leaving directory info building commit a4903f747ccd for platform triple x8664linuxgnu"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRefactor (move-only) into a \"block storage\" module\nsee"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd Ranges to to Output Descriptors\noutput descriptors do not contain support for ranges bip444984 account uses two chains for receiving addresses and for change addresses having possibility to express ranges would allow us to capture the essence of bip444984 accounts in one output descriptor eg note the 01 at the end"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGithub <> Slack integration\nis your feature request related to a problem please describe no describe the solution youd like can you add the slack github integration to this repo so that changes can be easily tracked in slack describe alternatives youve considered i understand that email notifications can be used but in my opinion slack notifications provides easier team organisation additional context none"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFeature: Add EditorConfig\nmotivation developers are supposed to follow coding style however from time to time a pr is created and then its author is asked to change tabs to spaces for example introducing an editorconfig file can mitigate these formatting issues user story a contributor wants to create a new pr she clones bitcoin core repo opens her editor the editor loads editorconfig rules and writes her patch with correct formatting rules less coding style issues is then discovered in the pr review process and thus less ci runs are needed what is editorconfig file provides very well and concise explanation what is editorconfig editorconfig helps maintain consistent coding styles for multiple developers working on the same project across various editors and ides the editorconfig project consists of a file format for defining coding styles and a collection of text editor plugins that enable editors to read the file format and adhere to defined styles editorconfig files are easily readable and they work nicely with version control systems support editorconfig is supported in many ides and text editors sometimes the support is outofbox and sometimes a plugin is needed however for example vs code detects editorconfig presence and automatically offers you to install the missing plugin see for details on support visual studio is supported vs code and intellij idea are supported and many others my editor does not support editorconfig then nothing really changes for you editorconfig vs clangformat as explained here note that visual studio also supports editorconfig which works in a similar way clangformat however has a much larger variety of style options than editorconfig including some very c specific rules that can be set and it is already used by c developers today having both editorconfig and clangformat in a project may not always work correctly though i think as some editors may have a plugin for editorconfig and a plugin for clangformatter which may not work correctly in unison proposed editorconfig this proposal is based on developer notes yaml this is the topmost editorconfig file root true for all files charset utf8 endofline lf insertfinalnewline false shell scripts sh indentsize 4 indentstyle space true c files hcpp indentsize 4 indentstyle space true python files py indentsize 4 indentstyle space true makefiles makefileam indentstyle tab true markdown files md true cirrusyml appveyoryml fuzzbuzzyml etc yml indentstyle space indentsize 2 true note that the syntax can be much shorter but it is not my goal here i prefer clarity at this point so what is this specifying charset use utf8 in all files endofline line endings should be lf by default in all files insertfinalnewline do not add a blank line at the end of a file by default and then there are rules for various types of files the rules does not cover everything one can see that there actually many different file types meaning unique file extensions using this simple powershell script powershell getchilditem recurse extensiontolower sort unique with the following output 1 ac adoc am bashcompletion bat bmp c cc cert cfg clangcomplete clangformat cmake cmd cnf com conf cpp css csv doxyfile dtd empty exe exp gci gitattributes github gitignore gitmodules guess h hex hpp html icns ico idb ilk in include ini init ipp jam js json lastbuildstate lib list log m m4 md mk mm moc obj openrc openrcconf patch pc pdb pl plist png po pro py pythonversion qbk qm qml qrc raw rb rc recipe res s sage sass scm scss service sgml sh sln spec sub supp svg targets td tlog ts tx txt ui user v2 vcxproj verbatim vscode xml xpm xsl y yapf yml yy what do you think"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nModify `testmempoolaccept` to handle client's `max_raw_tx_fee` check failure\nsee"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nlog: Add debug log category prefix\ni wanted to log especially incoming onion connections was unsure if category net or tor would do that in the debug log you do not see which debug message is of what category or if it is of no debug category at all standard log i would like if debug log categories are logged eg with a prefix eg for net debug category log line the line is currently logged like this i hope i am right that this belongs to netcategory so this is an example of the uncertainty that results in the current absence of the category logging 20210201t193308z socks5 connected my wish would be that it would be logged like this 20210201t193308z net socks5 connected if that would have any drawback like log gets bloated an option to toggle debug log category prefix logging could be introduced eg debugcategorylogging"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRPC field to indicate which of the conflicted wallet transactions is in the mempool\ndont currently indicate which of the conflicted unconfirmed wallet transactions are considered active in the nodes mempool and which arent to determine this one currently has to issue an additional getmempoolentry rpc call and check if that fails or not it would be useful if this information was more readily available without requiring additional calls additionally it appears that theres an inconsistency between gettransaction and listtransactions normally listtransactions returns a flattened concatenated list of the details for all the wallet transactions with one entry per detail entry but in this case gettransaction returns an empty details array for non active transactions which should to my understanding translate to the transaction not showing up in listtransactions at all yet it does this is wrong it was a pebmac my preference would be for non active unconfirmed transactions to show up in both but with a flag that indicates their status similarly to confirmations 0 for transactions that conflict with confirmed transactions"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nThreshold signing for releases\nfor signing the sha256sumsasc in the distribution i would like to move away from using a signing key that i solely personally possess im not entirely sure how threshold signing is only a possibility there might be others i think it would be ideal if we could distribute the process over multiple people like a m out of n scheme for example a few relatively trusted gitian builders the resulting signature should ideally be verifiable in the same way as it is now with gnupg getting people to adapt a custom tool for validation is going to be difficult"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBetter errors for address use from wrong network\ni spent too long to figure out i was putting mainnet addresses to regtest node errors werent helpful at getaddressinfo and validateaddress seems like a good first issue to augment the error messages when prefixhrp dont match current network"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`decodescript` returns wrong reqSigs for complex scripts\nthis issue may be related to but i dont think it is because i get the expected reqsigs for other p2sh p2wsh scripts create a redeem script that includes both opcheckmultisig and some other condition such as feed the redeem script into the decodescript rpc expected behavior i expect reqsigs to match the number corresponding to the opcheckmultisig portion of the redeem script actual behavior the output has reqsigs set to 1 to reproduce example script bitcoincli testnet named decodescript asm 1896380 opdrop 3 5 opcheckmultisig type nonstandard p2sh segwit asm 0 hex reqsigs 1 type witnessv0scripthash addresses p2shsegwit system information bitcoin core 0201 ubuntu 2004 using bitcoincli against local node"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCan we create a non proof-of-childs documentation to install and run properly this repo?\ni have tried several times to install and run this repo in a fresh ubuntu 2004 operative system all the documentation i have found is outdated and there is not an evident clear path to successfully install this repo in at least an os i would like to suggest if possible an exhaustive doc that explains how to install this repo in any linux distribution"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPlease split the `-msghand` thread into multiple threads.\nit seems when using good storage that this thread act as bottleneck in a way that other threads are waiting completion from it a the cpu level when performing initial full node synchronisation as a result bitcoin is mostly single threaded in that case the msghand thread take 100 of a single core leaving other cores idle even on a core duo cpu this what currently prevents syncing a full node with txindex in less than 1 hour"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPartially Signed Bitcoin Transaction (PSBT) GUI for Bitcoin Core Request\ndear developers do you fine people plan on adding a gui to bitcoin core so that users can create a psbt and also sign a psbt for cold storage users i would love this feature i think you can do this with command line but its risky and not simple i ask because i only use bitcoin core as my wallet and dont have easy cold storage spending method without bringing all online thank you and i love you all is your feature request related to a problem please describe no describe the solution youd like an easy to use gui to create a psbt and to sign a psbt for cold storage describe alternatives youve considered additional context"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd \"walletpassphrasechange\" command in bitcoin-wallet.exe\nthis is an underrated useful tool dear devs please add this feature thanks"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd macOS ARM build (universal or additional binaries)\nfirst arm based macs are available now see the porting guide and the architectural differences things to do x fix depends build on arm with macos 1016 done in merged 20482 x fix crc32 build issue fix in 20603 x update macos build readme if required x allow cross compiling arm64 mac on linuxgitian x fix make deploy on arm64"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGUI-Feedback on calculating transaction fees \ni stumbled across fee calculation messing up units please take a look at this discussion which is related to therefore id like to suggest the following use case user selects manually editing fee and user asks for sending next bitcoinqt calculates the fee added to the transaction then gui shows to user the calculated fee and ask for confirmation if ok then send transaction else edit fee calculation and repeat"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHardcoded seeds for Torv3 addresses\nfor the 022 release well want to start hardcoding torv3 addresses instead of or in addition to torv2 the biggest challenge here is not how to hardcode them although that will require a few minor script and code changes but how to collect them the release process is to get the addresses from dns seeders however these currently dont support the addrv2 message nor torv3 addresses in the first place nor do they really have a need to"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDandelion++\nis your feature request related to a problem please describe bip 156 never got implemented in bitcoin core which could improve privacy reasons tldr denial of service dandelion proposed for bitcoin implemented in monero describe the solution youd like implement dandelion in bitcoin core and if it involves any risks lets test try to find solutions or workarounds describe alternatives youve considered tor additional context not sure how much is this pr and associated project related to this issue also there is no option to specify tor for sendrawtransaction rpc command"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupport Tor v3 seeding\nis your feature request related to a problem please describe dns seeding for tor v3 edwards curve nodes is not possible in the current aaaaa design describe the solution youd like support for tor v3 seeding by creating a bip that outlines how that can be done until we have that add at least some fixed v3 node addresses in the vseeds list dns seeding for tor v3 nodes is not possible in the current aaaaa design when v2 fades out seeders are unable to hand over learned known v3 onions encoded in there dns aaaaa answer records not that enable dns seeding while using tor is a good privacy idea anyway but since some users are behind chains of nats and just like or must bootstrap over tor we should support that with the next release users will be reachable by v3 onions the node created and gossip them but be unable to get also those onion v3 seeds by the build in seeders or there own dns tor v2ipv46 seeders in the usual fashion on a clean bootstrap so to mitigate against fragmentation at least we should add some build in v3 node addresses ie from the known seeder nodes so nodes have a chance to stay solely in tor and v3 and are not forced to leak orand think about building for and using something like the lightning mechanism to support also seeding like we used to now also for tor v3 onions general caveat of long v3 onion names is that we can no longer bootstarp in out of ip4ip6 by use of a and aaaa records that fit the now long onion address but might be forced to support dns srv calls for the long names but srv dns calls are not supported by tor and the socks5 proxy so the task is that we must find a way to bootstrap in a private maner before tor v2 fades out describe alternatives youve considered until we have that add at least some fixed v3 node addresses in the vseeds list additional context"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDocument supported methods for backups and restore\nexisting literature on backing up and restoring are on external sites and forums and may become outdated they may also be recommending methods that could result in wallet file corruption we should document the supported backup and restoration methods in repo or on the website so that people can refer to those as the officially supported methods this also lets us update them as files and folder structures change"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nValidate user input and keep path in a separate argument for importwallet, createwallet and dumpwallet\nis your feature request related to a problem please describe wallets with weird names possible which can be exploited in vulnerable web applications that use bitcoin core and allow the users to create and importexport wallet testwallet for linux testwallet for windows tried on bitcoin core v 0200 describe the solution youd like keep two arguments walletname and walletpath for createwallet filename and filepath for dumpwallet importwallet validate user input name should not contain special characters path should be optional and if not specified use a default value describe alternatives youve considered web developers should create secure web apps that use bitcoin core additional context image i understand its not a vulnerability in bitcoin core and only affects vulnerable web apps that use bitcoin core however we can at least consider it a bug that may affect something in future or other projects that use bitcoin core basic checks for user input can improve the security in 2017 i had a website in which someone had reported a vulnerability that could be used to change price of flight tickets and book with almost zero bitcoin it was an issue with the website and we had to fix it although nobody could exploit it because the third party apis that we were using to book the fight tickets were validating all the things so a ticket couldnt be processed after tampering and changing the price by attacker similarly if any web developer makes a mistake and using bitcoin core for the web app would still be unaffected if bitcoin core itself doesnt allow such things for wallet names there have been lot of directory traversal related vulnerabilities recently one was reported in facebook android app"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUse orange icon for bitcoin account\ncurrently the account that hosts this repo and several others uses the black bitcoin icon which as far as im concerned is the bitcoin core brand icon would it not be more onbrand to use the orange icon for this account and the black bitcoin core icon for the bitcoincore account a discussions was had several weeks ago around branding here visualized below group 114 here is the orange icon on figma that can be exported as svg png jpg etc and used posted an issue over at regarding changing the orange icon to black for the bitcoincore account"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWallet: Reenable -fallbackfee by default for regtest and signet (and maybe testnet too)?\nthis pr merged in october 2019 disabled fallbackfee by default across all chains mainnet testnet regtest the only motivation for doing this for regtest and maybe testnet too that i can see is now it is 0 by default for all chains thus theres no need to call params comment however this does mean that if you dont set a fee or enable fallbackfee you get this error error code 4 error message fee estimation failed fallbackfee is disabled wait a few blocks or enable fallbackfee any thoughts on reenabling fallbackfee by default for regtest signet and maybe testnet too i think it makes sense to continue to have it disabled by default for real money on mainnet if im missing context please direct me to it and ill close this bitcoin stackexchange post"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsplit policy/error consensus codes for CLEANSTACK, MINAMALIF\ndiscussion here"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n\"Good First Review\" label\ni would like to suggest a small idea that i had to make it easier for beginner to review their first prs analogous to the good first issue label i am suggesting a good first review label as a general guideline labeled pull requests should have some ideally all of the following characteristics complexity level low a tentative small change 100 loc a detailed description of the pr background if needed general instructionshints on how to testreproduce examples of pulls that generally tend to be good first reviews a newly added rpc that can be easily manually tested to verify functionality a pr that only adds new functional test coverage since these tend to be selfdocumenting a documentation change that can be verified to be correct with manual testing similar to other labels the creator of the pull could ask for the label to be applied or contributors with the power to give labels could apply the proactively"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOnion address in Bitcoin Core Wallet\nis your feature request related to a problem please describe i am not sure if there is a rpc method available to directly get the onion address used so i checked it in localaddresses returned by getnetworkinfo it was also mentioned in debuglog file image describe the solution youd like i would love to see an onion address and maybe qr code in the wallet if it is listening on tor similar to abcore image describe alternatives youve considered check the onion address in debuglog or localaddresses returned for getnetworkinfo additional context linked to because if we add such option to check the onion address it will have to be added in the tor documentation"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFatal performance when importing 151M private keys\nearlier i was importing several thousands of private keys to bitcoin core and it took much time especially rescan of the blockchain few hours 3 surely but now when i am importing 151m private keys 10 gb file with keys the import process is now taking 2 days and i have 65 for now how badly bitcoin core is written is unbelivable there is no other way to scan such an amount of keys because other apps are for private limited use and do not offer scanning the blockchain with such a large amount of keys will this be fixed or even rewritten"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRevisit the chain view cache policy\noops wrong repo sorry"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrpc: pipe support for submitblock\nif you use the submitblock rpc with a large enough block youll run into argument list too long using a pipe should fix this at least on linux macos the submitblock rpc can be useful to check validity of a stale block that never made it into the main chain and that your node never fetched call invalidateblock on its sameheightsibling and then feed it the raw block easiest workaround is to use a library that connects directly to bitcoind via rpc be careful to avoid a line break character at the end using the gui console fails with block decode failed for me but havent tested that extensively"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nManual-pruning cursor rewind\nis your feature request related to a problem please describe setting a lowerthancurrent prune height via pruneblockchain currently requires a full resync on slower machines this can take a very long time it is also unnecessary describe the solution youd like since all block headers are retained for pow and chain reorg purposes bitcoind could feasibly redownload the raw blocks that are lower than the old cursor and above the new cursor and check their validity against the retained headers"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDecouple build system from source. Use CMake to help newcomers and ecosystem!\nproblem new developers unable to quickly get up and going in their ide the current build system is very brittle and the custom tailored nature of it leaves the development team having to address constant breaking changes and new architectures etc it also leaves new comers to the project in a state of despair when they realize that the current ide cannot pick up the project for example in this issue 13694 the user asked where i could find the guide on how to install an ide and debug the code because his top of the line ide clion works by using cmake the other well known cc ides that are currently used are able to and appear to prefer the cmake build system sadly the sarcastic response i hope from sipa was most developers dont use ides as far as i know for the windows users out there in issue 14118 the issue got alot of support to the idea of adding cmake as one is able to quickly work on cc projects given visual studios and vscode support for cmake projects improve ecosystem by having option to build shared libraries this last point will be a simple theory but if cmake is added one could imagine that the ecosystem to grow and flourish and bring in new support and tooling with it for instance if i wanted to instead wrap around the c code using cffi and call directly from pythonjswhatever i am unable to as where would i even begin to get started on compiling a library as opposed to the executable in a neat manner right now the best way to interact with bitcoin is via the rpc it seems but why not directly the other direct benefits of having a simple cmake build system is we can undo the tight coupling of what should be the build with the source code when developing the sanitizers can be added and help ensure there is strong checks with proper memory usage and addressing etc proper sanitizing and bug catching for instance i found a buffer overflow in the tests within the ctaes library inside crypto which was found trivially after setting up a proper standalone cmake file for it this was found within hours of me poking around and was there for a number of years makes one wonder how many other bugs are simple low hanging fruit just waiting to be picked solution according to the developer ecosystem in 2020 how c is doing the c community is moving with conviction to cmake as their build system of choice over the last couple years its gone from 34 to 53 of developers choosing it over makefiles or visual studio if the trend continues it is imperative the project invests in improving the current status quo begin adding cmake files to cover the major oss windows osx linux on the major processors x8664 then expand out to arm and the smaller targets like raspberry pis and the like eschew the many optimizations and customtailored functionsmodules for specific architectures and just add the generic standard library versions until the entire project builds and tests properly while this is a monumental task as noted by sipa the hardest part will be decoupling of the many build steps with source code but thats more tedious and repetitive than anything i can and already have a couple cmake files for some modules like crypto and ctaes to start off what i am not sure of exactly is the flow of direction between the libraries in the bitcoincore project and this one which one follows which"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTestnet reset?\ni was thinking since it looks like the testnet is very hard to mine and has already had many halvings i know they are faster what are your thoughts on a testnet reset for the next release of bitcoin core the testnet i believe should get a refresher as its been many years since the launch of testnet3 and many altcoins are on testnet4 if you all like this ill submit a pr to reset the testnet"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProvide skeleton bitcoin.conf during datadir generation\nis your feature request related to a problem please describe it would be helpful to provide the example bitcoinconf provided in the source code to the users that just download the binaryinstall from their package manager secondly a new bitcoind user may not be aware that bitcoinconf file is an available option while bitcoinconf is mentioned in the man page one would have to know what to look for or read a bit to get to the conf section by providing a skeleton file a new user is more exposed to such an option describe the solution youd like automatically generate a skeleton bitcoinconf with something like the one found at when first starting bitcoind describe alternatives youve considered additional context"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCVE-2012-2459, possible code and performance improvement\nok so in my effort to create a fullnode from scratch both for learning purpose and need not a topic for discussion thanks i was looking at the code that check merkle root to not be vulnerable to cve20122459 that vulnerability basically allows you to create a block that has a valid merkle root but contains duplicate transactions causing a node that receive such block before the correct one to be stuck on a fork because that block will be flagged as incorrect and having the same hash of a correct block will prevent the node to ask again for that block causing a node to be stuck anyway this is an old cve that was fixed back in 2012 and code changed during time now in bitcoin core the code is not that pretty and the method to compute merkle root are polluted from a boolean parameter that when read back reflects if the block has been mutated malleated or not the code is this uint256 hashes bool mutated bool mutation false while hashessize 1 if mutated for sizet pos 0 pos 1 hashessize pos 2 if hashespos hashespos 1 mutation true if hashessize 1 hashes0begin hashessize 2 2 if mutated mutated mutation if hashessize 0 return uint256 return hashes0 now thinking about the problem i think i found a better approach that is olog n and allows to have a better code too without having to pass the mutated flag around if it works and the logic isnt flawled so id like to know your thought about this my paint skill can show you some of the logic 123711 a b c etc are transactions the vertical line is what i call safe point basically all transactions before that safe point are guaranteed to be not duplicable this is one of the assumption i do and one thing to check if its correct then based on how merkle root is computed and how the cve uses that to do nasty things you can see some example of malleated blocks i created then a gist containing a linqpad code that can be run as it is and produce outputs to see if the logc is correct and can spot malleated blocks this is an output example of that gist enter image description here22 the core logic relies into checking the last transaction against the previous moving exponentially to the left at each iteration see the picture with the vertical blue arrows showing which element it checks or see the linqpad result where its explicitly detailed i handle both the cases where the tx count is even or odd to me it seems to work but would like to have some more eyes on that to see if the logic sounds correct or not note how for 9000 tx i have just to compare 14 transactions instead of thousands like current bitcoin code is doing apart from that in my case it has another pros that allow me to split the markle computation and markle cve check in two different places without having to use a solution like that mutated boolean parameter actually i cant setup an environment to check if my intuition is correct and benchmark it so i cant provide numbers but im more interested about the check logic itself 1 2"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nChange address selected randomly causes problem with hw. wallet\nusing core with hardware wallets coldcard in this case comes with a problem when you create a psbt with it pulls a random change address problem is coldcard i think justly says it is out of order and displays a strong warning like in our case in a pool of 1000 addresses coldcard scans and accepts the first 200 solution it would be nice to have an option default to pull change addresses in the derivation order alternative right now we can importmulti 200 addresses so any random address falls into the accepted first 200 problem is its easy to run out of that 200 i believe pulling random change addresses form a hd wallet gives no extra privacy"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBoundary Limit ?\nlukejr glozow fanquake marcofalke shouldnt be here in code less equal than ie for determination if an uxto is to be considered dust"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbitcoin-wallet reported as Wacatac malware\nis there an existing issue for this x i have searched the existing issues current behaviour running gpg verified binaries leads to an active wacatac malware was prevented expected behaviour not triggering the incident steps to reproduce follow curl o zxf cd downloads gpg verify sha256sumsasc tar zxf sudo cp bitcoin250binbitcoin usrlocalbin run bitcoind relevant log output an active wacatac malware was prevented how did you obtain bitcoin core prebuilt binaries what version of bitcoin core are you using 250arm64appledarwin operating system and version macos ventura 1351 machine specifications apple silicone chip"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhat is depends BUILD_ID_SALT ?\nis it unused if not how can it be used if yes can it be removed references git grep dependsmakefile they rely on the buildid variables env ccbuildcc cstandardcstandard cxxbuildcxx arbuildar ranlibbuildranlib stripbuildstrip debugdebug ltolto nohardennoharden genid buildidsalt guixenvironment the cache is not invalidated cd depends buildidsaltsalt make boost echo done done cd depends buildidsaltsalty make boost echo done done"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRegtest mode loses unspents after day\nis there an existing issue for this x i have searched the existing issues current behaviour testing in regtest mode i have noticed that after 1 day of send some funds from a wallet to b the unspent inputs disappear from wallet b bitcoinconf bash generated by this config should be placed in following path bitcoinbitcoinconf chain run this node on its own independent test network equivalent to chainregtest regtest1 core specify a nondefault location to store blockchain and other data reduce storage requirements by only storing most recent n mib of block this mode is incompatible with txindex and coinstatsindex warning reverting this setting requires redownloading th prune0 wallet bech32 addresstypebech32 bech32 changetypebech32 specify wallet database path can be specified multiple times to load multiple wallets path is interpreted relative to if it is not absolute and will be created if it does not ex walletdefault sections most options automatically apply to mainnet testnet and regtest networks if you want to confine an option to just one network you should add it in the relevant section exceptions the options addnode connect port bind rpcport rpcbind and wallet only apply to mainnet unless they appear in the appropriate section below options only for mainnet main options only for testnet test options only for regtest regtest accept command line and jsonrpc commands server1 bind to given address to listen for jsonrpc connections this option is ignored unless rpcallowip is also passed port is optional and overrides rpcport use hostport notation for ipv6 rpcbind127001 listen for jsonrpc connections on this port rpcport10001 allow jsonrpc connections from specified source valid for are a single ip eg 1234 a networknetmask eg 12342552552550 or a networkcidr eg 123424 this optio rpcallowip127001 username and hashed password for jsonrpc connections the field comes in the format rpc clients connect using rpcuserrpcpassword ar expected behaviour obtain unspent inputs steps to reproduce bash send unspent bitcoincorecli named send 0034 feerate25 generate blocks bitcoincorecli generatetoaddress 6 list unspent bitcoincorecli listunspent 0 9999999 after day trying again to list with listunspent and the result is empty relevant log output no response how did you obtain bitcoin core package manager what version of bitcoin core are you using v025 operating system and version debian 11 machine specifications no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfuzz:crc32c::ExtendArm64 Undefined symbols for architecture arm64:\nis there an existing issue for this x i have searched the existing issues current behaviour configure success make failed expected behaviour make failed steps to reproduce configure enablefuzz disableasm build options with external callbacks no with benchmarks no with tests yes with ctime tests no with coverage no with examples no module ecdh no module recovery yes module extrakeys yes module schnorrsig yes module ellswift yes asm no ecmult window size 15 ecmult gen prec bits 4 valgrind no cc gcc cppflags secpcflags o2 stdc89 pedantic wnolonglong wnestedexterns wshadow wstrictprototypes wundef wnooverlengthstrings wall wnounusedfunction wextra wcastalign wreservedidentifier fvisibilityhidden cflags g o2 ldflags options used to compile and link external signer no multiprocess no with libs no with wallet yes with sqlite yes with bdb yes with gui qt no with zmq no with test not building testbitcoin because fuzzing is enabled with fuzz binary yes with bench no with upnp no with natpmp no use asm no usdt tracing no sanitizers debug enabled no gprof enabled no werror no lto no target os darwin2260 build os darwin2260 cc gcc cflags pthread g o2 cppflags dabortonfailedassume ufortifysource dfortifysource3 dhavebuildinfo xclang dmacosx cxx g stdc17 cxxflags wstackprotector fstackprotectorall wall wextra wgnu wformat wformatsecurity wvla wshadowfield wthreadsafety wloopanalysis wredundantdecls wdatetime woverloadedvirtual wsuggestoverride wimplicitfallthrough wdocumentation wnounusedparameter wnoselfassign g o2 ldflags lpthread wlbindatload wlfixupchains wldeadstrip wldeadstripdylibs ar usrbinar arflags cr make relevant log output ar libbitcoinutila cxx cxx cxx cxx cxx cxx cxx cxx cxx cxx cxx ar libbitcoinconsensusa cxx cxx cxx cxx cxx cxx cxx cxx cxx cxx cxxld cxx ar libbitcoinclia cxxld testfuzzfuzz undefined symbols for architecture arm64 int unsigned char const unsigned long referenced from crc32cextendunsigned int unsigned char const unsigned long in ld symbols not found for architecture arm64 clang error linker command failed with exit code 1 use v to see invocation make2 testfuzzfuzz error 1 make1 allrecursive error 1 make allrecursive error 1 how did you obtain bitcoin core compiled from source what version of bitcoin core are you using 25x operating system and version macos ventura 135 machine specifications m1 macbook pro 16 103264gb 1tb"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBitcoin Core v25.0 Crashes\nis there an existing issue for this x i have searched the existing issues current behaviour bitcoin core keeps crashing and wont stay up i have been running a bitcoin node on a windows 10 computer for several years and had never experienced a bitcoin core crash before i had been running bitcoin core v0211 since if first came out but left the node unattended for a few weeks this summer i restarted it earlier this week and the bitcoin core log window showed its data base was several thousand blocks out of sync the last i saw on the bitcoin core log window was that it had some 50 blocks to go to complete the synchronization i do not know if the synchronization finished or not but a few hours later i noticed the bitcoin core log window gone and the bitcoinqtexe process disappeared from the task manager process list i restarted bitcoin core and surprisingly the log window showed its data base was more than one thousand blocks out of sync in other words it lost a large number of blocks in the crash i rebooted the windows computer and restarted bitcoin core three more times but it crashed within a few hours each time i updated bitcoin core to v250 hoping that the latest version would fix the problem unfortunately i tried v250 several times and it crashes within a few hours each time i reran bitcoin core from the command prompt window bitcoindexe with the debug option and wrote its output to a file bitcoinlogtxt which i am including below to help identify the problem i would really appreciate it if anyone would could give me some guidance on how to fix this problem so i can get my bitcoin node back up and running expected behaviour expected my bitcoin node to sync up to the bitcoin blockchain and continue to load new blocks like it has reliably done for several years now steps to reproduce restarted bitcoin core bitcoinqtexe after some 4 or 5 weeks offline relevant log output bitcoinlogtxt how did you obtain bitcoin core prebuilt binaries what version of bitcoin core are you using v250 operating system and version windows 10 version 22h2 machine specifications using a windows 10 computer running intel core i78565 cpu with 8 gb ram and 2 tb hdd"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFailure running CI locally: \"#0 15.01 Error: Unable to find a match: glibc-devel.x86_64 libstdc++-devel.x86_64 glibc-devel.i686 libstdc++-devel.i686\"\nis there an existing issue for this x i have searched the existing issues current behaviour im following the guide in cireadmemd but i cant get any of the environments to run successfully expected behaviour run ci locally steps to reproduce macos docker v docker version 2402 build cb74dfc uname a darwin 2160 darwin kernel version 2160 thu mar 9 201019 pst 2023 arm64 command citestrunallsh relevant log output full log end of log 0 7735 bash c dnf y allowerasing install gccc glibcdevelx8664 libstdcdevelx8664 glibcdeveli686 libstdcdeveli686 ccache libtool make git python3 python3pip which patch lbzip2 xz procpsng dash rsync coreutils bison utillinux 0 2506 extra packages for enterprise linux 9 aarch64 10 mbs 18 mb 0017 0 3034 extra packages for enterprise linux 9 next 448 kbs 606 kb 0001 0 3075 last metadata expiration check 00001 ago on sat jun 17 160648 2023 0 3146 no match for argument glibcdevelx8664 0 3147 no match for argument libstdcdevelx8664 0 3147 no match for argument glibcdeveli686 0 3148 no match for argument libstdcdeveli686 0 3148 package is already installed 0 3153 error unable to find a match glibcdevelx8664 libstdcdevelx8664 glibcdeveli686 libstdcdeveli686 how did you obtain bitcoin core compiled from source what version of bitcoin core are you using master operating system and version macos 1265 machine specifications no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBuild fails on Fedora 36 - configure failed for src/secp256k1\nis there an existing issue for this x i have searched the existing issues current behaviour found a recent similar issue but didnt help im trying to run a build on fedora 36 and im seeing the same error when i run configure i see the following configure warning bitcoin core requires this library for bdb legacy wallet support configure warning passing withoutbdb will suppress this warning checking for sqlite yes checking whether to build wallet with support for sqlite yes checking whether userspace statically defined tracing tracepoints are supported no checking for natpmph yes checking for initnatpmp in lnatpmp yes checking for boostlib 1640 106400 yes checking whether boostprocess can be used yes checking for seccompbpf linux x8664 yes checking for event yes checking for eventpthreads yes checking if expects const char no checking for zmq yes checking for libmultiprocess no checking whether to build bitcoind yes checking whether to build bitcoincli yes checking whether to build bitcointx yes checking whether to build bitcoinwallet yes checking whether to build bitcoinutil yes checking whether to build experimental bitcoinchainstate no checking whether to build libraries yes checking if ccache should be used yes checking whether c compiler accepts fdebugprefixmapab yes checking whether c preprocessor accepts fmacroprefixmapab yes checking if wallet should be enabled yes checking whether to build with support for upnp no checking whether to build with support for natpmp yes checking whether to build with natpmp enabled by default no checking whether to build testbitcoin yes checking whether to reduce exports no checking that generated files are newer than configure done configure creating configstatus configstatus creating configstatus creating makefile configstatus creating srcmakefile configstatus creating docmanmakefile configstatus creating sharesetupnsi configstatus creating shareqtinfoplist configstatus creating testconfigini configstatus creating configstatus creating configstatus is unchanged configstatus executing depfiles commands configstatus executing libtool commands configuring in srcsecp256k1 configure running binsh configure prefixusrlocal withoutminiupnpc disablebench withoutgui disableshared withpic enablebenchmarkno enablemodulerecovery cachefiledevnull srcdir configure error cannot find required auxiliary files compile missing configure error configure failed for srcsecp256k1 would be appreciate if you can guide if this error is because of a recent change expected behaviour configure script completes successfully steps to reproduce run the following on master configure withoutminiupnpc disablebench withoutgui relevant log output already pasted above how did you obtain bitcoin core compiled from source what version of bitcoin core are you using masterba616b9 operating system and version fedora 36 machine specifications no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAllow accepting non-standard transactions on mainnet via local rpc\nto mitigate mempool divergence between nodes and miners node operators should have the ability to submit nonstandard transactions to their local mempools one of the reasons to do so is to improve the quality of fee estimates acceptance via the p2p network has been discussed in and is deemed to be problematic this issue is for enabling nonstandard transaction submission for the sendrawtransaction rpc only"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndumpprivkey - This type of wallet does not support this command (code -4)\nis there an existing issue for this x i have searched the existing issues current behaviour hello when i try export private key for bitcoin address i got this type of wallet does not support this command code 4 i tried on all 4 types of bitcoin address base58 and bech32 legacy segwit im using zip version of bitcoin core v2310 downloaded from expected behaviour it should display private key bitcoin address cannot be found if i insert random value for bitcoin address i got this error steps to reproduce 1 run bitcoin core v2310 2 select help console 3 insert command and press enter dumpprivkey relevant log output no response how did you obtain bitcoin core compiled from source what version of bitcoin core are you using bitcoin core v2310 operating system and version windows machine specifications"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMethod not found\nissues reports or feature requests related to the gui should be opened directly on the gui repo x i still think this issue should be opened here report img width1018 src i build the node with ubuntu2004 and 2401 but some api return the error as the picture the run command bitcoind datadirdata2btcdata rpcuserxxxx rpcpasswordxxx server txindex1"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCompiling a bitcoin core version that accepts transactions over 100vkb\nplease describe the feature youd like to see added i couldnt manage to find any label that fits this when people try to inscribe ordinals that are bigger than 400kb they can not be able to because bitcoin core doesnt allow transactions over 100kvb even though that would require the person to be a miner or pay miners for it but it still would be nice to guide us on how to compile such bitcoin core version is your feature related to a problem if so please describe it no response describe the solution youd like a guide on what code changes should be done to compile such version describe any alternatives youve considered trying to look through the code to understand it and do it myself please leave any additional context no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nget block or transaction data via rpc api when in the ibd process\nplease describe the feature youd like to see added can i get the block or transaction data via the rpc api when the bitcoin core is still in the ibd process that has not been finished for example can i get the downloaded block data via calling the getblock api while the client is still in the ibd process is your feature related to a problem if so please describe it no response describe the solution youd like no response describe any alternatives youve considered no response please leave any additional context no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBitcoin-core. MacOs\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue when i install bitcoin core for my mac from official site i used datadir to my deskop but i did not found bitcoin folder and i checked out support but did not get any folder here too i am unable add to my path of mac but bitcoincore app running properly im stuck now please help expected behavior actual behavior to reproduce system information"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntest: p2p_message_capture.py fails with undefined sanitizer\non ubuntu 2210 relevant configure variable testframework info prng seed is 8604348948412116696 testframework info initializing test directory testframework info stopping nodes traceback most recent call last file line 72 in file line 157 in main exitcode selfshutdown file line 313 in shutdown selfstopnodes file line 577 in stopnodes nodestopnodewaitwait file line 356 in stopnode raise stderr formatstderr expectedstderr assertionerror unexpected stderr streamsh55619 runtime error null pointer passed as argument 1 which is declared to never be null node 0 cleaning up leftover process seems pretty consistent on the latest master"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHidden fee (about 15% of sum) while send\nhello my wallet is 18 transactions total i sent 01btc but in blockchain i found 2 transactions my own 01btc unknown fee 001999241btc 20 of sum txid next i sent 01btc but in blockchain i found 2 transactions my own 01btc unknown fee 000997949btc 10 of sum txid i do not understand how this could happen in bitcoin core i see only my transactions but blockchain show me more 2 transactions to unknown wallets so total balance in blockchain is less then in bitcoin core on this amount 002997189btc bitcoin core show me 138994437 btc but blockchain show me 135997247btc minus two fees above what is my really balance what are these hidden payments tell me more about it please what can i do to solve this problems in future screens from my bitcoin core is attached below thanks expected behavior actual behavior to reproduce system information bitcoin core version v0180 64bit from official site linux blockchain 415048generic 51ubuntu smp wed apr 3 082849 utc 2019 x8664 x8664 x8664 gnulinux balance sent1 sent2 transactions version"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBitCoin BlockChain Download Alternate\nplease anyone out there having knowledge help me that how can i deploy a node and start transactions on btc core without downloading the complete blockchain as its more than 350gb right now i want to know if there is any possible solution to it img width659 altscreenshot 20230202 at 8 06 19 pm src"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to interpret the asm section of scriptSig\ni tried asking the question in this post on but got no answer the question is this i am trying to understand the output from bitcoincli the sample transactions txid is from block 222222 the asm section of scriptpubkey ie opdup ophash160 opequalverify opchecksig is more understandable it decodes hex and shows the assembly in a sort of humanreadable format vout value 063918136 n 0 scriptpubkey asm opdup ophash160 opequalverify opchecksig hex address type pubkeyhash the question arises when it comes to the asm section of scriptsig txid vout 1 scriptsig asm hex as you can see it is which isnt really decoded i checked the same transaction from blockstreaminfo its result is oppushbytes72 oppushbytes65 which looks more readable and i can understand that this scriptsig pushes two byte arrays into the bitcoin vms stack so the questions are 1 why bitcoinclis output is like this 1 how to interpret it especially how to understand the all part in its asm perhaps you can just give me a rtfm link"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSender always unknown on the laatest version.\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue sender always show unknown is there any way to see senders in order to make our own accounting expected behavior to see sender too actual behavior to reproduce system information"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSHA256SUMS.asc  - Using untrusted key!\ngetting warning using untrusted key when running gpg verification gpg keyserver autokeyretrieve trustmodel always verify sha256sumsasc sha256sums output and warning 14 2271 gpg requesting key 0a41bdc3f4faff1c from hkp server keyserverubuntucom 14 2299 gpg key 0a41bdc3f4faff1c public key aaron clauson sipsorcery imported 14 2299 gpg total number processed 1 14 2299 gpg imported 1 14 2299 gpg good signature from aaron clauson sipsorcery unknown 14 2299 gpg warning using untrusted key 14 2299 gpg signature made thu nov 17 212322 2022 utc 14 2299 gpg using rsa key 14 2299 gpg requesting key 57ff9bdbcc301009 from hkp server keyserverubuntucom 14 2334 gpg key 57ff9bdbcc301009 3 duplicate signatures removed 14 2334 gpg key 57ff9bdbcc301009 public key sjors provoost imported 14 2334 gpg total number processed 1 14 2334 gpg imported 1 14 2334 gpg good signature from sjors provoost unknown 14 2334 gpg aka sjors provoost unknown 14 2334 gpg warning using untrusted key 14 2334 gpg signature made tue nov 22 110428 2022 utc 14 2334 gpg using rsa key 14 2334 gpg issuer 14 2386 gpg requesting key c2371d91cb716ea7 from hkp server keyserverubuntucom 14 2412 gpg key c2371d91cb716ea7 public key sebastian falbesoner thestack imported 14 2412 gpg total number processed 1 14 2412 gpg imported 1 14 2413 gpg good signature from sebastian falbesoner thestack unknown 14 2413 gpg warning using untrusted key 14 2413 gpg signature made thu nov 17 193552 2022 utc 14 2413 gpg using rsa key 14 2413 gpg issuer vertionprotonmailcom 14 2535 gpg key da43140f88b4e81f public key vertionprotonmailcom imported 14 2535 gpg total number processed 1 14 2535 gpg imported 1 14 2535 gpg requesting key a7beb2621678d37d from hkp server keyserverubuntucom 14 2558 gpg key a7beb2621678d37d public key vertion imported 14 2558 gpg total number processed 1 14 2558 gpg imported 1 14 2558 gpg good signature from vertion unknown 14 2558 gpg warning using untrusted key"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFlushing block file to disk failed when using external drive on macOS Ventura\ni kept getting an error regarding flushing block to disk ive tried to use bitcoin core v023 and it doesnt help although v022 was better at loading the backup file but i couldnt send any of my bitcoin out i cant seem to load the wallet or the backup file properly not a coder and hoping someone can help i dont think its an issue with the hard drive any suggestion im on macosx ventura 130 debuglog file 20221104t203428z using wallet volumesextreme ssdbruceltd walletdat 20221104t203428z logdirvolumesextreme ssddatabase ssddblog 20221104t205816z filecommit fcntl ffullfsync failed 25 20221104t205816z error serializefiledb failed to flush file volumesextreme ssdpeers176f dblog file fsync inappropriate ioctl for device panic inappropriate ioctl for device txncheckpoint failed to flush the buffer cache dbrunrecovery fatal error run database recovery"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd ability to ignore `SCRIPT_VERIFY_DISCOURAGE_x` flags when broadcasting transactions on test networks.\nafter bugs like it would be useful to be able to reproduce these bugs in regtest currently to do so you would need to manually edit the code and comment out the script flag then compile your self it would be beneficial if we could disable these flags to create more reproducible tests"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ninitialblockdownload set to false prematurely\nexpected behavior stays true until all blocks are imported actual behavior becomes false before before all blocks are imported 20221101t111639z updatetip new height761091 version0x20f0c000 log2work93816484 tx776463417 date20221031t111346z progress0999730 20221101t111639z leaving initialblockdownload latching to false 20221101t111642z updatetip new height761092 version0x20c00000 log2work93816497 tx776466523 date20221031t112940z progress0999733 20221101t111657z updatetip new height761255 version0x2e4a6000 log2work93818629 tx776748676 date20221101t110942z progress0999999 observe the 15 seconds it took my reasonably fast machine to import the remaining blocks this is a problem for me since my application relies on this field to determine if syncing is complete we can not rely on either due to to reproduce start a node that hasnt been synced in a while and observe the log output system information observed on version 22 from the website"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSQLite version vulnerability\nsqlite version is before vulnerability cve202235737 was fixed details of which are described here"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nestimatesmartfee returns 50 sat/vB on an empty mempool for inclusion in 1008 blocks\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue expected behavior when the mempool is empty i expect something really low at least smaller than 3 satvb but not 50 satvb actual behavior bitcoincli testnet estimatesmartfee 1 feerate 000050106 blocks 2 bitcoincli testnet estimatesmartfee 1008 feerate 000050106 blocks 111 to reproduce run bitcoincli testnet estimatesmartfee on the testnet when the difficulty drops to 1 happens every few months or so i dont know why system information bitcoincoreorg download v23 any extra information that might be useful in the debugging process blocks were flowing in like every few seconds a block got mined"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCentOS compilation error-  No rule to make target\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue any report issue or feature request related to the gui should be reported at im trying to compile bitcoin v230 tag commit id fcf6c8f during the compilation i received this error make2 no rule to make target reldirlibunivaluecpp needed by stop os centos 7 compiler gcc 1120"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbitcoin core's  sync has stop for days!\nimage image image os info windows11 21h2 what should i do"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSync slow\nsyncing blockchain is sometimes very slow i think this has become more common in the past months heres a screenshot from network traffic window in the gui see how there are long periods of absolutely no traffic also see how it only downloaded about 100 mb during the first 30minutes of syncing its also often connected to just 1 or 2 peers which is weird internet is stable and i can easily download 10 mbsecond cpu load stays mostly low so lack of cpu resources doesnt explain this memory usage is also not high i have set the memory option in the settings menu to 4 gb sometimes it starts to work faster if you close and restart the program but as i said this has become worse in the past months why doesnt it download blocks faster than this if the problem is that peers cant provide blocks faster why isnt it looking for more peers im using the latest master from git as of today"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nConan build system\ndoes bitcoin support building with conan build system is there a way to build bitcoin and the depends library with conan"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIs there an alternative to the -blockmaxsize option available in the client?\nthe blockmaxsize option for bitcoind was removed with issue 12640 and i need to be able to limit my block creation size is there an alternative setting that will accomplish this or is there no control of this now beyond restricting my mempool with fees"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nI can't define bitcoin.conf file in different folder as default\ni installed the bitcoin libraries on mntvolumefra102 ran it via the following setting bitcoind i get an error when i want to create a new wallet bitcoincli createwallet adminwallet response no authentication cookie could be found and rpc password is not set see rpcpassword and stdinrpcpass configuration file probably still based on directory could you help"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n./configure hang up\ni am using mac os 1301 i get to this point everytime everyway i try to configure the code from source checking dependency style of g gcc3 checking whether g supports c17 features with stdc17 yes checking whether stdfilesystem can be used without link library no checking whether stdfilesystem needs lstdcfs no checking whether stdfilesystem needs lcfs configure error in bitcoinbitcoincli configure error cannot figure out how to use stdfilesystem see configlog for more details what can i do to remedy the situation"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbitcoin-cli createwallet error : Compiled without sqlite support\ni installed bitcoin core on ubuntu server i got help from the following commands work fine bitcoincli getinfo bitcoincli getblockchaininfo bitcoincli getnetworkinfo bitcoincli getpeerinfo i get this error when i want to create a new wallet request bitcoincli createwallet adminwallet response error code 4 error message compiled without sqlite support required for descriptor wallets"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfeature_config_args.py failure\nrun test python3 featureconfigargspy results in error testframework info initializing test directory testframework info test config args logging testframework info test seed peers testframework error assertion failed traceback most recent call last file line 133 in main selfruntest file line 229 in runtest selftestseedpeers file line 175 in testseedpeers selfstartnode0 extraargsdnsseed1 fixedseeds1 fmocktimestart file line 124 in exit nextselfgen file line 423 in assertdebuglog messages does not partially match printlog file line 167 in raiseassertionerror raise assertionerror node 0 expected messages loaded 0 addresses from peersdat 0 addresses found from dns seeds opencon thread start does not partially match log init initcommoncpp127 logpackageversion bitcoin core version v23990ce3b75690d10 release build init initcpp657 parameter interaction bind set setting listen1 init initcpp922 validating signatures for all blocks init initcpp933 setting mocktime 20220801t210530z init kernelcontextcpp21 context using the sha256 implementation mocktime 20220801t210530z init randomcpp100 reporthardwarerand using rdseed as an additional entropy source mocktime 20220801t210530z init randomcpp103 reporthardwarerand using rdrand as an additional entropy source mocktime 20220801t210530z init initcommoncpp98 startlogging default data directory homeuserbitcoin mocktime 20220801t210530z init initcommoncpp99 startlogging using data directory mocktime 20220801t210530z init initcommoncpp104 startlogging config file mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest1 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest bind127001 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest discover0 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest dnsseed0 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest fallbackfee00002 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest fixedseeds0 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest keypool1 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest listenonion0 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest natpmp0 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest peertimeout999999999 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest port11093 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest printtoconsole0 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest rpcdoccheck1 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest rpcport16093 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest server1 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest shrinkdebugfile0 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest unsafesqlitesync1 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix config file arg regtest upnp0 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix commandline arg mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix commandline arg debug mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix commandline arg debugexcludelibevent mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix commandline arg debugexcludeleveldb mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix commandline arg dnsseed1 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix commandline arg fixedseeds1 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix commandline arg logsourcelocations mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix commandline arg logthreadnames mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix commandline arg logtimemicros mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix commandline arg mocktime1659387930 mocktime 20220801t210530z init utilsystemcpp1118 logargsprefix commandline arg uacommenttestnode0 mocktime 20220801t210530z init initcpp1148 appinitmain using at most 125 automatic connections 1024 file descriptors available mocktime 20220801t210530z init scriptsigcachecpp101 initsignaturecache using 16 mib out of 322 requested for signature cache able to store 524288 elements mocktime 20220801t210530z init validationcpp1669 using 16 mib out of 322 requested for script execution cache able to store 524288 elements mocktime 20220801t210530z init initcpp1175 appinitmain script verification uses 1 additional threads mocktime 20220801t210530z scheduler utilthreadcpp18 tracethread scheduler thread start mocktime 20220801t210530z init httpservercpp184 inithttpallowlist http allowing http connections from 1270008 1128 mocktime 20220801t210530z init httpservercpp321 httpbindaddresses http binding rpc on address 1 port 16093 mocktime 20220801t210530z init httpservercpp321 httpbindaddresses http binding rpc on address 127001 port 16093 mocktime 20220801t210530z init httpservercpp401 inithttpserver http initialized http server mocktime 20220801t210530z init httpservercpp403 inithttpserver http creating work queue of depth 16 mocktime 20220801t210530z init rpcservercpp291 startrpc rpc starting rpc mocktime 20220801t210530z init httprpccpp296 starthttprpc rpc starting http rpc server mocktime 20220801t210530z init httprpccpp245 using random cookie authentication mocktime 20220801t210530z init rpcrequestcpp106 generateauthcookie generated rpc authentication cookie mocktime 20220801t210530z init httpservercpp676 registerhttphandler http registering http handler for exactmatch 1 mocktime 20220801t210530z init httpservercpp676 registerhttphandler http registering http handler for wallet exactmatch 0 mocktime 20220801t210530z init httpservercpp425 starthttpserver http starting http server mocktime 20220801t210530z init httpservercpp427 starthttpserver http starting 4 worker threads mocktime 20220801t210530z http httpservercpp287 threadhttp http entering http event loop mocktime 20220801t210530z init walletloadcpp51 verifywallets using wallet directory mocktime 20220801t210530z init nouicpp56 nouiinitmessage init message verifying wallets… mocktime 20220801t210530z init initcpp1261 appinitmain using 16 prefix for ip bucketing mocktime 20220801t210530z init nouicpp56 nouiinitmessage init message loading p2p addresses… mocktime 20220801t210530z init loggingtimerh57 log addrman checkaddrman new 0 tried 0 total 0 started mocktime 20220801t210530z init loggingtimerh57 log addrman checkaddrman completed 000ms mocktime 20220801t210530z init addrdbcpp194 loadaddrman loaded 0 addresses from peersdat 0ms mocktime 20220801t210530z init nouicpp56 nouiinitmessage init message loading banlist… mocktime 20220801t210530z init banmancpp38 loadbanlist net loaded 0 banned node addressessubnets 0ms mocktime 20220801t210530z init netcpp1523 net setting try another outbound peerfalse mocktime 20220801t210530z init netcpp2170 setnetworkactive setnetworkactive true mocktime 20220801t210530z init policyfeescpp455 read estimatefee reading estimates 190 buckets counting confirms up to 48 blocks mocktime 20220801t210530z init policyfeescpp455 read estimatefee reading estimates 190 buckets counting confirms up to 12 blocks mocktime 20220801t210530z init policyfeescpp455 read estimatefee reading estimates 190 buckets counting confirms up to 1008 blocks mocktime 20220801t210530z init initcpp1403 appinitmain cache configuration mocktime 20220801t210530z init initcpp1404 appinitmain using 20 mib for block index database mocktime 20220801t210530z init initcpp1412 appinitmain using 80 mib for chain state database mocktime 20220801t210530z init initcpp1428 appinitmain using 4400 mib for inmemory utxo set plus up to 2861 mib of unused mempool space mocktime 20220801t210530z init nouicpp56 nouiinitmessage init message loading block index… mocktime 20220801t210530z init validationcpp4710 initializechainstate switching active chainstate to chainstate ibd height 1 null mocktime 20220801t210530z init dbwrappercpp150 cdbwrapper opening leveldb in mocktime 20220801t210530z init dbwrappercpp158 cdbwrapper opened leveldb successfully mocktime 20220801t210530z init dbwrappercpp183 cdbwrapper using obfuscation key for 0000000000000000 mocktime 20220801t210530z init loadblockindexdb loadblockindexdb last block file 0 mocktime 20220801t210530z init loadblockindexdb loadblockindexdb last block file info size293 heights00 time2011020220110202 mocktime 20220801t210530z init loadblockindexdb checking all blk files are present mocktime 20220801t210530z init dbwrappercpp150 cdbwrapper opening leveldb in mocktime 20220801t210530z init dbwrappercpp158 cdbwrapper opened leveldb successfully mocktime 20220801t210530z init dbwrappercpp183 cdbwrapper using obfuscation key for 223bb69586684f13 mocktime 20220801t210530z init validationcpp3894 loadchaintip loaded best chain height0 date20110202t231642z progress1000000 mocktime 20220801t210530z init nouicpp56 nouiinitmessage init message verifying blocks… mocktime 20220801t210530z init initcpp1474 appinitmain block index 35ms mocktime 20220801t210530z init initcpp1631 appinitmain block tree size 1 mocktime 20220801t210530z init initcpp1643 appinitmain nbestheight 0 mocktime 20220801t210530z loadblk utilthreadcpp18 tracethread loadblk thread start mocktime 20220801t210530z loadblk loadmempool imported mempool transactions from disk 0 succeeded 0 failed 0 expired 0 already there 0 waiting for initial broadcast mocktime 20220801t210530z loadblk utilthreadcpp20 tracethread loadblk thread exit mocktime 20220801t210530z init netcpp2103 bindlistenport bound to 12700111093 mocktime 20220801t210530z init netcpp2103 bindlistenport bound to 12700118445 mocktime 20220801t210530z init addrdbcpp228 readanchors loaded 0 addresses from anchorsdat mocktime 20220801t210530z init netcpp2277 start 0 blockrelayonly anchors will be tried for connections mocktime 20220801t210530z init nouicpp56 nouiinitmessage init message starting network threads… mocktime 20220801t210530z net utilthreadcpp18 tracethread net thread start mocktime 20220801t210530z addcon utilthreadcpp18 tracethread addcon thread start mocktime 20220801t210530z opencon utilthreadcpp18 tracethread opencon thread start mocktime 20220801t210530z msghand utilthreadcpp18 tracethread msghand thread start mocktime 20220801t210530z init nouicpp56 nouiinitmessage init message done loading mocktime 20220801t210530z dnsseed utilthreadcpp18 tracethread dnsseed thread start mocktime 20220801t210530z dnsseed netcpp1456 threaddnsaddressseed loading addresses from dns seed dummyseedinvalid mocktime 20220801t210530z dnsseed addrmancpp612 addsingle addrman added 100118444 mapped to as0 to new8135 mocktime 20220801t210530z dnsseed addrmancpp684 add addrman added 1 addresses of 1 from 0 tried 1 new mocktime 20220801t210530z dnsseed netcpp1485 threaddnsaddressseed 1 addresses found from dns seeds mocktime 20220801t210530z dnsseed utilthreadcpp20 tracethread dnsseed thread exit mocktime 20220801t210530z http httpservercpp240 httprequestcb http received a post request for from 12700143440 mocktime 20220801t210530z httpworker1 rpcrequestcpp179 parse rpc threadrpcserver methodgetblockcount usercookie mocktime 20220801t210530z http httpservercpp240 httprequestcb http received a post request for from 12700143440 mocktime 20220801t210530z httpworker0 rpcrequestcpp179 parse rpc threadrpcserver methodgetmempoolinfo usercookie mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon netcpp455 connectnode netdebug trying connection 100118444 lastseen1469hrs mocktime 20220801t210530z opencon netcpp2729 cnode net added connection peer0 mocktime 20220801t210530z opencon netcpp2745 pushmessage net sending version 114 bytes peer0 mocktime 20220801t210530z opencon netprocessingcpp1303 pushnodeversion net send version message version 70016 blocks0 txrelay1 peer0 mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new mocktime 20220801t210530z opencon addrmancpp769 select addrman selected 100118444 from new testframework info stopping nodes testframework warning not cleaning up dir testframework error test failed test logging available at testframework error testframework error hint call to consolidate all logs testframework error testframework error if this failure happened unexpectedly or intermittently please file a bug and provide a link or upload of the combined log testframework error testframework error logs python3 pasted here"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nLoadWalletInternal logic check\nin the rpc method when the rpc method loadwallet is called it will call loadwallet and loadwalletinternal when the user repeatedly call the loadwallet with same wallet name in the loadwalletinternal funcntion although it does not call addwallet repeatedly to add to contextwallets and avoid open sqlite database repeatedly but it will make new sqlitedatabase uniqueptr and do some series checks is it better to use getwallet to determine if the wallet is already loaded before calling loadwalletinternal"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReproducible Test Failures\nive been having issues performing tests on prs so ive tried it multiple times now on master deleting the directory and starting fresh this is what i get each time make ar cxxld testtestbitcoin collect2 fatal error ld terminated with signal 9 killed compilation terminated make2 makefile7539 testtestbitcoin error 1 make2 leaving directory homeuserbitcoinsrc make1 makefile18626 allrecursive error 1 make1 leaving directory homeuserbitcoinsrc make makefile818 allrecursive error 1 make a second time successful cxx cxxld make2 leaving directory homeuserbitcoinsrc make1 leaving directory homeuserbitcoinsrc making all in docman make1 entering directory make1 nothing to be done for all make1 leaving directory make1 entering directory homeuserbitcoin make1 nothing to be done for allam make1 leaving directory homeuserbitcoin userlocalhostbitcoin make check making check in src make1 entering directory homeuserbitcoinsrc make2 entering directory homeuserbitcoinsrc make3 entering directory homeuserbitcoin make3 leaving directory homeuserbitcoin make checktests checklocal make3 entering directory homeuserbitcoinsrc make4 entering directory homeuserbitcoinsrc pass minisketchtest pass univaluetestobject pass pass univaluetestnonul make5 entering directory homeuserbitcoin make5 leaving directory homeuserbitcoin pass qttesttestbitcoinqt testsuite summary for bitcoin core 23990 total 5 pass 5 skip 0 xfail 0 fail 0 xpass 0 error 0 make4 leaving directory homeuserbitcoinsrc running tests addrmantests from testaddrmantestscpp binbash line 2 testtestbitcoin permission denied make3 makefile20866 error 1 make3 leaving directory homeuserbitcoinsrc make2 makefile18969 checkam error 2 make2 leaving directory homeuserbitcoinsrc make1 makefile18626 checkrecursive error 1 make1 leaving directory homeuserbitcoinsrc make makefile818 checkrecursive error 1 errors also userlocalhostbitcoin sudo make install no issues python3 testrunnerpy extended featureblockpy multiply failed 83 s featuredbcrashpy multiply failed 2812 s featurepruningpy multiply failed 582 s details for each failed test 9245 featureblockpy failed duration 83 s stdout testframework info initializing test directory testframework info reject block with invalid tx outputmissing testframework info reject block with invalid tx inputmissing testframework info reject block with invalid tx testframework info reject block with invalid tx duplicateinput testframework info reject block with invalid tx prevoutnullinput testframework info reject block with invalid tx nonexistentinput testframework info reject block with invalid tx spendtoomuch testframework info reject block with invalid tx createnegative testframework info reject block with invalid tx createtoolarge testframework info reject block with invalid tx createsumtoolarge testframework info reject block with invalid tx toomanysigops testframework info dont reorg to a chain of the same length testframework info reorg to a longer chain testframework info reorg back to the original chain testframework info reject a chain with a double spend even if it is longer testframework info reject a block where the miner creates too much coinbase reward testframework info reject a chain where the miner creates too much coinbase reward even if the chain is longer testframework info reject a chain where the miner creates too much coinbase reward even if the chain is longer on a forked chain testframework info accept a block with lots of checksigs testframework info reject a block with too many checksigs testframework info reject a block with a spend from a reorged out tx testframework info reject a block with a spend from a reorged out tx on a forked chain testframework info reject a block spending an immature coinbase testframework info reject a block spending an immature coinbase on a forked chain testframework info accept a block of weight maxblockweight testframework info reject a block of weight maxblockweight 4 testframework info reject a block with coinbase input script size out of range testframework info accept a block with the max number of opcheckmultisig sigops testframework info reject a block with too many opcheckmultisig sigops testframework info accept a block with the max number of sigops testframework info reject a block with too many sigops testframework info accept a block with the max number of opchecksigverify sigops testframework info reject a block with too many opchecksigverify sigops testframework info reject a block spending transaction from a block which failed to connect testframework info check p2sh sigops are correctly counted testframework info reject a block with too many p2sh sigops testframework info accept a block with the max number of p2sh sigops testframework info build block 44 manually testframework info reject a block with a noncoinbase as the first tx testframework info reject a block with no transactions testframework info reject a block with invalid work testframework info reject a block with a timestamp 2 hours in the future testframework info reject a block with invalid merkle hash testframework info reject a block with incorrect pow limit testframework info reject a block with two coinbase transactions testframework info reject a block with duplicate transactions testframework info reject a block with timestamp before mediantimepast testframework info accept a previously rejected future block at a later time testframework info reject a block with a duplicate transaction in the merkle tree but with a valid merkle root testframework info reject a block with two duplicate transactions in the merkle tree but with a valid merkle root testframework info reject a block with a transaction with prevoutn out of range testframework info reject a block with a transaction with outputs inputs testframework info reject a block with a transaction with a duplicate hash of a previous transaction bip30 testframework info reject a block with a transaction with a nonfinal locktime testframework info reject a block with a coinbase transaction with a nonfinal locktime testframework info accept a valid block even if a bloated version of the block has previously been sent testframework info accept a block with a transaction spending an output created in the same block testframework info reject a block with a transaction spending an output created later in the same block testframework info reject a block with a transaction double spending a transaction created in the same block testframework info reject a block trying to claim too much subsidy in the coinbase transaction testframework info accept a block claiming the correct subsidy in the coinbase transaction testframework info reject a block containing a transaction spending from a nonexistent input testframework info reject a block containing a duplicate transaction but with the same merkle root merkle tree malleability testframework info reject a block containing too many sigops after a large script element testframework info check sigops are counted correctly after an invalid script element testframework info test transaction resurrection during a reorg testframework info accept a block with invalid opcodes in dead execution paths testframework info test reorging blocks with opreturn in them testframework info test a reorg of one weeks worth of blocks 1088 blocks stderr 21245 featurepruningpy failed duration 582 s stdout testframework info initializing test directory testframework info warning this test requires 4gb of disk space testframework info mining a big blockchain of 995 blocks testframework info check that we havent started pruning yet because were below pruneafterheight testframework info success testframework info though were already using more than 550mib current usage 5921861438751221 testframework info mining 25 more blocks should cause the first block file to be pruned testframework info success testframework info usage should be below target 48031389808654785 testframework info check that well exceed disk space target if we have a very high stale block rate testframework info mine 24 stale blocks on node 1 followed by 25 main chain block reorg from node 0 for 12 rounds testframework info usage can be over target because of high stale rate 5123138980865479 testframework info check that we can survive a 288 block reorg still testframework info current block height 1320 testframework info invalidating block at height 1033 testframework info new best height 1032 testframework info generating new longer chain of 300 more blocks testframework info reconnect nodes testframework error jsonrpc error traceback most recent call last file line 166 in getresponse httpresponse selfconngetresponse file line 1347 in getresponse responsebegin file line 307 in begin version status reason selfreadstatus file line 268 in readstatus line 1 iso88591 file line 704 in readinto return selfsockrecvintob sockettimeout timed out during handling of the above exception another exception occurred traceback most recent call last file line 133 in main selfruntest file line 418 in runtest selfreorgtest 1033 file line 217 in reorgtest timeout120 file line 676 in syncblocks besthash xgetbestblockhash for x in rpcconnections file line 676 in besthash xgetbestblockhash for x in rpcconnections file line 49 in call returnval kwargs file line 142 in call response status selfrequestpost selfurlpath postdataencodeutf8 file line 108 in request return selfgetresponse file line 168 in getresponse raise jsonrpcexception getbestblockhash rpc took longer than 60000000 seconds consider using larger timeout for calls that take longer to return 344 testframework info stopping nodes testframeworknode0 error unable to stop node traceback most recent call last file line 336 in stopnode selfstopwaitwait file line 49 in call returnval kwargs file line 142 in call response status selfrequestpost selfurlpath postdataencodeutf8 file line 107 in request path postdata headers file line 1255 in request url body headers encodechunked file line 1266 in sendrequest selfputrequestmethod url skips file line 1092 in putrequest raise requestsent node 5 cleaning up leftover process node 2 cleaning up leftover process node 1 cleaning up leftover process node 0 cleaning up leftover process stderr traceback most recent call last file line 486 in prunetestmain file line 156 in main exitcode selfshutdown file line 311 in shutdown selfstopnodes file line 571 in stopnodes nodewaituntilstopped file line 382 in waituntilstopped timeouttimeout file line 265 in waituntilhelper if predicate file line 372 in isnodestopped assert returncode 0 selfnodemsg assertionerror node 0 node returned nonzero exit code 9 when stopping 245245 featuredbcrashpy failed duration 2812 s stdout testframework info initializing test directory testframework info prepped 5000 utxo entries testframework info iteration 0 generating 2500 transactions 0 0 0 testframework info iteration 1 generating 2500 transactions 0 0 0 testframework info iteration 2 generating 2500 transactions 0 0 0 testframework info iteration 3 generating 2500 transactions 0 0 0 testframework info iteration 4 generating 2500 transactions 0 0 0 testframework info iteration 5 generating 2500 transactions 0 0 0 testframework info iteration 6 generating 2500 transactions 0 0 0 testframework info iteration 7 generating 2500 transactions 1 1 0 testframework info iteration 8 generating 2500 transactions 2 1 0 testframework info iteration 9 generating 2500 transactions 3 1 0 testframework info iteration 10 generating 2500 transactions 4 1 0 testframework info iteration 11 generating 2500 transactions 4 1 0 testframework info iteration 12 generating 2500 transactions 4 1 0 testframework info iteration 13 generating 2500 transactions 4 1 0 testframework info iteration 14 generating 2500 transactions 5 2 0 testframework info iteration 15 generating 2500 transactions 5 2 0 testframework info iteration 16 generating 2500 transactions 5 3 0 testframework info iteration 17 generating 2500 transactions 6 3 0 testframework info iteration 18 generating 2500 transactions 6 3 0 testframework info iteration 19 generating 2500 transactions 6 3 0 testframework info iteration 20 generating 2500 transactions 6 3 0 testframework info iteration 21 generating 2500 transactions 6 3 0 testframework info iteration 22 generating 2500 transactions 6 4 0 testframework info iteration 23 generating 2500 transactions 7 4 0 testframework info iteration 24 generating 2500 transactions 7 5 0 testframework info iteration 25 generating 2500 transactions 7 5 0 testframework info iteration 26 generating 2500 transactions 8 6 0 testframework info iteration 27 generating 2500 transactions 8 6 0 testframework info iteration 28 generating 2500 transactions 9 7 0 testframework info iteration 29 generating 2500 transactions 9 7 0 testframework info iteration 30 generating 2500 transactions 9 7 0 testframework info iteration 31 generating 2500 transactions 10 7 0 testframework info iteration 32 generating 2500 transactions 10 8 0 testframework info iteration 33 generating 2500 transactions 10 8 0 testframework info iteration 34 generating 2500 transactions 11 8 0 testframework info iteration 35 generating 2500 transactions 12 8 0 testframework info iteration 36 generating 2500 transactions 12 8 0 testframework info iteration 37 generating 2500 transactions 12 8 0 testframework info iteration 38 generating 2500 transactions 12 8 0 testframework info iteration 39 generating 2500 transactions 12 8 0 testframework error unexpected exception caught during testing traceback most recent call last file line 108 in request return selfgetresponse file line 166 in getresponse httpresponse selfconngetresponse file line 1347 in getresponse responsebegin file line 307 in begin version status reason selfreadstatus file line 276 in readstatus raise end closed connection without remote end closed connection without response during handling of the above exception another exception occurred traceback most recent call last file line 133 in main selfruntest file line 263 in runtest file line 106 in rescanutxos res file line 49 in call returnval kwargs file line 142 in call response status selfrequestpost selfurlpath postdataencodeutf8 file line 113 in request path postdata headers file line 1255 in request url body headers encodechunked file line 1301 in sendrequest selfendheadersbody file line 1250 in endheaders file line 1010 in sendoutput selfsendmsg file line 950 in send selfconnect file line 921 in connect selfsock selfcreateconnection file line 843 in createconnection raise err file line 831 in createconnection sockconnectsa errno 111 connection refused testframework info stopping nodes testframeworknode3 error unable to stop node traceback most recent call last file line 336 in stopnode selfstopwaitwait file line 49 in call returnval kwargs file line 142 in call response status selfrequestpost selfurlpath postdataencodeutf8 file line 107 in request path postdata headers file line 1255 in request url body headers encodechunked file line 1266 in sendrequest selfputrequestmethod url skips file line 1092 in putrequest raise requestsent node 3 cleaning up leftover process stderr traceback most recent call last file line 288 in file line 156 in main exitcode selfshutdown file line 311 in shutdown selfstopnodes file line 571 in stopnodes nodewaituntilstopped file line 382 in waituntilstopped timeouttimeout file line 265 in waituntilhelper if predicate file line 372 in isnodestopped assert returncode 0 selfnodemsg assertionerror node 3 node returned nonzero exit code 9 when stopping try failed tests individually python3 featureblockpy testframework info test reorging blocks with opreturn in them testframework info test a reorg of one weeks worth of blocks 1088 blocks killed i didnt terminate not sure why this was killed python3 featuredbcrashpy testframework info iteration 39 generating 2500 transactions 14 6 5 testframework info verifying utxo hash matches for all nodes testframework info restarted nodes 14 6 5 crashes on restart 19 testframework info stopping nodes testframework info cleaning up on exit testframework info tests successful this succeeds when tested individually python3 featurepruningpy testframework info done testframework info stopping nodes testframework info cleaning up on exit testframework info tests successful this also succeeds python3 testrunnerpy successful bitcoinqt opens as expected machine details qubes 41 up to date debian 11 standard vm coreboot 414 x86"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIssues with compiling Bitcoin using the Depends folder Bitcoin Core version 23.0\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue hello everyone i have ran into a make host issue while doing the steps needed to compile bitcoin on my computer below is a screenshot of the situation and the steps detailed i used to get this program working for another reference i followed the steps to compile bitcoin from these links the screen shot below shows everything else thank you for your time new bitcoin issue expected behavior to compile normally to finish compiling the core on my laptop actual behavior a makefile error to reproduce system information i am using bitcoin core 230 i am using windows 11 as my operating system and wsl for the terminal"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBitcoin core will not compile on Windows 11\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue any report issue or feature request related to the gui should be reported at i have ran into several issues during my compiling of bitcoin i have tried to compile this thing but each time i try to do so there is a new issue for reference i am using ubuntu bash terminal to compile bitcoin my operating system is windows 11 and i have tried everything i know to troubleshoot this issue i have downloaded clang mingw g and i will attach the a photo to explain this issue each time i try to use the configure autogensh and sudo make there seems to be issues and this will not compile at all any help will be greatly appreciated thank you ps i have also created a virtual environment and i have installed the necessary tools for it as well bitcoin error i expected the bitcoin core to compile the version of bitcoin core is version 230 i have forked it from the bitcoin github bitcoin page i am using an asus x555y series laptop my operating system is windows 11 configlog"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nwalletpassphrase gives error \"must request wallet RPC through /wallet/<filename>\"\nwhen issuing an rpc for walletpassphrase the following error is returned file not specified must request wallet rpc through wallet uripathid0 documentation from here states sample call looks like this as a jsonrpc call curl user myusername databinary jsonrpc 10 id curltest method walletpassphrase params my pass phrase 60 h contenttype textplain eg no wallet in the rpc further my issue stems from wallet names with embedded spaces for example encrypted with space qt allows for the creation of wallet names with spaces and other characters which are not valid in a uri at least as plain text the cli functions as expected when issued with the rpcwallet parameter and allows for spaces because the wallet name is enclosed in double quotes at a minimum the docs should reflect the proper usage of the rpc call however its unclear how support for wallet names with internal spaces would be supported at all given the current design a better design would be to add the wallet name as a parameter in the array to avoid using different uris which is inconsistent with the usage of all other rpcs in core btc 021"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMultiplication result may overflow\ni believe there is chance of overflow due to multiplication in this line of code"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nwallet address issue \ngood time i have bitcoin core wallet fully update it whenever i try to do sending using the wallet the address box alwayes become red color how this issue can be resolved pls i need help thank u so much"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCannot sync with limited RAM and Swap\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue any report issue or feature request related to the gui should be reported at while syncing headers with bitcoinqt my device runs out of memory i have a computer with only 1gb of ram and no swap while syncing headers it runs out of memory approximately 600000 headers is where it runs out i expected to be able to sync all the headers and then start downloadingverifying the blockchain while syncing the headers my device runs out of memory i can reproduce this issue every time simply start the bitcoinqt application and wait until it runs out of memory at approximately 600000 headers debian package 2201 orange pi one cpu h3 quadcore cortexa7 h265hevc 4k drive 256gb microsd this issue is probably caused because all the headers are stored in ram eventually this will become a problem with common lower end computers even if they have swap when the index becomes too large it is an important issue to consider so that cheap nodes can be run in third world countries to ensure good decentralization of the network"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUbuntu Jammy can't compile fuzz tests with libc++?\nsteps to reproduce on a fresh ubuntu install export apt update apt install curl wget htop git vim ccache y git clone bitcoincore cd bitcoincore apt install buildessential libtool autotoolsdev automake pkgconfig bsdmainutils python3zmq libeventdev libboostsystemdev libboosttestdev clang llvm libcdev libcabidev y autogensh configure ccclang cxxclang stdliblibc enablefuzz withsanitizersfuzzer make jnproc ubuntu focal passes ubuntu jammy fails checking whether the linker accepts fsanitizefuzzer no configure error linker did not accept requested flags you are missing required libraries"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDoes the Txcount obtained by getwalletinfo represent the number of transaction hashes?\nthe length of the array obtained by listtransaction and the value obtained by txcount are different careful observation revealed duplicate txids"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nimportprivkey - This type of wallet does not support this command\nwhen i run importprivkey it returns unsupported wallet instead of importing code bitcoincli importprivkey privkey label false error code 4 error message this type of wallet does not support this command version bitcoincli version bitcoin core rpc client version v229909d099b02d8f0 node fully synced full node chain main blocks 716934 headers 716934 verification progress 999999 difficulty 2427233199697997 image"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCannot install Bitcoin v22.0 on Ubuntu 20.04 with current Berkeley DB version (18.1.4)\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue a fresh install of bitcoin v220 is not going through on ubuntu 2004 with an underlying fresh install of berkeley db version 1814 the same error was obtained on two completely unrelated systems expected behavior no error on installation actual behavior the following error console making all in src make1 entering directory make2 entering directory make3 entering directory make3 leaving directory cxxld bitcoind usrbinld in function repmgrnetctext0x247 undefined reference to usrbinld repmgrnetctext0x252 undefined reference to usrbinld repmgrnetctext0x25d undefined reference to x509storectxgeterror usrbinld repmgrnetctext0x28c undefined reference to x509getissuername usrbinld repmgrnetctext0x29c undefined reference to x509nameoneline usrbinld repmgrnetctext0x2be undefined reference to x509getsubjectname usrbinld repmgrnetctext0x2ce undefined reference to x509nameoneline usrbinld repmgrnetctext0x2f0 undefined reference to usrbinld in function repmgrnetctext0x446 undefined reference to sslfree usrbinld in function repmgrsetsslctx repmgrnetctext0x138d undefined reference to opensslinitssl usrbinld repmgrnetctext0x1399 undefined reference to opensslinitssl usrbinld repmgrnetctext0x13a5 undefined reference to opensslinitcrypto usrbinld repmgrnetctext0x13b1 undefined reference to tlsmethod usrbinld repmgrnetctext0x13b9 undefined reference to sslctxnew usrbinld repmgrnetctext0x13d9 undefined reference to sslctxsetverify usrbinld repmgrnetctext0x13f6 undefined reference to sslctxsetcipherlist usrbinld repmgrnetctext0x147b undefined reference to usrbinld repmgrnetctext0x14ee undefined reference to usrbinld repmgrnetctext0x1502 undefined reference to usrbinld repmgrnetctext0x1512 undefined reference to usrbinld repmgrnetctext0x1530 undefined reference to usrbinld repmgrnetctext0x1541 undefined reference to usrbinld repmgrnetctext0x1584 undefined reference to sslctxsetverifydepth usrbinld repmgrnetctext0x1600 undefined reference to sslctxfree usrbinld repmgrnetctext0x174d undefined reference to sslctxfree usrbinld in function repmgrsslaccept repmgrnetctext0x1842 undefined reference to sslnew usrbinld repmgrnetctext0x1858 undefined reference to sslsetfd usrbinld repmgrnetctext0x1874 undefined reference to errclearerror usrbinld repmgrnetctext0x187c undefined reference to sslaccept usrbinld repmgrnetctext0x18cf undefined reference to sslisinitfinished usrbinld repmgrnetctext0x18fb undefined reference to errprinterrorsfp usrbinld repmgrnetctext0x1905 undefined reference to sslgeterror usrbinld repmgrnetctext0x19c0 undefined reference to sslfree usrbinld repmgrnetctext0x19c5 undefined reference to errclearerror usrbinld in function repmgrsslconnect repmgrnetctext0x1c53 undefined reference to sslnew usrbinld repmgrnetctext0x1c71 undefined reference to sslsetfd usrbinld repmgrnetctext0x1c76 undefined reference to errclearerror usrbinld repmgrnetctext0x1c7e undefined reference to sslconnect usrbinld repmgrnetctext0x1cd8 undefined reference to sslisinitfinished usrbinld repmgrnetctext0x1cfb undefined reference to errprinterrorsfp usrbinld repmgrnetctext0x1d06 undefined reference to sslgeterror usrbinld repmgrnetctext0x1d5c undefined reference to sslnew usrbinld repmgrnetctext0x1e7a undefined reference to sslfree usrbinld in function repmgrsslshutdown repmgrnetctext0x20c4 undefined reference to errclearerror usrbinld repmgrnetctext0x20cc undefined reference to sslshutdown usrbinld repmgrnetctext0x20f3 undefined reference to sslshutdown usrbinld repmgrnetctext0x20fb undefined reference to sslfree usrbinld repmgrnetctext0x221b undefined reference to errprinterrorsfp usrbinld in function repmgrsslwrite repmgrnetctext0x2d72 undefined reference to errclearerror usrbinld repmgrnetctext0x2d80 undefined reference to sslwrite usrbinld repmgrnetctext0x2e03 undefined reference to errprinterrorsfp usrbinld repmgrnetctext0x2e0e undefined reference to sslgeterror usrbinld in function repmgrsslreadv repmgrnetctext0x4e2d undefined reference to errclearerror usrbinld repmgrnetctext0x4e64 undefined reference to sslread usrbinld repmgrnetctext0x4e76 undefined reference to errprinterrorsfp usrbinld repmgrnetctext0x4e82 undefined reference to sslgeterror usrbinld repmgrnetctext0x4eb6 undefined reference to sslshutdown usrbinld repmgrnetctext0x4ffa undefined reference to sslpending usrbinld repmgrnetctext0x5042 undefined reference to sslpending usrbinld repmgrnetctext0x51be undefined reference to sslshutdown usrbinld in function repmgrnetctext0x5325 undefined reference to sslpending usrbinld in function repmgrconnwork undefined reference to sslpending usrbinld undefined reference to sslpending usrbinld in function repmgrreadfromsite repmgrselctext0x3e58 undefined reference to sslpending collect2 error ld returned 1 exit status make2 makefile5933 bitcoind error 1 make2 leaving directory make1 makefile16186 allrecursive error 1 make1 leaving directory make makefile821 allrecursive error 1 to reproduce i followed a flow inspired from this gist 1 install all required dependencies bash sudo apt install buildessential libtool autotoolsdev autoconf pkgconfig libssldev libboostalldev libminiupnpcdev libzmq3dev libqt5gui5 libqt5core5a libqt5dbus5 qttools5dev qttools5devtools libprotobufdev protobufcompiler libqrencodedev 2 get and install current berkeley db version bash cd mntprojectscrypto wget tar xvzf db18140targz cd db18140buildunix mkdir distconfigure disableshared enablecxx withpic prefixbdbprefix mkdir docsbdbsql docsgsgdbserver sudo make install 3 get the latest bitcoin stable version and install bash cd mntprojectscrypto git clone cd bitcoin git checkout v220 autogensh mkdir configure o2 ldflagslbdbprefixlib withgui withincompatiblebdb withzmq enablezmq 4 get the error console making all in src make1 entering directory make2 entering directory make3 entering directory make3 leaving directory cxxld bitcoind usrbinld in function repmgrnetctext0x247 undefined reference to usrbinld repmgrnetctext0x252 undefined reference to usrbinld repmgrnetctext0x25d undefined reference to x509storectxgeterror usrbinld repmgrnetctext0x28c undefined reference to x509getissuername usrbinld repmgrnetctext0x29c undefined reference to x509nameoneline usrbinld repmgrnetctext0x2be undefined reference to x509getsubjectname usrbinld repmgrnetctext0x2ce undefined reference to x509nameoneline usrbinld repmgrnetctext0x2f0 undefined reference to usrbinld in function repmgrnetctext0x446 undefined reference to sslfree usrbinld in function repmgrsetsslctx repmgrnetctext0x138d undefined reference to opensslinitssl usrbinld repmgrnetctext0x1399 undefined reference to opensslinitssl usrbinld repmgrnetctext0x13a5 undefined reference to opensslinitcrypto usrbinld repmgrnetctext0x13b1 undefined reference to tlsmethod usrbinld repmgrnetctext0x13b9 undefined reference to sslctxnew usrbinld repmgrnetctext0x13d9 undefined reference to sslctxsetverify usrbinld repmgrnetctext0x13f6 undefined reference to sslctxsetcipherlist usrbinld repmgrnetctext0x147b undefined reference to usrbinld repmgrnetctext0x14ee undefined reference to usrbinld repmgrnetctext0x1502 undefined reference to usrbinld repmgrnetctext0x1512 undefined reference to usrbinld repmgrnetctext0x1530 undefined reference to usrbinld repmgrnetctext0x1541 undefined reference to usrbinld repmgrnetctext0x1584 undefined reference to sslctxsetverifydepth usrbinld repmgrnetctext0x1600 undefined reference to sslctxfree usrbinld repmgrnetctext0x174d undefined reference to sslctxfree usrbinld in function repmgrsslaccept repmgrnetctext0x1842 undefined reference to sslnew usrbinld repmgrnetctext0x1858 undefined reference to sslsetfd usrbinld repmgrnetctext0x1874 undefined reference to errclearerror usrbinld repmgrnetctext0x187c undefined reference to sslaccept usrbinld repmgrnetctext0x18cf undefined reference to sslisinitfinished usrbinld repmgrnetctext0x18fb undefined reference to errprinterrorsfp usrbinld repmgrnetctext0x1905 undefined reference to sslgeterror usrbinld repmgrnetctext0x19c0 undefined reference to sslfree usrbinld repmgrnetctext0x19c5 undefined reference to errclearerror usrbinld in function repmgrsslconnect repmgrnetctext0x1c53 undefined reference to sslnew usrbinld repmgrnetctext0x1c71 undefined reference to sslsetfd usrbinld repmgrnetctext0x1c76 undefined reference to errclearerror usrbinld repmgrnetctext0x1c7e undefined reference to sslconnect usrbinld repmgrnetctext0x1cd8 undefined reference to sslisinitfinished usrbinld repmgrnetctext0x1cfb undefined reference to errprinterrorsfp usrbinld repmgrnetctext0x1d06 undefined reference to sslgeterror usrbinld repmgrnetctext0x1d5c undefined reference to sslnew usrbinld repmgrnetctext0x1e7a undefined reference to sslfree usrbinld in function repmgrsslshutdown repmgrnetctext0x20c4 undefined reference to errclearerror usrbinld repmgrnetctext0x20cc undefined reference to sslshutdown usrbinld repmgrnetctext0x20f3 undefined reference to sslshutdown usrbinld repmgrnetctext0x20fb undefined reference to sslfree usrbinld repmgrnetctext0x221b undefined reference to errprinterrorsfp usrbinld in function repmgrsslwrite repmgrnetctext0x2d72 undefined reference to errclearerror usrbinld repmgrnetctext0x2d80 undefined reference to sslwrite usrbinld repmgrnetctext0x2e03 undefined reference to errprinterrorsfp usrbinld repmgrnetctext0x2e0e undefined reference to sslgeterror usrbinld in function repmgrsslreadv repmgrnetctext0x4e2d undefined reference to errclearerror usrbinld repmgrnetctext0x4e64 undefined reference to sslread usrbinld repmgrnetctext0x4e76 undefined reference to errprinterrorsfp usrbinld repmgrnetctext0x4e82 undefined reference to sslgeterror usrbinld repmgrnetctext0x4eb6 undefined reference to sslshutdown usrbinld repmgrnetctext0x4ffa undefined reference to sslpending usrbinld repmgrnetctext0x5042 undefined reference to sslpending usrbinld repmgrnetctext0x51be undefined reference to sslshutdown usrbinld in function repmgrnetctext0x5325 undefined reference to sslpending usrbinld in function repmgrconnwork undefined reference to sslpending usrbinld undefined reference to sslpending usrbinld in function repmgrreadfromsite repmgrselctext0x3e58 undefined reference to sslpending collect2 error ld returned 1 exit status make2 makefile5933 bitcoind error 1 make2 leaving directory make1 makefile16186 allrecursive error 1 make1 leaving directory make makefile821 allrecursive error 1 system information bitcoin core v220 from github cf commands above tested on both ubuntu 2004 as host system no vm and ubuntu 2004 as guest system as vm please note this was highly reproducible as fresh install on two different ubuntu 2004 systems"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrpc: getnetworkinfo subversion has spurious trailing 0\nreported by k9ert confirmed on the 220x branch bitcoincli getnetworkinfo version 220000 subversion satoshi2200 cc achow101"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n'event2/buffer.h' file not found\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue any report issue or feature request related to the gui should be reported at what behavior did you expect building bitcoincore on macos bigsur 116 mac mini m1 2020 what was the actual behavior provide screenshots if the issue is guirelated make hostarmappledarwin20 fails cxx fatal error event2bufferh file not found include 1 error generated make2 error 1 make1 allrecursive error 1 make allrecursive error 1 how reliably can you reproduce the issue what are the steps to do so cd depends make cd autogensh export configure withboostboostroot make hostarmappledarwin20 what version of bitcoin core are you using where did you get it website selfcompiled etc did a git pull today nov 20 2021 what type of machine are you observing the error on oscpu and disk type macos bigsur 116 mac mini m1 2020 guirelated issue what is your operating system and its version if linux what is your desktop environment and graphical shell not a gui related issue"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nA bug: The wallet passphrase entered was incorrect\nhi im new to bitcoin so i just start to use bitcoin core on my ubuntu server i first created 2 wallet one of which is called testwallet bitcoincli createwallet testwallet false false false false true however when i try to unlock it for 60s bitcoincli rpcwallettestwallet walletpassphrase test1234567 60 error returned error code 14 error message error the wallet passphrase entered was incorrect its a little bit confusing because another one wallet seemed to be normal is it because i use one more wallets here is the environment of my machine and bitcoincore uname a linux 540050400generic 201911242031 smp mon nov 25 013510 utc 2019 x8664 x8664 x8664 gnulinux bitcoincli getnetworkinfo version 220000 subversion satoshi2200 protocolversion 70016 localservices 0000000000000409 localservicesnames network witness networklimited localrelay true timeoffset 0 networkactive true connections 10 connectionsin 0 connectionsout 10 networks name ipv4 limited false reachable true proxy false name ipv6 limited false reachable true proxy false name onion limited true reachable false proxy false name i2p limited true reachable false proxy false relayfee 000001000 incrementalfee 000001000 localaddresses warnings hope somebody could help thanks a lot"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIn file included from util/strencodings.cpp:6:0: fatal error: charconv: No such file.\nhello i have a trouble make3 выход из каталога cxx cxx bitcoindbitcoindo in file included from fatal error charconv нет такого файла или каталога include compilation terminated makefile11830 recipe for target failed make2 error 1 make2 ожидание завершения заданий… in file included from netaddressh190 from chainparamsh11 from bitcoindcpp10 fatal error charconv нет такого файла или каталога include compilation terminated what i have to do ubuntu 1804 x64 nogui"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nhow to quicken the make process after modifing the codes?\nhello i am just learning the bitcoin codes of version bitcoin020 so i compiled the codes for a very long time to generate the bitcoind and so on after a period of learning i want to modify some codes in order to verify some ideas by the way i run the bitcoin on my wsl of the windows10 however i found the makefile period is a very long time despite i only modify one sentence codes hence would you please tell me how to quicken the make process after modifing the bitcoin codes thank you very much"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n300GB of Blockchain in dir, prune is set to 20GB\ni assume its just rubbish from old client versions of bitcoin core how to identify files that are not used any more"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIs listtransactions correct? \nubuntuenvironment bitcoincli datadirbtcdir testnet rpcwallettomo2 listtransactions address category receive amount 000010000 label user1 vout 0 confirmations 12 blockhash blockheight 2062825 blockindex 91 blocktime 1627916153 txid walletconflicts time 1627915291 timereceived 1627915291 bip125replaceable no address category receive amount 000010000 label user2 vout 1 confirmations 12 blockhash blockheight 2062825 blockindex 113 blocktime 1627916153 txid walletconflicts time 1627915300 timereceived 1627915300 bip125replaceable no address category send amount 000010000 vout 1 fee 000000208 confirmations 9 blockhash blockheight 2062828 blockindex 102 blocktime 1627918629 txid walletconflicts time 1627917768 timereceived 1627917768 bip125replaceable no abandoned false address category send amount 000005000 vout 0 fee 000000141 confirmations 9 blockhash blockheight 2062828 blockindex 103 blocktime 1627918629 txid walletconflicts time 1627918027 timereceived 1627918027 bip125replaceable no abandoned false address category send amount 000001000 vout 1 fee 000000141 confirmations 3 blockhash blockheight 2062834 blockindex 25 blocktime 1627920653 txid walletconflicts time 1627920400 timereceived 1627920400 bip125replaceable no comment coomentmove abandoned false address category send amount 000001000 vout 0 fee 000000141 confirmations 2 blockhash blockheight 2062835 blockindex 78 blocktime 1627920941 txid walletconflicts time 1627920839 timereceived 1627920839 bip125replaceable no comment coomenttomove abandoned false ubuntuenvironment bitcoincli datadirbtcdir testnet rpcwallettomo2 listtransactions 3 3 address category receive amount 000010000 label user1 vout 0 confirmations 12 blockhash blockheight 2062825 blockindex 91 blocktime 1627916153 txid walletconflicts time 1627915291 timereceived 1627915291 bip125replaceable no address category receive amount 000010000 label user2 vout 1 confirmations 12 blockhash blockheight 2062825 blockindex 113 blocktime 1627916153 txid walletconflicts time 1627915300 timereceived 1627915300 bip125replaceable no address category send amount 000010000 vout 1 fee 000000208 confirmations 9 blockhash blockheight 2062828 blockindex 102 blocktime 1627918629 txid walletconflicts time 1627917768 timereceived 1627917768 bip125replaceable no abandoned false i want to skip 3 past transactions however it seems that the three latest transactions have been eliminated is this the correct behavior ideal bitcoincli listtransactions 20 100 list transactions 100 to 120 realty bitcoincli listtransactions 20 100 list transactions 0 to 20 20210802t132329z bitcoin core version v0211 release build"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCannot sign a transaction with P2WSH/P2SH while using signrawtransactionwithwallet\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue any report issue or feature request related to the gui should be reported at im creating a raw transaction using the rpc command createrawtransaction when im signing the transaction with the rpc command im receiving the following error response code 500 responsemessage internal server error response does not match scriptpubkeyid1 when im using the transaction signed and sent correctly bitcoin version 021 os linuxwindows"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRate limits for `ping` RPC\nissue what are the rate limits for ping rpc which was added in if no rate limits do we need them what behavior did you expect i was expecting some errors in bitcoind or maybe peers ban my node based on the rate limits mentioned in i added a ratelimit to rpcrequested ping so that it will limit to 1second per peer the regular automated keepalive ping is immune to this but this comment says there is no rate limit got rid of the idea of ratelimiting userrequested rpc pings that simplifies a chunk of code what was the actual behavior no errors peers did not ban my node i was sending 50100 ping per second how reliably can you reproduce the issue what are the steps to do so its easy to reproduce everyone can use different ways to send ping i used the below steps 1 run bitcoind with bitcoinconf testnet1 server1 testrpcport18444 rpcuseruser3 rpcpasswordpassword3 2 use intruder in burp suite to brute force and send ping rpc with different id in each request request post http11 host 12700118444 authorization basic dxnlcjm6cgfzc3dvcmqz contenttype textplain contentlength 68 jsonrpc 10 id curltest method ping params 3 check peers with netinfo and getpeerinfo keep an eye on bitcoind for errors bitcoincli netinfo bitcoin core v21990bb4790816d84 testnet 70016satoshi21990 ipv4 ipv6 onion total block in 0 0 1 1 out 6 0 4 10 2 total 6 0 5 11 local addresses port 18333 score 4 getpeerinfo requests sent at 06 jul 2021 172801 gmt 72111 72028 83 first image last image bitcoin core version bitcoin core v21990bb4790816d84 had compiled yesterday for testing pr 17355 what type of machine are you observing the error on oscpu and disk type linux popos as vm related question"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nthe 2 block relay connections don't seem to be providing any value\nin all my time running the code where 2 block relays are allocated i have never seen them receiving any blocks its always the full relay nodes that are receiving the blocks perhaps i am misunderstanding the purpose of these 2 connections but so far i am seeing no benefit in them my understanding was that they were in some way more likely to be ready to receive a block than the full delay nodes but this is not what happens from several weeks of observation"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNeed help understanding parts of span.h\nhi in spanh you define a strange macro could someone please tell me the reasoning behind this it doesnt seem to be mentionned in the comments maybe i overlooked it the reason i dont understand is that it as far as i know does not have to change anything whatsoever in terms of code generation static initialization can happen without constexpr in fact its a sneaky way to introduce bugs whenever you have a global stdmap… its a lot of fun but i digress then we have this now im very confused is this checking if an incomplete type is convertible to another incomplete type i dont know how that template could possibly do anything else its not checking if t is implicitly convertible to c is it i dont know what that does why is it only constexpr when not in debug why is it only doing this rather important looking assertion in debug does it become valid to violate that assertion in prod why it seems odd and bug prone thank you for your time"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nEXCEPTION: N5boost10filesystem16filesystem_errorE\ni got this message when i run bitcoind exception boost filesytem createdirectory file exists homesatsbitcoin bitcoind chainparambasecpp36 const cbasechainparams base params assertion failed aborted core dumped any ideas whats happening"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhy don't we have more checkpoints?\nis your feature request related to a problem please describe srcchainparamscpp146 has few checkpoints for the mainnet using a table of block and blockhash why does it end at block 295000 describe the solution youd like either add a comment with an explanation for given number checkpoints or add checkpoints at an agreed block interval describe alternatives youve considered additional context screen shot 20210509 at 8 58 49 am"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFailed to start bitcoind using Ubuntu 20.10\nhey i keep getting this error when i run sudo systemctl start bitcoindservice job for bitcoindservice failed because the control process exited with error code see systemctl status bitcoindservice and journalctl xe for details when i input sudo journalctl xe i get this ░░ the job identifier is 6033 abr 15 161636 satsdesktop bitcoind7207 error error parsing command line arguments invalid parameter daemonwait abr 15 161636 satsdesktop systemd1 bitcoindservice control process exited codeexited status1failure ░░ subject unit process exited ░░ definedby systemd ░░ support ░░ ░░ an execstart process belonging to unit bitcoindservice has exited ░░ ░░ the process exit code is exited and its exit status is 1 abr 15 161636 satsdesktop systemd1 bitcoindservice failed with result exitcode ░░ subject unit failed ░░ definedby systemd ░░ support ░░ ░░ the unit bitcoindservice has entered the failed state with result exitcode abr 15 161636 satsdesktop systemd1 failed to start bitcoin daemon ░░ subject a start job for unit bitcoindservice has failed ░░ definedby systemd ░░ support ░░ ░░ a start job for unit bitcoindservice has finished with a failure ░░ ░░ the job identifier is 6033 and the job result is failed abr 15 161636 satsdesktop systemd1 bitcoindservice scheduled restart job restart counter is at 5 ░░ subject automatic restarting of a unit has been scheduled ░░ definedby systemd ░░ support ░░ ░░ automatic restarting of the unit bitcoindservice has been scheduled as the result for ░░ the configured restart setting for the unit abr 15 161636 satsdesktop systemd1 stopped bitcoin daemon ░░ subject a stop job for unit bitcoindservice has finished ░░ definedby systemd ░░ support ░░ ░░ a stop job for unit bitcoindservice has finished ░░ ░░ the job identifier is 6113 and the job result is done abr 15 161636 satsdesktop systemd1 bitcoindservice start request repeated too quickly abr 15 161636 satsdesktop systemd1 bitcoindservice failed with result exitcode ░░ subject unit failed ░░ definedby systemd ░░ support ░░ ░░ the unit bitcoindservice has entered the failed state with result exitcode abr 15 161636 satsdesktop systemd1 failed to start bitcoin daemon ░░ subject a start job for unit bitcoindservice has failed ░░ definedby systemd ░░ support ░░ ░░ a start job for unit bitcoindservice has finished with a failure ░░ ░░ the job identifier is 6113 and the job result is failed lines 184118941894 end when i input systemctl status bitcoindservice i get this bitcoindservice bitcoin daemon loaded loaded enabled vendor preset enabled active failed result exitcode since thu 20210415 141316 cest 21min ago docs process 5604 daemonwait codeexited status1failure abr 15 141316 satsdesktop systemd1 bitcoindservice scheduled restart job restart counter is at 5 abr 15 141316 satsdesktop systemd1 stopped bitcoin daemon abr 15 141316 satsdesktop systemd1 bitcoindservice start request repeated too quickly abr 15 141316 satsdesktop systemd1 bitcoindservice failed with result exitcode abr 15 141316 satsdesktop systemd1 failed to start bitcoin daemon some idea how can i solve the problem"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPSBT strange behavior\nhi i am trying to setup a coldcard to work airgapped with bitcoin core via sd card latest bitcoin core 0210 and latest coldcard firmware used expected behavior i create a watchonly nondescriptor wallet and i execute the importmulti command created by coldcard 2x5000 addresses i do a two simple 1in 1 out test transactions mainnet all looks good core exports the psbt file 600 bytes coldcard signs it and creates the final txn 400 bytes all good i believe the exported unsigned psbt should stay small but its not actual behavior nothing changed i mean core closed and reopened few hours later thats all new tx arrives in trying to do the same spend and psbt export exported psbt file is now 176 kilobytes see attached partial file psbtpartialtxt takes minutes while coldcard digs through all of that and finally signs the one used and produces a 400 bytes txn with the one input one output nothing fancy is going on no multisig used no nothing why does core include a lotall addresses in a psbt also its not doing it at the beginning to reproduce create a watchonly nondescriptor wallet and i execute the importmulti command created by coldcard 2x5000 addresses importdescriptors range 0 5000 timestamp now active true watchonly true desc internal false range 0 5000 timestamp now active true watchonly true desc internal true check you received the correct addresses from core make two receive and send full amount transaction tofrom on other wallet now you should see the huge psbt file now i have done this from scratch with bip44 and bip84 addresses and both suffer from the same issue system information core v0210 from download amd 2920x win10 x64"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBitcoins im jahr  2009 hier angelegt   komme nicht mehr  drauf zu\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue expected behavior actual behavior to reproduce system information"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUse of testmempoolaccept is not clear. testmempoolaccept yields unexpected error.\nexpected behavior i would expect to get no error message when using testmempoolaccept on a raw transaction that decodes just fine using decoderawtransaction or at least a hint at what went wrong actual behavior getrawtransaction decoderawtransaction txid testmempoolaccept error error parsing json to reproduce probably always reproducible with confirmed transactions system information bitcoin core 0181 tgz 0200 snap and tgz"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCannot generate change address on descriptor wallets.\ni am trying to create an unsigned transaction in a wallet that contains a 3 of 7 public key descriptor expected behavior to be able to send half a utxo and bitcoin core to handle the change address generation actual behavior instead i get this error on clicking create unsigned transaction needs a change address but we cant generate it please call keypoolrefill first to reproduce to create descriptor 1 create a standard wallet using bitcoin core 2 run getnewaddress to generate an address 3 run dumpprivkey using the address previously generated to get a wif key 4 xor the wif key with 256 1s to create a unique keynot to add security or randomness 4 create a new standard wallet and run sethdseed with the modified wif key 5 dump the second wallet to get the xpriv 6 repeat steps 25 to generate 7 xprivs 7 using the xprivs create the 3 of 7 descriptor example below remove from the above string 8 in the first wallet run getdescriptorinfo to both generate the checksum for the xpriv descriptor and the xpub descriptor itself to reproduce error 1 create a descriptor wallet with disabled private keys 2 import the public key descriptor with importdescriptors example bellow importdescriptors timestamp now active true remove from the above string 3 click create new receiving address in the bitcoin core ui 4 send a small amount to the address 5 in the send tab enter a recipient and then attempt to send half of the original amount sent to the address 6 you should get an error transaction needs a change address but we cant generate it please call keypoolrefill first system info i am using ubuntu 20 with bitcoin core 0210 rc3"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCan't sync signet using 0.21-rc3\ni downloaded from bitcoincoreorgbin and ran it with no prior bitcoin folder output bitcoind signet 20201212t153904z bitcoin core version v0210rc3 release build 20201212t153904z signet derived magic message start 0a03cf40 20201212t153904z assuming ancestors of block have valid signatures 20201212t153904z setting 20201212t153904z using the sha256 implementation 20201212t153904z using rdseed as additional entropy source 20201212t153904z using rdrand as an additional entropy source 20201212t153904z default data directory hometwitchbitcoin 20201212t153904z using data directory 20201212t153904z config file not found skipping 20201212t153904z commandline arg signet 20201212t153904z using at most 125 automatic connections 1024 file descriptors available 20201212t153904z using 16 mib out of 322 requested for signature cache able to store 524288 elements 20201212t153904z using 16 mib out of 322 requested for script execution cache able to store 524288 elements 20201212t153904z script verification uses 7 additional threads 20201212t153905z scheduler thread start 20201212t153905z http creating work queue of depth 16 20201212t153905z using random cookie authentication 20201212t153905z generated rpc authentication cookie 20201212t153905z http starting 4 worker threads 20201212t153905z using wallet directory 20201212t153905z init message verifying wallets 20201212t153905z init message loading banlist 20201212t153905z error deserializefiledb failed to open file 20201212t153905z invalid or missing banlistdat recreating 20201212t153905z setnetworkactive true 20201212t153905z using 16 prefix for ip bucketing 20201212t153905z cache configuration 20201212t153905z using 20 mib for block index database 20201212t153905z using 80 mib for chain state database 20201212t153905z using 4400 mib for inmemory utxo set plus up to 2861 mib of unused mempool space 20201212t153905z init message loading block index 20201212t153905z switching active chainstate to chainstate ibd height 1 null 20201212t153905z opening leveldb in 20201212t153905z opened leveldb successfully 20201212t153905z using obfuscation key for 0000000000000000 20201212t153905z loadblockindexdb last block file 0 20201212t153905z loadblockindexdb last block file info size0 heights00 time1970010119700101 20201212t153905z checking all blk files are present 20201212t153905z initializing databases 20201212t153905z preallocating up to position 0x1000000 in blk00000dat 20201212t153905z opening leveldb in 20201212t153905z opened leveldb successfully 20201212t153905z wrote new obfuscate key for 170005111e9356f3 20201212t153905z using obfuscation key for 170005111e9356f3 20201212t153905z init message rewinding blocks 20201212t153905z block index 34ms 20201212t153905z loadblk thread start 20201212t153905z updatetip new height0 version0x00000001 log2work22206105 tx1 date20200901t000000z progress0000064 cache00mib0txo 20201212t153905z block tree size 1 20201212t153905z nbestheight 0 20201212t153905z failed to open mempool file from disk continuing anyway 20201212t153905z loadblk thread exit 20201212t153905z torcontrol thread start 20201212t153905z bound to 38333 20201212t153905z bound to 000038333 20201212t153905z bound to 12700138334 20201212t153905z init message loading p2p addresses 20201212t153905z error deserializefiledb failed to open file 20201212t153905z invalid or missing peersdat recreating 20201212t153905z error deserializefiledb failed to open file 20201212t153905z 0 blockrelayonly anchors will be tried for connections 20201212t153905z init message starting network threads 20201212t153905z dnsseed thread start 20201212t153905z loading addresses from dns seed 2a017c8d0053905 20201212t153905z net thread start 20201212t153905z init message done loading 20201212t153905z opencon thread start 20201212t153905z addcon thread start 20201212t153905z msghand thread start 20201212t153905z loading addresses from dns seed 178128221177 20201212t153905z loading addresses from dns seed 20201212t153905z 0 addresses found from dns seeds 20201212t153905z dnsseed thread exit 20201212t153906z new outbound peer connected version 70016 blocks15726 peer0 fullrelay 20201212t153906z cannot create socket for unsupported network 20201212t154006z adding fixed seed nodes as dns doesnt seem to be available if i switch back to rc2 it works fine i expect rc3 to sync but it doesnt"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ngeneratetoaddress blocks don't include tx'es from mempool\ni mined in offline mode 101 test blocks then i try to send some test coins on other wallet coins stay unconfirmed even after 14 new blocks made by generatetoaddress command in console expected behavior generated blocks by command generatetoaddress include txes from mempool actual behavior all new blocks made by generatetoaddress command have only one tx it dont use mempool to reproduce 1 run new installation of bitcoin core in offline mode 2 generate 101 blocks by command in console generatetoaddress 102 getnewaddress 1 3 create new wallet and send some coins on it 4 generate more blocks by command in console generatetoaddress 10 getnewaddress 1 system information v01901"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncompile_commands.json generated ERROR with ccls under VIM mode\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue autogensh configure withoutgui compliedb n make when i use vim to open the project the are some warning information display as follow wx20201111174002 which are all about c standard library does it have relationship to makefile which was auto generated by autopensh expected behavior no error display actual behavior to reproduce system information bitcoin version commitid"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQ: cs_main protection for referencing m_blockman/g_chainman?\nwhile making my deglobalize chainstatemanager changes i noticed something that i wasnt sure what to make of both the global instance of chainstatemanager gchainman and the blockmanager member of gchainman are protected by csmain this means that changes like the following where im simply passing a blockmanager to a function have to add an awkward withlock in order to appease thread safety analysis examples 1 d227dfe 20158 2 f8e91ed 20158 however im not entirely sure if these csmain protections should be required for referencing these objects themselves especially since chainstatemanager and blockmanagerss member variablesfunctions are already well annotated wre locks any insights would be useful"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTest Failure in Alpine Linux - 'Ensure adding witness outputs with uncompressed pubkeys fails'\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue expected behavior pass the test actual behavior failed the test to reproduce run make check creates a new transaction with a single 2of3 multisig in a p2wsh output creates a new transaction with a single 2of3 multisig in a p2wsh output output in json creates a new transaction with a single 2of3 multisig in a p2wsh output wrapped in p2sh creates a new transaction with a single 2of3 multisig in a p2wsh output wrapped in p2sh output in json uncompressed pubkeys should work just fine for nonwitness outputs ensure adding witness outputs with uncompressed pubkeys fails make3 makefile19028 checklocal error 1 make3 leaving directory make2 makefile17578 checkam error 2 make2 leaving directory make1 makefile17263 checkrecursive error 1 make1 leaving directory make makefile781 checkrecursive error 1 error bitcoin check failed system information bitcoin 0201 alpine linux edge 3121 currently lxc container"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbitcoin-cli does not include wallet functionalities when compiling dependencies\nbehavior when compiling bitcoin on linux 64bit ubuntu 20041 lts git clone git checkout v0201 autogensh cd depends make noqt1 cd configure withguino disabletests disableguitests make make install getnewaddress expected behaviour shows getnewaddress help actual behaviour error code 32601 error message method not found none of the wallet commands are available i understand that the wallet feature should enabled by default did i mess up a step configlog this file contains any messages produced by compilers while running configure to aid debugging if configure makes a mistake it was created by bitcoin core configure 0201 which was generated by gnu autoconf 269 invocation command line was configure withguino disabletests disableguitests enablewallet platform hostname nuc uname m x8664 uname r 54047generic uname s linux uname v 51ubuntu smp fri sep 4 195052 utc 2020 usrbinuname p unknown binuname x unknown binarch unknown usrbinarch k unknown usrconvexgetsysinfo unknown usrbinhostinfo unknown binmachine unknown usrbinoslevel unknown binuniverse unknown path homedantebin path varlibgems18bin path homedantecargobin path homedantebin path homedantebin path varlibgems18bin path usrlocalsbin path usrlocalbin path usrsbin path usrbin path sbin path bin path usrgames path usrlocalgames path snapbin path sbin path path sbin path usrlocalscripts path usrlocalbin path homedantegobin path sbin path path sbin path usrlocalscripts path usrlocalbin core tests configure2943 loading site script dependsprefixdirname acsitefile crosscompilingmaybe if test z withboost then fi if test z withqtplugindir then fi if test z withqttranslationdir then fi if test z withqtbindir test z 1 then fi if test z withqrencode test n then withqrencodeno fi if test z enablewallet test n then enablewalletno fi if test z withminiupnpc test n then withminiupnpcno fi if test z withgui test n 1 then withguino fi if test z enablezmq test n then enablezmqno fi if test xlinux xdarwin then brewno portno fi if test xlinux xmingw32 then if test z withqtincdir then fi if test z withqtlibdir then fi fi pkgconfigwhich pkgconfig static these two need to remain exported because pkgconfig does not see them otherwise that means they must be unexported at the end of configureac to avoid ruining the cache sigh export if test z then export fi cppflags ldflags if test n gcc m64 a z cc then ccgcc m64 fi if test n g m64 a z cxx then cxxg m64 fi if test n ar then arar accvpathacptarar fi if test n ranlib then ranlibranlib fi if test n nm then nmnm accvpathacptnmnm fi if test n then fi if test n pipe o2 then cflagspipe o2 cflags fi if test n pipe o2 then cxxflagspipe o2 cxxflags fi if test n then cppflags cppflags fi if test n then ldflags ldflags fi configure3088 checking build system type configure3102 result x8664pclinuxgnu configure3122 checking host system type configure3135 result x8664pclinuxgnu configure3178 checking for a bsdcompatible install configure3246 result usrbininstall c configure3257 checking whether build environment is sane configure3312 result yes configure3369 checking for x8664pclinuxgnustrip configure3399 result no configure3409 checking for strip configure3425 found usrbinstrip configure3436 result strip configure3461 checking for a threadsafe mkdir p configure3500 result binmkdir p configure3507 checking for gawk configure3523 found usrbingawk configure3534 result gawk configure3545 checking whether make sets make configure3567 result yes configure3596 checking whether make supports nested variables configure3613 result yes configure3732 checking whether to enable maintainerspecific portions of makefiles configure3741 result yes configure3766 checking whether make supports nested variables configure3783 result yes configure3912 checking for c compiler version configure3921 g m64 version 5 g ubuntu 93010ubuntu2 930 copyright c 2019 free software foundation inc this is free software see the source for copying conditions there is no warranty not even for merchantability or fitness for a particular purpose configure3932 0 configure3921 g m64 v 5 using builtin specs collectgccg target x8664linuxgnu configured with srcconfigure v withpkgversionubuntu 93010ubuntu2 prefixusr programsuffix9 enableshared enablelinkerbuildid libexecdirusrlib enablethreadsposix libdirusrlib enablenls enableclocalegnu enablelibstdcxxdebug disablevtableverify enableplugin enabledefaultpie withsystemzlib enableobjcgcauto enablemultiarch disablewerror witharch32i686 withabim64 enablemultilib withtunegeneric withoutcudadriver buildx8664linuxgnu hostx8664linuxgnu targetx8664linuxgnu thread model posix gcc version 930 ubuntu 93010ubuntu2 configure3932 0 configure3921 g m64 v 5 g error unrecognized command line option v g fatal error no input files compilation terminated configure3932 1 configure3921 g m64 qversion 5 g error unrecognized command line option qversion did you mean version g fatal error no input files compilation terminated configure3932 1 configure3952 checking whether the c compiler works configure3974 g m64 pipe o2 conftestcpp 5 configure3978 0 configure4026 result yes configure4029 checking for c compiler default output file name configure4031 result aout configure4037 checking for suffix of executables configure4044 g m64 o conftest pipe o2 conftestcpp 5 configure4048 0 configure4070 result configure4092 checking whether we are cross compiling configure4100 g m64 o conftest pipe o2 conftestcpp 5 configure4104 0 configure4111 conftest configure4115 0 configure4103 result no configure4108 checking for suffix of object files configure4130 g m64 c pipe o2 conftestcpp 5 configure4134 0 configure4155 result o configure4159 checking whether we are using the gnu c compiler configure4178 g m64 c pipe o2 conftestcpp 5 configure4178 0 configure4187 result yes configure4196 checking whether g m64 accepts g configure4216 g m64 c g conftestcpp 5 configure4216 0 configure4257 result yes configure4283 checking whether make supports the include directive configure4298 make f confmfgnu cat confincout this is the amdoit target configure4301 0 configure4320 result yes gnu style configure4345 checking dependency style of g m64 configure4456 result gcc3 configure4494 checking whether g m64 supports c11 features with stdc11 configure4790 g m64 stdc11 c pipe o2 conftestcpp 5 configure4790 0 configure4799 result yes configure4843 checking whether stdatomic can be used without link library configure4861 g m64 stdc11 o conftest pipe o2 conftestcpp 5 configure4861 0 configure4863 result yes configure4932 checking for x8664pclinuxgnug configure4959 result g m64 stdc11 configure5028 checking for objective c compiler version configure5037 g m64 stdc11 version 5 g ubuntu 93010ubuntu2 930 copyright c 2019 free software foundation inc this is free software see the source for copying conditions there is no warranty not even for merchantability or fitness for a particular purpose configure5048 0 configure5037 g m64 stdc11 v 5 using builtin specs collectgccg target x8664linuxgnu configured with srcconfigure v withpkgversionubuntu 93010ubuntu2 prefixusr programsuffix9 enableshared enablelinkerbuildid libexecdirusrlib enablethreadsposix libdirusrlib enablenls enableclocalegnu enablelibstdcxxdebug disablevtableverify enableplugin enabledefaultpie withsystemzlib enableobjcgcauto enablemultiarch disablewerror witharch32i686 withabim64 enablemultilib withtunegeneric withoutcudadriver buildx8664linuxgnu hostx8664linuxgnu targetx8664linuxgnu thread model posix gcc version 930 ubuntu 93010ubuntu2 configure5048 0 configure5037 g m64 stdc11 v 5 g error unrecognized command line option v g fatal error no input files compilation terminated configure5048 1 configure5037 g m64 stdc11 qversion 5 g error unrecognized command line option qversion did you mean version g fatal error no input files compilation terminated configure5048 1 configure5052 checking whether we are using the gnu objective c compiler configure5071 g m64 stdc11 c conftestmm 5 g fatal error cannot execute cc1objplus execvp no such file or directory compilation terminated configure5071 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 end confdefsh int main ifndef gnuc choke me endif return 0 configure5080 result no configure5089 checking whether g m64 stdc11 accepts g configure5109 g m64 stdc11 c g conftestmm 5 g fatal error cannot execute cc1objplus execvp no such file or directory compilation terminated configure5109 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 end confdefsh int main return 0 configure5124 g m64 stdc11 c conftestmm 5 g fatal error cannot execute cc1objplus execvp no such file or directory compilation terminated configure5124 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 end confdefsh int main return 0 configure5140 g m64 stdc11 c g conftestmm 5 g fatal error cannot execute cc1objplus execvp no such file or directory compilation terminated configure5140 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 end confdefsh int main return 0 configure5150 result no configure5175 checking dependency style of g m64 stdc11 configure5284 result gcc3 configure5348 checking how to print strings configure5375 result printf configure5404 checking for x8664pclinuxgnugcc configure5431 result gcc m64 configure5700 checking for c compiler version configure5709 gcc m64 version 5 gcc ubuntu 93010ubuntu2 930 copyright c 2019 free software foundation inc this is free software see the source for copying conditions there is no warranty not even for merchantability or fitness for a particular purpose configure5720 0 configure5709 gcc m64 v 5 using builtin specs collectgccgcc target x8664linuxgnu configured with srcconfigure v withpkgversionubuntu 93010ubuntu2 prefixusr programsuffix9 enableshared enablelinkerbuildid libexecdirusrlib enablethreadsposix libdirusrlib enablenls enableclocalegnu enablelibstdcxxdebug disablevtableverify enableplugin enabledefaultpie withsystemzlib enableobjcgcauto enablemultiarch disablewerror witharch32i686 withabim64 enablemultilib withtunegeneric withoutcudadriver buildx8664linuxgnu hostx8664linuxgnu targetx8664linuxgnu thread model posix gcc version 930 ubuntu 93010ubuntu2 configure5720 0 configure5709 gcc m64 v 5 gcc error unrecognized command line option v gcc fatal error no input files compilation terminated configure5720 1 configure5709 gcc m64 qversion 5 gcc error unrecognized command line option qversion did you mean version gcc fatal error no input files compilation terminated configure5720 1 configure5724 checking whether we are using the gnu c compiler configure5743 gcc m64 c pipe o2 conftestc 5 configure5743 0 configure5752 result yes configure5761 checking whether gcc m64 accepts g configure5781 gcc m64 c g conftestc 5 configure5781 0 configure5822 result yes configure5839 checking for gcc m64 option to accept iso c89 configure5902 gcc m64 c pipe o2 conftestc 5 configure5902 0 configure5915 result none needed configure5940 checking whether gcc m64 understands c and o together configure5962 gcc m64 c conftestc o conftest2o configure5965 0 configure5962 gcc m64 c conftestc o conftest2o configure5965 0 configure5977 result yes configure5996 checking dependency style of gcc m64 configure6107 result gcc3 configure6122 checking for a sed that does not truncate output configure6186 result binsed configure6204 checking for grep that handles long lines and e configure6262 result bingrep configure6267 checking for egrep configure6329 result bingrep e configure6334 checking for fgrep configure6396 result bingrep f configure6431 checking for ld used by gcc m64 configure6498 result usrbinld configure6505 checking if the linker usrbinld is gnu ld configure6520 result yes configure6532 checking for bsd or mscompatible name lister nm configure6586 result nm configure6716 checking the name lister nm interface configure6723 gcc m64 c pipe o2 conftestc 5 configure6726 nm conftesto configure6729 output 0000000000000000 b somevariable configure6730 result bsd nm configure6733 checking whether ln s works configure6737 result yes configure6745 checking the maximum length of command line arguments configure6876 result 1572864 configure6924 checking how to convert x8664pclinuxgnu file names to x8664pclinuxgnu format configure6964 result funcconvertfilenoop configure6971 checking how to convert x8664pclinuxgnu file names to toolchain format configure6991 result funcconvertfilenoop configure6998 checking for usrbinld option to reload object files configure7005 result r configure7039 checking for configure7069 result no configure7079 checking for objdump configure7095 found usrbinobjdump configure7106 result objdump configure7138 checking how to recognize dependent libraries configure7338 result passall configure7383 checking for configure7413 result no configure7423 checking for dlltool configure7453 result no configure7483 checking how to associate runtime and link libraries configure7510 result printf sn configure7527 checking for x8664pclinuxgnuar configure7554 result ar configure7635 checking for archiver file support configure7652 gcc m64 c pipe o2 conftestc 5 configure7652 0 configure7655 ar cr libconftesta conftestlst 5 configure7658 0 configure7663 ar cr libconftesta conftestlst 5 ar conftesto no such file or directory configure7666 1 configure7665 result configure7683 checking for x8664pclinuxgnustrip configure7710 result strip configure7782 checking for configure7809 result ranlib configure7951 checking command to parse nm output from gcc m64 object configure8104 gcc m64 c pipe o2 conftestc 5 configure8107 0 configure8111 nm conftesto sed n e s abcdgirstwabcdgirstw azazazaz091 2 2p sed gnultod conftestnm configure8177 gcc m64 o conftest pipe o2 conftestc conftstmo 5 configure8180 0 configure8218 result ok configure8265 checking for sysroot configure8295 result no configure8302 checking for a working dd configure8340 result bindd configure8344 checking how to truncate binary pipes configure8359 result bindd bs4096 count1 configure8495 gcc m64 c pipe o2 conftestc 5 configure8498 0 configure8648 checking for x8664pclinuxgnumt configure8678 result no configure8688 checking for mt configure8704 found binmt configure8715 result mt configure8738 checking if mt is a manifest tool configure8744 mt configure8752 result no configure9429 checking how to run the c preprocessor configure9460 gcc m64 e conftestc configure9460 0 configure9474 gcc m64 e conftestc conftestc1010 fatal error acnonexistenth no such file or directory 10 include compilation terminated configure9474 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 end confdefsh include configure9499 result gcc m64 e configure9519 gcc m64 e conftestc configure9519 0 configure9533 gcc m64 e conftestc conftestc1010 fatal error acnonexistenth no such file or directory 10 include compilation terminated configure9533 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 end confdefsh include configure9562 checking for ansi c header files configure9582 gcc m64 c pipe o2 conftestc 5 configure9582 0 configure9655 gcc m64 o conftest pipe o2 conftestc 5 configure9655 0 configure9655 conftest configure9655 0 configure9666 result yes configure9679 checking for systypesh configure9679 gcc m64 c pipe o2 conftestc 5 configure9679 0 configure9679 result yes configure9679 checking for sysstath configure9679 gcc m64 c pipe o2 conftestc 5 configure9679 0 configure9679 result yes configure9679 checking for stdlibh configure9679 gcc m64 c pipe o2 conftestc 5 configure9679 0 configure9679 result yes configure9679 checking for stringh configure9679 gcc m64 c pipe o2 conftestc 5 configure9679 0 configure9679 result yes configure9679 checking for memoryh configure9679 gcc m64 c pipe o2 conftestc 5 configure9679 0 configure9679 result yes configure9679 checking for stringsh configure9679 gcc m64 c pipe o2 conftestc 5 configure9679 0 configure9679 result yes configure9679 checking for inttypesh configure9679 gcc m64 c pipe o2 conftestc 5 configure9679 0 configure9679 result yes configure9679 checking for stdinth configure9679 gcc m64 c pipe o2 conftestc 5 configure9679 0 configure9679 result yes configure9679 checking for unistdh configure9679 gcc m64 c pipe o2 conftestc 5 configure9679 0 configure9679 result yes configure9693 checking for dlfcnh configure9693 gcc m64 c pipe o2 conftestc 5 configure9693 0 configure9693 result yes configure9958 checking for objdir configure9973 result libs configure10237 checking if gcc m64 supports fnortti fnoexceptions configure10255 gcc m64 c pipe o2 fnortti fnoexceptions conftestc 5 cc1 warning command line option fnortti is valid for cdobjc but not for c configure10259 0 configure10272 result no configure10636 checking for gcc m64 option to produce pic configure10643 result fpic dpic configure10651 checking if gcc m64 pic flag fpic dpic works configure10669 gcc m64 c pipe o2 fpic dpic dpic conftestc 5 configure10673 0 configure10686 result yes configure10715 checking if gcc m64 static flag static works configure10743 result yes configure10758 checking if gcc m64 supports c o fileo configure10779 gcc m64 c pipe o2 o outconftest2o conftestc 5 configure10783 0 configure10805 result yes configure10813 checking if gcc m64 supports c o fileo configure10860 result yes configure10893 checking whether the gcc m64 linker usrbinld m elfx8664 supports shared libraries configure12156 result yes configure12193 checking whether lc should be explicitly linked in configure12201 gcc m64 c pipe o2 conftestc 5 configure12204 0 configure12219 gcc m64 shared fpic dpic conftesto v wlsoname wlconftest o conftest 21 bingrep lc devnull 21 configure12222 0 configure12236 result no configure12396 checking dynamic linker characteristics configure12977 gcc m64 o conftest pipe o2 wlrpath wlfoo conftestc 5 configure12977 0 configure13226 result gnulinux ldso configure13348 checking how to hardcode library paths into programs configure13373 result immediate configure13921 checking whether stripping libraries is possible configure13926 result yes configure13961 checking if libtool supports shared libraries configure13963 result yes configure13966 checking whether to build shared libraries configure13991 result yes configure13994 checking whether to build static libraries configure13998 result yes configure10797 checking how to run the c preprocessor configure10824 g m64 stdc11 e conftestcpp configure10824 0 configure10838 g m64 stdc11 e conftestcpp conftestcpp2210 fatal error acnonexistenth no such file or directory 22 include compilation terminated configure10838 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs end confdefsh include configure10863 result g m64 stdc11 e configure10883 g m64 stdc11 e conftestcpp configure10883 0 configure10897 g m64 stdc11 e conftestcpp conftestcpp2210 fatal error acnonexistenth no such file or directory 22 include compilation terminated configure10897 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs end confdefsh include configure11059 checking for ld used by g m64 stdc11 configure11126 result usrbinld m elfx8664 configure11133 checking if the linker usrbinld m elfx8664 is gnu ld configure11148 result yes configure11203 checking whether the g m64 stdc11 linker usrbinld m elfx8664 supports shared libraries configure12276 result yes configure12312 g m64 stdc11 c pipe o2 conftestcpp 5 configure12315 0 configure12796 checking for g m64 stdc11 option to produce pic configure12803 result fpic dpic configure12811 checking if g m64 stdc11 pic flag fpic dpic works configure12829 g m64 stdc11 c pipe o2 fpic dpic dpic conftestcpp 5 configure12833 0 configure12846 result yes configure12869 checking if g m64 stdc11 static flag static works configure12897 result yes configure12909 checking if g m64 stdc11 supports c o fileo configure12930 g m64 stdc11 c pipe o2 o outconftest2o conftestcpp 5 configure12934 0 configure12956 result yes configure12961 checking if g m64 stdc11 supports c o fileo configure13008 result yes configure13038 checking whether the g m64 stdc11 linker usrbinld m elfx8664 supports shared libraries configure13081 result yes configure13222 checking dynamic linker characteristics configure13979 result gnulinux ldso configure14044 checking how to hardcode library paths into programs configure14069 result immediate configure12965 checking for x8664pclinuxgnuar configure12998 result no configure13008 checking for ar configure13038 result ar configure13063 checking for configure13096 result no configure13106 checking for ranlib configure13136 result ranlib configure13161 checking for x8664pclinuxgnustrip configure13194 result no configure13204 checking for strip configure13222 found usrbinstrip configure13234 result usrbinstrip configure13259 checking for x8664pclinuxgnugcov configure13292 result no configure13302 checking for gcov configure13320 found usrbingcov configure13332 result usrbingcov configure13356 checking for lcov configure13389 result no configure13398 checking for python35 configure13416 found usrbinpython35 configure13428 result usrbinpython35 configure13441 checking for genhtml configure13474 result no configure13481 checking for git configure13499 found usrbingit configure13511 result usrbingit configure13521 checking for ccache configure13554 result no configure13561 checking for xgettext configure13594 result no configure13601 checking for hexdump configure13619 found usrbinhexdump configure13631 result usrbinhexdump configure13642 checking for configure13675 result no configure13685 checking for readelf configure13703 found usrbinreadelf configure13715 result usrbinreadelf configure13740 checking for x8664pclinuxgnucfilt configure13773 result no configure13783 checking for cfilt configure13801 found usrbincfilt configure13813 result usrbincfilt configure13838 checking for configure13871 result no configure13881 checking for objcopy configure13899 found usrbinobjcopy configure13911 result usrbinobjcopy configure13935 checking for doxygen configure13968 result no configure13974 warning doxygen not found configure14222 checking whether c compiler accepts werror configure14241 g m64 stdc11 c pipe o2 werror conftestcpp 5 configure14241 0 configure14249 result yes configure15407 checking whether c compiler accepts msse42 configure15426 g m64 stdc11 c pipe o2 werror msse42 conftestcpp 5 configure15426 0 configure15435 result yes configure15444 checking whether c compiler accepts msse41 configure15463 g m64 stdc11 c pipe o2 werror msse41 conftestcpp 5 configure15463 0 configure15472 result yes configure15481 checking whether c compiler accepts mavx mavx2 configure15500 g m64 stdc11 c pipe o2 werror mavx mavx2 conftestcpp 5 configure15500 0 configure15509 result yes configure15518 checking whether c compiler accepts msse4 msha configure15537 g m64 stdc11 c pipe o2 werror msse4 msha conftestcpp 5 configure15537 0 configure15546 result yes configure15557 checking for sse42 intrinsics configure15583 g m64 stdc11 c pipe o2 msse42 conftestcpp 5 configure15583 0 configure15584 result yes configure15596 checking for sse41 intrinsics configure15615 g m64 stdc11 c pipe o2 msse41 conftestcpp 5 configure15615 0 configure15616 result yes configure15630 checking for avx2 intrinsics configure15649 g m64 stdc11 c pipe o2 mavx mavx2 conftestcpp 5 configure15649 0 configure15650 result yes configure15664 checking for shani intrinsics configure15685 g m64 stdc11 c pipe o2 msse4 msha conftestcpp 5 configure15685 0 configure15686 result yes configure15700 checking whether c compiler accepts marcharmv8acrccrypto configure15719 g m64 stdc11 c pipe o2 werror marcharmv8acrccrypto conftestcpp 5 cc1plus error bad value armv8acrccrypto for march switch cc1plus note valid arguments to march switch are nocona core2 nehalem corei7 westmere sandybridge corei7avx ivybridge coreavxi haswell coreavx2 broadwell skylake skylakeavx512 cannonlake icelakeclient icelakeserver cascadelake bonnell atom silvermont slm goldmont goldmontplus tremont knl knm x8664 edenx2 nano nano1000 nano2000 nano3000 nanox2 edenx4 nanox4 k8 k8sse3 opteron opteronsse3 athlon64 athlon64sse3 athlonfx amdfam10 barcelona bdver1 bdver2 bdver3 bdver4 znver1 znver2 btver1 btver2 native configure15719 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 end confdefsh int main return 0 configure15728 result no configure15739 checking for arm crc32 intrinsics configure15758 g m64 stdc11 c pipe o2 conftestcpp 5 conftestcpp2714 fatal error armacleh no such file or directory 27 include compilation terminated configure15758 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 end confdefsh include include int main crc32cb0 0 crc32ch0 0 crc32cw0 0 crc32cd0 0 vmullp640 0 return 0 configure15762 result no configure17195 checking for configure17225 result usrbinpkgconfig static configure17293 checking pkgconfig is at least version 090 configure17296 result yes configure17408 checking whether byte ordering is bigendian configure17423 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp279 error expected unqualifiedid before not token 27 not a universal capable compiler configure17423 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 end confdefsh ifndef applecc not a universal capable compiler endif typedef int dummy configure17468 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure17468 0 configure17486 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp in function int main conftestcpp338 error big was not declared in this scope 33 not big endian configure17486 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 end confdefsh include include int main if byteorder bigendian not big endian endif return 0 configure17614 result no configure17816 checking whether gcc m64 is clang configure17841 result no configure17964 checking whether pthreads work with pthread configure18058 gcc m64 o conftest pipe o2 pthread dhavebuildinfo dstdcformatmacros conftestc 5 configure18058 0 configure18067 result yes configure18086 checking for joinable pthread attribute configure18104 gcc m64 o conftest pipe o2 pthread dhavebuildinfo dstdcformatmacros conftestc 5 configure18104 0 configure18112 result configure18126 checking whether more special flags are required for pthreads configure18139 result no configure18147 checking for pthreadprioinherit configure18163 gcc m64 o conftest pipe o2 pthread dhavebuildinfo dstdcformatmacros conftestc 5 configure18163 0 configure18172 result yes configure18282 checking for special c compiler options needed for large files configure18327 result no configure18333 checking for fileoffsetbits value needed for large files configure18358 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure18358 0 configure18390 result no configure18475 checking whether strerrorr is declared configure18475 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure18475 0 configure18475 result yes configure18488 checking for strerrorr configure18488 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure18488 0 configure18488 result yes configure18497 checking whether strerrorr returns char configure18521 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure18521 0 configure18559 result yes configure18583 checking for attributevisibility configure18607 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure18607 0 configure18620 result yes configure18636 checking for attributedllexport configure18657 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp3462 warning dllexport attribute directive ignored wattributes 34 attributedllexport int foo void return 0 configure18657 0 configure18670 result no configure18686 checking for attributedllimport configure18707 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp3462 warning dllimport attribute directive ignored wattributes 34 int foo void attributedllimport configure18707 0 configure18720 result no configure18840 checking for library containing clockgettime configure18871 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure18871 0 configure18888 result none required configure19019 checking whether c compiler accepts fpic configure19038 g m64 stdc11 c pipe o2 fpic dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19038 0 configure19046 result yes configure19056 checking whether c compiler accepts fstackreusenone configure19075 g m64 stdc11 c pipe o2 fstackreusenone dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19075 0 configure19083 result yes configure19093 checking whether c compiler accepts wstackprotector configure19112 g m64 stdc11 c pipe o2 wstackprotector dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19112 0 configure19120 result yes configure19128 checking whether c compiler accepts fstackprotectorall configure19147 g m64 stdc11 c pipe o2 fstackprotectorall dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19147 0 configure19155 result yes configure19165 checking whether c preprocessor accepts dfortifysource2 configure19184 g m64 stdc11 e dhavebuildinfo dstdcformatmacros dfortifysource2 conftestcpp configure19184 0 configure19192 result yes configure19196 checking whether c preprocessor accepts ufortifysource configure19215 g m64 stdc11 e dhavebuildinfo dstdcformatmacros ufortifysource conftestcpp configure19215 0 configure19223 result yes configure19241 checking whether the linker accepts wldynamicbase configure19260 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros wldynamicbase conftestcpp 5 usrbinld unrecognized option dynamicbase usrbinld use the help option for usage information collect2 error ld returned 1 exit status configure19260 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 end confdefsh int main return 0 configure19269 result no configure19277 checking whether the linker accepts wlnxcompat configure19296 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros wlnxcompat conftestcpp 5 usrbinld unrecognized option nxcompat usrbinld use the help option for usage information collect2 error ld returned 1 exit status configure19296 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 end confdefsh int main return 0 configure19305 result no configure19313 checking whether the linker accepts wlhighentropyva configure19332 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros wlhighentropyva conftestcpp 5 usrbinld unrecognized option highentropyva usrbinld use the help option for usage information collect2 error ld returned 1 exit status configure19332 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 end confdefsh int main return 0 configure19341 result no configure19349 checking whether the linker accepts wlzrelro configure19368 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros wlzrelro conftestcpp 5 configure19368 0 configure19377 result yes configure19385 checking whether the linker accepts wlznow configure19404 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros wlznow conftestcpp 5 configure19404 0 configure19413 result yes configure19422 checking whether the linker accepts fpie pie configure19441 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros werror fpie pie conftestcpp 5 configure19441 0 configure19451 result yes configure19662 checking endianh usability configure19662 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19662 0 configure19662 result yes configure19662 checking endianh presence configure19662 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp configure19662 0 configure19662 result yes configure19662 checking for endianh configure19662 result yes configure19662 checking sysendianh usability configure19662 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp6610 fatal error sysendianh no such file or directory 66 include compilation terminated configure19662 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 end confdefsh include ifdef havesystypesh include endif ifdef havesysstath include endif ifdef stdcheaders include include else ifdef havestdlibh include endif endif ifdef havestringh if defined stdcheaders defined havememoryh include endif include endif ifdef havestringsh include endif ifdef haveinttypesh include endif ifdef havestdinth include endif ifdef haveunistdh include endif include configure19662 result no configure19662 checking sysendianh presence configure19662 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp conftestcpp3310 fatal error sysendianh no such file or directory 33 include compilation terminated configure19662 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 end confdefsh include configure19662 result no configure19662 checking for sysendianh configure19662 result no configure19662 checking byteswaph usability configure19662 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19662 0 configure19662 result yes configure19662 checking byteswaph presence configure19662 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp configure19662 0 configure19662 result yes configure19662 checking for byteswaph configure19662 result yes configure19662 checking stdioh usability configure19662 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19662 0 configure19662 result yes configure19662 checking stdioh presence configure19662 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp configure19662 0 configure19662 result yes configure19662 checking for stdioh configure19662 result yes configure19662 checking for stdlibh configure19662 result yes configure19662 checking for unistdh configure19662 result yes configure19662 checking for stringsh configure19662 result yes configure19662 checking for systypesh configure19662 result yes configure19662 checking for sysstath configure19662 result yes configure19662 checking sysselecth usability configure19662 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19662 0 configure19662 result yes configure19662 checking sysselecth presence configure19662 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp configure19662 0 configure19662 result yes configure19662 checking for sysselecth configure19662 result yes configure19662 checking sysprctlh usability configure19662 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19662 0 configure19662 result yes configure19662 checking sysprctlh presence configure19662 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp configure19662 0 configure19662 result yes configure19662 checking for sysprctlh configure19662 result yes configure19662 checking syssysctlh usability configure19662 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 in file included from conftestcpp75 warning warning the header is deprecated and will be removed wcpp 21 warning the header is deprecated and will be removed configure19662 0 configure19662 result yes configure19662 checking syssysctlh presence configure19662 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp in file included from conftestcpp42 warning warning the header is deprecated and will be removed wcpp 21 warning the header is deprecated and will be removed configure19662 0 configure19662 result yes configure19662 checking for syssysctlh configure19662 result yes configure19662 checking vmvmparamh usability configure19662 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7610 fatal error vmvmparamh no such file or directory 76 include compilation terminated configure19662 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 end confdefsh include ifdef havesystypesh include endif ifdef havesysstath include endif ifdef stdcheaders include include else ifdef havestdlibh include endif endif ifdef havestringh if defined stdcheaders defined havememoryh include endif include endif ifdef havestringsh include endif ifdef haveinttypesh include endif ifdef havestdinth include endif ifdef haveunistdh include endif include configure19662 result no configure19662 checking vmvmparamh presence configure19662 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp conftestcpp4310 fatal error vmvmparamh no such file or directory 43 include compilation terminated configure19662 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 end confdefsh include configure19662 result no configure19662 checking for vmvmparamh configure19662 result no configure19662 checking sysvmmeterh usability configure19662 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7610 fatal error sysvmmeterh no such file or directory 76 include compilation terminated configure19662 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 end confdefsh include ifdef havesystypesh include endif ifdef havesysstath include endif ifdef stdcheaders include include else ifdef havestdlibh include endif endif ifdef havestringh if defined stdcheaders defined havememoryh include endif include endif ifdef havestringsh include endif ifdef haveinttypesh include endif ifdef havestdinth include endif ifdef haveunistdh include endif include configure19662 result no configure19662 checking sysvmmeterh presence configure19662 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp conftestcpp4310 fatal error sysvmmeterh no such file or directory 43 include compilation terminated configure19662 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 end confdefsh include configure19662 result no configure19662 checking for sysvmmeterh configure19662 result no configure19662 checking sysresourcesh usability configure19662 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7610 fatal error sysresourcesh no such file or directory 76 include compilation terminated configure19662 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 end confdefsh include ifdef havesystypesh include endif ifdef havesysstath include endif ifdef stdcheaders include include else ifdef havestdlibh include endif endif ifdef havestringh if defined stdcheaders defined havememoryh include endif include endif ifdef havestringsh include endif ifdef haveinttypesh include endif ifdef havestdinth include endif ifdef haveunistdh include endif include configure19662 result no configure19662 checking sysresourcesh presence configure19662 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp conftestcpp4310 fatal error sysresourcesh no such file or directory 43 include compilation terminated configure19662 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 end confdefsh include configure19662 result no configure19662 checking for sysresourcesh configure19662 result no configure19673 checking fdzero memcpy dependence configure19696 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19696 0 configure19697 result no configure19737 checking whether getifaddrs is declared configure19737 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19737 0 configure19737 result yes configure19750 checking whether freeifaddrs is declared configure19750 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19750 0 configure19750 result yes configure19764 checking whether strnlen is declared configure19764 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19764 0 configure19764 result yes configure19776 checking whether daemon is declared configure19776 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19776 0 configure19776 result yes configure19788 checking whether le16toh is declared configure19788 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19788 0 configure19788 result yes configure19803 checking whether le32toh is declared configure19803 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19803 0 configure19803 result yes configure19818 checking whether le64toh is declared configure19818 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19818 0 configure19818 result yes configure19833 checking whether htole16 is declared configure19833 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19833 0 configure19833 result yes configure19848 checking whether htole32 is declared configure19848 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19848 0 configure19848 result yes configure19863 checking whether htole64 is declared configure19863 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19863 0 configure19863 result yes configure19878 checking whether be16toh is declared configure19878 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19878 0 configure19878 result yes configure19893 checking whether be32toh is declared configure19893 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19893 0 configure19893 result yes configure19908 checking whether be64toh is declared configure19908 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19908 0 configure19908 result yes configure19923 checking whether htobe16 is declared configure19923 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19923 0 configure19923 result yes configure19938 checking whether htobe32 is declared configure19938 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19938 0 configure19938 result yes configure19953 checking whether htobe64 is declared configure19953 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19953 0 configure19953 result yes configure19970 checking whether bswap16 is declared configure19970 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19970 0 configure19970 result yes configure19983 checking whether bswap32 is declared configure19983 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19983 0 configure19983 result yes configure19996 checking whether bswap64 is declared configure19996 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure19996 0 configure19996 result yes configure20011 checking whether builtinclz is declared configure20011 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure20011 0 configure20011 result yes configure20021 checking whether builtinclzl is declared configure20021 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure20021 0 configure20021 result yes configure20031 checking whether builtinclzll is declared configure20031 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure20031 0 configure20031 result yes configure20043 checking for getmemoryinfo configure20056 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure20056 0 configure20057 result yes configure20068 checking for mallopt marenamax configure20081 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure20081 0 configure20082 result yes configure20093 checking for visibility attribute configure20102 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure20102 0 configure20107 result yes configure20126 checking for threadlocal support configure20140 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros pthread conftestcpp 5 configure20140 0 configure20155 result yes configure20172 checking for gmtimer configure20185 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure20185 0 configure20186 result yes configure20220 checking for linux getrandom syscall configure20235 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure20235 0 configure20236 result yes configure20247 checking for getentropy configure20260 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp in function int main conftestcpp7512 warning ignoring return value of int getentropyvoid sizet declared with attribute warnunusedresult wunusedresult 75 getentropynullptr 32 configure20260 0 configure20261 result yes configure20272 checking for getentropy via randomh configure20286 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp in function int main conftestcpp7712 warning ignoring return value of int getentropyvoid sizet declared with attribute warnunusedresult wunusedresult 77 getentropynullptr 32 configure20286 0 configure20287 result yes configure20298 checking for sysctl configure20315 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 in file included from conftestcpp74 warning warning the header is deprecated and will be removed wcpp 21 warning the header is deprecated and will be removed conftestcpp796 error error dont use sysctl on linux its deprecated even when it works 79 error dont use sysctl on linux its deprecated even when it works conftestcpp in function int main conftestcpp8152 warning int sysctlint int void sizet void sizet is deprecated 81 sysctlnullptr 2 nullptr nullptr nullptr 0 in file included from conftestcpp74 note declared here 70 extern int sysctl int name int nlen void oldval conftestcpp8152 warning int sysctlint int void sizet void sizet is deprecated 81 sysctlnullptr 2 nullptr nullptr nullptr 0 in file included from conftestcpp74 note declared here 70 extern int sysctl int name int nlen void oldval configure20315 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 end confdefsh include include int main ifdef linux error dont use sysctl on linux its deprecated even when it works endif sysctlnullptr 2 nullptr nullptr nullptr 0 return 0 configure20321 result no configure20327 checking for sysctl kernarnd configure20345 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 in file included from conftestcpp74 warning warning the header is deprecated and will be removed wcpp 21 warning the header is deprecated and will be removed conftestcpp796 error error dont use sysctl on linux its deprecated even when it works 79 error dont use sysctl on linux its deprecated even when it works conftestcpp in function int main conftestcpp8137 error kernarnd was not declared in this scope did you mean kernrandom 81 static int name2 ctlkern kernarnd kernrandom conftestcpp8249 warning int sysctlint int void sizet void sizet is deprecated 82 sysctlname 2 nullptr nullptr nullptr 0 in file included from conftestcpp74 note declared here 70 extern int sysctl int name int nlen void oldval conftestcpp8249 warning int sysctlint int void sizet void sizet is deprecated 82 sysctlname 2 nullptr nullptr nullptr 0 in file included from conftestcpp74 note declared here 70 extern int sysctl int name int nlen void oldval configure20345 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 end confdefsh include include int main ifdef linux error dont use sysctl on linux its deprecated even when it works endif static int name2 ctlkern kernarnd sysctlname 2 nullptr nullptr nullptr 0 return 0 configure20351 result no configure20357 checking for if type char equals int8t configure20371 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp in function int main conftestcpp7844 error static assertion failed 78 configure20371 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 end confdefsh include include int main return 0 configure20377 result no configure20383 checking for fdatasync configure20396 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure20396 0 configure20397 result yes configure20406 checking for ffullfsync configure20419 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp in function int main conftestcpp7711 error ffullfsync was not declared in this scope 77 fcntl0 ffullfsync 0 configure20419 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 end confdefsh include int main fcntl0 ffullfsync 0 return 0 configure20423 result no configure20429 checking for ocloexec configure20442 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure20442 0 configure20443 result yes configure20452 checking for builtinprefetch configure20469 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure20469 0 configure20470 result yes configure20479 checking for mmprefetch configure20496 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure20496 0 configure20497 result yes configure20506 checking for strong getauxval support in the system headers configure20525 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7414 fatal error armacleh no such file or directory 74 include compilation terminated configure20525 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 end confdefsh include include include int main getauxvalathwcap return 0 configure20529 result no configure20535 checking for weak getauxval support in the compiler configure20553 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure20553 0 configure20554 result yes configure20601 checking for stdsystem configure20615 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure20615 0 configure20616 result yes configure20628 checking for wsystem configure20642 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp in function int main conftestcpp7815 error wsystem has not been declared 78 int nerr wsystem configure20642 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 end confdefsh int main int nerr wsystem return 0 configure20648 result no configure24653 checking whether to build bitcoin core gui configure24687 result no configure24711 checking for berkeley db c headers configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error bdb48dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error libdb48dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error db48dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error bdb48dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error libdb48dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error db48dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error bdb4dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error libdb4dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error db4dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error bdb5dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error libdb5dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error db5dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error bdb53dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error libdb53dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error db53dbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error bdbdbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error libdbdbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 conftestcpp7618 fatal error dbdbcxxh no such file or directory 76 include compilation terminated configure24741 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem end confdefsh include int main if dbversionmajor 4 dbversionminor 8 dbversionmajor 4 error failed to find bdb 48 endif return 0 configure24741 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure24741 0 configure24770 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure24770 0 configure24813 result default configure24836 checking for main in ldbcxx48 configure24855 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp ldbcxx48 5 configure24855 0 configure24865 result yes configure24887 checking miniupnpcminiwgeth usability configure24887 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure24887 0 configure24887 result yes configure24887 checking miniupnpcminiwgeth presence configure24887 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp configure24887 0 configure24887 result yes configure24887 checking for miniupnpcminiwgeth configure24887 result yes configure24892 checking for upnpdiscover in lminiupnpc configure24917 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp lminiupnpc 5 configure24917 0 configure24926 result yes configure24887 checking miniupnpcminiupnpch usability configure24887 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure24887 0 configure24887 result yes configure24887 checking miniupnpcminiupnpch presence configure24887 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp configure24887 0 configure24887 result yes configure24887 checking for miniupnpcminiupnpch configure24887 result yes configure24892 checking for upnpdiscover in lminiupnpc configure24926 result yes configure24887 checking usability configure24887 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure24887 0 configure24887 result yes configure24887 checking presence configure24887 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp configure24887 0 configure24887 result yes configure24887 checking for configure24887 result yes configure24892 checking for upnpdiscover in lminiupnpc configure24926 result yes configure24887 checking miniupnpcupnperrorsh usability configure24887 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure24887 0 configure24887 result yes configure24887 checking miniupnpcupnperrorsh presence configure24887 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp configure24887 0 configure24887 result yes configure24887 checking for miniupnpcupnperrorsh configure24887 result yes configure24892 checking for upnpdiscover in lminiupnpc configure24926 result yes configure24942 checking whether miniupnpc api version is supported configure24963 g m64 stdc11 e dhavebuildinfo dstdcformatmacros conftestcpp configure24963 0 configure24965 result yes configure25080 checking for boostlib 1470 104700 includes in configure25084 result yes configure25088 checking for boostlib 1470 104700 lib path in configure25098 result no configure25088 checking for boostlib 1470 104700 lib path in configure25098 result no configure25088 checking for boostlib 1470 104700 lib path in configure25098 result no configure25088 checking for boostlib 1470 104700 lib path in configure25092 result yes configure25132 checking for boostlib 1470 104700 configure25164 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure25164 0 configure25166 result yes configure25361 checking whether the boostsystem library is available configure25386 g m64 stdc11 c dhavebuildinfo dstdcformatmacros conftestcpp 5 configure25386 0 configure25401 result yes configure25416 checking for exit in lboostsystemmtx64 configure25441 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp lboostsystemmtx64 5 conftestcpp886 warning declaration of char exit conflicts with builtin declaration void exitint 88 char exit configure25441 0 configure25451 result yes configure25606 checking whether the boostfilesystem library is available configure25630 g m64 stdc11 c pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure25630 0 configure25644 result yes configure25655 checking for exit in configure25680 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp lboostsystemmtx64 5 conftestcpp896 warning declaration of char exit conflicts with builtin declaration void exitint 89 char exit configure25680 0 configure25690 result yes configure25840 checking whether the boostthread library is available configure25873 g m64 stdc11 c pthread pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp 5 configure25873 0 configure25888 result yes configure25917 checking for exit in lboostthreadmtx64 configure25942 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros conftestcpp lboostthreadmtx64 5 conftestcpp906 warning declaration of char exit conflicts with builtin declaration void exitint 90 char exit configure25942 0 configure25952 result yes configure26404 checking for mismatched boost c11 scoped enums configure26432 g m64 stdc11 o conftest pipe o2 dhavebuildinfo dstdcformatmacros dboostspusestdatomic dboostacusestdatomic pthread conftestcpp lboostsystemmtx64 lboostthreadmtx64 lpthread 5 conftestcpp in function int main conftestcpp1005 error choke was not declared in this scope 100 choke configure26432 1 configure failed program was confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem define 1 define 1 define 1 define 1 define haveboost define haveboostsystem define haveboostfilesystem define haveboostthread end confdefsh include include if boostversion 105700 define boostnoscopedenums define define check endif include int main if definedcheck bar else choke endif return 0 configure26436 result ok configure26532 checking for event configure26539 pkgconfig exists printerrors libevent 2021 configure26542 0 configure26556 pkgconfig exists printerrors libevent 2021 configure26559 0 configure26597 result yes configure26604 checking for eventpthreads configure26611 pkgconfig exists printerrors libeventpthreads 2021 configure26614 0 configure26628 pkgconfig exists printerrors libeventpthreads 2021 configure26631 0 configure26669 result yes configure26679 checking for zmq configure26686 pkgconfig exists printerrors libzmq 4 configure26689 0 configure26703 pkgconfig exists printerrors libzmq 4 configure26706 0 configure26754 result yes configure27163 checking whether to build bitcoind configure27173 result yes configure27176 checking whether to build bitcoincli configure27186 result yes configure27189 checking whether to build bitcointx configure27199 result yes configure27202 checking whether to build bitcoinwallet configure27212 result yes configure27215 checking whether to build libraries configure27232 result yes configure27243 checking if ccache should be used configure27256 result no configure27297 checking if wallet should be enabled configure27300 result yes configure27313 checking whether to build with support for upnp configure27324 result yes configure27326 checking whether to build with upnp enabled by default configure27334 result no configure27406 checking whether to build testbitcoin configure27413 result no configure27418 checking whether to reduce exports configure27424 result no configure27836 checking that generated files are newer than configure configure27842 result done configure27998 creating configstatus running configstatus this file was extended by bitcoin core configstatus 0201 which was generated by gnu autoconf 269 invocation command line was configfiles configheaders configlinks configcommands configstatus on nuc configstatus1452 creating configstatus1452 creating makefile configstatus1452 creating srcmakefile configstatus1452 creating docmanmakefile configstatus1452 creating sharesetupnsi configstatus1452 creating shareqtinfoplist configstatus1452 creating testconfigini configstatus1452 creating configstatus1452 creating configstatus1633 is unchanged configstatus1712 executing depfiles commands configstatus1789 cd src sed e amincludemarkerd makefile make f amdepfiles make nothing to be done for amdepfiles configstatus1794 0 configstatus1712 executing libtool commands configure30523 configuring in srcunivalue configure30586 running binbash configure withguino disabletests disableguitests enablewallet disableshared withpic enablebenchmarkno withbignumno enablemodulerecovery disablejni cachefiledevnull srcdir configure30523 configuring in srcsecp256k1 configure30586 running binbash configure withguino disabletests disableguitests enablewallet disableshared withpic enablebenchmarkno withbignumno enablemodulerecovery disablejni cachefiledevnull srcdir cache variables accvcbigendianno accvccompilergnuyes accvenvarflagsset accvenvarflagsvalue accvenvbdbcflagsset accvenvbdblibsset accvenvbdblibsvalue accvenvcccset accvenvcccvalue accvenvccset accvenvccvalue accvenvcflagsset accvenvcflagsvalue accvenvcppflagsset accvenvcppflagsvalue accvenvcppset accvenvcppvalue accvenvcxxcppset accvenvcxxcppvalue accvenvcxxflagsset accvenvcxxflagsvalue accvenvcxxset accvenvcxxvalue accvenveventlibsset accvenvldflagsset accvenvldflagsvalue accvenvlibsset accvenvlibsvalue accvenvobjcxxset accvenvobjcxxvalue accvenvpkgconfigset accvenvpythonpathset accvenvqrcflagsset accvenvqrcflagsvalue accvenvqrlibsset accvenvqrlibsvalue accvenvqt5cflagsset accvenvqt5libsset accvenvqt5libsvalue accvenvqtcgllibsset accvenvqtfbcflagsset accvenvqtfblibsset accvenvqtfblibsvalue accvenvqtdbuslibsset accvenvqttestlibsset accvenvzmqcflagsset accvenvzmqlibsset accvenvzmqlibsvalue accvenvbuildaliasset accvenvhostaliasset accvfuncstrerrorryes accvheaderdlfcnhyes accvheaderendianhyes accvheadermemoryhyes accvheaderstdcyes accvheaderstdinthyes accvheaderstdiohyes accvheaderstdlibhyes accvheaderstringhyes accvheaderunistdhyes accvobjexto accvpathegrepbingrep e accvpathfgrepbingrep f accvpathgitusrbingit accvpathgrepbingrep static accvpathsedbinsed accvpathacptarar accvpathacptnmnm c accvpathltddbindd accvprogarar accvprogawkgawk accvprogccgcc m64 accvprogcppgcc m64 e accvprogcxxcppg m64 stdc11 e accvprogobjcxxg m64 stdc11 accvprogranlibranlib accvprogstripstrip accvprogccc89 accvprogccgyes accvprogcxxgyes accvprogobjcxxgno required accvsyslargefileccno amcvprogcccoyes axcvpthreadclangno axcvboostsystemyes axcvboostthreadyes ltcvaratfile ltcvldreloadflagr ltcvnminterfacebsd nm ltcvobjdirlibs ltcvpathldusrbinld m elfx8664 ltcvpathnmnm dpic dpic ltcvproggnuldyes ltcvproggnuldcxxyes sn n e s abcdgirstwabcdgirstw azazazaz091 2 2p sed gnultod n e s 1 void 0p e 1 void 1p n e s 1 void 0p e lib 1 void 1p e lib1 void 1p n e st extern int 1p e extern char 1p ltcvtruncatebinbindd bs4096 count1 levent leventpthreads levent lzmq lpthread lrt output variables aclocalshell aclocal116 amdepbackslash amdepfalse amdeptrue amtartartar ambackslash amdefaultverbosity0 amvv arar arflagscr armcrccxxflags autoconfshell autoconf autoheadershell autoheader automakeshell automake116 avx2cxxflagsmavx mavx2 awkgawk bdbcflags bdbcppflags bdblibsldbcxx48 dboostacusestdatomic pthread lboostsystemmtx64 lboostthreadmtx64 lpthread lpthread brew buildbitcoindfalse buildbitcoindtrue buildbitcoinclifalse buildbitcoinclitrue buildbitcoinlibstrue buildbitcointxfalse buildbitcointxtrue builddarwinfalse builddarwintrue ccgcc m64 ccache ccdepmodedepmodegcc3 cflagspipe o2 clientversionbuild0 clientversionmajor0 clientversionminor20 compatldflags copyrightholdersthe s developers bitcoin core developers core copyrightyear2020 cppgcc m64 e cppfiltusrbincfilt dhavebuildinfo dstdcformatmacros cxxg m64 stdc11 cxxcppg m64 stdc11 e cxxflagspipe o2 cygpathwecho debugcppflags debugcxxflags defsdhaveconfigh depdirdeps dlltoolfalse doxygen dsymutil dumpbin echoc echonn echot egrepbingrep e embeddedleveldbfalse embeddedleveldbtrue embeddedunivaluetrue enablearmcrcfalse enablearmcrctrue enableavx2false enableavx2true enablebenchfalse enablebenchtrue enablefuzzfalse enablefuzztrue enablemanfalse enablemantrue enableqtfalse enableqttestsfalse enableqtteststrue enableqttrue enableshanifalse enableshanitrue enablesse41false enablesse41true enablesse42false enablesse42true enabletestsfalse enableteststrue enablewalletfalse enablewallettrue enablezmqfalse enablezmqtrue errorcxxflags levent leventpthreads levent exeext fgrepbingrep f gcovusrbingcov genhtml genisoimage gitusrbingit glibcbackcompatfalse glibcbackcompattrue gprofcxxflags gprofldflags grepbingrep hardenedcppflags ufortifysource dfortifysource2 hardenedcxxflags fstackreusenone wstackprotector fstackprotectorall hardenedldflags wlzrelro wlznow pie hardenfalse hardentrue havebuiltinprefetch1 havecxx111 havedoxygenfalse havedoxygentrue havefdatasync1 havefullfsync0 havegmtimer havemmprefetch1 haveocloexec1 havestronggetauxval0 haveweakgetauxval1 hexdumpusrbinhexdump imagemagickconvert installnametool installdatainstall m 644 installscriptinstall c s lcov lcovopts ldusrbinld m elfx8664 leveldbcppflags libleveldb libmemenv libobjs libs libtoolshell topbuilddirlibtool libtoolappldflags lipo lnsln s lrelease ltlibobjs ltsyslibrarypath lupdate maint maintainermodefalse maintainermodetrue makeinfoshell makeinfo makensis manifesttool miniupnpccppflags mkdirpbinmkdir p moc mocdefsdhaveconfigh isrcdir nmnm nmedit nowarncxxflags objcopyusrbinobjcopy objcxxg m64 stdc11 objcxxflags objdumpobjdump objexto otool64 otool packagebitcoin packagebugreport packagenamebitcoin core packagestringbitcoin core 0201 packageurl packageversion0201 pathseparator picflagsfpic pieflagsfpie static pthreadccgcc m64 pthreadcflagspthread pthreadlibs pythonusrbinpython35 qrcflags qrlibs qt5cflags qt5libs qtaccessibilitylibs qtcglcflags qtcgllibs qtclipboardcflags qtclipboardlibs qtfbcflags qtfblibs qtfontdatabasecflags qtfontdatabaselibs qtgraphicscflags qtgraphicslibs qtplatformcflags qtplatformlibs qtthemecflags qtthemelibs qtxcbqpacflags qtxcbqpalibs qtdbuscflags qtdbusincludes qtdbuslibs qtincludes qtldflags qtlibs qtpieflags qtselectqt5 qttestcflags qttestincludes qttestlibs ranlibranlib rcc readelfusrbinreadelf reldflags rsvgconvert sanitizercxxflags sanitizerldflags sedbinsed setmake shanicxxflagsmsse4 msha shellbinbash sse41cxxflagsmsse41 sse42cxxflagsmsse42 stripusrbinstrip targetdarwinfalse targetdarwintrue targetwindowsfalse targetwindowstrue testdefs tiffcp uic useasmfalse useasmtrue uselcovfalse uselcovtrue useqrcode useqrcodefalse useqrcodetrue useupnp version0201 warncxxflags windres wordsbigendianfalse wordsbigendiantrue xgettext lzmq lpthread lrt acctar acctcc acctcxx acctdumpbin acctobjcxx amexeextfalse amexeexttrue amfastdepccfalse amfastdepcctrue amfastdepcxxfalse amfastdepcxxtrue amfastdepobjcxxfalse amfastdepobjcxxtrue amincludeinclude amisrc amleadingdot amnodepno amquote amtartartar chof tardir amuntartartar xf axpthreadconfig bindirexecprefixbin buildx8664pclinuxgnu buildalias buildcpux8664 buildoslinuxgnu buildvendorpc datadirdatarootdir dvidirdocdir execprefixprefix hostx8664pclinuxgnu hostcpux8664 hostoslinuxgnu hostvendorpc htmldirdocdir installshshell libdirexecprefixlib mandirdatarootdirman mkdirpmkdirp pdfdirdocdir psdirdocdir subdirs srcunivalue srcsecp256k1 sysconfdirprefixetc targetalias confdefsh confdefsh define packagename bitcoin core define packagetarname bitcoin define packageversion 0201 define packagestring bitcoin core 0201 define packagebugreport define packageurl define havecxx11 1 define stdcheaders 1 define havesystypesh 1 define havesysstath 1 define havestdlibh 1 define havestringh 1 define havememoryh 1 define havestringsh 1 define haveinttypesh 1 define havestdinth 1 define haveunistdh 1 define havedlfcnh 1 define ltobjdir libs define useasm 1 define enablesse41 1 define enableavx2 1 define enableshani 1 define 1 define havepthread 1 define havedeclstrerrorr 1 define havestrerrorr 1 define strerrorrcharp 1 define 1 define haveendianh 1 define havebyteswaph 1 define havestdioh 1 define havestdlibh 1 define haveunistdh 1 define havestringsh 1 define havesystypesh 1 define havesysstath 1 define havesysselecth 1 define havesysprctlh 1 define havesyssysctlh 1 define havedeclgetifaddrs 1 define havedeclfreeifaddrs 1 define havedeclstrnlen 1 define havedecldaemon 1 define havedeclle16toh 1 define havedeclle32toh 1 define havedeclle64toh 1 define havedeclhtole16 1 define havedeclhtole32 1 define havedeclhtole64 1 define havedeclbe16toh 1 define havedeclbe32toh 1 define havedeclbe64toh 1 define havedeclhtobe16 1 define havedeclhtobe32 1 define havedeclhtobe64 1 define havedeclbswap16 1 define havedeclbswap32 1 define havedeclbswap64 1 define havedeclbuiltinclz 1 define havedeclbuiltinclzl 1 define havedeclbuiltinclzll 1 define havemallocinfo 1 define havemalloptarenamax 1 define 1 define havethreadlocal 1 define havegmtimer 1 define havesysgetrandom 1 define havegetentropy 1 define havegetentropyrand 1 define havestdsystem 1 define havesystem havestdsystem havewsystem define 1 define 1 define 1 define 1 define haveboost define haveboostsystem define haveboostfilesystem define haveboostthread define enablezmq 1 define haveconsensuslib 1 define enablewallet 1 define useupnp 0 define clientversionmajor 0 define clientversionminor 20 define 1 define clientversionbuild 0 define true define copyrightyear 2020 define copyrightholders the s developers define bitcoin core define the bitcoin core developers configure exit 0"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfreebsd 12.1 build broken\nconfigure withguino disabletests disablewallet makegmake cxxld benchbenchbitcoin usrlocalbinld in function setupenvironment undefined reference to const usrlocalbinld undefined reference to const collect2 error ld returned 1 exit status gmake2 makefile7354 bitcointx error 1 gmake2 waiting for unfinished jobs usrlocalbinld in function setupenvironment undefined reference to const usrlocalbinld undefined reference to const collect2 error ld returned 1 exit status gmake2 makefile7350 bitcoincli error 1 usrlocalbinld in function setupenvironment undefined reference to const usrlocalbinld undefined reference to const collect2 error ld returned 1 exit status gmake2 makefile7362 bitcoind error 1 usrlocalbinld in function setupenvironment undefined reference to const usrlocalbinld undefined reference to const collect2 error ld returned 1 exit status gmake2 makefile7346 benchbenchbitcoin error 1 gmake2 leaving directory gmake1 makefile17262 allrecursive error 1 gmake1 leaving directory gmake makefile780 allrecursive error 1"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to reproduce -Werror=sign-compare failures locally?\ni tried gcc and clang but those failures wont show for me see while i like the warning and error if developers cant see them on their boxes it makes it tedious to fix those issues up"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGetMedianTimePast: Can it be optimized with a simple index - 5?\ni was working on an blockchain indexer and explorer and as i was trying to figure out how to calculate the returned mediantime from the getblockchaininfo i realized that the value is not what i was expecting it to be this was in an c implementation of similar code to bitcoin so i initially thought it was a bug in the net implementation then i had a look at the c implementation and to me it appears to be the same static constexpr int nmediantimespan 11 int64t getmediantimepast const int64t int64t pbegin int64t pend const cblockindex pindex this for int i 0 i pprev pbegin pindexgetblocktime stdsortpbegin pend return pbeginpend pbegin2 from what i can understand the method loops backwards through the blocks from the current block populates the block time into an array sort it its already sorted then picks the middle one 5 and returns that is that correctly assumed wouldnt simply selecting index 5 do the exact same thing of course one would need to calculate for genesis and the first 10 blocks but thats easy i was expecting this method to do something else namely take the diff time not the timestamp between each block then picking the middle one which would give the average time between each block for the last 10 blocks another quick way to calculate would be take getblocktime from the block 10 indexes back diff with current block and divide by 10 should give one type of average the current code populates an array of 10 timestamps but it only picks the one in the middle there is no reason to populate it with 10 timestamps as the 5 oldest are not used for anything it also doesnt use or calculatecare about any of the other blocks so if the last 5 blocks took 1 hour 10 minutes 10 minutes 10 minutes 10 minutes 10 minutes 10 minutes 10 minutes 10 minutes 10 minutes then getmediantimepast will return a timestamp 1 hour and 40 minutes back in time from current block i understand median is correct name for the method it returns the middle of the sorted numbers but is the numbers to be sorted suppose to be time between blocks datediff and not the actual timestamps the mediantime returned is also not the time between blocks it is the time 5 blocks back which is why im wondering why not simply grab the datetime of the block 5 indexes back instead for for me to show the median time between blocks in the block explorer i must take blocktime mediantime 5 from what i know i think the calculate is used for consensusmining and not suppose to be what im after average block time i can calculate that another way but i stumbled upon this and initially thought it to be something else and thought it could maybe be improved a bit is that the way it is suppose to work or am i not able to read the code properly thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrunning full profiler\nhow can i run a profiler to get the timings on each function of the overall executable looking to find out which functions are running slow and to look more into them"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBIP 152 status\nim not sure where to put this issue anyway reading bip 152 thats active in the protocol i see it has a status reported as draft for someone like me thats trying to implement the protocol following the specification its already difficult to dodge the official dev documentation with its dated and even wrong informations and reading bips its not clear if a bip is included or not for sure in a protocol without checking the code id expect official bips having at least a correct status reported but as just said bip 152 is reported as draft that sounds confusing and probably wrong image as a side note whats the most updated reference not mentioning the code currently available thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOSX Mojave (10.14.6) build fails compiling univalue\ngit pull origin go in to srcunivalue autogensh configure make make clean and two different coins attempted with same results osx 10146 mojave please advise if this is incompatibility or if im missing something gcc v configured with apple clang version 1100 clang110003312 target x8664appledarwin1870 thread model posix installeddir full output autogensh glibtoolize putting auxiliary files in acconfigauxdir buildaux glibtoolize copying file buildauxltmainsh glibtoolize putting macros in acconfigmacrodirs buildauxm4 glibtoolize copying file buildauxm4libtoolm4 glibtoolize copying file glibtoolize copying file buildauxm4ltsugarm4 glibtoolize copying file glibtoolize copying file configure configureac45 installing buildauxcompile configureac45 installing buildauxconfigguess configureac45 installing buildauxconfigsub configureac28 installing buildauxinstallsh configureac28 installing buildauxmissing makefileam installing buildauxdepcomp paralleltests installing buildauxtestdriver machecking whether make supports nested variables yes checking for a bsdcompatible install usrbininstall c checking whether build environment is sane yes kchecking for a threadsafe mkdir p buildauxinstallsh c d checking for gawk no checking for mawk no checking for nawk no checking for awk awk checking whether make sets make yes echecking build system type x8664appledarwin1870 checking host system type x8664appledarwin1870 checking how to print strings printf checking whether make supports the include directive yes gnu style checking for gcc gcc checking whether the c compiler works yes checking for c compiler default output file name aout checking for suffix of executables checking whether we are cross compiling no checking for suffix of object files o checking whether we are using the gnu c compiler yes checking whether gcc accepts g yes checking for gcc option to accept iso c89 none needed checking whether gcc understands c and o together yes checking dependency style of gcc gcc3 checking for a sed that does not truncate output usrbinsed checking for grep that handles long lines and e usrbingrep checking for egrep usrbingrep e checking for fgrep usrbingrep f checking for ld used by gcc checking if the linker is gnu ld no checking for bsd or mscompatible name lister nm usrlocalbinnm b checking the name lister usrlocalbinnm b interface bsd nm checking whether ln s works yes checking the maximum length of command line arguments 196608 checking how to convert x8664appledarwin1870 file names to x8664appledarwin1870 format funcconvertfilenoop checking how to convert x8664appledarwin1870 file names to toolchain format funcconvertfilenoop checking for option to reload object files r checking for objdump objdump checking how to recognize dependent libraries passall checking for dlltool dlltool checking how to associate runtime and link libraries printf sn checking for ar ar checking for archiver file support checking for strip strip checking for ranlib ranlib checking command to parse usrlocalbinnm b output from gcc object ok checking for sysroot no checking for a working dd bindd checking how to truncate binary pipes bindd bs4096 count1 checking for mt no checking if is a manifest tool no checking for dsymutil dsymutil checking for nmedit nmedit checking for lipo lipo checking for otool otool checking for otool64 no checking for singlemodule linker flag yes checking for exportedsymbolslist linker flag yes checking for forceload linker flag no checking how to run the c preprocessor gcc e checking for ansi c header files yes checking for systypesh yes checking for sysstath yes checking for stdlibh yes checking for stringh yes checking for memoryh yes checking for stringsh yes checking for inttypesh yes checking for stdinth yes checking for unistdh yes checking for dlfcnh yes checking for objdir libs checking if gcc supports fnortti fnoexceptions yes checking for gcc option to produce pic fnocommon dpic checking if gcc pic flag fnocommon dpic works yes checking if gcc static flag static works no checking if gcc supports c o fileo yes checking if gcc supports c o fileo cached yes checking whether the gcc linker supports shared libraries yes checking dynamic linker characteristics darwin1870 dyld checking how to hardcode library paths into programs immediate checking whether stripping libraries is possible yes checking if libtool supports shared libraries yes checking whether to build shared libraries yes checking whether to build static libraries yes checking for g g checking whether we are using the gnu c compiler yes checking whether g accepts g yes checking dependency style of g gcc3 checking how to run the c preprocessor g e checking for ld used by g checking if the linker is gnu ld no checking whether the g linker supports shared libraries yes checking for g option to produce pic fnocommon dpic checking if g pic flag fnocommon dpic works yes checking if g static flag static works no checking if g supports c o fileo yes checking if g supports c o fileo cached yes checking whether the g linker supports shared libraries yes checking dynamic linker characteristics darwin1870 dyld checking how to hardcode library paths into programs immediate checking that generated files are newer than configure done configure creating configstatus configstatus creating makefile configstatus creating pclibunivaluepc configstatus creating configstatus creating univalueconfigh configstatus executing depfiles commands configstatus executing libtool commands make allam cxx testobjectobjecto cxx cxx cxx cxx cxxld libunivaluela ar u modifier ignored since d is the default see u cxxld testobject ld warning ignoring file libslibunivaluea building for macosx8664 but attempting to link with file built for unknownunsupported file format 0x21 0x3c 0x61 0x72 0x63 0x68 0x3e 0x0a 0x2f 0x20 0x20 0x20 0x20 0x20 0x20 0x20 undefined symbols for architecture x8664 const referenced from univaluearray in objectobjecto univaluereadchar const unsigned long referenced from univaluetypecheck in objectobjecto univaluereadwrite in objectobjecto univalueclear referenced from univalueset in objectobjecto univaluearray in objectobjecto univalueobject in objectobjecto std1allocator const univalue const referenced from univalueobject in objectobjecto std1allocator const char const in objectobjecto univaluesetintlong long referenced from univalueset in objectobjecto univalueobject in objectobjecto univalueunivaluelong long in objectobjecto univalueunivalueint in objectobjecto long long referenced from univalueset in objectobjecto long long in objectobjecto std1allocator const referenced from univalueset in objectobjecto univaluearray in objectobjecto std1allocator const in objectobjecto univalueunivaluechar const in objectobjecto const referenced from univalueobject in objectobjecto univaluesetboolbool referenced from univaluetypecheck in objectobjecto univalueset in objectobjecto univalueunivaluebool in objectobjecto univaluesetnull referenced from univalueset in objectobjecto std1allocator const univalue const referenced from univalueobject in objectobjecto univaluesetarray referenced from univalueset in objectobjecto referenced from univalueset in objectobjecto in objectobjecto const referenced from univaluearray in objectobjecto univaluepushbackchar const in objectobjecto std1allocator const referenced from univalueconstructor in objectobjecto univaluetypecheck in objectobjecto univalueset in objectobjecto univaluesetobject referenced from univalueset in objectobjecto univalueobject in objectobjecto std1allocator univaluevtype std1less std1allocator std1allocator std1allocator const univaluevtype const const referenced from univalueobject in objectobjecto int unsigned int const referenced from univaluereadwrite in objectobjecto std1allocator const unsigned long const referenced from univalueobject in objectobjecto univaluegetkeys const referenced from univaluetypecheck in objectobjecto univaluegetint const referenced from univaluetypecheck in objectobjecto univaluegetobj const referenced from univaluetypecheck in objectobjecto univaluegetstr const referenced from univaluetypecheck in objectobjecto univaluegetbool const referenced from univaluetypecheck in objectobjecto univaluegetreal const referenced from univaluetypecheck in objectobjecto std1allocator univalue std1less std1allocator std1allocator std1allocator const univalue const referenced from univalueobject in objectobjecto univaluegetvalues const referenced from univaluetypecheck in objectobjecto univaluegetarray const referenced from univaluetypecheck in objectobjecto univaluegetint64 const referenced from univaluetypecheck in objectobjecto std1allocator const const referenced from univalueobject in objectobjecto univaluereadwrite in objectobjecto long const referenced from univaluearray in objectobjecto univaluereadwrite in objectobjecto ld symbols not found for architecture x8664 clang error linker command failed with exit code 1 use v to see invocation make1 testobject error 1 make all error 2"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Question] Compiling only bitcoind, not others.\nquestion hi im working on bitcoind to write something to test locally when i type make in the working directorytop directory the compile processcode which is written in makefile is very long time because others are compiled with so this is timeconsuming in my current work id like to compile only bitcoind can i get some guide thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to start bitcoind after power failure\nhi im unable to restart bitcoind after a power failure here is the debuglog error i am getting bitcoinraspberrypi tail f 20191111t164954z opening leveldb in 20191111t164954z fatal leveldb error corruption current file does not end with newline 20191111t164954z you can use debugleveldb to get more complete diagnostic messages 20191111t164954z fatal leveldb error corruption current file does not end with newline 20191111t164954z error opening block database please restart with reindex or reindexchainstate to recover 20191111t164954z aborted block database rebuild exiting 20191111t164954z shutdown in progress 20191111t164954z scheduler thread interrupt 20191111t164954z shutdown done ive tried running bitcoind reindex bitcoin reindexchainstate not sure what i am doing wrong"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMissing entry to install \nbitcoin setup is not successfull on a clean ubuntu system following the install instructions expected behavior i would expect that installation to complete and that my setup is able to build bitcoin actual behavior apparently configure gave this error configure error libdbcxx headers missing bitcoin core requires this library for wallet functionality disablewallet to disable wallet functionality next make does not work make make no targets specified and no makefile found stop system information to reproduce the bitcoin version this happens is fix there are many solutions specified in but for me the woking one was the comment from bellaj sudo addaptrepository ppabitcoinbitcoin sudo aptget update sudo aptget install libdb48dev libdb48dev so i guess this could be added to the ubuntu section of"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nwallet: decodepsbt & decoderawtransaction should show RBF status\nthe decodepsbt and decoderawtransaction rpc calls return the sequence for each input but id rather not have to manually determine if that implies rbf i mainly care about this for mempool transactions cc instagibbs achow101"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSerialization-deserialization roundtrip of CPubKey does not necessarily result in an equal object\nwhen fuzzing the serialization code for cpubkey i noticed that obj does not hold true for all cpubkey obj is there any reason to why cpubkey is deviating from the other serializable classes for which equality is defined in this regard context template cdatastream serializeconst t obj cdatastream dssernetwork initprotoversion ds obj return ds template t ds t obj ds obj return obj"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError: connect ECONNREFUSED v0.18.0\nmy config is below the bitcoin core version is v0180 txindex1 server1 rpcuserusername rpcpasswordpassword rpcallowip the ip i connect rpcportport but i got error error connect econnrefused"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNo addresses returned by getnodeaddresses RPC call\nthe issue i am attempting to use the getnodeaddresses rpc call to return all addresses known by a node in a docker network im using the regtest environment the rpc call returns an empty array although nodes have been added on the referent node using the add rpc call expected behavior the getnodeaddresses rpc call should return nodes added via the add rpc call actual behavior no addresses are returned ie an empty array is returned bitcoincli regtest datadirrootbitcoin getnodeaddresses 5 reproduction setup a regtest network of 11 nodes no mining has been done and the bitcoin folder contains only bitcoinconf with the following content regtest regtest1 server1 rpcport8332 port8333 connect to the referent node and run the command bitcoincli regtest datadirrootbitcoin addnode p8333 add where p is the other node address for every node the referent node wants to add run the commands on the referent node bitcoincli regtest datadirrootbitcoin getconnectioncount 10 bitcoincli regtest datadirrootbitcoin getpeerinfo id 2 addr 1000353378 cut out part of response id 11 addr 1000436236 addrbind 100028333 services 000000000000040d relaytxes true lastsend 1569835448 lastrecv 1569835448 bytessent 464 bytesrecv 488 conntime 1569835207 timeoffset 0 pingtime 0001063 minping 0000456 version 70015 subver satoshi0180 inbound true addnode false startingheight 303 banscore 0 syncedheaders 1 syncedblocks 1 inflight whitelisted false minfeefilter 000001000 bytessentpermsg feefilter 32 ping 96 pong 96 sendcmpct 66 sendheaders 24 verack 24 version 126 bytesrecvpermsg feefilter 32 getaddr 24 ping 96 pong 96 sendcmpct 66 sendheaders 24 verack 24 version 126 bitcoincli regtest datadirrootbitcoin getnodeaddresses 5 bitcoin core version bitcoincli version bitcoin core rpc client version bitcoind version bitcoin core daemon version installed via the repository ppabitcoinbitcoin os docker container info lsbrelease a no lsb modules are available distributor id ubuntu description ubuntu 18043 lts release 1804 codename bionic host info lsbrelease a no lsb modules are available distributor id ubuntu description ubuntu 18043 lts release 1804 codename bionic cat proccpuinfo grep name uniq model name intelr coretm i74600m cpu 290ghz 1 tb ssd disk"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nEntity Too Large \nclient error post resulted in a 413 request entity too large response i got error when using decoderawtransaction i already set the postmaxsize 2g and uploadmaxfilesize 2g in phpini in apache i already set the limitrequestbody 104857600 where do i need to change in order to pass this error thank you"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBTC 0.18 Node\nwhy cant docker use rpc commands directly through mount ports as in previous versions does bitcoinconf need special configuration"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Feature] Get utxos for non-wallet addresses\nhey team adding a feature request here for the ability to query all utxos for a given addresss regardless if its in the nodes wallet or not i understand the reasoning here of why its not included outofthebox as it could add a significant amount of overhead to the core requirements of running the node however its fairly concerning that the most of the articles about how to get this functionality just point to using an external api to fetch this info tutorials of how to get this functionality on the developer side are also painful when just trying to get this fairly common feature up and running isnt part of the point of running a full node to be able to get anything you need without the reliance of a third party dont trust verify i would imagine the best implementation for this would be to add a flag in the bitcoinconf of something like indexaddrs1 or something like that anyway just putting the idea out there thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCannot create low fee transaction via RPC\nissue were running bitcoind lnd on a raspberry pi with several other pieces of software because we want bitcoind to be really light weight we set the maxmempool to be 20 mb we dont really care about having mempool data itself but we do care about being able to create transactions and broadcast those transactions to the network the problem weve been running into is that when the mempool is constricted like this 20 mb limit mempoolminfee seams to start out at 000000001 at boot time but then gets larger the longer bitcoind is online we typically create transactions at 1 satperbyte because we dont care about them being validated immediately the problem is were getting this lncli rpc error code unknown desc 26 mempool min fee not met 143 2005 code 66 this error is of course being propagated by bitcoind we set mintxfee to 000000001 and even minrelaytxfee to 000000001 but neither seem to stop mempoolminfee from increasing over time is there anyway to guarantee these transactions always get inserted into the mempool and broadcasted i did some research and it looks like the mempool operates like that to avoid dos attacks but shouldnt rpc calls bypass these ddos issues it makes sense that rpc calls should always work expected behavior there are two appropriate ways i think this could be handled 1 creating a transaction via rpc should always be accepted by the local mempool and broadcasted to peers that will accept that feerate 2 creating a transaction via rpc should always be broadcasted to peers that will accept that feerate actual behavior the rpc call fails with an error message similar to this mempool min fee not met 143 2005 environment we compile our own docker containers important lines from the docker file are below we are also using lnd 070 from ubuntu1804 arg version0180 env binarylink machine info this specifically is happening on a raspberry pi 3b but i believe it is not machine based"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbitcoin.conf assumevalid=0 does not seem to be working\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue assumevalid0 does not seem to work when it is in the bitcoinconf file but does when set as a cli argument i thought setting this in the config file would be enough to set this value when set in the config file the log says it is still using the default hex value it does work when set as a command line argument screenshot from 20190622 111343 screenshot from 20190622 111326 screenshot from 20190622 110837 just setting the config option without the command line argument recreates the issue i did test my config file by removing the dbcache setting and that was reflected in the logs screenshot from 20190622 112623 screenshot from 20190622 112632 i am using the downloaded release version 180 i am using a laptop with ubuntu and a platter hard drive"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to compile and debug the latest version of bitcoin source code with Visual Studio 2015 or Visual Studio 2013\nhello everyone my question is how to compile and debug the latest version of bitcoin source code with visual studio 2015 or visual studio 2013"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ngetnewaddress always returns same type \nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue when i run getnewaddress legacy i expect to get an address starting with a 1 when i run getnewaddress p2shsegwit i expect to get an address starting with a 3 when i run getnewaddress bech32 i expect to get an address starting with bc1 i always get an address starting a 3 another user i know always gets an address starting with a 1 this is reproducible both from command line running bitcoind and also bitcoinqt from bitcoind i type bitcoincli getnewaddress legacy or from bitcoinqt i issue the commands from the debug window console as shown in the screenshot above running version 018 downloaded from im running on macos mojave version 10145 and i always get an address starting with 3 the other user i know runs ubuntu and always gets an address starting with a 1 na"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTransaction Fee calculated is only 1% of what it ought to be\nthe transaction fee recommended only seems to be calculating 1 of what it should be and this is causing transactions to hang or not get processed in a timely manner i have spent three lots of coins from my bitcoin core wallet in each case the fee has been set to automatically calculate i do not believe i changed the parameter since installation and it is set to confirmation target time of 60 minutes which when initially writing this was supposed to be 000064232 btckb three transactions lastly a transaction size of 221 bytes 0221 kbytes the expected fee from two weeks ago based on the 000091727 btckb should be about 0000203 however the fee charged is only about 1 of this 000000238 btc seemingly out by a factor of 100 it is now confirmed but attempting to accelerate on failed because the fee was too low secondly a similar small fee of 000000224 btc was applied on a previous transaction two weeks earlier i have no idea of what the calculation btckb would have then been and thirdly a transaction another week earlier had a fee calculated of 000001194 btc or 00000632 btckb i again have no idea of what the btckb was at that time but this is also seemingly out be a factor of 50 or 100 if the calculation is out using mbtc instead of satoshis or some such thing then i worry any sudden change could adversely impact people who have identified the bug and have manually set their btckb value to 100 times what it ought to be any workaround setting the btckb value manually is really worrisome for anyone not using wallets regularly i would worry i could pay 100 time more than i ought to"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to get onion addresses for seeds\nthank you emzy however your list doesnt have onion addresses at all originally posted by laanwj in i have no idea why my comandline is dnsseed h dnsseedemzyde n node3emzyde m emzyemzyde p 5353"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbitcoin-cli does'nt have \"getnewaddress\" method\ni have installed bitcoin core running on my local machine i want to create a new address using bitcoincli executing a command as follows then an error message was displayed how can i solve it bitcoincli getnewaddress error code 32601 error message method not found the version of bitcoincore is as follows bitcoincli version bitcoin core rpc client version v01800742f7dd97 the machine running bitcoin core is virtual machine on virtualbox on windows7 the guest os is ubuntu server and version is as follows uname a linux ubuntu 415045generic 48ubuntu smp tue jan 29 162813 utc 2019 x8664 x8664 x8664 gnulinux"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhy Bitcoin Core is a monolith?\ni dont understand why bitcoin core software was designed as a monolith and not as a microservices architecture now the node the gui the cli the wallet are all in one for example some people dont need the gui others dont need the cli or others dont need the wallet for example some people can install a cli set the node and use it remotely or some people can be take a wallet with a remote node so my question is why the core team deceided a monolith architecture i dont find any reasonable fact for do this"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTransaction broadcasting failed\ncont when i try to broadcast a raw hex transaction all look nice bitcoincli return a transaction id for the sended hex data but i looking on blockchain explorer and nohing happens a my txid not found likely i dont have no one peers that known about it in my debug log i not seen no one rejects for sendedded transaction only invgetdatatx messagesd bitcoin core version os ubuntu 1804 txzip"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[Windows, MinGW] error windres -f invalid option\nhaving the hardest time figuring out this issue for some reason it seems like its trying to pass f option to windres during the check test f windres i dont see where f is being passed to windres at all i know i know i could just build it on linux but i am trying to bring back an old and this seems to be my last issue im really just stuck with no solution image configlog"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRPC: Connection Refused\ni see that there has been some configuration updates which is why i am sure i am getting a connection refused i tried searching for an updated bitcoinconf example but couldnt find anything this is the config throwing the error rpcuseruser rpcpasswordpass rpcport10301 rpcthreads64 rpcallowip127001 rpcallowip10003 rpcallowip10002 rpcallowip10004 rpcallowip10007 rpcallowip10008 rpcallowip10009 rpcallowip100010 rpcallowip100011 maxconnections25 daemon1 gen0 alertnotifyecho s mail s bitcoin alert supportxxxxxxx port 6 s"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nQuestion: miner_tests.cpp with new data\nhi bitcoin devs smiley cpp 4 0xa4a3e223 2 0x15c32f9e 1 0x0375b547 1 0x7004a8a5 2 0xce440296 2 0x52cfe198 1 0x77a72cd0 2 0xbb5d6f84 2 0x83f30c2c 1 0x48a73d5b 1 0xef7dcd01 2 0x6809c6c4 2 0x0883ab3c 1 0x087bbbe2 2 0x2104a814 2 0xdffb6daa i want to do minertests with new data could you tell me how to create new one blockinfo i would especially like to check blockchain data after segwit this data is maybe outdated thinking if i can i would like to reinforce the test data and contribute to this project smile i tried a lot but i could not get the extranonce sob"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbitcoin-cli console walletpassphrase can't unlock wallet Password with some special characters will not work\nbitcoincli console walletpassphrase cant unlock wallet password with some special characters will not work i am trying unlock my wallet by console using walletpassphrase my problem is in my password i have a lot special characters like i tried include before the special characters and did not help can you guys share for me what is considered be a special characters here in bitcoin cli as well could guys give a sample of solve this problem here the commnand i used to open the wallet for 20 minutes was walletpassphrase 1200 so my question is how to fix this problem and make my wallet understand what is special characters and what is not thank you"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCan't use signrawtransaction in the new version\nafter i update the latest version of bitcoin core 017 i cant use signrawtransaction to signe my tx my cmd is this bitcoincli rpcuserxxx rpcpasswordxxx rpcportxxx signrawtransaction the log is error code 32 error message signrawtransaction was removed in v018 clients should transition to using and"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFix virtual size limit enforcement in transaction package context\nalternative minimal subset of to 1 replace maxpackagesize with maxpackageweight which accounts for additional wu necessary to not exclude default chain limit transactions that would have been accepted individually avoids sigops vbyte confusion 2 pass correct vsize to chain limit evaluations in package context 3 stop overlylarge packages that have no existing mempool ancestors also a bugfix by itself if someone sets nonstandard chain limits this should fix the known issues while not blocking additional refactoring later"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nvalidation: fix coins disappearing mid-package evaluation\nwhile we are evaluating a package we split it into subpackages for evaluation currently subpackages all have size 1 except the last one if a subpackage has size 1 we may add a tx to mempool and call limitmempoolsize which evicts transactions if the mempool gets full we handle the case where the justsubmitted transaction is evicted immediately but we dont handle the case in which a transaction from a previous subpackage either just submitted or already in mempool is evicted mainly since the coins created by the evicted transaction are cached in mview we dont realize the utxo has disappeared until asserts that they exist also the returned reports that the transaction is in mempool even though it isnt anymore fix this by not calling limitmempoolsize until the very end and editing the results map with mempool full if things fall out pointed out by instagibbs in on top of the v3 pr"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrpc: signed-integer-overflow in analyzepsbt[\"estimated_feerate\"]\nis there an existing issue for this x i have searched the existing issues current behaviour crashub in expected behaviour no crash steps to reproduce compile with ubsan srcqtbitcoinqt analyzepsbt relevant log output 0 0x55a94d97befd in int const 1 0x55a94d4648ca in cfeerategetfeeperk const 2 0x55a94d4648ca in const jsonrpcrequest const const summary policyfeeratecpp2963 in how did you obtain bitcoin core compiled from source what version of bitcoin core are you using current master operating system and version linux machine specifications no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFuzz: Mitigate timeout in CalculateTotalBumpFees\nthe slow fuzz seed described in 27799 was just slower than expected not an endless loop ensuring that every anscestor is only processed once speeds up the termination of the graph traversal fixes 27799"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfuzz: improve `coinselection`\nthis pr moves coin creation to its own function called createcoins add coverage for eligibleforspending add coverage for addinputs get result of each algorithm srd knapsack and bnb call createcoins and add into them add coverage for and getinputset using the result of each algorithm srd knapsack and bnb add coverage for merge call srd with the new utxos and if successful try to merge with the previous srd result"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBitcoin Core compiled with Ubuntu Focal gcc-8 immediately segfaults\nis there an existing issue for this x i have searched the existing issues current behaviour segfault expected behaviour no segfault steps to reproduce fresh install of ubuntu focal export apt update apt install curl wget htop git vim ccache y git clone depth1 bitcoincore cd bitcoincore apt install buildessential libtool autotoolsdev automake pkgconfig bsdmainutils python3zmq libeventdev libboostdev gcc8 g8 y autogensh configure ccgcc8 cxxg8 make j nproc srcbitcoind valgrind srcbitcoind relevant log output valgrind srcbitcoind 19993 memcheck a memory error detector 19993 copyright c 20022017 and gnu gpld by julian seward et al 19993 using valgrind3150 and libvex rerun with h for copyright info 19993 command srcbitcoind 19993 19993 invalid read of size 8 19993 at 0x1fd15f vector stlvectorh567 19993 by 0x1fd15f fspathh209 19993 by 0x1fd18b cmpt fspathh644 19993 by 0x1fd18b destroy stlconstructh98 19993 by 0x1fd18b destroy stlconstructh108 19993 by 0x1fd18b destroy stlconstructh137 19993 by 0x1fd18b destroy stlconstructh206 19993 by 0x1fd18b vector stlvectorh567 19993 by 0x1fd18b fspathh209 19993 by 0x1c5a7c path fsh30 19993 by 0x1c5a7c const clone cold494 systemcpp838 19993 by 0x6057e0 stdallocator bool systemcpp849 19993 by 0x4f557f stdfunction stdallocator stdallocator stdallocator const initcpp24 19993 by 0x1cc16e appinit bitcoindcpp155 19993 by 0x1cc16e main bitcoindcpp266 19993 address 0x2b is not stackd mallocd or recently freed 19993 19993 19993 process terminating with default action of signal 11 sigsegv dumping core 19993 access not within mapped region at address 0x2b 19993 at 0x1fd15f vector stlvectorh567 19993 by 0x1fd15f fspathh209 19993 by 0x1fd18b cmpt fspathh644 19993 by 0x1fd18b destroy stlconstructh98 19993 by 0x1fd18b destroy stlconstructh108 19993 by 0x1fd18b destroy stlconstructh137 19993 by 0x1fd18b destroy stlconstructh206 19993 by 0x1fd18b vector stlvectorh567 19993 by 0x1fd18b fspathh209 19993 by 0x1c5a7c path fsh30 19993 by 0x1c5a7c const clone cold494 systemcpp838 19993 by 0x6057e0 stdallocator bool systemcpp849 19993 by 0x4f557f stdfunction stdallocator stdallocator stdallocator const initcpp24 19993 by 0x1cc16e appinit bitcoindcpp155 19993 by 0x1cc16e main bitcoindcpp266 19993 if you believe this happened as a result of a stack 19993 overflow in your programs main thread unlikely but 19993 possible you can try to increase the size of the 19993 main thread stack using the mainstacksize flag 19993 the main thread stack size used in this run was 8388608 19993 19993 heap summary 19993 in use at exit 122654 bytes in 1182 blocks 19993 total heap usage 2545 allocs 1363 frees 383342 bytes allocated 19993 19993 leak summary 19993 definitely lost 0 bytes in 0 blocks 19993 indirectly lost 0 bytes in 0 blocks 19993 possibly lost 136 bytes in 1 blocks 19993 still reachable 122518 bytes in 1181 blocks 19993 suppressed 0 bytes in 0 blocks 19993 rerun with leakcheckfull to see details of leaked memory 19993 19993 for lists of detected and suppressed errors rerun with s 19993 error summary 1 errors from 1 contexts suppressed 0 from 0 segmentation fault core dumped how did you obtain bitcoin core compiled from source what version of bitcoin core are you using current master operating system and version machine specifications no response"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIssue in `p2p_ibd_stalling.py` under Valgrind\nat with the nativevalgrind job bash test testframeworknode0 debug connecting to 12700112173 outboundfullrelay node0 msghand netprocessingcpp5807 sendmessages net requesting block 21 peer0 node0 msghand netcpp2816 pushmessage net sending getdata 37 bytes peer0 node0 http httpservercpp239 httprequestcb http received a post request for from 12700140916 node0 msghand netprocessingcpp3169 processmessage net received headers 82947 bytes peer1 node0 httpworker0 rpcrequestcpp179 parse rpc threadrpcserver methodaddconnection usercookie node0 httpworker0 netcpp457 connectnode netdebug trying connection 12700112173 lastseen00hrs node0 httpworker0 netcpp2803 cnode net added connection peer2 test testframeworkutils error waituntil failed predicate testfunction lambda selfisconnected test testframework error assertion failed traceback most recent call last file line 134 in main selfruntest file line 77 in runtest p2pidxid file line 663 in file line 467 in waitforconnect timeouttimeout lockp2plock file line 281 in waituntilhelper raise not true after timeout assertionerror predicate testfunction lambda selfisconnected not true after 600 seconds test testframework debug closing down network thread test testframeworkutils error waituntil failed predicate not timeouttimeout node0 msghand netprocessingcpp2760 net protecting outbound peer1 from eviction node0 msghand netcpp2816 pushmessage net sending sendheaders 0 bytes peer1"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUse of a wallet shouldn't be blocked in prune mode (\"wallet loading failed... beyond pruned data\")\nit is impossible to load and use a wallet neither in bitcoinqt gui nor consolerpc commands the wallet is only about 2 weeks old and typical settings are used data pruned to 2 gb expected behavior a wallet is loaded either manually or automatically on startup and addresses are shown in bitcoinqt successful execution of wallet rpc commands eg getwalletinfo dumpwallet etc not different from the way it had worked and looked the previous time a user started bitcoin core actual behavior wallet loading failed prune wallet loading failed prune last wallet synchronisation goes beyond pruned data you need to reindex download the whole blockchain again in case of pruned node also rpc commands fail for example loadwallet getwalletinfo dumpwallet except for listwallets to reproduce 1 start bitcoinqt 2 select fileopen walletwallet name reproducible every time in prune mode the wallet was created at the time for which data were pruned the wallet was created in bitcoinqt system information official binary bitcoin core 2401 windows 11"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncore stops to run with `Failed to read block` error\nexpected behavior while my node was running it get an internal failure that force it to stop the running 20230221t232922z syncing basic block filter index with block chain from height 624447 20230221t232934z error serializefiledb renameintoplace failed 20230221t232952z syncing basic block filter index with block chain from height 624889 20230221t233022z error readblockfromdisk deserialize or io error readcompactsize size too large iostream error at flatfileposnfile2030 npos82255446 20230221t233022z threadsync failed to read block from disk 20230221t233022z error a fatal internal error occurred see debuglog for details the code is based on the commit to reproduce no idea how i can reproduce it now i switch to the tagged version to see if this happens too system information ➜ bitcoin gitmaster neofetch metgg vincentx86 gp gp y os debian gnulinux 11 bullseye x8664 p host optiplex 3050 p ggs b kernel 510021amd64 d p uptime 5 days 16 hours 33 mins p d p packages 502 dpkg d shell zsh 58 yb dp terminal devpts1 y yp cpu intel i57500t 4 3300ghz b gpu intel hd graphics 630 y memory 2214mib 7840mib y b yb yb"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nerror: timeout on transient error: Could not connect to the server 127.0.0.1:8333 (error code 1 - \"EOF reached\")\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue when im trying to use bitcoincli while bitcoind running it displays error message error timeout on transient error could not connect to the server 1270018333 error code 1 eof reached make sure the bitcoind server is running and that you are connecting to the correct rpc port running command bitcoincli getblockchaininfo bitcoind txindex 20230217t180320z bound to 1270018334 20230217t180320z bound to 8333 20230217t180320z bound to 00008333 i am on macos ventura 131 intel i5 macbook pro 20230217t180307z bitcoin core version v2401 release build i saw a related issue few years ago and apparently this issue should to be patched"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndecodescript miniscript functionality tops out at 520 bytes\nafter miniscript is extracted from compatible scripts unless the check for maxscriptelementsize fails which then it falls back to legacy behavior achow101"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRPC getdescriptorinfo shouldn't output undefined value of the \"descriptor\"\nexpected behavior descriptor checksum tdkpah70 isrange false issolvable true hasprivatekeys true actual behavior descriptor checksum tdkpah70 isrange false issolvable true hasprivatekeys true to reproduce execure the rpc command eg getdescriptorinfo system information bitcoin 2401"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWallet passphrases silently ignore everything after a null character\nproblem encrypting a wallet through json rpc or qt appears to allow a user to include null characters in the passphrase but silently ignores everything including and after the first null character for instance on regtest trying to set a passphrase of anull characterb curl user cookie databinary jsonrpc 10 idcurltest method encryptwallet params au0000b h contenttype textplain this will succeed but allow the user to unlock with the passphrase a instead of the expected full passphrase which also works curl user cookie databinary jsonrpc 10 idcurltest method walletpassphrase params a10 h contenttype textplain i am also able to replicate it in qt on my macos machine by running printf a0b pbcopy and pasting the result into the passphrase dialog my main concern is a user thinking that theyre generating say 32 random bytes as a passphrase and if theyre unlucky and get a zero in the first few bytes it unexpectedly cuts their security down to almost nothing root cause the reason is due to our securestring type securestring is a stdstring specialization with a secure allocator however when assigned its treated like a c string no explicit length and nullterminated see the original pr for more details potential solutions i think there are two plausible approaches to take the first and my preference is to allow and support null characters and i will submit a pr that enables that by making securestring use the entire string the second is to explicitly reject any passphrases that contain null characters one significant complication may be that if anyone is already using a passphrase with a null then my first solution would stop their wallet from unlocking however it would still be unlockable just by trimming the null and any subsequent characters"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nevery other change address is unused\nim seeing 50 of generated change addresses not being used its as if two are reserved for every one that is used this is happening in version v2401 heres a sequence of commands that shows what i mean only the odd numbered change hdkeypaths are used binrm fr bitcoinregtest bitcoinqt regtest bitcoincli regtest createwallet 1 devnull bitcoincli regtest createwallet 2 devnull bitcoincli regtest rpcwallet1 generate 1 devnull bitcoincli regtest rpcwallet2 generate 100 devnull tobitcoincli regtest rpcwallet2 getnewaddress txsfor i in 15 do bitcoincli regtest rpcwallet1 sendtoaddress to 1 done addrsfor i in txs do bitcoincli regtest getrawtransaction i true jq mc done grep v 1 jq r addr for a in addrs do bitcoincli regtest rpcwallet1 getaddressinfo a jq r hdkeypath done m841011 m841013 m841015 m841017 m841019 this happens whether or not i create descriptor wallets for example with a descriptor wallet i get these descriptors for the change addresses and for a legacy wallet i get these"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n.\n"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntest: format-truncation warning in dbwrapper_tests\ncompiling master at on ubuntu 2210 with depends cpp cxx in member function ‘void error ‘d’ directive output may be truncated writing between 1 and 11 bytes into a region of size 10 365 snprintfbuf sizeofbuf d x note directive argument in the range 2147483648 9 365 snprintfbuf sizeofbuf d x in file included from usrincludestdioh906 from from from from from clientversionh30 from dbwrapperh8 from in function ‘int snprintfchar sizet const char ’ inlined from ‘void at note ‘builtinsnprintfchk’ output between 2 and 12 bytes into a destination of size 10 54 return builtinsnprintfchk s n usefortifylevel 1 55 glibcobjsize s fmt 56 vaargpack i ran with enablewerror otherwise its merely a warning cc achow101"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPrivate Key import result with 3 Address generation.\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue private key import result with 3 address generation expected behavior therefore it seems a bug but also future request assumes that as bitcoin address generation has choice of version like segwit or leacy the private key import should result within the setup actual behavior generates 3 types wallet like legacy segwit and p2pkh to reproduce system information"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbuild: xproto fails to install on aarch64-unknown-linux-musl\nbash staging xproto make1 entering directory making install in specs make2 entering directory making install in siaddresses make3 entering directory make4 entering directory make4 nothing to be done for installexecam make4 nothing to be done for installdataam make4 leaving directory make3 leaving directory make3 entering directory make4 entering directory make4 nothing to be done for installexecam make4 leaving directory make3 leaving directory make2 leaving directory make2 entering directory make3 entering directory make3 nothing to be done for installexecam installsh c d installsh c d installsh c d mkdir cant create directory file exists mkdir cant create directory file exists make3 makefile487 error 1 make3 waiting for unfinished jobs usrbininstall c m 644 xprotopc usrbininstall c m 644 apkeysymh deckeysymh hpkeysymh keysymdefh keysymh sunkeysymh xallocah xarchh xatomh xdefsh xf86keysymh xfuncsh xh xmdh xosdefsh xosh xosrh xprotoh xprotostrh xthreadsh xw32defsh xwdfileh xwindowsh xwinsockh make3 leaving directory make2 makefile838 installam error 2 make2 leaving directory make1 makefile535 installrecursive error 1 make1 leaving directory make funcsmk289 error 2 make leaving directory bitcoindepends does not happen when building just the package"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nintermittent issue in wallet_backwards_compatibility (BerkeleyEnvironment::Open: Error -30974 opening database environment: DB_RUNRECOVERY: Fatal error, run database recovery)\nwget tar xvf c tail 525 head 13 node2 httpworker2 walletbdbcpp145 open node2 httpworker2 walletbdbcpp172 open error 30974 opening database environment dbrunrecovery fatal error run database recovery test testframework error jsonrpc error traceback most recent call last file line 134 in main selfruntest file line 185 in runtest file line 49 in call returnval kwargs file line 146 in call raise status wallet file verification failed error initializing wallet database environment this error could occur if this wallet was not shutdown cleanly and was last loaded using a build with a newer version of berkeley db if so please use the software that last loaded this wallet 4"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\np2p_permissions intermittent timeout\nsh wget tar xvf p2ppermissionstarxz c p2ppermissions15 tail 131 head 33 test testframeworkutils error waituntil failed predicate selfwaituntillambda txid in test testframework error assertion failed traceback most recent call last file line 134 in main selfruntest file line 34 in runtest selfchecktxrelay file line 128 in checktxrelay selfwaituntillambda txid in file line 732 in waituntil return timeouttimeout file line 281 in waituntilhelper raise not true after timeout assertionerror predicate selfwaituntillambda txid in not true after 24000 seconds"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntest: sqlite tests on freebsd fail with ModuleNotFoundError: No module named '_sqlite3'\nit would be good if the test was skipped instead or if the documentation explained how to install pysqlite 126256 walletdescriptorpy descriptors failed duration 0 s stdout stderr traceback most recent call last file line 7 in import sqlite3 file line 57 in from sqlite3dbapi2 import file line 27 in from sqlite3 import modulenotfounderror no module named sqlite3"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBitcoin Core startup is interrupted if there is the setting mintxfee=0 in bitcoin.conf\nexpected behavior it is expected that bitcoin core is not shutdown automatically during startup moreover it should be possible to set transaction fee at 0 actual behavior bitcoin core error mintxfee to reproduce 1 click bitcoinqtexe system information 1 a wallet that contained unspent funds was opened previously 2 the bitcoinconf file contains mintxfee0 3 bitcoin core 2401 official binary for windows portable"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncontrib/install_db4.sh script fails on FreeBSD\nrunning contribinstalldb4sh to download and build libdb4 for legacy wallet support fails on freebsd contribinstalldb4sh pwd sha256sum option requires an argument c usage sha256sum pqrtx c file s string files this is on freebsd 131 fixed by 26772"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIntermittent failure in `tool_wallet.py`\n"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbitcoind.service: Start request repeated too quickly.\nim obtaining the following error when initializing bitcoind service × bitcoindservice bitcoin daemon loaded loaded enabled vendor preset enabled active failed result exitcode since sat 20221217 174809 03 5min ago process 1141 daemon confhomesatoshisna cpu 24ms dez 17 174809 nakamoto systemd1 bitcoindservice scheduled restart job restart counter is at 5 dez 17 174809 nakamoto systemd1 stopped bitcoin daemon dez 17 174809 nakamoto systemd1 bitcoindservice start request repeated too quickly dez 17 174809 nakamoto systemd1 bitcoindservice failed with result exitcode dez 17 174809 nakamoto systemd1 failed to start bitcoin daemon bitcoindservice file it is not recommended to modify this file inplace because it will be overwritten during package upgrades if you want to add further options or overwrite existing ones then use systemctl edit bitcoindservice see man systemdservice for details note that almost all daemon options could be specified in but keep in mind those explicitly specified as arguments in execstart will override those in the config file unit descriptionbitcoin daemon afternetworktarget service daemon make sure the config directory is readable by the service user execstartprebinchgrp bitcoin etcbitcoin process management typeforking restartonfailure timeoutstopsec600 directory creation and permissions run as bitcoinbitcoin usersatoshi groupsatoshi runbitcoind etcbitcoin varlibbitcoind hardening measures provide a private tmp and vartmp privatetmptrue mount usr boot and etc readonly for the process protectsystemfull deny access to home root and runuser protecthometrue disallow the process and all of its children to gain new privileges through execve nonewprivilegestrue use a new dev namespace only populated with api pseudo devices such as devnull devzero and devrandom privatedevicestrue deny the creation of writable and executable memory mappings install ive installed bitcoincore via snap bitcoin core rpc client version v2401 os ubuntu 22041 lts x8664"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbitcoind v23.0.0: traps: b-scheduler[3227] trap invalid opcode\nissue bitcoind process ended abruptly expected behaviour bitcoind should continue to run log output nothing unusual terminal output 1879 illegal instruction core dumped dmesg output traps bscheduler3227 trap invalid opcode ip555ad42d5cb2 sp7efc897f9590 error0 in cannot reproduce easily this happened first time in last 4 years running bitcoind nonstop bitcoincli version bitcoin core rpc client version v2300 official build from the website running normally from the user folder no systemd no service but in screen session in bash loop bash loop allows it to automatically restart so i experienced no downtime bitcoind has started again automatically full command line bitcoind was running with is 21 serverstyle machine with ecc ram os debian gnulinux 11 bullseye x8664 cpu amd ryzen 7 1700 16 3000ghz 280°c ram 64gb ram 2666 mts multibit ecc hdd btrfs raid10 mode 4x 4tb hard drives no issues with btrfs or drives all perfectly clean no gui bitcoind running in screen session logging to a file i could upload entire session debuglog 25mib on request bitcoind process was running from 11 november to 13 december then crashed log file ends cleanly with no error messages last few lines are 20221213t175000z socks5 connect to xxxonion8333 failed host unreachable 20221213t175044z connect to 1270017656 failed after wait connection refused 111 20221213t175314z connect to 1270017656 failed after wait connection refused 111 20221213t175722z updatetip new height767249 version0x20a00000 log2work93893910 tx787817132 date20221213t175718z progress1000000 cache56mib23274txo 20221213t175916z connect to 1270017656 failed after wait connection refused 111 20221213t175934z updatetip new height767250 version0x23778000 log2work93893921 tx787819399 date20221213t175922z progress1000000 cache66mib31759txo"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCan't bump fee after abandoning child transaction\nsteps 1 send transaction a to a different wallet 2 using the change create another transaction b to a different wallet 3 abandontransaction b 4 bumpfee a fails with transaction has descendants in the wallet"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nvalidation, bugfix: provide more info in *MempoolAcceptResult\nthis pr fixes a bug and improves the mempool accept interface to return information more predictably bug in package validation we first try the transactions individually see docpolicypackagesmd for more explanation and if they all failed for missing inputs and policyrelated ie fee reasons well try package validation otherwise well just quit early since for example if a transaction had an invalid signature adding a child will not help make it valid currently when we quit early were not setting the packagestate to be invalid so the caller might think it succeeded also were returning no results it makes more sense to return the individual transaction failure thanks instagibbs for catching also make the package results interface generally more usefulpredictable always return the feerate at which a transaction was considered for checkfeerate in when it was successful this can replace the current which only sometimes exists always provide an entry for every transaction in when the error is pckgtx"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n The BTC module is not working with the latest Magento php 8.1 version \nhello team hope that you are doing well we are facing an issue with the btc modules not working with the latest magento php version 81 kindly please check and let us know on this how we can use the module with php version 81 looking forward to hearing from you soon thank you"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nnew bitcoin ddos technique\nedit the issue has been closed while the bug undergoes further review hi i will keep this concise as the attack is neither innovative nor sophisticated it is possible to slow and entirely halt external connections from communicating with a bitcoincore node i dont know whether peer connections remain open or frequently disconnectreconnect what happens to syncd nodes with active peers is yet to be seen its too early at least for me to know whether peers would drop a node under attack over timeouts and how bitcoind behaves with peers while tcp8333 is under fire so further research required this needs to be tested against syncd nodes there is a dos here but also a probably slim possibility that a scaled attack would only result in new nodes being unable to enter the network it is accomplished by repeatedly sending a small request eg x x with thousands of concurrent socket requests in this screen shot im using a handful of cheap digital ocean machines to attack 1 node corn as the script exhausts itself and finds trouble assigning itself open sockets the ddos becomes hit or miss in external requests sometimes connecting usually not connecting and sometimes producing black hole events wherein its impossible to disconnect from an external telnet request until it drops you — which is atypical behavior the attack works the best within the first 20 seconds of the attack script being launched and so may require further optimization am i missing something because im definitely able to stress my own nodes with this technique it is my opinion that a botnet could probably tango down the bitcoin network or at least slow finality considerably ive opted for full disclosure for a variety of reasons kev"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntest: intermittent failure in rpc_net.py\nsee master the problem here is is that calling disconnectp2ps waits until 0 checks the field subver in getpeerinfo to distinguish p2p nodes from full nodes however if we are dealing with a p2p connection that has never sent a version the node has never received the special subversion and the wait is ineffective we continue even though the disconnection is not yet completed"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBreking in Mac OS\nim trying to use bitcoin core on mac os i want to record on an external hd but i get the following error all the time 20221117t220744z msghand thread exit 20221117t220744z net thread exit 20221117t220744z opencon thread exit 20221117t220744z filecommit fcntl ffullfsync failed 25 20221117t220744z error serializefiledb failed to flush file volumesextreme 20221117t220744z dumpanchors flush 2 outbound blockrelayonly peer addresses to anchorsdat started 20221117t220744z filecommit fcntl ffullfsync failed 25 20221117t220744z error serializefiledb failed to flush file volumesextreme 20221117t220744z dumpanchors flush 2 outbound blockrelayonly peer addresses to anchorsdat completed 001s 20221117t220744z scheduler thread exit 20221117t220744z writing 0 unbroadcast transactions to disk 20221117t220744z filecommit fcntl ffullfsync failed 25 20221117t220744z failed to dump mempool filecommit failed continuing anyway 20221117t220745z filecommit fcntl ffullfsync failed 25 20221117t220745z error flush failed to commit file 1 20221117t220745z flushing block file to disk failed this is likely the result of an io error 20221117t220745z error a fatal internal error occurred see debuglog for details 20221117t220745z filecommit fcntl ffullfsync failed 25 20221117t220745z error flush failed to commit file 1 20221117t220745z flushing undo file to disk failed this is likely the result of an io error 20221117t220745z error a fatal internal error occurred see debuglog for details 20221117t220746z filecommit fcntl ffullfsync failed 25 20221117t220746z error flush failed to commit file 1 20221117t220746z flushing block file to disk failed this is likely the result of an io error 20221117t220746z error a fatal internal error occurred see debuglog for details 20221117t220746z filecommit fcntl ffullfsync failed 25 20221117t220746z error flush failed to commit file 1 20221117t220746z flushing undo file to disk failed this is likely the result of an io error 20221117t220746z error a fatal internal error occurred see debuglog for details 20221117t220746z shutdown done"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nmacOS reports error on shutdown of GUI\nmacos reports error on shutdown of gui bitcoin core quit unexpectedly although this may be hardware related memory and cpu load seem normal screenshots and logs attached expected behavior application closes without error message actual behavior application quits and restarts without error or corruption of data but message persists to reproduce the error message seems to persist every time under normal conditions closing the application invokes the message bitcoin core is shutting down do not shut down the computer until this window has disappeared then opens fine on relaunch system information bitcoin core 2300 version 2300 2300 code type x8664 native parent process launchd 1 os version macos 130 22a380 log20221111txt img width280 altscreenshot 20221111 at 20 51 52 src img width631 altscreenshot 20221111 at 21 24 41 src img width615 altscreenshot 20221111 at 21 24 48 src"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nwhitelisting fails for nodes added with addnode\nwhitelisting works for subnets for outgoing and incoming connections unless the node has been added using addnode in which case the permissions are always na in the gui and the node is disconnected as if there is no whitelisting eg when historical block download is reached or a mempool request comes in etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntest: failure in interface_rest.py\nbash test testframework error assertion failed traceback most recent call last file line 133 in main selfruntest file line 103 in runtest selfsyncall file line 715 in syncall file line 708 in syncmempools raise sync timed out after sformat assertionerror mempool sync timed out after 480s set test testframework debug closing down network thread"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to cross compile Zeromq Dependency for arm64-apple-darwin\ntrying to compile starting with dependencies fails with checking build system type x8664pclinuxgnu checking host system type invalid configuration arm64appledarwin machine arm64apple not recognized configure error binbash configconfigsub arm64appledarwin failed expected behavior actual behavior checking for no checking for pkgconfig usrbinpkgconfig checking pkgconfig is at least version 090 yes checking for xmlto no checking for asciidoc no checking build system type x8664pclinuxgnu checking host system type invalid configuration arm64appledarwin machine arm64apple not recognized configure error binbash configconfigsub arm64appledarwin failed make funcsmk289 error 1 to reproduce command make hostarm64appledarwin j 8 system information master branch ubuntu 2004 core i5 intel 16gb ram"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nInstability in `listunspent` after #24699\ni maintain a wallet that uses bitcoincli for signing transactions and its test system uses regtest to create a bunch of utxos for the signing tests to sign these tests use a gitcommitted walletdat that is copied into the newlycreated datadir before launching bitcoind for years up until part of 24699 this was stable and worked well occasionally i would need to recreate all the transactions when this project changed mining 24732 or coin selection 24584 but i could handle that what i cant handle is having the generated transactions be different each time i run the exact same sequence of bitcoincli commands starting from the same walletdat starting with thats what happens is this a supported use model or is it unreasonable to expect this to be stable summarizing v0200 stable v0210 stable v220 stable v230 stable which is stable unstable v240rc2 unstable current master unstable expected behavior the generated transactions should be identical given an identical series of bitcoincli calls actual behavior the generated transactions choose different input coins from the regtest blockchain every time i run to reproduce in my glacier wallet fork run recreatealltests git commit the result run the same command again git status should show no changes when its unstable dozens of files change system information running on whonix 16 building inside the git repo as such cd depends make j4 noqt1 autogensh configure make j4"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsignrawtransactionwithwallet fails with signed non-wallet inputs and breaks the existing signatures\nthe error returned by the rpc is unable to sign input invalid stack size possibly missing key it seems that this rpc alters the scriptsig of all of the inputs that were already signed the problem is very similar to which is already solved heres an example of the broken signatures after signing diff 0beforetxt 20221024 174631105518559 0300 1aftertxt 20221024 174631146517797 0300 118 118 txid hash txid hash version 1 size 406 vsize 406 weight 1624 size 373 vsize 291 weight 1162 locktime 0 vin txid vout 1 scriptsig asm 0 hex asm 0 0 hex sequence 0 236 2310 asm hex txinwitness sequence 0 ive prepared a bash script that reproduces it i used hal to merge the transactions bash binbash set x set e shopt s expandaliases alias datadirpwd daemon1 alias datadirpwd declare a privkeys declare a pubkeys declare a multisigs declare a addresses declare a redeemscripts declare a txs declare a scriptpubkeys declare a vouts declare a mergetxs parameters for the multisig addreesses addresstypelegacy multisign2 multisigm3 multisigcount1 create the keypairs for i in seq 0 multisigcount multisigm 1do keypairhal key generate regtest 2devnull privkeysiecho keypair jq r wifprivatekey pubkeysiecho keypair jq r publickey done bcli stop sleep 5 true rm rf regtest bdae bcli rpcwait createwallet echo create the multisig addresses for i in seq 0 multisigcount 1do mspubkeys sep for j in seq i multisigm i multisigm multisigm 1do mspubkeysseppubkeysj sep done mspubkeys echo bcli createmultisig multisign mspubkeys addresstype multisigsibcli rpcwait createmultisig multisign mspubkeys addresstype addressesiecho multisigsi jq r address redeemscriptsiecho multisigsi jq r redeemscript done echo pubkeys pubkeys echo privkeys privkeys generate enough blocks to unlock the reward destbcli getnewaddress bcli generatetoaddress 101 dest devnull 21 send 1 btc to each multisig address for i in seq 0 multisigcount 1do txsibcli sendtoaddress addressesi 1 scriptpubkeysibcli decoderawtransaction bcli getrawtransaction txsi jq r vout scriptpubkey selectaddress addressesi hex voutsibcli decoderawtransaction bcli getrawtransaction txsi jq r vout addressesi n echo txsi scriptpubkeysi bcli generatetoaddress 1 dest devnull 21 done echo each multisig sends its coins to a new wallet destwallet and signs the transaction using echo createwallet destwallet bcli createwallet destwallet destaddressbcli rpcwalletdestwallet getnewaddress echo unloadwallet destwallet bcli unloadwallet destwallet for i in seq 0 multisigcount 1do echo sending utxo txsi to final address destaddress txbcli createrawtransaction txidtxsivoutvoutsi destaddress1 sign with keys one by one for j in seq i multisigm i multisigm multisign 1do txbcli tx privkeysj prevtxs singleanyonecanpay txecho txjq r hex done mergetxsitx done echo finalinputs finaloutputs create the transaction to provide the funds to pay for the previous transactions feeinputbcli listunspentjq r 0 feeinputamountecho feeinputjq r amount fee00001 changeamountbc l feeinputamount fee changeaddressbcli getnewaddress changetxbcli createrawtransaction feeinput sepin sepout prepare a json with the inputs and another one with the outputs for i in seq 0 multisigcountdo decodedtxhal tx decode mergetxsi inputnoecho decodedtx jq r inputs length 1 for k in seq 0 inputnodo inputecho decodedtx jq r inputsk delsequence sepin done outputnoecho decodedtx jq r outputs length 1 for k in seq 0 outputnodo outputecho decodedtx jq r outputsk deln sepout done done fulltx version 1 locktime 0 inputs finalinputs outputs finaloutputs echo fulltxjq fulltxtxt create the transaction with all the inputs and outpts and sign it using fails finaltxecho fulltxjqhal tx create 2devnull bcli decoderawtransaction finaltx 0beforetxt echo tx before finaltx signedfinaltxbcli finaltx echo tx after echo signedfinaltxjq r hex bcli decoderawtransaction echo signedfinaltxjq r hex 1aftertxt diff naurwp 0beforetxt 1aftertxt 0diff true signerrorecho signedfinaltxjq r errors0errorempty if n signerror then echo error signing with wallet signerror exit 1 fi senttxbcli sendrawtransaction echo signedfinaltxjq r hex bcli gettransaction senttx bcli generatetoaddress 1 dest devnull 21 bcli gettransaction senttx ive tested with bitcoin core 230 please let me know if theres anything else i can test"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIntermitted failure in p2p_sendtxrcncl.py\ni have seen p2psendtxrcnclpy fail randomly multiple times by now eg also noted here log node0 preregisterpeer preregister peer8 node0 pushmessage net sending sendtxrcncl 14 bytes peer8 node0 pushmessage net sending verack 0 bytes peer8 node0 processmessage net receive version message pythonp2ptester003 version 70016 blocks1 us12700114312 txrelay1 peer8 node0 processmessage net received verack 0 bytes peer8 node0 pushmessage net sending sendcmpct 9 bytes peer8 node0 forgetpeer forget txreconciliation state of peer8 node0 pushmessage net sending ping 8 bytes peer8 node0 pushmessage net sending getheaders 645 bytes peer8 node0 sendmessages net initial getheaders 199 to peer8 startheight1 node0 pushmessage net sending feefilter 8 bytes peer8 node0 processmessage net received ping 8 bytes peer8 node0 pushmessage net sending pong 8 bytes peer8 node0 processmessage net received wtxidrelay 0 bytes peer8 node0 processmessage net wtxidrelay received after verack from peer8 disconnecting test testframeworkp2p debug closed connection to 12700114312 node0 net disconnecting peer8 node0 finalizenode net cleared nodestate for peer8 test testframework error assertion failed traceback most recent call last file line 133 in main selfruntest file line 138 in runtest file line 553 in sendandping file line 570 in syncwithping timeouttimeout file line 463 in waituntil timeouttimeout lockp2plock file line 267 in waituntilhelper if predicate file line 460 in testfunction assert selfisconnected assertionerror"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbitcoin-qt crashed after completing a full blockchain rescan\nwhile investigating 26317 i tried running bitcoincli rescanblockchain to rescan the full blockchain it took about 9 hours to run the full rescan and after the scan was complete bitcoinqt crashed with this error in gdb thread 35 bhttp received signal sigpipe broken pipe the end of the debuglog file showed this at the time of the crash 20221019t091507z chris still rescanning at block 758431 progress0997985 20221019t091607z chris still rescanning at block 759032 progress0999291 20221019t091639z chris scanning current mempool transactions 20221019t091639z chris rescan completed in 34260150ms i posted the full backtraces in before making a separate report for this crash this was bitcoinqt built from git tag v240rc1 on debian linux running on intelr coretm i78750h cpu 220ghz with ssd hard drives"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntest: Intermittent failure in `feature_index_prune.py`\n"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`scanblocks` RPC result includes false-positives\nthe recently introduced scanblocks rpc uses bip157 block filters for quickly determining which blocks contain a specified set of output scripts by nature this can lead to falsepositive results ie the filter set matches the block filter even though none of the contained txs spend or create utxos with the specified set of scriptpubkeys can be reproduced on testnet with address srcbitcoincli testnet scanblocks start fromheight 0 toheight 2375004 relevantblocks completed true looking closer at the first returned block one can see that the contained single coinbase transaction is not related to the passed address srcbitcoincli testnet getblock 3 vout value 1250000000 n 0 scriptpubkey asm opdup ophash160 opequalverify opchecksig desc hex address type pubkeyhash it might make sense to introduce an option that actives a second pass phase in which the found blocks are inspected in order to filter out these falsepositives i guess it is debatable if this can really be considered a bug in practice it shouldnt be a problem but at the very least we should mention the possibility of falsepositives in the rpc help to not confuse users"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nadd lock annotation for FeeFilterRounder::round()\nci failure from 24407 calling withlock on a nonrecursive mutex requires not holding it beforehand"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbitcoind dumps core when deriveaddresses is called with index 2147483647 (2^31-1)\nthe deriveaddresses jsonrpc endpoint accepts a descriptor and an index for the derivation currently the rpc interface caps the allowed index derivation range in the interval 02311 however calling deriveaddresses using a range that includes the index 2147483647 2311 results in a crash of bitcoind on an amd64 machine bitcoincli deriveaddresses descriptor 2147483647 2147483647 bitcoind dumps core in the pr that addresses this pull request 26275 is included a test case that causes the crash for convenience heres the contents of a core dump generated with that test sudo coredumpctl debug bitcoind pid 110184 bitcoind uid 1000 muxator gid 1000 muxator signal 6 abrt timestamp thu 20221006 174808 cest 4min 56s ago command line srcbitcoind logtimemicros debug debugexcludelibevent debugexcludeleveldb uacommenttestnode0 logthreadnames logsourcelocations logleveltrace sandboxlogandabort executable srcbitcoind message process 110184 bitcoind of user 1000 dumped core elf object binary architecture amd x8664 gnu gdb gdb fedora 1211fc36 core was generated by srcbitcoind program terminated with signal sigabrt aborted 0 0x00007f55a8ac6c4c in from lib64libcso6 current thread is 1 thread 0x7f5576ffd640 lwp 110197 missing separate debuginfos use dnf debuginfoinstall glibc23517fc36x8664 libgcc12212fc36x8664 zlib121133fc36x8664 gdb bt 0 0x00007f55a8ac6c4c in from lib64libcso6 1 0x00007f55a8a769c6 in raise from lib64libcso6 2 0x00007f55a8a607f4 in abort from lib64libcso6 3 0x00007f55a8c40c11 in addvsi3 from lib64libgccsso1 4 0x0000563935a84d73 in operator self request at 5 0x0000563935a87ec2 in stdinvokeimpl const rpchelpman const struct f at 6 0x0000563935a8773f in stdinvoker const rpchelpman const jsonrpcrequeststruct fn at 7 0x0000563935a86ec3 in stdfunctionhandler minvokeconst stdanydata const rpchelpman const jsonrpcrequest functor args0 args1 at 8 0x00005639360b4641 in const jsonrpcrequest const const this0x7f5576ffbd50 args0 args1 at 9 0x00005639360a93b8 in this0x7f5576ffbd30 request at rpcutilcpp585 10 0x00005639359cc1a2 in stdallocator rpchelpman lambdajsonrpcrequest const univalue const univalue bool const request result at rpcserverh109 11 0x00005639359e0be3 in stdinvokeimpl stdallocator rpchelpman lambdajsonrpcrequest const univalue bool1 jsonrpcrequest const univalue boolstdinvokeother stdallocator rpchelpman lambdajsonrpcrequest const univalue bool1 jsonrpcrequest const univalue bool f at 12 0x00005639359da9ba in stdinvoker stdallocator rpchelpman lambdajsonrpcrequest const univalue bool1 jsonrpcrequest const univalue stdallocator rpchelpman lambdajsonrpcrequest const univalue bool1 jsonrpcrequest const univalue bool fn at 13 0x00005639359d4916 in stdfunctionhandler stdallocator rpchelpman lambdajsonrpcrequest const univalue const jsonrpcrequest const univalue bool functor args0 args1 args20x7f5576ffbf44 true at 14 0x00005639359302c6 in const univalue bool const this0x5639368fbb00 args0 args1 args2true at 15 0x0000563935b0afd5 in executecommand command request result lasthandlertrue at rpcservercpp475 16 0x0000563935b0abae in executecommands commandsstdvector of length 1 capacity 1 request result at rpcservercpp440 17 0x0000563935b0ad52 in crpctableexecute this0x5639368fc4c0 request at rpcservercpp460 18 0x0000563935cbe3f5 in httpreqjsonrpc contextstdany containing nodenodecontext req0x7f556c002da0 at httprpccpp201 19 0x0000563935cc0548 in operator req0x7f556c002da0 at httprpccpp300 20 0x0000563935cc1c3a in stdinvokeimpl httprequest const stdcxx11basicstring stdallocator stdinvokeother struct f at 21 0x0000563935cc1a78 in stdinvoker httprequest const stdcxx11basicstring stdallocator struct fn at 22 0x0000563935cc182e in stdfunctionhandler stdallocator starthttprpcconst stdany minvokeconst stdanydata httprequest const stdcxx11basicstring stdallocator functor args00x7f5576ffcb80 0x7f556c002da0 args1 at 23 0x0000563935cd1c0c in stdfunction stdallocator stdcxx11basicstring stdallocator const const this0x7f556c003fb0 args00x7f556c002da0 args1 at 24 0x0000563935cd0fc2 in httpworkitemoperator this0x7f556c003f80 at httpservercpp56 25 0x0000563935cd326d in workqueuerun this0x563938765d10 at httpservercpp111 26 0x0000563935ccbf1d in httpworkqueuerun queue0x563938765d10 workernum3 at httpservercpp343 27 0x0000563935cdfd51 in stdinvokeimpl int workqueue int f0x56393877e7f8 0x563935ccbeb2 int at 28 0x0000563935cdfaaa in stdinvoke int workqueue int fn0x56393877e7f8 0x563935ccbeb2 int at 29 0x0000563935cdf8a6 in stdthreadinvoker int workqueue int minvoke this0x56393877e7e8 at 30 0x0000563935cdf7db in stdthreadinvoker int workqueue int operator this0x56393877e7e8 at 31 0x0000563935cdf60f in stdthreadstateimpl int workqueue int mrun this0x56393877e7e0 at 32 0x00007f55a8e15b03 in from lib64libstdcso6 33 0x00007f55a8ac4e2d in startthread from lib64libcso6 34 0x00007f55a8b4a1b0 in clone3 from lib64libcso6 the affected code seems to be in frame 4 and corresponds to the following code gdb frame 4 4 0x0000563935a84d73 in operator self request at 276 for int i rangebegin i rangeend i i think the reason is that while rangebegin and rangeend are uint64t i is an int which on many platforms means int32t when i is assigned 2311 and is then incremented it wraps back and causes the crash"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nwallet/spend.cpp assertion error\nthis issue tracker is only for technical issues related to bitcoin core general bitcoin questions andor support requests are best directed to the bitcoin stackexchange at for reporting security issues please read instructions at if the node is stuck during sync or giving block checksum mismatch errors please ensure your hardware is stable by running memtest and observe cpu temperature with a loadtest tool such as linpack before creating an issue bitcoind fails to determine a fee rate which ends up crashing rpc method sentoaddress should work as intended and properly calculate the fee it throws and error and exits bitcoind 20221003t031942z feeest 48 85 decay 099520 feerate 1000 from 0 1000 9911 3063730677 0 mem 236 out fail 1 1 000 0000 0 mem 00 out 20221003t031942z feeest 12 85 decay 096200 feerate 1000 from 0 1000 9741 33183406 0 mem 00 out fail 1 1 000 0000 0 mem 00 out 20221003t031942z feeest 612 95 decay 099931 feerate 1000 from 0 1000 10000 9445094450 0 mem 00 out fail 1 1 000 0000 0 mem 00 out bitcoind walletspendcpp783 bool stdvector ctransactionref camount int bilingualstr const ccoincontrol feecalculation bool assertion feeneeded changeandfee changeamount failed aborted core dumped cant reproduce the error is seemingly random 220 windows 11 wsl linux ubuntu 2004 ryzen 9 5950x 64 gb ram"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`bitcoind` and `bitcoin-qt` crashes while creating PSBT\nbitcoind and bitcoinqt crashes when creating a psbt with expected behavior bitcoind and bitcoinqt should not crash and users should not see assertion errors on mainnet failing gracefully with some error message would be better although i was not able to reproduce this issue on fedora so ideally this should be fixed actual behavior error in bitcoind assertion failed target file line 391 error in bitcoinqt image to reproduce 1 create bitcoinconf signet1 txindex1 signetrpcport38332 rpcuseruser rpcpasswordpass fallbackfee00004 2 add descriptor in a wallet using bitcoinqt console importmulti desc timestampnow 3 create psbt using bitcoinqt click on different options in the error message and you will notice it creates psbt with no change by clicking ignore 3 times else crashes with others 4 close bitcoinqt and open powershell or command prompt to create psbt bitcoindexe bitcoincliexe rpcwalletm1 system information windows 10 bitcoin core master branch"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCI: Old versions of git can't handle merges\nit appears git versions older than 233 cant handle some simple merges and many of our ci tasks use such old versions the simplest fix is probably to just use githubs generated merge branch rather than trying to merge in each ci instance but i havent tested it"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nci ERROR: Commit: Failed to commit latest coinstatsindex state\nthis error happened in a push in i pushed the code again git commit amend and didnt happen it seems to be intermittent mocktime 20200831t153412z coinstatsindex utilsystemh50 error error commit failed to commit latest coinstatsindex state summary threadsanitizer data race on vptr ctordtor vs virtual call srcindexbasecpp691 in baseindexbaseindex"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntest: failure in wallet_resendwallettransactions.py\n"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nI2P: Transient destinations should be SIGNATURE_TYPE=7\n"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDon't assume signature grinding for external signers\nsince 13666 our fee calculation assumes that ecsda signatures are a maximum of 71 bytes rather than 72 however not all hardware wallets implement rvalue grinding this can cause us to underpay fees when using an external signer thats especially problematic when the user picks 1 satvbyte as the fee because it wont even get into our own mempool the easiest solution would be to modify to assume 72 bytes for ecsda signatures slightly more advanced would be to expand hwi to keep track of which devices and firmware versions if any support rvalue grinding wed then have to store that in the wallet in some new field personally id rather work on better taproot support which thanks to schnorr avoids this issue altogether"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnknown descriptor in wallet crashes\nattempting to load a wallet with an unknown descriptor causes a fatal error 20220906t015106z init message loading wallet… 20220906t015106z descriptor invalid descriptor can only have tr at top level iostream error 20220906t015106z descriptor invalid descriptor can only have tr at top level iostream error 20220906t015106z descriptor setting spkman to active id type legacy internal false 20220906t015106z descriptor setting spkman to active id type p2shsegwit internal false 20220906t015106z descriptor setting spkman to active id type bech32 internal false 20220906t015106z descriptor setting spkman to active id type bech32m internal false 20220906t015106z descriptor releasing wallet 20220906t015106z exception st12outofrange mapat bitcoin in runaway exception exception st12outofrange mapat bitcoin in runaway exception bitcoinqt checkqueueh204 t cscriptcheck assertion mworkerthreadsempty failed aborted a fatal error occurred bitcoin core can no longer continue safely and will quit to reproduce a quick hack c 14087 14087 stduniqueptr parsescriptuint32t keyexpindex spanconst error can only have addr at top level return nullptr if ctx functr expr if ctx functrx expr auto arg exprexpr auto internalkey arg out error if internalkey"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfs: `_OVERLAPPED` missing initializers\nbash fscpp in member function ‘bool fscpp12932 error missing initializer for member 129 overlapped overlapped 0 fscpp12932 error missing initializer for member ‘overlapped’ fscpp12932 error missing initializer for member ‘overlappedhevent’"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSegmentation fault when compiling with libfuzzer and lto (x86_64)\nsteps to reproduce install fresh ubuntu jammy operating system export apt update apt install curl wget htop git vim ccache y git clone bitcoincore cd bitcoincore apt install buildessential libtool autotoolsdev automake pkgconfig bsdmainutils python3zmq libeventdev libboostdev libsqlite3dev libdbdev clang llvm libcdev libcabidev y autogensh configure ccclang flto cxxclang flto enablefuzz withsanitizersfuzzer make jnproc output ar ar libbitcoinwalleta cxxld testfuzzfuzz clang error unable to execute command segmentation fault core dumped the same does not happen when compiling normally dropping withsanitizersfuzzer"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIntermittent failure in `wallet_groups.py`\nfile line 150 in runtest txid6 295 assertionerror node 4 expected messages fee nongrouped 5520 grouped 8240 using grouped does not partially match log"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCheckBlockIndex stalls for extremely long time\nstale chain tips can block the rpc and all other responses from the peer for very long time more than 15 minutes sometimes hours or undefinetely during that time i can see that my local node no longer replies to any other peer eg to bitnodeio core and in process viewers i can see that theres a single thread blocking all other threads in a tight loop using 100 cpu in a tight loop ive seen that this is occurs in any db indexer notably the chainstate indexer during ibd or the txindexer or the coinstat db indexer notably in some critical steps where new blocks are added to the chain once every about 15 minutes this seems to happen when a new block contains a transaction validating a better chain and invalidating other blocks from dead branches in that case the ongoin indexer will fail with unchecked conditions in its internal iterator apparently because it expect the next block to be present and locks it incorrectly and is not able to release it and retry if that next valid block has been replaced by a better block in the chain netprocessingcpp2797 processmessage new outbound peer connected version 70015 blocks750474 peer58 blockrelayonly indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 330879 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 331746 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 332578 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 333378 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 334219 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 334916 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 335794 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 336769 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 337743 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 338611 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 339322 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 340016 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 340630 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 341499 validationcpp2441 updatetiplog updatetip new height750475 version0x2281c000 log2work93689008 tx758464817 date20220821t195059z progress1000000 cache37mib27192txo indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 341803 validationcpp2441 updatetiplog updatetip new height750476 version0x20000004 log2work93689019 tx758465224 date20220821t195212z progress1000000 cache39mib28964txo indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 341814 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 342683 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 343432 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 344012 indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 344718 validationcpp2441 updatetiplog updatetip new height750477 version0x2ab96000 log2work93689030 tx758465722 date20220821t195436z progress1000000 cache41mib30966txo indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 344913 mapportcpp204 processupnp upnp port mapping successful mapportcpp204 processupnp upnp port mapping successful finally later it may eventually detect that and detect the inconsistency by eviting some peers indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 344915 netprocessingcpp4381 potential stale tip detected will try using extra outbound peer last tip update 1871 seconds ago netprocessingcpp2797 processmessage new outbound peer connected version 70016 blocks750480 peer194 outboundfullrelay netprocessingcpp2797 processmessage new outbound peer connected version 70016 blocks750480 peer195 outboundfullrelay netprocessingcpp2797 processmessage new outbound peer connected version 70016 blocks750480 peer196 outboundfullrelay netprocessingcpp2797 processmessage new outbound peer connected version 70016 blocks750480 peer198 outboundfullrelay validationcpp2441 updatetiplog updatetip new height750478 version0x20800000 log2work93689041 tx758467003 date20220821t200524z progress0999995 cache55mib41861txo indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 344926 validationcpp2441 updatetiplog updatetip new height750479 version0x20c00000 log2work93689052 tx758468307 date20220821t200838z progress0999996 cache66mib48588txo validationcpp2441 updatetiplog updatetip new height750480 version0x20400000 log2work93689063 tx758468706 date20220821t201040z progress0999996 cache68mib50180txo indexbasecpp169 threadsync syncing coinstatsindex with block chain from height 344927 netprocessingcpp2797 processmessage new outbound peer connected version 70015 blocks750480 peer205 outboundfullrelay netprocessingcpp2797 processmessage new outbound peer connected version 70016 blocks750480 peer208 outboundfullrelay netprocessingcpp2797 processmessage new outbound peer connected version 70016 blocks750480 peer211 outboundfullrelay netprocessingcpp2797 processmessage new outbound peer connected version 70016 blocks750480 peer213 outboundfullrelay and here again we see the deadlock occuring for long time in the coindb indexer note the difference of time between the last too events and in fact nothing else occured no resposes to other peers the coindb indexer was stalled the rpc service stopped to respond even locally it seems then that there are malicious nodes on the p2p network sending bad blocks that partially pass the basic security but can cause bitcoin core to be blocked and become unresponsive it can no longer respond even to a basic rpc such as bitcoin getinfo or bitcoin netinfo it will not even repond to a bitcoincli stop some threads are stopped but not all and the indexer thread is still running in its tight loop if you are in that situation the only way to recover is to kill the process entirely and youll get the related index to become invalid as it was not committed it will have to be reconstructed from zero most often you have no way to recover given that the rpc service is not responsive and even the ctrlc breaker or a simple kill hangup will not work you have to do an instant kill kill 9 on linux or manual kill in the process viewer on windows nothing else will be synced to disk if the index was the ibd index the chainstate can only be recovered by check level 4 works often but not necessarily always but never with check level 3 if it does not work then you have to rebuild the chainstate entirely but for any other index such as the txindex or coinstats index theres no check at all with recovery at startup so the only way to recover is to entirely delete the content of that index directory and rebuild it from zero and this will take many hours and may fail again in the middle due to bad blocks sent by malicious peers and that may have still not been replaced by valid blocks in the main chain apparently these bad blocks seem to come from unapproved forks possibly implementing segwit with too large block sizes which are not correctly detected and cause the indexer to fail or run into some infinite loops or some bad signatures using bytecodes taking extremely long time to validate or just discard rapidly as invalid such events with bad blocks coming from malicious peers tend to be frequent now unfortunately its not easy to track which nodes caused that bug as they may not even be connected since long they have sent their garbage and have disconnected themselves as soon as done just to crash specific versions of bitcoin core not detecting them note this is once again occuring with the current unmodified release v230 from your official site it affects both linux and windows versions are there blocks that are extremely long to validate or index taking much more than just about 1 minutes normally needed here to process every logged group of about 15 blocks such as more than 30 minutes in the 1st break above but still not completed after several hours at end of the logs above isnt it one of the reasons why segwit was asked for with blocks grouping many signatures for example those generated by very large miner pools and needing tons of transactions to validate all their micropayments to many participants see also bug may be related with the same race issue when theres a new chaintip updated while the indexer is running and iterating from the older chain view if this is the cause the bug is manifested only when you run it on a machine with enough cores to allow more threads to run concurrently the crasheshangs i experiment are all runing with 8 cores activates your test environment may just have 1 or 2 cores configured most probably not enough to experiment the race issue between concurrent threads and not experienced by people running it on cheap pc or notebooks or in cheapfree vms for azure and amazon if you get just 1 or 2 non dedicated cores note also that synchronization issues in code may even more likely to cause bugs on cpus running multiple threads per core or using more complex parallelism eg new intel processors with powerefficient and performance cpus with more complex caching layers or needing special kernelinitiated firmware mitigations like retpoline against attacks based on latency response time on caches and with speculative execution models those possibile attacks and firmware or os mitigations exist on many processors and their effect on execution latency may vary depending on the number of active concurrent threads if you have low io latency on disk storage this will also increase the likelyhood of race issues caused by improper synchronization but in all these cases this greatly impacts the leveldb indexers not properly iterating over the main chain of blocks if you want to experiment it faster you may want to test it on a machine with many more cpu cores like newest amd threadripper 48 concurrent threads and then try running multiple indexers running in parallel the chainstate indexer in ibd the coinsdbindexer the txindex and the coinsdbindex one of them will crashhand or report data corruption but not caused by any hardware issue but incorrect synchronization in bitcoin cores code as well it seems that all bugs like reported quite often but always diagnosed in replies incorrectly as a hardware issue just supposed but never really verified are also related to the same synchronization issues between any indexer thread and the thread handling any changes of the tips on the chainstate notably if theres a change between concurrent forks for new blocks after establishing a consensus they more likely occurs at end of a trading day when more blocks are announced for compensating transactions made by major traders its then more frequent to get new blocks emitted more rapidly than just once every 10 minutes during the rest of the day subsidiary question is there way to have a knonw list of trustable peers and a blacklist for bad peers sending fakecorrupted data isnt bitcoin missing some additional checks of the structure of these blocks not just the validation of the individual attempted transactions but basically its assumed format includnig for complex multipart signature schemes or peers attempting to force the use of a hard fork with a disappoved bip proposal or attemping to use it too early before a valid date and proper nogociation if they run some specific subchains one remote peer i remarked was always present when i saw crasheshangs was this one type net mping ping send recv txn blk hb addrp addrl age id address version out full ipv6 27 27 4 1 0 1002 1 11 200141d03032b2b8333 ive seen it several times sending groups of 2 or 3 unconfirmed blocks with large transactions in a row it is likely a nonupgraded miner node according to whois is is hosted by ovh in france and likely on a fiber access it uses the most antique version of satoshi i seen for a full node but with local patches trying to enforce bip148 but with wrong version announcements do i need to list it in my banlist"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndocfix: `sighash` parameter for `walletprocesspsbt`\ni think the documentation is incorrect since 22514 see"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUndefinedBehaviorSanitizer: stack-overflow in miniscript (descriptor_parse)\nto reproduce wget fuzzdescriptorparse srctestfuzzfuzz rsslimitmb1000 119584error stackoverflow on address 0x7ffcf4e35ff8 pc 0x55a9a0f40e0c bp 0x7ffcf4e36010 sp 0x7ffcf4e36000 t119584 0 0x55a9a0f40e0c in void constminiscriptnode const 1 0x55a9a0f3c96b in void conststdallocator miniscriptnode const 2 0x55a9a0f3c96b in const stdallocator 3 0x55a9a0f40eec in 4 0x55a9a0f40eec in 5 0x55a9a0f40eec in stdsharedptr const 6 0x55a9a0f40eec in void stddestroy conststdsharedptr const 7 0x55a9a0f40eec in void stddestroyauxdestroy conststdsharedptr const stdsharedptr const 8 0x55a9a0f40eec in void stddestroy conststdsharedptr const stdsharedptr const 9 0x55a9a0f40eec in void stddestroy const stdsharedptr conststdsharedptr const stdsharedptr const stdallocator const 10 0x55a9a0f40eec in stdvector const stdallocator constvector 11 0x55a9a0f40eec in miniscriptnodenode 12 0x55a9a0f40eec in void constminiscriptnode const 13 0x55a9a0f3c96b in void conststdallocator miniscriptnode const 14 0x55a9a0f3c96b in const stdallocator 9bitsstlvectorh6772 1475 0x55a9a0f40eec in miniscriptnodenode 1476 0x55a9a0f40eec in void constminiscriptnode const 1477 0x55a9a0f3c96b in void conststdallocator miniscriptnode const 1478 0x55a9a0f3c96b in const stdallocator 1479 0x55a9a0f40eec in 1480 0x55a9a0f40eec in 1481 0x55a9a0f40eec in stdsharedptr const 1482 0x55a9a0f40eec in void stddestroy conststdsharedptr const 1483 0x55a9a0f40eec in void stddestroyauxdestroy conststdsharedptr const stdsharedptr const 1484 0x55a9a0f40eec in void stddestroy conststdsharedptr const stdsharedptr const 1485 0x55a9a0f40eec in void stddestroy const stdsharedptr conststdsharedptr const stdsharedptr const stdallocator const 1486 0x55a9a0f40eec in stdvector const stdallocator constvector 1487 0x55a9a0f40eec in miniscriptnodenode 1488 0x55a9a0f40eec in void constminiscriptnode const summary stackoverflow in void constminiscriptnode const"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ntest: failure in interface_usdt_validation.py \nbash test testframework info handleblockconnected height202 transactions1 inputs1 sigops0 duration517 test testframework info handleblockconnected height201 transactions1 inputs1 sigops0 duration338 test testframework info check that we traced 2 blocks test testframework error assertion failed traceback most recent call last file line 133 in main selfruntest file line 131 in runtest blockschecked file line 52 in assertequal raise assertionerrornots joinstrarg for arg in thing1 thing2 args assertionerror not2 0"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\npsbt.h:644:51: runtime error: unsigned integer overflow: 0 - 1 cannot be represented in type 'unsigned long'\nsteps to reproduce build with integer sanitizer srcqtbitcoinqt enter into the rpc debug console decodepsbt"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBitcoin Core 0.23 installer incompatible with Windows mandatory ASLR\ntry downloading the current version 023 of bitcoin core for windows from the official site the installer exe is corrupted wont run corrupted exe format only the zip file is correct workaround you can use the 022 installer then download the 023 zip and extract the executables from there to overwrite the existing exe files qtexe in the main program filesbitcoin folder other executables in the zip go to the daemon subfolder so the exe package was incorrectly built or was incorrectly transferedtruncated on the download site on bitcoinorg"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\npsbt.h:896:51: runtime error: unsigned integer overflow: 0 - 1 cannot be represented in type 'unsigned long'\nthis needs a code change or suppression added info running with entropic power schedule 0xff 100 info seed 3574901271 info loaded 1 modules 322037 inline 8bit counters 322037 0x555887da9f40 0x555887df8935 info loaded 1 pc tables 322037 pcs 322037 running 1 inputs 1 times each running psbth89651 runtime error unsigned integer overflow 0 1 cannot be represented in type unsigned long 0 0x555885271598 in void srcpsbth89651 1 0x555885233a4e in void psbtoutput srcserializeh6827 2 0x555885233a4e in cdatastream srcstreamsh3399 3 0x55588523024f in void srcpsbth119115 4 0x55588522edee in void srcserializeh6827 5 0x55588522edee in cdatastream srcstreamsh3399 6 0x5558852067f5 in void anonymous stdoptional int 7 0x5558852067f5 in 8 0x555885106682 in stdfunctionhandler void const span 9 0x55588549ae5a in const 10 0x55588549aad6 in 11 0x555885029372 in char const unsigned long buildid 12 0x5558850138d0 in char const unsigned long buildid 13 0x555885019587 in char int unsigned char const unsigned long buildid 14 0x555885042342 in main buildid 15 0x7fa7994a3082 in libcstartmain 16 0x55588500e1cd in start buildid summary psbth89651 in base64"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIntermittent failure in feature_startupnotify.py\non the master branch 172245 failed duration 2 s stdout testframework info initializing test directory testframework info test startupnotify command is run when node starts testframework info test startupnotify is executed once testframework error assertion failed traceback most recent call last file line 133 in main selfruntest file line 34 in runtest 1 file line 51 in assertequal raise assertionerrornots joinstrarg for arg in thing1 thing2 args assertionerror not0 1 didnt find an existing open issue but looks to be the same win64 ci failure reported in"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nverifychain 4 111000 aborts with assertion \"hashPrevBlock == view.GetBestBlock()\" failed\nproviding a low number of blocks works however it just crashed for me with 111000 blocks if this is not supported it might be better to document that or reject the input commit output bitcoinqt validationcpp2005 bool cblock blockvalidationstate cblockindex ccoinsviewcache bool assertion hashprevblock viewgetbestblock failed"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ngui: Check for readlink buffer overflow and handle gracefully\nif readlink returns the size of the buffer an overflow may have safely occurred pass a buffer size of maxpath1 the size of the actual buffer to detect this scenario"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nConfusing filtering by block hash behaviour in `listsinceblock`\nthe reproduction speaks for itself diff diff git index fc06565983e06fbf120a 100755 3213 3214 class selfconnectnodes1 2 coinbasematurity 1 selftestnoblockhash selftestreorg selftestdoublespend selftestdoublesend selftestnoblockhash selftestreorg selftestdoublespend selftestdoublesend def testnoblockhashself selfloginfotest no blockhash 3835 38419 class false false def test the filtering in listtransactions is consistent with gettransactions output the block hash parameter gives according to the documentation the block hash to list transactions since test that if we have a transaction confirmed at a certain block listing the coins since this block will output this transaction txid 1 1 tx coins assert txid in ctxid for c in coins if name main is it intended that filtering transaction since block n only output transactions confirmed from block n1"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nqa: Intermittent failure in `wallet_encryption.py --descriptors`\nlog excerpt 177244 walletencryptionpy descriptors failed duration 6 s stdout testframework info initializing test directory testframework info check a timeout less than the limit testframework error assertion failed traceback most recent call last file line 133 in main selfruntest file line 85 in runtest actualtime file line 56 in assertgreaterthan raise assertionerrors s strthing1 strthing2 assertionerror 1756315608992383 1756315609 testframework info stopping nodes testframework warning not cleaning up dir testframework error test failed test logging available at testframework error testframework error hint call to consolidate all logs testframework error testframework error if this failure happened unexpectedly or intermittently please file a bug and provide a link or upload of the combined log testframework error testframework error"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nThreadSanitizer: data race on vptr (ctor/dtor vs virtual call) in BaseIndex\nbash warning threadsanitizer data race on vptr ctordtor vs virtual call pid24158 write of size 8 at 0x7ffe0efae9f8 by main thread 0 baseindexbaseindex srcindexbasecpp531 testbitcoin0xcc6b69 1 testbitcoin0x3b9b21 2 testbitcoin0x3b9b21 3 testbitcoin0x3b814b 4 testbitcoin0x2bbf1d 5 const testbitcoin0x220877 6 testbitcoin0x220877 7 testbitcoin0x220877 8 const testbitcoin0x1ae59e 9 int boostdetaildoinvoke boostfunction boostsharedptr const boostfunction const testbitcoin0x1ae59e 10 const testbitcoin0x1ae59e 11 const testbitcoin0x1ae8c0 12 const testbitcoin0x1aa21b 13 const unsigned long testbitcoin0x1aa21b 14 long unsigned long const testbitcoin0x1ddb63 15 long unsigned long const testbitcoin0x1de1d8 16 long unsigned long const testbitcoin0x1de1d8 17 long bool testbitcoin0x1a8e66 18 int char int char testbitcoin0x1c19c6 19 main testbitcoin0x1c1ff6 previous read of size 8 at 0x7ffe0efae9f8 by thread t1 mutexes write m603 0 const1operator const srcindexbasecpp3889 testbitcoin0xcc74e6 1 const srcindexbasecpp3889 testbitcoin0xcc74e6 2 const cblockindex const srcindexbasecpp2739 testbitcoin0xcc9759 3 const cblockindex const8operator const testbitcoin0x10223a4 4 void const cblockindex const8operator const cblockindex const8operator testbitcoin0x10223a4 5 const cblockindex const8operator const testbitcoin0x10223a4 6 const cblockindex const9operator const testbitcoin0x10223a4 7 decltypestaticcast const cblockindex const9fp std1invoke const cblockindex const cblockindex const9 testbitcoin0x10223a4 8 void const cblockindex const cblockindex const9 testbitcoin0x10223a4 9 const cblockindex const9 std1allocator const cblockindex const9 void operator testbitcoin0x10223a4 10 std1functionfunc const cblockindex const9 std1allocator const cblockindex const9 void operator testbitcoin0x10223a4 11 const testbitcoin0x10b6b71 12 std1functionoperator const testbitcoin0x10b6b71 13 srcschedulercpp1755 testbitcoin0x10b6b71 14 const srcschedulercpp14441 testbitcoin0x10b8875 15 decltypestaticcastfp testbitcoin0x10b8875 16 void testbitcoin0x10b8875 17 void operator testbitcoin0x10b8875 18 std1functionfunc void operator testbitcoin0x10b8875 19 const testbitcoin0x10b5b5c 20 std1functionoperator const testbitcoin0x10b5b5c 21 srcschedulercpp6217 testbitcoin0x10b5b5c 22 std1allocator const std1vector const0operator const testbitcoin0xa4e7b8 23 decltypestaticcast std1allocator const std1vector const0fp std1invoke std1allocator const std1vector std1allocator const std1vector const0 testbitcoin0xa4e7b8 24 void std1allocator const std1vector std1allocator const std1vector const0 testbitcoin0xa4e7b8 25 std1allocator const std1vector const0 std1allocator std1allocator const std1vector const0 void operator testbitcoin0xa4e7b8 26 std1functionfunc std1allocator const std1vector const0 std1allocator std1allocator const std1vector const0 void operator testbitcoin0xa4e7b8 27 const testbitcoin0x115760f 28 std1functionoperator const testbitcoin0x115760f 29 utiltracethreadchar const std1function srcutilthreadcpp189 testbitcoin0x115760f 30 staticcast std1allocator const std1vector const0fp0 std1invoke char const std1allocator const std1vector const0void char const std1function char const std1allocator const std1vector const0 testbitcoin0xa4e3b1 31 void std1threadexecute void char const std1function char const std1allocator const std1vector const0 2ul 3ulstd1tuple void char const std1function char const std1allocator const std1vector const0 std1tupleindices testbitcoin0xa4e3b1 32 void std1threadproxy void char const std1function char const std1allocator const std1vector const0 void testbitcoin0xa4e3b1 location is stack of main thread location is global at 0x7ffe0ef91000 stack0x00000001d9f8 mutex m603 0x558df2c934a0 created at 0 pthreadmutexinit testbitcoin0x11cf6f 1 libcso10x49fb3 2 libcstartmain libcso60x29eba thread t1 bscheduler tid24216 running created by main thread at 0 pthreadcreate testbitcoin0x11b7fd 1 long void void void testbitcoin0xa47a76 2 std1threadthread char const 10 std1allocator const std1vector const0 voidvoid char const std1function char const 10 std1allocator const std1vector const0 testbitcoin0xa47a76 3 std1allocator const std1vector const testbitcoin0xa47a76 4 std1allocator const std1vector const testbitcoin0xa47ed9 5 std1allocator const std1vector const testbitcoin0xa48be3 6 testbitcoin0x3b7c8b 7 testbitcoin0x3b7c8b 8 testbitcoin0x2bbf1d 9 const testbitcoin0x220877 10 testbitcoin0x220877 11 testbitcoin0x220877 12 const testbitcoin0x1ae59e 13 int boostdetaildoinvoke boostfunction boostsharedptr const boostfunction const testbitcoin0x1ae59e 14 const testbitcoin0x1ae59e 15 const testbitcoin0x1ae8c0 16 const testbitcoin0x1aa21b 17 const unsigned long testbitcoin0x1aa21b 18 long unsigned long const testbitcoin0x1ddb63 19 long unsigned long const testbitcoin0x1de1d8 20 long unsigned long const testbitcoin0x1de1d8 21 long bool testbitcoin0x1a8e66 22 int char int char testbitcoin0x1c19c6 23 main testbitcoin0x1c1ff6 summary threadsanitizer data race on vptr ctordtor vs virtual call srcindexbasecpp531 in baseindexbaseindex exit status 2"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n./wallet/bdb.h:27:10: fatal error: db_cxx.h: No such file or directory\nim having build error with current master with gentoo linux make clean autogensh configure make cxx in file included from qtrpcconsolecpp32 walletbdbh2710 fatal error dbcxxh no such file or directory 27 include compilation terminated locate dbcxxh usrincludedb48dbcxxh usrincludedb53dbcxxh reverting 25244 fixes the problem"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nnlocktime bug in Bitcoin Core v23\nrecreating the bug report because the previous one closed by a party who doesnt know nothing about bitcoin apparently block height for nlocktime doesnt work and this poses a serious risk for smart contracts i have added block height to nlocktime and got converted to timestamp which corresponds to 19700420 212525 found this bug when verifying a raw transaction"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndepends bdb -Werror=format-security \"format not a string literal and no format arguments\"\nrunning make c depends on nixos with gcc 1030 results in c libtool compile gcc c i idist dgnusource dreentrant pipe o2 disttxntxnc fpic dpic o txno disttxntxnc in function ‘txnbegin’ disttxntxnc1713 error format not a string literal and no format arguments werrorformatsecurity 171 dberrxenv txnalloc disttxntxnc in function ‘txncompensatebegin’ disttxntxnc3183 error format not a string literal and no format arguments werrorformatsecurity 318 dberrxenv txnalloc cc1 some warnings being treated as errors make1 makefile1980 txno error 1 make1 leaving directory make funcsmk288 error 2 make leaving directory i could work around it with diff diff git index 100644 147 147 dunicode endef but i dont know if this is the right fix or if there possibly is a real bug in the code causing the warning"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nStarting with an unsupported wallet configured leads to a segfault (master only?)\n0 void void at 1 2 this0x13dca9a70 at 3 0x000000011f25c9c0 in stdcxx11list stdallocator this0x7ffef8013e98 position at 4 0x000000011f241cc4 in stdcxx11list stdallocator this0x7ffef8013e98 position at 5 stdfunction 1operator const this at walletwalletcpp165 6 stdinvokeimpl 1stdinvokeother stdfunction 1 f at 7 stdinvoker stdfunction 1 fn at 8 stdfunctionhandler 1minvokestdanydata const functor at 9 0x000000011e8fb1f8 in stdfunctionoperator const this at 10 0x000000011f08d6c0 in interfacesanonymous this0x7ffef801edd0 at 11 0x000000011f08d7fc in interfacesanonymous this0x7ffef801edd0 at 12 0x000000011e7fcd34 in ptr0x7ffef801edd0 this at 13 stduniqueptr uniqueptr this at 14 0x000000011e90e038 in this0x13dc49f00 at qtsplashscreencpp138 15 0x000000011e90e6ec in this0x13dc49f00 at qtsplashscreencpp136 16 0x00007fffa4ff35f4 in o at 17 0x00007fffa4ff8550 in qobjectevent this e at 18 0x00007fffa45bd41c in qwidgetevent this0x13dc49f00 event0x7fff98023f40 at 19 0x00007fffa455da70 in this receiver0x13dc49f00 e0x7fff98023f40 at 20 0x00007fffa4569374 in qapplicationnotify this0x7ffff9f207a0 receiver0x13dc49f00 e0x7fff98023f40 at 21 0x00007fffa4faec80 in receiver0x13dc49f00 event0x7fff98023f40 at 22 0x00007fffa4faf00c in receiver event at 23 0x00007fffa4fb3ee4 in receiver0x0 eventtype0 data0x13dad8900 at 24 0x00007fffa4fb4244 in receiver0x0 eventtype at 25 0x00007fffa5037290 in s0x13dbb9ce0 at 26 0x00007fffa22e9794 in gmaindispatch at 27 0x00007fffa22ee930 in gmaincontextdispatch at 28 0x00007fffa22eeb58 in gmaincontextiterate blockblockentry1 self at 29 0x00007fffa22eec60 in mayblock at 30 0x00007fffa5036e7c in this0x13dbbcc70 flags at 31 0x00007fff9ef44e64 in this flags at 32 0x00007fffa4fabcc8 in this flags at 33 0x00007fffa4fac488 in qeventloopexec this0x7ffff9f204c8 flags at 34 0x00007fffa4fb9588 in qcoreapplicationexec at 35 0x00007fffa3d5704c in qguiapplicationexec at 36 0x00007fffa455d98c in qapplicationexec at 37 0x000000011e7b4354 in guimain argc argv at qtbitcoincpp661 38 0x000000011e7ac070 in main argc argv at qtmaincpp21"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrpc: createmultisig adds incorrect warning for address type p2sh-segwit\nthe createmultisig rpc adds a spurious warning message when creating for address type p2shsegwit createmultisig 2 p2shsegwit address redeemscript descriptor warnings unable to make chosen address type please ensure no uncompressed public keys are present i think this traces back to in the code the comparison at fails since outputtype is outputtypep2shsegwit and returns outputtypelegacy expected behavior no warning message for example createmultisig 2 p2shsegwit address redeemscript descriptor"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGuix build w/o substitutes failing at libgit2 check\nthis is an upstream guix issue 55273 but they seem to be planning to resolve it with a version bump and either way we have versions pinned i think building unpack phaseildlog 356 178 17 ildlog 356 189 warning error may be used uninitialized in this function wmaybeuninitialized 148 if error 0 17 ildlog 356 72 18 building c object check phasenote keeping build directory builder for failed with exit code 1 build of failed refsrevparsef 1 failure refsrevparsedate function call succeeded error no error expected nonzero return"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBitcoin Core wallet -> HD key generation disabled\nthe bitcoin core wallet window has icons in the lower right corner one of those icons is the letters hd with the v220 version when passing the mouse cursor over this icon a message appeared which said hd key generation is enabled however after downloading the latest version of bitcoin core 230 the message that appears to me is the opposite hd key generation is disabled 1st screenshot the wallet had no funds and in that sense i have not lost anything but i am concerned that after upgrading bitcoin core to the latest version the hd key generation has changed im pretty new to this and dont understand much i have asked read and looked for some solution but no one has been able to tell me what happens whether it is normal or not what the solution isetc also note that when using the getwalletinfo command in the bitcoin core console appeared this 2nd screenshot and that i do not know if it refers to the same hd key generation or not also tried to upgrade the bitcoin core wallet with the upgradewallet comand 3rd screenshot i got the latest version of bitcoin core from and i got this url from the bitcoin core project profile on twitter my os is windows 10 pro and my cpu is a intelr coretm i54460 cpu 320ghz 320 ghz for me this is first time doing thisso sorry for what might be wrong and sorry for my english i do not speak it well enough captura de pantalla 20220505 113132 captura de pantalla 20220501 200018 upgrade wallet"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAutomatic prune on Tails OS\nrunning bitcoin core full node on tails os new version 230 automatically prunes when started i dont want to prune and have therefore set prune0 in bitcoinconf but that wont stop 230 from pruning have to manually untick the tick box at startup this was never the case in 220 so wondering if prune0 is disabled even though its stated in options image"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBUG  ./configure  /install\nafter the latest update can not be installed in the configure section with the following problem configure checking dependency style of g gcc3 checking whether g supports c17 features with stdc17 yes checking whether stdatomic can be used without link library yes checking whether stdfilesystem can be used without link library no checking whether stdfilesystem needs lstdcfs no checking whether stdfilesystem needs lcfs configure error in homebi tcoin configure error cannot figure out how to use stdfilesystem see configlog for more details"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nwallet_taproot.py fails with \"Insufficient funds (-4)\"\ntest testframework error jsonrpc error traceback most recent call last file line 133 in main selfruntest file line 448 in runtest psbt none 0psbt file line 49 in call returnval kwargs file line 144 in call raise status insufficient funds 4"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nwallet: ignore chainStateFlushed notifications while attaching chain\nfixes 24487 when a rescan is performed during cwalletattachchain eg when loading an old wallet but this is interrupted by a shutdown signal the wallet will currently stop the rescan receive a chainstateflushed signal set the saved best block to the tip and shut down at next startup the rescan is not continued or repeated because of this but some blocks have never been scanned by the wallet which could lead to an incorrect balance fix this by ignoring chainstateflushed notifications until the chain is attached since is being manually called by attachchain anyway after finishing with the rescan it is not a problem if intermediate notifications are ignored manual rescans started aborted by the rescanblockchain abortrescan rpcs are not affected by this i didnt choose alternative ways of fixing this issue that would delay the validationinterface registration or change anything else about the handling of blockconnected signals for the reasons mentioned in this existing comment"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n-onlynet=onion plus -onlynet=ipv4/etc, without -onion=, in spite of -torcontrol= specified, incorrectly kills startup\nin v22 using the options onlynetonion onlynetipv4 onlynetipv6 combined with the options torcontrol etc functioned and bitcoind correctly pulled the onion socks address via a probe to tor in v23 that combination of options no longer functions and onion is required expected using onlynetonion and ipv4 and ipv6 if torcontrol is specified should still work actual behavior bitcoind refuses to start up due to commitid e53a8505db preventing it from doing so in initcpp to reproduce run as per above system information sources built from tag v230 as of this writing i think error message in debuglog is error outbound connections restricted to tor onlynetonion but the proxy for reaching the tor network is not provided no proxy and no onion given or it is explicitly forbidden onion0 shutdown in progress scheduler thread exit shutdown done"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRPC: Calls to Bitcoin RPC are truncated.\nrpc calls to bitcoin rpc are truncated im having a problem making batching calls to bitcoin rpc it is returning a truncated json my suspicions is that there is some maxsize for the response of requests if that is true it should return a message error bitcoin core version 220 to reproduce the problem bash curl x post d jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 jsonrpc 20 method getblock params 0 h silent"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnresponsive CLI\nissue report 24810 reminds me that ive been seeing a similar issue since several months on master built with enabledebug in my development environment where the cli becomes unresponsive and eventually returns error timeout on transient error could not connect to the server 1270018332 error code 0 timeout reached make sure the bitcoind server is running and that you are connecting to the correct rpc port once the cli becomes unresponsive it seems to happen with any cli command this didnt occur for me with v21 and im not sure about v22 as iirc it began sometime last fall 2021 for me until now ive been discounting it as something related to my local environment and working around it by restarting since i restart very often for review and testing debian testing currently debian 516181 20220329 x8664 gnulinux im going to try to narrow down the issue more is anyone else running into this"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbuild: Do not modify `common.init.vcxproj` directly\nwhen building with msvc and using a nondefault toolset the following command python toolset v143 actually modifies the source tree diff git diff warning lf will be replaced by crlf in the file will have its original line endings in your working directory diff git index 0cbe2effd44b7efff3 100644 397 397 false false v142 v143 unicode no 497 497 true true v142 v143 unicode this pr fixes this bug"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRace in generatetoaddress?\ntest failure at seems to indicate generatetoaddress has a path that doesnt set the height in coinbase correctly rpc call node1 httpworker2 rpcrequestcpp179 parse threadrpcserver usercookie a new block immediately arrives over the network via the msghand thread node1 httpworker2 loggingtimerh57 log enter lock contention csmain rpcminingcpp156 started node1 msghand newpowvalidblock newpowvalidblock block node1 httpworker2 loggingtimerh57 log enter lock contention csmain rpcminingcpp156 completed 4225μs then msghand gets held up in the middle of activatebestchain short lock contention node1 msghand loggingtimerh57 log enter lock contention csmain validationcpp2889 started node1 httpworker2 nodeminercpp160 createnewblock createnewblock block weight 892 txs 0 fees 0 sigops 400 node1 httpworker2 validationcpp1988 connectblock sanity checks 001ms 000s 000msblk node1 httpworker2 validationcpp2087 connectblock fork checks 008ms 001s 008msblk node1 httpworker2 validationcpp2172 connectblock connect 1 transactions 004ms 0035mstx 0000mstxin 001s 005msblk node1 httpworker2 validationcpp2185 connectblock verify 0 txins 007ms 0000mstxin 001s 010msblk node1 httpworker2 nodeminercpp175 createnewblock createnewblock packages 015ms 0 packages 0 updated descendants validity 040ms total 055ms node1 httpworker2 loggingtimerh57 log enter lock contention csmain rpcminingcpp124 started node1 msghand loggingtimerh57 log enter lock contention csmain validationcpp2889 completed 446μs at this point msghand has the ball again and httpworker2 is waiting before calling incrementextranonce which is where the height in coinbase is set node1 msghand validationcpp2617 connecttip load block from disk 000ms 000s node1 msghand validationcpp1988 connectblock sanity checks 000ms 000s 000msblk node1 msghand validationcpp2087 connectblock fork checks 008ms 001s 008msblk node1 msghand validationcpp2172 connectblock connect 1 transactions 005ms 0049mstx 0000mstxin 001s 005msblk node1 msghand validationcpp2185 connectblock verify 0 txins 009ms 0000mstxin 001s 010msblk node1 msghand validationcpp2204 connectblock index writing 014ms 001s 008msblk node1 msghand blockchecked blockchecked block statevalid node1 msghand validationcpp2629 connecttip connect total 050ms 005s 037msblk node1 msghand validationcpp2634 connecttip flush 004ms 000s 003msblk node1 msghand validationcpp2640 connecttip writing chainstate 006ms 001s 004msblk node1 msghand policyfeescpp654 processblock blockpolicy estimates updated by 0 of 0 block txs since last block 0 of 0 tracked mempool map size 0 max target 51 from current node1 msghand validationcpp2433 updatetiplog updatetip new height305 version0x30000000 log2work9257388 tx310 date20220331t224307z progress1000000 cache00mib112txo node1 msghand validationcpp2651 connecttip connect postprocess 158ms 016s 114msblk node1 msghand validationcpp2652 connecttip connect block 218ms 022s 158msblk node1 msghand txmempoolcpp722 check checking mempool with 0 transactions and 0 inputs node1 msghand blockconnected enqueuing blockconnected block block height305 node1 msghand updatedblocktip enqueuing updatedblocktip new block fork block in ibdfalse now the tip has been updated looks like msghand releases the lock but manages to reacquire it before any other thread node1 msghand loggingtimerh57 log enter lock contention newtaskmutex schedulercpp78 started node1 msghand loggingtimerh57 log enter lock contention newtaskmutex schedulercpp78 completed 3μs the scheduler thread seems to get the lock next node1 scheduler operator blockconnected block block height305 node1 scheduler loggingtimerh57 log enter lock contention csmain netprocessingcpp1596 started node1 scheduler loggingtimerh57 log enter lock contention csmain netprocessingcpp1596 completed 2398μs and finally httpworker2 gets it incrementing the extra nonce and presumably updating to the new block node1 httpworker2 loggingtimerh57 log enter lock contention csmain rpcminingcpp124 completed 5139μs other threads do their thing node1 msghand loggingtimerh57 log enter lock contention csmain validationcpp5081 started node1 msghand loggingtimerh57 log enter lock contention csmain validationcpp5081 completed 32μs node1 scheduler operator updatedblocktip new block fork block in ibdfalse then httpworker2 is calling processnewblock and everything falls apart node1 httpworker2 loggingtimerh57 log enter lock contention csmain validationcpp3687 started node1 httpworker2 loggingtimerh57 log enter lock contention csmain validationcpp3687 completed 58μs node1 msghand loggingtimerh57 log enter lock contention csmain validationcpp5081 started test testframework error jsonrpc error traceback most recent call last file line 132 in main selfruntest file line 258 in runtest coinbasematurity 1 address2 syncfunselfnoop file line 649 in generatetoaddress blocks invalidcallfalse kwargs file line 311 in generatetoaddress return kwargs file line 49 in call returnval kwargs file line 144 in call raise status processnewblock block not accepted 32603 node1 httpworker2 utilsystemh51 error error acceptblock badcbheight block height mismatch in coinbase node1 httpworker2 blockchecked blockchecked block statebadcbheight block height mismatch in coinbase node1 httpworker2 utilsystemh51 error error processnewblock acceptblock failed badcbheight block height mismatch in coinbase node1 msghand loggingtimerh57 log enter lock contention csmain validationcpp5081 completed 1364μs"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nwallet: Postpone wallet loading notification for encrypted wallets\nfixes bitcoincoregui571 cwalletcreate notifies about wallet loading too early that results the notification goes before were created and added to an encrypted wallet and in erroneously returns false for just created encrypted descriptor wallets"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbench: `MempoolCheck` actually runs with `check_ratio = 0`\nfor mempoolcheck it seems that the intention was to have a mempool with checkratio 1 see checkmempool1 however in the subsequent line in the above snippet a ctxmempool gets constructed with no arguments which means that checkratio will default to 0 manually specifying checkratio to 1 according to the original intention and running the mempoolcheck benchmark results in an assertion error diff git index afa4618e1b32cdb70539 100644 1057 1057 static void bench const int childtxs benchcomplexityn 1 2000 const stdvector orderedcoins childtxs minancestors 5 const auto testingsetup checkmempool1 ctxmempool pool ctxmempool poolnullptr 1 lock2csmain poolcs const ccoinsviewcache coinstip for auto tx orderedcoins addtxtx pool sh srcbenchbenchbitcoin filtermempoolcheck benchbitcoin txmempoolcpp759 void ctxmempoolcheckconst ccoinsviewcache int64t const assertion failed aside from this problem we should also probably just reuse the ctxmempool in testingsetup ping glozow"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nguix: Linker warning for darwin builds\ncxxld ld warning double slash removed from installname"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfeature_init intermittent issue:                                    UnicodeDecodeError: 'utf-8' codec can't decode bytes in position 1215-1217: unexpected end of data\npresumably because a unicode character was only written partially test testframework error unexpected exception caught during testing traceback most recent call last file line 132 in main selfruntest file line 79 in runtest blockfilterindex1 coinstatsindex1 file line 120 in exit nextselfgen file line 442 in waitfordebuglog log dlread file line 322 in decode result consumed selfbufferdecodedata selferrors final unicodedecodeerror utf8 codec cant decode bytes in position 12151217 unexpected end of data"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUse designated initializers\ndesignated initializers are supported since gcc 47 our minimum required is 8 and clang 3 our minimum required is 7 they work out of the box with c17 and only msvc requires the c20 flag to be set i dont expect any of our msvc users will run into issues due to this see also"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBitcoind repeatedly crashing at `UpdateTip` with no error message\nexpected behavior bitcoind either doesnt crash or provides some error information in debuglog about the crash actual behavior about 10 seconds after starting bitcoind it reliably crashes right after 20220305t234740z updatetip new 5f height425259 version0x20000000 log2work85132165 tx149305533 date20160815t014346z progre ss0211905 cache01mib867txo 20220305t234740z updatetip new ec height425260 version0x20000000 log2work85132195 tx149307741 date20160815t020356z progre ss0211908 cache12mib9061txo im currently stuck on block 425258 but thats after trying to run reindex when this was happening more up towards the high 600000s so im not sure if its anything particular with this block or not to reproduce this happens every time consistently for me system information bitcoind version bitcoin core version v220 originally tried with building my own then tried again with the prebuild binary from bitcoincoreorg to make sure i didnt do something wrong same issue lsbrelease a no lsb modules are available distributor id ubuntu description ubuntu 20043 lts release 2004 codename focal lscpu architecture x8664 cpu opmodes 32bit 64bit cpus 4 vendor id genuineintel cpu family 6 model 158 model name intelr coretm i37100 cpu 390ghz lsmem lsmem range size state removable block 23g online no 017 138g online no 32141 memory block size 128m total online memory 16g total offline memory 0b sudo smartctl all devsda start of information section model family western digital red lu wwn device id 5 0014ee 26488ca44 firmware version 8200a82 user capacity 3000592982016 bytes 300 tb sector sizes 512 bytes logical 4096 bytes physical rotation rate 5400 rpm ata version is acs2 minor revision not indicated sata version is sata 30 60 gbs current 60 gbs smart support is available device has smart capability smart support is enabled start of read smart data section smart overallhealth selfassessment test result passed i put my debuglogs over in this gist one default logging and one with debug1"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHomebrew Boost 1.78 breaks external signer configure\ntest on macos 1221 against the master branch 24397 doesnt fix it brew info boost boost stable 1780 bottled head configure enableexternalsigner checking for boostlib 1640 106400 yes checking whether boostprocess can be used no configure error external signing is not supported for this boost version it does work with boost 176 there was no 177 release in homebrew brew install boost176 configure enableexternalsigner checking for boostlib 1640 106400 yes checking whether boostprocess can be used yes options used to compile and link external signer yes theres nothing in the release notes about boostprocess for either 177 or 178 the homebrew formula changes are nothing but a trivial version and hash bump"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGUI: \"registerShutdownBlockReason: Successfully registered: Dogecoin Core didn't yet exit safely...\" and ERROR: AcceptToMemoryPool: non-final\nthis is a dogecoincore qt not sync to reproduce file log debug system information debuglog"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSegmentation fault. \"b-httpworker.0\"\nafter calling importaddress trough http rpc i get segmentation fault at the end of synctracked by progress expected behavior should complete importaddress should complete importaddress actual behavior segmentation fault to reproduce just try to call importaddress trought wallet rpc in bitcoin testnet 1010 times system information ubuntu 0211 digital ocean ubuntu instance gdb heres log right before crash 20220219t101115z sending verack 0 bytes peer2291 20220219t101115z receive version message satoshi0171 version 70013 blocks0 us68183751418333 peer2291 20220219t101115z socket closed for peer2290 20220219t101115z disconnecting peer2290 20220219t101115z received verack 0 bytes peer2290 20220219t101115z sending sendheaders 0 bytes peer2290 thread 11 bhttpworker0 received signal sigsegv segmentation fault switching to thread 0x7fffcffff700 lwp 1008189"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTest-only UB in fuzz tests\nthis line c connmantestmsg connman in is constructing a reference to a connmantestmsg which actually refers to an object of type connman even though connmantestmsg inherits from connman and adds no fields i am pretty sure this is undefined behavior it isnt detected by the sanitizer because theyre not polymorphic types for which runtime type information is tracked but if you make connmanconnman virtual it does get detected testfuzzutilcpp26523 runtime error member call on address 0x619000034380 which does not point to an object of type connmantestmsg 0x619000034380 note object is of type cconnman 00 00 00 00 90 8e a0 29 19 56 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 01 00 00 00 vptr for cconnman i dont know how to quickly solve this myself as im unfamiliar with this part of the code so im opening an issue to discuss it"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbuild: compilation error in `tinyformat.h` on Manjaro Linux\nheres the output from make walletwalleth8029 required from ‘void params const with params stdoptional stdstring stdcxx11basicstring’ required from here tinyformath2919 error no match for ‘operator’ and ‘const stdoptional’ 291 tmp value tinyformath2919 note candidate ‘operatorint int’ builtin walletwalleth8029 required from ‘void params const with params stdoptional stdstring stdcxx11basicstring’ required from here error no type named ‘type’ in ‘struct stdenableif’ in file included from from from fsh11 from walletwalleth10 from walletwalletcpp6 tinyformath in instantiation of ‘void const t int with t stdoptional stdostream stdbasicostream’ tinyformath35532 required from ‘void const char const char int const t with t stdoptional stdostream stdbasicostream’ tinyformath54324 required from ‘static void const char const char int const void with t stdoptional stdostream stdbasicostream’ tinyformath51913 required from t with t stdoptional’ tinyformath97532 required from args with args stdcxx11basicstring stdallocator stdoptional int n 2’ tinyformath102820 required from args with args stdcxx11basicstring stdallocator stdoptional’ tinyformath106437 required from ‘void const char const args with args stdcxx11basicstring stdallocator stdoptional stdostream stdbasicostream’ tinyformath107311 required from ‘stdstring char const args with args stdcxx11basicstring stdallocator stdoptional stdstring stdcxx11basicstring’ same with clang note candidate function not viable no known conversion from const stdoptional to aka basicstreambuf for 1st argument sb in file included from walletwalletcpp6 in file included from walletwalleth10 in file included from fsh8 tinyformath2919 error invalid operands to binary expression stdostringstream aka basicostringstream and const stdoptional tmp value"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSegmentation Fault in V21 and V22 releases\nos ubuntu 2004 releases bitcoin core v21 and v22 the problem i have a lot of hd wallets with the first transaction in dic 2017 encrypted not checked for 5 years it starts reescaning and segmentation fault error tried with bitcoinqt bitcoind reindex the whole blockchain and still segmentation fault after loading the gui load the wallet again it closes with segmentation fault v21 and v22 downloaded and checked for signatures and hashes the same wallets if checked after mid20182019 a year or more work the machine is a dell inspiron with 16gb of ram dbcache8000 tried a lot of other things rescan etc that didnt work all other wallets work fine no problems but these ones fail with newer versions of bitcoin core run bitcoinwallet info the wallets are ok not corrupted or anything if i do the reindex while the wallet is loaded it crashes the moment the reindex gets to dic 2017jan 2018 then i reestart without the wallet loaded and it finishes reindexing ok in the log says it loads the wallet ok 5s starts reescaning and then nothing else it crashes it crashes 4 or 5 seconds after reescaning really fast both bitcoinqt and bitcoind"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`gestdescriptorinfo` ignores hardened paths in origin info for computing the checksum (therefore returns invalid checksums)\nlets say i have two xpubs derived at m1230 from a master xpub id like to create a descriptor describing a multisig between those 2 keys i create a descriptor wallet bcreg1 named createwallet walletnamerepro descriptorstrue name repro warning since i wont compute the checksum by hand i use the hack of getting it from getdescriptorinfo bcreg1 getdescriptorinfo descriptor checksum hs0kuwwv isrange true issolvable true hasprivatekeys false now i use the output of getdescriptorinfo to import the descriptor and bcreg1 rpcwalletrepro importdescriptors success false error code 5 message provided checksum hs0kuwwv does not match computed checksum rgsu3znf hmm turns out the checksum getdescriptorinfo gave me is invalid both in the descriptor and checksum fields i remember some discussions around canonicalization and the h vs notation for hardened paths so i try by using h instead bcreg1 getdescriptorinfo descriptor checksum 6nuh6ujc isrange true issolvable true hasprivatekeys false it outputs the same invalid descriptor in the descriptor field fortunately the checksum in checksum is actually valid so i can use that in importdescriptors maybe worth mentioning before trying on latest master i had an additional issue with 220 where getdescriptorinfo would literally remove the hardened paths from the origin info bc getdescriptorinfo descriptor checksum kvvtf4uz isrange true issolvable true hasprivatekeys false so maybe the bad checksum above was the checksum without the hardened paths bcreg1 getdescriptorinfo descriptor checksum rgsu3znf isrange true issolvable true hasprivatekeys false bingo"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsegfault when compiled with depends DEBUG=1 and libc++\nsee also and steps to reproduce on a fresh install of ubuntu focal export apt update apt install curl wget htop git vim ccache y git clone bitcoincore cd bitcoincore apt install buildessential libtool autotoolsdev automake pkgconfig bsdmainutils python3zmq make automake cmake curl clang llvm libcdev libcabidev gmultilib libtool binutilsgold bsdmainutils pkgconfig python3 patch bison y cd depends make debug1 noqt1 nowallet1 nozmq1 noupnp1 nonatpmp1 j nproc autogensh configure ccclang cxxclang stdliblibc enablefuzz withsanitizersfuzzer make j nproc fuzztxpool srctestfuzzfuzz 52419error segv on unknown address 0x000000000008 pc 0x7f5d814ccb47 bp 0x7fff699e4ef0 sp 0x7fff699e4ea0 t52419 52419the signal is caused by a read memory access 52419hint address points to the zero page 0 0x7f5d814ccb47 in std1libcppdbswapvoid void 1 0x564aea7e1377 in std1basicstring std1allocator std1allocator 2 0x564aea80cf94 in 3 0x564aea80bd04 in 4 0x564aeb1f46ad in fsabsolutefspath const 5 0x564aeb1f4c8b in const 6 0x564aea80bbfa in const 7 0x564aeb1fa2bb in const bool 8 0x564aeb0d5074 in const 9 0x564aeaaddd15 in const 10 0x564aeaa06412 in std1allocator const std1vector const 11 0x564aeaa073e2 in std1allocator const std1vector const 12 0x564aeaa0877f in std1allocator const std1vector const 13 0x564aea85508d in std1makeunique std1allocator const std1vector conststd1basicstring std1allocator const std1vector const 14 0x564aea852a22 in std1uniqueptr std1allocator const std1vector const 15 0x564aea9c5817 in anonymous 16 0x564aea7c8d20 in std1invokevoid 17 0x564aea7c8c6d in void 18 0x564aea7c8c0d in void operator 19 0x564aea7c7049 in std1functionfunc void operator 20 0x564aeaab965c in const 21 0x564aeaab95e5 in std1functionoperator const 22 0x564aeb25ac9d in initialize 23 0x564aeb25b71f in llvmfuzzerinitialize 24 0x564aea743437 in char int unsigned char const unsigned long 25 0x564aea76df22 in main 26 0x7f5d810e60b2 in libcstartmain 27 0x564aea719e7d in start can not provide additional info summary segv in std1libcppdbswapvoid void 52419aborting"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nbitcoind and bitcoin-cli does not supports symbolic link anymore\ni just pulled latest master at and i cannot run bitcoind or bitcoincli without providing a full path for data directory using datadir option it was working fine couple of days ago while running i suspect it may be related to latest switch to the standard stdfilesystem library expected behavior i use a symbolic link to point my homemebitcoin to an external hard drive when running bitcoind from command line or executing bitcoincli commands without using the datadir option it should not terminate or crash unexpectedly those commands should be able to follow the symbolic link and be able to readwrite into the final folder actual behavior bitcoind and bitcoincli are not able to follow the symbolic link bitcoinqt runs fine even when running it from command line see below commands examples create a symbolic link btcthingsbitcoin ln s mediadatabitcoin homemebitcoin try to run bitcoind crashes btcthingsbitcoin bitcoind exception filesystem error cannot create directories not a directory homemebitcoin bitcoin in appinit bitcoind chainparamsbasecpp35 const cbasechainparams baseparams assertion failed aborted core dumped run bitcoinqt it works fine the node runs btcthingsbitcoin bitcoinqt qt5ct using qt5ct plugin try to run a bitcoincli command to interact with the running node does not work btcthingsbitcoin bitcoincli getblockhash 501726 exception filesystem error cannot create directories not a directory homemebitcoin bitcoin in appinitrpc try the same previous command but give an absolute path for datadir works fine btcthingsbitcoin bitcoincli getblockhash 501726 to reproduce steps are indicated previously system information running bitcoin core version v229903ace3a17c9bc self compiled from master branch im using linux mint with the following kernel linux 54096generic x8664 im using an additional hard drive to store the full blockchain ssd i had no prior issues before pulling latest changes i was previously running at"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n-reindex-chainstate with -prune hangs\nsteps to reproduce create a datadir that is pruned start with prune550 reindexchainstate hangs with idle cpu reindex works"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFixed OpenCL FP16 fallback in Einsum layer\nfixes pull request readiness checklist see details at i agree to contribute to the project under apache 2 license to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nerror loading onnx model while reading it from opencv dnn module\nsystem information ubuntu 2204 python 38 python 480 opset version 14 detailed description hello i have converted the rafdbmodelbestpth model into onnx for facial emotion recognition i am able to read the model using onnxruntime and able to generate inference but when read it using its throwing me error opencv480 error 2unspecified error in function handlenode node parse error opencv480 error 215assertion failed intnumaxes inputs0size in function getmemoryshapes can someone explain me how to solve this error steps to reproduce using issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndnn: wrong internal results in `expand_neg_batch` in Test_ONNX_layers.Expand\nsystem information lastest opencv and lastest onnxruntime 1160 released just now detailed description the model expandnegbatchonnx is as follows note that i manually added output 8 image for output 8 onnxruntime produces value 2 1 1 1 dnn produces value 2 1 1 1 my own calculation is the same as onnxruntimes model is attached here asmorkalov should we run every single onnx model in testonnximportercpp with onnxruntime and verify with our input and output data to see whether the model is correctly built and dnn can produce correct results steps to reproduce 1 download the model and run inference to get outputs with onnxruntime python import numpy as np import onnxruntime as ort import cv2 as cv x nprandomrandn1 2 2astypenpfloat32 def net out netrun8 0 printort result out def net netsetinputx out netforward8 printocv result out forget this small 3d tensor is parsed incorrectly because of opencv python binding 2 clone my expand refactor pr add the following code to print shape in about line 2318 cpp for int i 0 i matinputshapetotal i stdcout i cvchecki matinputshapeptr i 0 invalid shape dimension issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFix memory leak and handle realloc failure\nin the previous code there was a memory leak issue where the previously allocated memory was not freed upon a failed realloc operation this commit addresses the problem by releasing the old memory before setting the pointer to null in case of a realloc failure this ensures that memory is properly managed and avoids potential memory leaks pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRISC-V: fix compilation in RVV scalable mode\ntested with clang 16 and gcc 13 riscv rvv scalable variant also on x8664 default ubuntu 2204 gcc forcebuilderscustom testtimeoutcustom600"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBuild with OpenVINO in Debug\npull request readiness checklist resolves see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfix type cast in drawDetectedMarkers, drawDetectedCornersCharuco, drawDetectedDiamonds\ndrawdetectedmarkers drawdetecteddiamonds uses only point2f cv32fc2 for detected corners but this corners are casted to int later in the code drawdetectedmarkers drawdetecteddiamonds has a requirement on cv32fc2 for corners this requirement is lost in strict input data requirements have been removed added only the requirement to have 2 channels the input corners are then casted to cv32sc2 added tests pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSIGILL in `merge`\nsystem information opencv version 454 operating system platform ubuntu 22043 lts compiler compiler version g ubuntu 11401ubuntu12204 1140 i also reproduced error on cv 460 on windows but the minimal example has been tested on ubuntu with cv454 detailed description using cvmerge with null matrix is causing sigill im fully expecting a crash or any error but not a sigill as this leads to not executing the final stacktrace in our application steps to reproduce maincpp c include include int mainint argc char argv cvmat planes4 cvmat mm stdcout hello there beforestdendl cvmergeplanes3mm stdcout hello there afterstdendl return 0 compile with g o yourprogramname maincpp pkgconfig opencv4 cflags libs issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRevert PR 24186 as it forces skipping tests\nreverts current test skipping issue binopencvtestdnn ok 3 ms run where getparam ngraphcpu ok 8 ms run where getparam ocvocl ok 4 ms run where getparam ocvoclfp16 skip test with tag dnnskipoclfp16 is skipped dnnskipoclfp16 is in skip list ok 0 ms run where getparam ocvcpu skip ok 0 ms run where getparam ngraphcpu skip ok 0 ms run where getparam ocvocl skip ok 0 ms run where getparam ocvoclfp16 skip ok 0 ms run where getparam ocvcpu skip ok 0 ms all further tests are skipped more focused test invocation works well binopencvtestdnn run where getparam ngraphcpu ok 23 ms run where getparam ocvocl ok 4 ms run where getparam ocvoclfp16 ok 2 ms run where getparam ocvcpu ok 1 ms 4 tests from testcaffelayers 30 ms total global test environment teardown 4 tests from 1 test case ran 30 ms total passed 4 tests pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncore: arm64: v_round() works with round to nearest, ties to even.\nfix pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[RFC] rounding rule for cv::divide()\nsystem information opencv version 4x branch operating system platform ubuntu 2004 raspi4 arm64 compiler compiler version gcc 930 detailed description this issue is about cvdivide related with rounding rule for it is not describled at cvdivide in arm64 it works with round to nearest ties away from zero in x8664 it works with round to nearest ties to even possibly the behavior may change according to the rounding mode specification of the floating point unit q their results are different which are these behaviours correctbetter if arm64 behaviours should be fixed for arm64 i think it can fix following patch however vround function seems to used many times i feel the risk of breaking backwards compatibility i would appreciate it if you could comment on this issue before after diff diff git index 6f8973231b14eb180819 100644 199712 199712 inline vint32x4 vtruncconst vfloat32x4 a inline vint32x4 vroundconst vfloat64x2 a static const int32x2t zero vdupns320 return zero return zero inline vint32x4 vroundconst vfloat64x2 a const vfloat64x2 b return return steps to reproduce cpp include include int mainvoid cvmat src1 cvmat33 25230 000 000 stdcout src1 stdendl cvmat dst cvdividesrc1 2 dst stdcout dst stdendl return 0 bash x8664 aout 25 23 0 0 0 0 0 0 0 12 12 0 0 0 0 0 0 0 arm64 aout 25 23 0 0 0 0 0 0 0 13 12 0 0 0 0 0 0 0 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFixed bug with the last 4 bytes in MJPEG encoder\nresolves 19634 resolves 24171 enabled parallel processing that was temporary disabled in 19812 because of the issue 19634"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nThe cmake cann libopsproto.so library compiled with opencv4.8.0 could not be found\nsystem information my device cpu kunpeng 920 npu ascend310，aarch64 platform detailed description ascendcanntoolkit download address the download version is 601 opencv compiler options reference steps to reproduce trial version opencv version 480 and cannbackend221010 seem to have been tried by 46 download toolkit ascendcanntoolkit installation command install installforall first step： source second step cmake d withcannon d buildopencvgapioff d error message ： cann updated canninstalldir from cann libascendclso is found at cann libgraphso is found at cann libgecompilerso is found at cann missing libopsprotoso turning off havecann issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nONNX DNN inference produce Wrong result compare to 4.7.0\nsystem information opencv version 480 operating system platform windows10 compiler compiler version visual studio 170 for cpp and python version 3915 opencv python version 48076 for python detailed description i had a model in python using the pytorch platform and converted it into onnx using torchexportonnx and i wanted to infer it in cpp after hours i only got weird results compared to the torch version i ran it onnxruntime and the results were the same as the pytorch model then i inferred it in python and got the result exactly the same as cpp and very different from onnxruntime and pytorch here are the pictures of the results in onnxruntimepytorch vs opencv dnn onnxruntimepytorch image opencv dnn image i dont know what exactly going on but there is no problem in using opencv 470 steps to reproduce raw wideonnx this is the image for testing in python for onnxruntime and opencv and you can access the model file with the link above to load the image ccv2imreadrawjpg cnptransposec210 xnpexpanddimsc axis0astypenpfloat32 then infer it with onnxruntime import onnxruntime as ort import numpy as np ortsess outputs ortsessrunnone input x resoutputs000 0 255 to reproduce the result in opencv set the image as input of the net model modelsetinputx outputblob 0 255 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhy  OpenCV CUDA morphology SLOWER than my simple cu kernel?\nsystem information c user opencv version 480 win10 msvc2019 gpu nvidia3060ti cuda 122 detailed description img size 3k2k element size 43 43 use opencv cpu spend 4ms，my cpu is amd r5 5500 opencvcuda spend 380ms this is my cuda code spend 28ms cuda npp spend 54ms steps to reproduce img size 3k2k element size 43 43 use opencv cpu spend 4ms，my cpu is amd r5 5500 although there are three main functions blow i have placed them in one project to ensure consistency in the environment i comment out two main functions when using them this is opencvcuda morphology code spend 380ms include include include include include cudaruntimeh include if 0 int main cvmat inputimage cvcvtcolorinputimage inputimage cvcolorbgr2gray cvcudagpumat src srcuploadinputimage int an 21 cvmat element cvsizean 2 1 an 2 1 cvpointan an cvptr erodefilter srctype element cvcudagpumat gpuoutputimage cudaeventt start stop cudaeventcreatestart cudaeventcreatestop cudaeventrecordstart auto starttime double start cvgettickcount erodefilterapplysrc gpuoutputimage double fps cvgettickfrequency cvgettickcount start stdcout fps fps stdendl auto endtime auto duration starttimecount stdcout duration 1000 ms stdendl cudaeventrecordstop float milliseconds 0 start stop stdcout gpu runtime milliseconds ms stdendl cvmat outputimage cvimshowinput image inputimage cvimshoweroded image outputimage cvwaitkey0 return 0 this is my cuda code spend 28ms include include include cudaruntimeh include include global void erodekerneljunkconst uchar input uchar output int rows int cols int kernelsize int kernelsize2 int x blockidxx blockdimx threadidxx int y blockidxy blockdimy threadidxy if x cols y rows const int halfsize kernelsize 2 const int halfsize2 kernelsize2 2 uchar minval 255 for int i halfsize2 i halfsize2 i for int j halfsize j halfsize j int px x j int py y i if px 0 px 0 py rows uchar val inputpy cols px if val minval minval val outputy cols x minval int main cvmat inputimage cvcvtcolorinputimage inputimage cvcolorbgr2gray int w 43 int h 43 cvmat inputimage2 cvmat element cvsizew h auto starttime cverodeinputimage inputimage2 element auto endtime auto duration starttimecount stdcout 程序运行时间 duration 毫秒 stdendl stdendl stdendl int numgpus if numgpus 0 stdcerr no cudacapable devices found stdendl return 1 int deviceid 0 cudadeviceprop deviceprop deviceid int inrows inputimagerows int incols inputimagecols uchar dinputimage doutputimage dtempimage sizet inputsize inrows incols sizeofuchar sizet outputsize inrows incols sizeofuchar inputsize outputsize inputimagedata inputsize dim3 block16 16 dim3 gridincols blockx 1 blockx inrows blocky 1 blocky cudaeventt start stop cudaeventcreatestart cudaeventcreatestop cudaeventrecordstart erodekerneljunk dinputimage doutputimage inrows incols w h cudaeventrecordstop float milliseconds 0 start stop stdcout gpu runtime milliseconds ms stdendl cvmat outputimageinrows incols cv8uc1 doutputimage outputsize cudafreedinputimage cudafreedoutputimage cvnamedwindoweroded cvwindowkeepratio cvimshoweroded outputimage cvwaitkey0 return 0 this is cuda npp code include include int main cvmat inputimage cvcvtcolorinputimage inputimage cvcolorbgr2gray if inputimageempty stdcout failed to load image stdendl return 1 npp8u pu8srcdatadev null inputimagecols inputimagerows sizeofnpp8u inputimagedata inputimagecols inputimagerows sizeofnpp8u cvmat element cvsize43 43 npp8u pu8tmpldev null elementcols elementrows sizeofnpp8u cudamemcpypu8tmpldev elementdata elementcols elementrows sizeofnpp8u nppisize tmplsize elementcols elementrows nppipoint anchor elementcols1 elementrows1 npp8u pu8dstdatadev null inputimagecols inputimagerows sizeofnpp8u nppisize osizeroi inputimagecols inputimagerows cudaeventt start stop cudaeventcreatestart cudaeventcreatestop nppstatus status cudaeventrecordstart status inputimagecols pu8dstdatadev inputimagecols osizeroi pu8tmpldev tmplsize anchor cudaeventrecordstop float milliseconds 0 start stop stdcout npp gpu runtime milliseconds ms stdendl cvmat inputimagecols cv8uc1 pu8dstdatadev inputimagerows inputimagecols cvnamedwindowdilated image cvwindowkeepratio cvimshowdilated image outputimage cvwaitkey0 return 0 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUse STRING instead of PATH to fix #24141\nresolves 24141 pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nadd missing include\nbackport of 24167"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDNN: fix the issue in layer_fuse\nfix issue relates 22401 handling when the operation of the elemtwise layer is missing will fail when the operation is missing this patch adds default value for such case pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nwhy minMaxIdx  Restored reduced IPP calls\nsystem information example for c user opencv version 40 or later operating system platform centos 79 compiler compiler version gcc 485 detailed description cvminmaxidx unable to use ipp acceleration modulescoresrc minmaxcpp undef haveipp undef cvipprunfast define cvipprunfastf undef cvipprun define cvipprunc f define 1 see test after restored reduced ipp calls cvminmaxidx need more time to run why unable to use ipp acceleration steps to reproduce run cvminmaxidx and statistical time issue submission checklist x i report the issue its not a question i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nmac m1  ld: symbol(s) not found for architecture arm64.    build java opencv for opencv-4.8.0\nsystem information base guoquanhaomacbookpro build clang version apple clang version 1403 clang1403022141 target arm64appledarwin2260 thread model posix installeddir base guoquanhaomacbookpro build java version java 1708 20230718 lts javatm se runtime environment build 17089lts211 java hotspottm 64bit server vm build 17089lts211 mixed mode sharing base guoquanhaomacbookpro build img width530 altimage src img width280 altimage src using following command cmake dwithopenjpegoff dwithippoff dbuildopencvjavaon dinstallcexamplesoff dbuildzliboff dbuildexampleson detailed description 73 building cxx object 73 building cxx object 73 building cxx object 73 building cxx object 73 building cxx object 73 linking cxx executable 73 built target 73 building cxx object 73 building cxx object 73 building cxx object 73 linking cxx executable 73 built target 73 building cxx object 74 linking cxx executable 74 built target 74 building cxx object 74 building cxx object 74 building cxx object 74 building cxx object 74 building cxx object 74 building cxx object 74 linking cxx executable binopencvperfaruco 74 building cxx object 74 built target opencvperfaruco 74 building cxx object 74 linking cxx executable binopencvtestaruco 74 built target opencvtestaruco 74 building cxx object in file included from warning sprintf is deprecated this function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead sprintfbuf flags ssss note sprintf has been explicitly marked deprecated here deprecatedmsgthis function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead note expanded from macro deprecatedmsg define deprecatedmsgmsg 74 building cxx object 74 building cxx object in file included from warning sprintf is deprecated this function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead sprintfbuf flags ssss note sprintf has been explicitly marked deprecated here deprecatedmsgthis function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead note expanded from macro deprecatedmsg define deprecatedmsgmsg 1 warning generated 74 linking cxx executable 74 building cxx object 74 built target in file included from warning sprintf is deprecated this function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead sprintfbuf flags ssss note sprintf has been explicitly marked deprecated here deprecatedmsgthis function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead note expanded from macro deprecatedmsg define deprecatedmsgmsg 74 building cxx object 1 warning generated 74 linking cxx executable 74 building cxx object 1 warning generated 74 built target 74 linking cxx executable 74 building cxx object 74 built target 75 building cxx object 75 building cxx object 75 building cxx object in file included from warning sprintf is deprecated this function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead sprintfbuf flags ssss note sprintf has been explicitly marked deprecated here deprecatedmsgthis function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead note expanded from macro deprecatedmsg define deprecatedmsgmsg 75 building cxx object 1 warning generated 75 linking cxx executable 75 linking cxx executable 75 built target in file included from warning sprintf is deprecated this function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead sprintfbuf flags ssss note sprintf has been explicitly marked deprecated here deprecatedmsgthis function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead note expanded from macro deprecatedmsg define deprecatedmsgmsg 75 building cxx object 75 built target 75 building cxx object 75 building cxx object 75 building cxx object 1 warning generated 75 linking cxx executable 75 linking cxx shared library 75 built target 75 building cxx object 75 built target opencvgapi 75 building cxx object in file included from warning sprintf is deprecated this function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead sprintfbuf flags ssss note sprintf has been explicitly marked deprecated here deprecatedmsgthis function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead note expanded from macro deprecatedmsg define deprecatedmsgmsg in file included from warning sprintf is deprecated this function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead sprintfbuf flags ssss note sprintf has been explicitly marked deprecated here deprecatedmsgthis function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead note expanded from macro deprecatedmsg define deprecatedmsgmsg in file included from warning sprintf is deprecated this function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead sprintfbuf flags ssss note sprintf has been explicitly marked deprecated here deprecatedmsgthis function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead note expanded from macro deprecatedmsg define deprecatedmsgmsg 1 warning generated 1 warning generated in file included from warning sprintf is deprecated this function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead sprintfbuf flags ssss note sprintf has been explicitly marked deprecated here deprecatedmsgthis function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead note expanded from macro deprecatedmsg define deprecatedmsgmsg 75 linking cxx executable 75 linking cxx executable 75 building cxx object 75 built target 75 built target 75 building cxx object 75 building cxx object 75 building cxx object 1 warning generated 76 linking cxx executable 1 warning generated 76 linking cxx executable 76 built target 76 building cxx object 76 built target 76 building cxx object 77 building cxx object in file included from warning sprintf is deprecated this function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead sprintfbuf flags ssss note sprintf has been explicitly marked deprecated here deprecatedmsgthis function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead note expanded from macro deprecatedmsg define deprecatedmsgmsg 77 linking cxx executable 77 built target opencvtestximgproc 77 building cxx object 77 linking cxx executable binexamplebgsegmbgfg 1 warning generated 77 linking cxx executable 77 linking cxx executable 77 built target examplebgsegmbgfg 77 built target 77 building cxx object 77 built target 77 building cxx object 77 building cxx object 77 building cxx object 77 building cxx object 77 linking cxx executable 77 built target 77 building cxx object 77 linking cxx executable binopencvtestbgsegm 77 built target opencvtestbgsegm warning sprintf is deprecated this function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead 77 building cxx object sprintfbuff faces i 032f fps fit030f note sprintf has been explicitly marked deprecated here deprecatedmsgthis function is provided for compatibility reasons only due to security concerns inherent in the design of sprintf3 it is highly recommended that you use snprintf3 instead note expanded from macro deprecatedmsg define deprecatedmsgmsg 77 linking cxx executable 77 building cxx object 77 built target 77 building cxx object 1 warning generated 77 linking cxx executable 77 built target 77 building cxx object 77 linking cxx executable 77 built target 77 building cxx object 77 building cxx object 77 building cxx object 77 linking cxx executable 77 built target 77 building cxx object 77 building cxx object 77 building cxx object 77 linking cxx executable 77 building cxx object 77 built target 77 building cxx object 77 linking cxx executable 77 built target 77 building cxx object 77 linking cxx executable binopencvtestface 77 linking cxx executable 77 building cxx object 77 built target opencvtestface 77 built target 77 building cxx object 77 building cxx object 77 linking cxx executable 77 linking cxx executable 77 built target 77 built target 77 building cxx object 77 linking cxx executable 77 linking cxx executable 77 building cxx object 77 built target 77 built target 78 building cxx object 78 building cxx object 78 linking cxx executable 78 built target 78 building cxx object 78 linking cxx executable 78 linking cxx executable 78 built target 78 building cxx object 78 linking cxx executable 78 built target 78 building cxx object 78 built target 79 linking cxx executable 79 building cxx object 79 built target 79 building cxx object 79 linking cxx executable 79 linking cxx executable 79 built target 79 building cxx object 79 built target 79 building cxx object 79 linking cxx executable 79 built target 79 building cxx object 79 building cxx object 79 building cxx object 79 linking cxx executable 79 built target 79 building cxx object 79 linking cxx executable 79 built target 79 building cxx object 79 building cxx object 79 linking cxx executable 79 built target 79 building cxx object 79 building cxx object 79 building cxx object 79 building cxx object 79 linking cxx executable 79 built target 79 building cxx object 79 building cxx object 79 building cxx object 79 building cxx object 79 linking cxx executable 79 built target 79 building cxx object 79 linking cxx executable 79 built target examplegapioakcopy 79 building cxx object 79 building cxx object 79 building cxx object 79 linking cxx executable 79 built target 79 building cxx object 79 linking cxx executable 79 built target 79 building cxx object 79 building cxx object 79 building cxx object 79 building cxx object 79 building cxx object 79 linking cxx executable 79 built target 79 building cxx object 79 linking cxx executable 79 built target 80 building cxx object 80 building cxx object 80 linking cxx executable 80 built target 80 building cxx object 80 building cxx object 80 linking cxx executable 80 built target 80 building cxx object 80 building cxx object 80 building cxx object 80 linking cxx executable 80 built target 80 building cxx object 80 building cxx object 80 linking cxx executable 80 built target 80 building cxx object 80 linking cxx executable 80 built target 80 building cxx object 80 building cxx object 80 linking cxx executable 80 built target 80 building cxx object 80 building cxx object 80 building cxx object 80 building cxx object 80 processing opencl kernels optflow 80 building cxx object 80 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 linking cxx executable 81 built target 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 processing opencl kernels stitching 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 linking cxx executable binopencvperfgapi 81 building cxx object 81 built target opencvperfgapi 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 building cxx object 81 linking cxx executable 81 building cxx object 81 built target 81 building cxx object 81 linking cxx executable 81 built target opencvperftracking 81 building cxx object 81 building cxx object 81 building cxx object 81 linking cxx executable 81 built target exampletrackingcsrt 81 building cxx object 81 building cxx object 82 linking cxx shared library liblibopencvsfmdylib undefined symbols for architecture arm64 googleinitvlog3int int char const int referenced from const eigenmatrix const const eigenmatrix in const const const in eigenmatrixmodel libmvestimate eigenmatrix libmvmlescorer eigenmatrix const libmvmlescorer eigenmatrix const libmvvector double double in eigenmatrixmodel libmvestimate eigenmatrix libmvmlescorer eigenmatrix const libmvmlescorer eigenmatrix const libmvvector double double in const bool in const in const eigenmatrix const const eigenmatrix in ld symbols not found for architecture arm64 clang error linker command failed with exit code 1 use v to see invocation make2 error 1 make1 error 2 make1 waiting for unfinished jobs 82 building cxx object 82 building cxx object 82 building cxx object 82 linking cxx executable 82 built target 82 building cxx object 82 building cxx object 82 building cxx object 82 linking cxx executable 82 built target opencvtesttracking 82 building cxx object 82 building cxx object 82 building cxx object 82 linking cxx shared library 82 built target opencvoptflow 82 building cxx object 82 building cxx object 82 building cxx object 82 building cxx object 82 building cxx object 82 building cxx object 82 building cxx object 82 building cxx object 82 building cxx object 82 building cxx object 82 building cxx object 82 building cxx object 83 building cxx object 83 building cxx object 83 linking cxx shared library 83 built target opencvstitching 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 linking cxx executable binopencvtestgapi 84 built target opencvtestgapi make all error 2 steps to reproduce as above issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nModify the outputVideoFormat after changing the output format in MSMF backend\nafter changing the output format need to modify the outputvideoformat otherwise the outputvideoformat is always cvcapmodebgr and an error will occur when converting the format in retrievevideoframe and will always enter case cvcapmodebgr process pull request readiness checklist see details at i agree to contribute to the project under apache 2 license to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfix refineDetectedMarkers\nfixes 24127 to refine corners of aruco markers we need to call matchimagepoints from base class board the method matchimagepoints implemented in pimpl and we need to create temp board object pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFixed bug when MSMF webcamera doesn't start when build with VIDEOIO_PLUGIN_ALL\nfixed 23937 and 23056"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRefineDetectedMarkers fails if cameraMatrix is given as a param\nsystem information opencv python version 480 operating system platform windows 10 python version 3916 detailed description method of arucodetector fails if optional cameramatrix param is given when running following line corners ids rejected imagegrayscaleimage boardcharucoboard detectedidsarucoids distcoeffsdistcoeffs an assertion error is raised corners ids rejected cv2error opencv480 error 215assertion failed 2 in function no error is raised if no cameramatrix is specified steps to reproduce python import imageiov3 as iio import numpy as np import cv2 grayscaleimage iioimread cameramatrix nparray 108444638e03 000000000e00 699703945e02 000000000e00 108545749e03 524978509e02 000000000e00 000000000e00 100000000e00 distcoeffs nparray001183206 001096358 00 00 charucoboard cv2arucocharucoboard 11 8 35 26 arucodetector arucocorners arucoids arucorejected following line works corners ids rejected imagegrayscaleimage boardcharucoboard detectedidsarucoids distcoeffsdistcoeffs following line fails corners ids rejected imagegrayscaleimage boardcharucoboard detectedidsarucoids distcoeffsdistcoeffs following image is used as input grayscaleimage issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFix v_pack_store alignment issue on Windows 32-bit.\nnightly build issue the issue introduced in pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPython sample code tst_scene_render.py not compatible with modern NumPy when using one image or no image\nsystem information opencv python version 48074 operating system platform macos 1341 python version 3114 numpy 125 detailed description is outdated and needs minor changes 1 npint is deprecated since numpy 120 release when getting next frame with no foreground image provided to the class npint is used to update a rectangle and gives error messages numpy120 in class testscenerender def getnextframeself if selfforeground is not none else selfcurrentrect npint error message 1 traceback most recent call last file line 120 in main file line 108 in main img rendergetnextframe file line 88 in getnextframe selfcurrentrect selfinitialrect npint file line 313 in getattr raise did you mean inf change npint to int or npint seems to be ok 2 npzeros takes take int or tuple of ints for shape parameter numpy 125 when initializing the class with no background image two ints are given for shape parameter of npzeros and gives error messages tested with numpy 125 in class testscenerender def init bgimg if bgimg is not none else selfscenebg npzerosdefaultsize defaultsize npuint8 numpy reference numpyzerosshape dtypefloat parameters shape int or tuple of ints error message 2 traceback most recent call last file line 120 in main file line 104 in main render testscenerenderfgimg fgr file line 28 in init selfscenebg npzerosdefaultsize defaultsize npuint8 typeerror cannot interpret 512 as a data type steps to reproduce import testscenerender and prepare images working directory opencvsamplespython import cv2 as cv from tstscenerender import testscenerender backgr fgr test with both foreground and background images works fine render testscenerenderbgimg backgr fgimg fgr img rendergetnextframe cvimshowimgimg cvwaitkey10000 cvdestroyallwindows test with passing none to foreground image error message 1 render testscenerenderbgimg backgr fgimg none img rendergetnextframe test with passing none to background image error message 2 render testscenerenderbgimg none fgimg fgr issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSolved bug in Reduce layer #24044\npull request readiness checklist resolves see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nInvalid memory access fix for ONNX split layer parser #24076\npull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPort stereoRectify grid fix #24035\nreview and merge after address 24035 in 5x manual port of pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nVideoWriter resulting size one off error\nsystem information opencv python version 48074 operating system platform ubuntu 2004 python version 3810 detailed description saving an image of shape 960 1699 3 gives shape 960 1698 3 1699 vs 1698 steps to reproduce python import numpy as np import cv2 writer 1 1699 960 1699 3 npuint8 writerrelease the reproducer also prints opencv ffmpeg tag 0x47504a4dmjpg is not supported with codec id 7 and format image2 image2 sequence after line writer 1 1699 960 also reproducible for c tested commit issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nException in ONNX::parseSplit \nsystem information general configuration for opencv 480dev version control 480113g0323761ea6 extra modules location extra version control extra 48012gdaaf6451 platform timestamp 20230729t122525z host windows 10022621 amd64 cmake 3261 cmake generator visual studio 17 2022 cmake build tool cprogram filesmicrosoft visual msvc 1935 configuration debug release cpuhw features baseline sse sse2 sse3 requested sse3 dispatched code generation sse41 sse42 fp16 avx avx2 avx512skx requested sse41 sse42 avx fp16 avx2 avx512skx sse41 18 files ssse3 sse41 sse42 2 files ssse3 sse41 popcnt sse42 fp16 1 files ssse3 sse41 popcnt sse42 fp16 avx avx 8 files ssse3 sse41 popcnt sse42 avx avx2 37 files ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 avx512skx 8 files ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 avx512f avx512common avx512skx cc built as dynamic libs yes c standard 11 c compiler cprogram filesmicrosoft visual ver 1935322150 c flags release dwin32 dwindows w4 gr d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise eha wd4127 wd4251 wd4324 wd4275 wd4512 wd4589 wd4819 mp md o2 ob2 dndebug c flags debug dwin32 dwindows w4 gr d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise eha wd4127 wd4251 wd4324 wd4275 wd4512 wd4589 wd4819 mp mdd zi ob0 od rtc1 c compiler cprogram filesmicrosoft visual c flags release dwin32 dwindows w3 d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise mp md o2 ob2 dndebug c flags debug dwin32 dwindows w3 d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise mp mdd zi ob0 od rtc1 linker flags release machinex64 incrementalno linker flags debug machinex64 debug incremental ccache no precompiled headers yes extra dependencies cudartstaticlib nppclib nppiallib nppicclib nppideilib nppiflib nppiglib nppimlib nppistlib nppisulib nppitclib nppslib cublaslib cudnnlib cufftlib libpathcprogram filesnvidia gpu computing 3rdparty dependencies opencv modules to be built alphamat aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnnobjdetect dnnsuperres dpm face features2d flann fuzzy gapi hfs highgui imghash imgcodecs imgproc intensitytransform java linedescriptor mcc ml objdetect optflow phaseunwrapping photo plot python3 quality rapid reg rgbd saliency sfm shape stereo stitching structuredlight superres surfacematching text tracking ts video videoio videostab viz wechatqrcode xfeatures2d ximgproc xobjdetect xphoto disabled world disabled by dependency unavailable cvv freetype hdf julia matlab ovis python2 applications tests perftests examples apps documentation doxygen python javadoc nonfree algorithms yes windows rt support no gui win32ui win32 ui yes opengl support yes opengl32 glu32 vtk support yes ver 925 media io zlib optimized debug ver 1213 jpeg buildlibjpegturbo ver 21362 simd support request yes simd support no webp build ver encoder 0x020f png optimized debug ver 1640 tiff build ver 42 420 jpeg 2000 build ver 250 openexr build ver 230 hdr yes sunraster yes pxm yes pfm yes video io dc1394 no ffmpeg yes prebuilt binaries avcodec yes 58134100 avformat yes 5876100 avutil yes 5670100 swscale yes 59100 avresample yes 400 gstreamer no directshow yes media foundation yes dxva yes parallel framework tbb ver 20203 interface 11103 other thirdparty libraries intel ipp 20218 202180 at intel ipp iw sources 202180 at lapack no openvino yes 202230 eigen yes ver custom hal no protobuf build 3191 flatbuffers builtin3rdparty 2359 nvidia cuda yes ver 121 cufft cublas nvidia gpu arch 86 nvidia ptx archs cudnn yes ver 880 opencl yes nvd3d11 include path link libraries dynamic load python 3 interpreter cprogram ver 31010 libraries optimized cprogram debug cprogram ver 31010 numpy ver 1235 install path python for build cprogram java ant ver 11013 java no jni cprogram cprogram cprogram java wrappers yes ant java tests yes install to cinstallopencv detailed description model is here thanks to fengyuentau i can read this model in python or in c in release but not in debug output is reading info03872 global onnximportercpp835 dnnonnx loading onnx v8 model produced by pytorch200 number of nodes 313 initializers 168 inputs 5 outputs 2 info03873 global onnximportercpp728 dnnonnx onnx opset version 17 info03950 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs addonnxnodeadd from domainaionnx info03950 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs divonnxnodediv from domainaionnx info03950 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs mulonnxnodemul from domainaionnx info03951 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs subonnxnodesub from domainaionnx info03951 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs matmulonnxnodematmul from domainaionnx info03952 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs mulonnxnodemul1 from domainaionnx info03952 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs sinonnxnodesin from domainaionnx info03952 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs cosonnxnodecos from domainaionnx info03952 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs concatonnxnodeconcat from domainaionnx info03953 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info03953 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs expandonnxnodeexpand from domainaionnx info03961 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs equalonnxnodeequal from domainaionnx info03961 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs notonnxnodenot from domainaionnx info03962 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs castonnxnodecast from domainaionnx info03962 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs mulonnxnodemul2 from domainaionnx info03962 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs equalonnxnodeequal1 from domainaionnx info03962 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs castonnxnodecast1 from domainaionnx info03962 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs mulonnxnodemul3 from domainaionnx info03963 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs addonnxnodeadd1 from domainaionnx info03963 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs equalonnxnodeequal2 from domainaionnx info03963 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs castonnxnodecast2 from domainaionnx info03963 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs mulonnxnodemul4 from domainaionnx info03963 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs addonnxnodeadd2 from domainaionnx info03963 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs equalonnxnodeequal3 from domainaionnx info03963 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs castonnxnodecast3 from domainaionnx info03963 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs mulonnxnodemul5 from domainaionnx info03964 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs addonnxnodeadd3 from domainaionnx info03964 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs equalonnxnodeequal4 from domainaionnx info03964 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs castonnxnodecast4 from domainaionnx info03964 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs mulonnxnodemul6 from domainaionnx info03964 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs addonnxnodeadd4 from domainaionnx info03964 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs equalonnxnodeequal5 from domainaionnx info03964 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs castonnxnodecast5 from domainaionnx info03964 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs mulonnxnodemul7 from domainaionnx info03964 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs addonnxnodeadd5 from domainaionnx info03965 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info03965 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info03965 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info03965 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info03965 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info03965 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info03965 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info03966 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info03966 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info03966 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info03966 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info03966 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info03966 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info03967 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info03967 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info03967 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info03967 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info03967 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info03967 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info03967 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info03968 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info03968 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info03968 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info03968 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs mulonnxnodemul8 from domainaionnx info03968 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs subonnxnodesub1 from domainaionnx info03968 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs mulonnxnodemul9 from domainaionnx info03969 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs addonnxnodeadd6 from domainaionnx info03969 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info03969 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs splitonnxnodesplit1 from domainaionnx exception is program file cprogram filesmicrosoft visual line 1949 expression vector subscript out of range its here slicepoint size is 0 and hence there is no adress for slicepoints0 and stack strace is unsigned int64 pos line 1948 at cprogram filesmicrosoft visual layerparams const opencvonnxnodeproto nodeproto line 1394 at opencvonnxnodeproto nodeproto line 1029 at line 919 at net const char onnxfile line 282 at char line 77 at char line 84 at stdstring onnxfile line 4076 at stdstring model const stdstring config const stdstring framework line 54 at steps to reproduce in c and in debug net netmask readnet issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDoesnt use cuda for specific layer\nsystem information opencv version 480 current 4x branch windows compiler msvc 2022 running a onnx file same as here i noticed very high cpu usage gpu also gets used but its bottlenecked by the cpu so we went and profiled with intel vtune turns out that most of the time is spent on optavc2fastgemm1t is this op only available for cpu why doesnt the full model run on gpu image cuda runtime is enabled i can run many other models without issue on gpu detailed description image steps to reproduce very basic just use netforward with the model linked in the other issue issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSubtracting a tuple from an image gives `error: (-215:Assertion failed) type2 == CV_64F && (sz2.height == 1 || sz2.height == 4) in function 'cv::arithm_op'`\nsystem information opencv python version 48074 operating system windows 11 22h2 python version 31011 detailed description from what i understand of the docs cv2subtract should be able to subtract a tuple from an array if it has the same width as the array has channels difference between an array and a scalar when src2 is constructed from scalar or has the same number of elements as src1channels however loading an image with imread and attempting to subtract a tuple gives cv2subtractmat 10 10 10 traceback most recent call last file line 1 in cv2error opencv470 error 215assertion failed type2 cv64f sz2height 1 sz2height 4 in function cvarithmop the same error occurs when trying to use a tuple of floats cv2subtractmat 100 100 100 traceback most recent call last file line 1 in cv2error opencv470 error 215assertion failed type2 cv64f sz2height 1 sz2height 4 in function cvarithmop and numpy arrays of various types cv2subtractmat npuint810 10 10 traceback most recent call last file line 1 in cv2error opencv470 error 215assertion failed type2 cv64f sz2height 1 sz2height 4 in function cvarithmop cv2subtractmat nparray10 10 10 traceback most recent call last file line 1 in cv2error opencv470 error 215assertion failed type2 cv64f sz2height 1 sz2height 4 in function cvarithmop cv2subtractmat npfloat6410 10 10 traceback most recent call last file line 1 in cv2error opencv470 error 215assertion failed type2 cv64f sz2height 1 sz2height 4 in function cvarithmop subtracting a number works cv2subtractmat 5 array103 122 116 102 122 114 106 122 114 as does subtracting the tuple using numpy but that wont work in my case because numpy doesnt saturate the subtraction like opencv does mat 10 20 30 array 98 102 86 97 102 84 101 102 84 the error message is also correct if i remove a channel from the tuple cv2subtractmat 10 10 traceback most recent call last file line 1 in cv2error opencv470 error 209sizes of input arguments do not match the operation is neither array op array where arrays have the same size and the same number of channels nor array op scalar nor scalar op array in function cvarithmop steps to reproduce py import cv2 mat cv2imreadcpng printcv2subtractmat 10 10 10 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTest_TensorFlow_layers.tf2_prelu fails with OpenVINO CPU backend\nsystem information os linux x64 openvino 202301 official docker image ci link detailed description run where getparam ngraphcpu unknown file failure c exception with description opencv480dev error 2unspecified error in function initplugin failed to initialize inference engine backend device cpu check false failed at check inshape failed at while validating node f321312 with friendlyname failed to create broadcastable shapes in snippets canonicalization thrown in the test body failed where getparam ngraphcpu 7 ms steps to reproduce binopencvtestdnn issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfix compilation error on Windows ARM, use vaddq_f32 instead of +=\npull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncv.cuda.GpuMat.convertTo failed to convert data types\nsystem information example for python user opencv python version 470 operating system platform ubuntu 1804 python version 3716 detailed description image cv2error opencv470 error 213the functionfeature is not implemented getgpumat is available only for cudagpumat and cudahostmem in function getgpumat i use cv2 cudacodec createvideoreader read the video streaming mat type for the data type is 8uc4 and i tried to convert the data type to float32 but got an error steps to reproduce cap ret frame capnextframe image issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFix stereoRectify image boundaries.\nthis should have been fixed with pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfeat: add cuda_Stream and cuda_GpuMat to simple types mapping\nthis patch fixes usage of cudastream in function arguments affected modules cudacodec using namespace cuda in public cudacodechpp header can be removed after merge of the patch pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfix: preserve NumPY writeable flag in output arguments\nexample error output opencv480dev 1 error 5bad argument in function rectangle overload resolution failed img marked as output argument but provided numpy array marked as readonly expected ptr for argument img img marked as output argument but provided numpy array marked as readonly expected ptr for argument img resolves pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFix python typing stubs generation for CUDA modules\nresolves 23946 resolves 23945 resolves pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTest_Caffe_nets.FasterRCNN_vgg16 fails with ENABLE_FAST_MATH option\nsystem information opencv current 4x 480dev platform ubuntu 1804 gcc 75 hardware core i5 2500k no avx2 and no avx512 detailed description net inference accuracy issue is raised steps to reproduce cmake denablefastmath1 opencv make j4 binopencvtestdnn log run where getparam ocvcpu unmatched prediction class 7 score 0997029 box 235421 x 830574 from 483244 927312 highest iou 0970777 failure value of matched actual false expected true model name unmatched prediction class 12 score 0993107 box 213524 x 372432 from 13632 189653 highest iou 0 failure value of matched actual false expected true model name unmatched prediction class 2 score 0948399 box 502178 x 25137 from 988219 211123 highest iou 0 failure value of matched actual false expected true model name unmatched reference class 2 score 0949398 box 50196 x 252708 from 992454 210141 iou diff 1 failure expected refscoresi confthreshold actual 0949398 vs 08 model name unmatched reference class 7 score 0997022 box 240844 x 836312 from 481841 923218 iou diff 00292231 failure expected refscoresi confthreshold actual 0997022 vs 08 model name unmatched reference class 12 score 0993028 box 217773 x 373789 from 133221 189377 iou diff 1 failure expected refscoresi confthreshold actual 0993028 vs 08 model name failed where getparam ocvcpu 9083 ms issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[TFLite] Pack layer and other fixes for SSD from Keras\npull request readiness checklist resolves merge with extra see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIt is not possible to redirect some error printed directly to cerr\nsystem information problem in source code at any platform and on other places detailed description the code uses direct print to stdcerr eg then it is not possible to redirect via cvredirecterror steps to reproduce see code issue submission checklist x i report the issue its not a question i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpencv Build form source\nsystem information opencv version 480 operating system platform windows10 compiler compiler version cmakevs2022x64 image image image image image detailed description build started 1 build started project opencvworld configuration release x64 1regionlayercpp error c2666 operator 14 overloads have similar conversions compiling source file message could be bool cvoperator const cvmatconstiterator const cvmatconstiterator compiling source file message or cvmatexpr cvoperator doubleconst cvmat compiling source file message or cvmatexpr cvoperator const cvmat double compiling source file message or cvmatexpr cvoperator const cvmat const cvmat compiling source file 1cprogram filesnvidia gpu computing message or bool operator const half const half found using argumentdependent lookup compiling source file 1cprogram filesnvidia gpu computing message or bool operator const half2 const half2 found using argumentdependent lookup compiling source file 1cprogram filesnvidia gpu computing message or bool operator const nvbfloat16 const nvbfloat16 found using argumentdependent lookup compiling source file 1cprogram filesnvidia gpu computing message or bool operator const nvbfloat162 const nvbfloat162 found using argumentdependent lookup compiling source file message or builtin c operatorfloat int compiling source file message or builtin c operatorsigned char int compiling source file message or builtin c operatorunsigned char int compiling source file message or builtin c operatorchar int compiling source file message or builtin c operatorshort int compiling source file message or builtin c operatorunsigned short int compiling source file message or builtin c operatorint int compiling source file message or builtin c operatorunsigned int int compiling source file message or builtin c operatorlong int compiling source file message or builtin c operatorunsigned long int compiling source file message or builtin c operatorint64 int compiling source file message or builtin c operatorunsigned int64 int compiling source file message or builtin c operatorbool int compiling source file message while trying to match the argument list t int 1 with 1 1 thalf 1 compiling source file message while compiling class template member function void const compiling source file message see reference to class template instantiation being compiled compiling source file message see reference to function template instantiation cvptr ty being compiled 1 with 1 1 tycvmat 1 error c2666 operator 14 overloads have similar conversions compiling source file message could be bool cvoperator const cvfilenodeiterator const cvfilenodeiterator compiling source file message or bool cvoperator const const compiling source file message or bool cvoperator const cvmatconstiterator const cvmatconstiterator compiling source file message or cvmatexpr cvoperator doubleconst cvmat compiling source file message or cvmatexpr cvoperator const cvmat double compiling source file message or cvmatexpr cvoperator const cvmat const cvmat compiling source file message or bool cvoperator const cvumatdatamemoryflag const int compiling source file message or bool cvoperator const cvinputarraykindflag const int compiling source file message or bool cvoperator const cvaccessflag const int compiling source file message or bool cvoperator const cvrange const cvrange compiling source file message or const const compiling source file message or const const compiling source file message or const const compiling source file message or const const compiling source file message or const const compiling source file message or const const compiling source file message or const const compiling source file message or const const compiling source file message or const const compiling source file message or const const compiling source file 1cprogram filesnvidia gpu computing message or bool operator const half const half found using argumentdependent lookup compiling source file 1cprogram filesnvidia gpu computing message or bool operator const half2 const half2 found using argumentdependent lookup compiling source file 1cprogram filesnvidia gpu computing message or bool operator const nvbfloat16 const nvbfloat16 found using argumentdependent lookup compiling source file 1cprogram filesnvidia gpu computing message or bool operator const nvbfloat162 const nvbfloat162 found using argumentdependent lookup compiling source file message or builtin c operatorfloat double compiling source file message or builtin c operatorsigned char double compiling source file message or builtin c operatorunsigned char double compiling source file message or builtin c operatorchar double compiling source file message or builtin c operatorshort double compiling source file message or builtin c operatorunsigned short double compiling source file message or builtin c operatorint double compiling source file message or builtin c operatorunsigned int double compiling source file message or builtin c operatorlong double compiling source file message or builtin c operatorunsigned long double compiling source file message or builtin c operatorint64 double compiling source file message or builtin c operatorunsigned int64 double compiling source file message or builtin c operatorbool double compiling source file message while trying to match the argument list t double 1 with 1 1 thalf 1 compiling source file message while compiling class template member function void const compiling source file message see reference to class template instantiation being compiled compiling source file message see reference to function template instantiation cvptr const cvmat being compiled 1done building project opencvworldvcxproj failed 2 build started project configuration release x64 3 build started project opencvvisualisation configuration release x64 4 build started project opencvversionwin32 configuration release x64 5 build started project opencvversion configuration release x64 6 build started project configuration release x64 7 build started project configuration release x64 8 build started project opencvimghash configuration release x64 9 build started project opencvannotation configuration release x64 10 build started project opencvtestxphoto configuration release x64 11 build started project opencvtestximgproc configuration release x64 12 build started project configuration release x64 13 build started project configuration release x64 14 build started project opencvtestvideostab configuration release x64 15 build started project opencvtestvideoio configuration release x64 16 build started project opencvtestvideo configuration release x64 17 build started project opencvtesttracking configuration release x64 18 build started project opencvtesttext configuration release x64 8link fatal error lnk1181 cannot open input file 8done building project opencvimghashvcxproj failed 6link fatal error lnk1181 cannot open input file 6done building project failed 9link fatal error lnk1181 cannot open input file 9done building project failed 4link fatal error lnk1181 cannot open input file 4done building project failed 7link fatal error lnk1181 cannot open input file 7done building project failed 19 build started project opencvtestsuperres configuration release x64 20 build started project configuration release x64 21 build started project opencvteststitching configuration release x64 22 build started project opencvtestimghash configuration release x64 2link fatal error lnk1181 cannot open input file 2done building project failed 3link fatal error lnk1181 cannot open input file 3done building project failed 23 build started project opencvteststereo configuration release x64 5link fatal error lnk1181 cannot open input file 5done building project opencvversionvcxproj failed 24 build started project opencvtestshape configuration release x64 25 build started project opencvtestsaliency configuration release x64 26 build started project opencvtestrgbd configuration release x64 27 build started project opencvtestreg configuration release x64 28 build started project opencvtestrapid configuration release x64 29 build started project opencvtestquality configuration release x64 20link fatal error lnk1181 cannot open input file 13link fatal error lnk1181 cannot open input file 18link fatal error lnk1181 cannot open input file 14link fatal error lnk1181 cannot open input file 19link fatal error lnk1181 cannot open input file 20done building project failed 13done building project failed 30 build started project opencvtestphoto configuration release x64 18done building project failed 19done building project failed 14done building project failed 12link fatal error lnk1181 cannot open input file 12done building project failed 31 build started project configuration release x64 23link fatal error lnk1181 cannot open input file 23done building project failed 32 build started project opencvtestoptflow configuration release x64 11link fatal error lnk1181 cannot open input file 11done building project failed 24link fatal error lnk1181 cannot open input file 24done building project failed 33 build started project opencvtestobjdetect configuration release x64 25link fatal error lnk1181 cannot open input file 25done building project failed 27link fatal error lnk1181 cannot open input file 27done building project opencvtestregvcxproj failed 10link fatal error lnk1181 cannot open input file 10done building project failed 28link fatal error lnk1181 cannot open input file 28done building project failed 21link fatal error lnk1181 cannot open input file 21done building project failed 26link fatal error lnk1181 cannot open input file 26done building project failed 16link fatal error lnk1181 cannot open input file 16done building project failed 34 build started project opencvtestml configuration release x64 35 build started project opencvtestmcc configuration release x64 29link fatal error lnk1181 cannot open input file 29done building project failed 17link fatal error lnk1181 cannot open input file 17done building project failed 36 build started project configuration release x64 15link fatal error lnk1181 cannot open input file 15done building project failed 30link fatal error lnk1181 cannot open input file 30done building project failed 37 build started project configuration release x64 31link fatal error lnk1181 cannot open input file 31done building project failed 32link fatal error lnk1181 cannot open input file 32done building project failed 38 build started project opencvtestimgproc configuration release x64 39 build started project opencvtestimgcodecs configuration release x64 40 build started project opencvtesthighgui configuration release x64 33link fatal error lnk1181 cannot open input file 33done building project failed 41 build started project opencvtestgapi configuration release x64 42 build started project opencvtestfuzzy configuration release x64 22link fatal error lnk1181 cannot open input file 22done building project failed 43 build started project opencvtestflann configuration release x64 44 build started project opencvtestfeatures2d configuration release x64 45 build started project opencvtestface configuration release x64 46 build started project configuration release x64 47 build started project opencvtestdnn configuration release x64 48 build started project configuration release x64 35link fatal error lnk1181 cannot open input file 35done building project opencvtestmccvcxproj failed 34link fatal error lnk1181 cannot open input file 34done building project opencvtestmlvcxproj failed 36link fatal error lnk1181 cannot open input file 36done building project failed 49 build started project opencvtestcudastereo configuration release x64 37link fatal error lnk1181 cannot open input file 37done building project failed 50 build started project configuration release x64 51 build started project configuration release x64 40link fatal error lnk1181 cannot open input file 40done building project failed 42link fatal error lnk1181 cannot open input file 42done building project failed 39link fatal error lnk1181 cannot open input file 39done building project failed 52 build started project opencvtestcudalegacy configuration release x64 53 build started project configuration release x64 43link fatal error lnk1181 cannot open input file 43done building project failed 45link fatal error lnk1181 cannot open input file 45done building project failed 46link fatal error lnk1181 cannot open input file 46done building project failed 48link fatal error lnk1181 cannot open input file 48done building project failed 47link fatal error lnk1181 cannot open input file 47done building project opencvtestdnnvcxproj failed 54 build started project configuration release x64 55 build started project configuration release x64 44link fatal error lnk1181 cannot open input file 44done building project failed 56 build started project opencvtestcudacodec configuration release x64 57 build started project opencvtestcudabgsegm configuration release x64 49link fatal error lnk1181 cannot open input file 49done building project failed 50link fatal error lnk1181 cannot open input file 50done building project failed 58 build started project opencvtestcudaarithm configuration release x64 51link fatal error lnk1181 cannot open input file 51done building project failed 59 build started project opencvtestcore configuration release x64 60 build started project opencvtestcalib3d configuration release x64 61 build started project configuration release x64 38link fatal error lnk1181 cannot open input file 38done building project failed 62 build started project opencvtestbgsegm configuration release x64 53link fatal error lnk1181 cannot open input file 53done building project failed 63 build started project opencvtestaruco configuration release x64 64 build started project opencvperfxphoto configuration release x64 65 build started project opencvperfximgproc configuration release x64 54link fatal error lnk1181 cannot open input file 54done building project failed 41link fatal error lnk1181 cannot open input file 41done building project failed 55link fatal error lnk1181 cannot open input file 55done building project failed 66 build started project configuration release x64 52link fatal error lnk1181 cannot open input file 52done building project failed 67 build started project configuration release x64 57link fatal error lnk1181 cannot open input file 57done building project failed 56link fatal error lnk1181 cannot open input file 56done building project failed 68 build started project opencvperfvideoio configuration release x64 69 build started project opencvperfvideo configuration release x64 70 build started project opencvperftracking configuration release x64 58link fatal error lnk1181 cannot open input file 58done building project failed 71 build started project opencvperfsuperres configuration release x64 62link fatal error lnk1181 cannot open input file 62done building project failed 72 build started project opencvperfstitching configuration release x64 73 build started project opencvperfstereo configuration release x64 61link fatal error lnk1181 cannot open input file 61done building project failed 74 build started project opencvperfrgbd configuration release x64 64link fatal error lnk1181 cannot open input file 64done building project failed 75 build started project opencvperfreg configuration release x64 63link fatal error lnk1181 cannot open input file 63done building project failed 60link fatal error lnk1181 cannot open input file 60done building project failed 65link fatal error lnk1181 cannot open input file 65done building project failed 67link fatal error lnk1181 cannot open input file 67done building project failed 68link fatal error lnk1181 cannot open input file 68done building project failed 76 build started project opencvperfphoto configuration release x64 77 build started project opencvperfoptflow configuration release x64 66link fatal error lnk1181 cannot open input file 66done building project failed 70link fatal error lnk1181 cannot open input file 70done building project failed 78 build started project opencvperfobjdetect configuration release x64 79 build started project configuration release x64 69link fatal error lnk1181 cannot open input file 69done building project failed 71link fatal error lnk1181 cannot open input file 71done building project failed 80 build started project opencvperfimgproc configuration release x64 73link fatal error lnk1181 cannot open input file 73done building project failed 72link fatal error lnk1181 cannot open input file 72done building project failed 74link fatal error lnk1181 cannot open input file 74done building project failed 81 build started project opencvperfimgcodecs configuration release x64 82 build started project opencvperfgapi configuration release x64 83 build started project opencvperffeatures2d configuration release x64 75link fatal error lnk1181 cannot open input file 75done building project opencvperfregvcxproj failed 84 build started project configuration release x64 85 build started project opencvperfdnn configuration release x64 77link fatal error lnk1181 cannot open input file 77done building project failed 76link fatal error lnk1181 cannot open input file 76done building project failed 86 build started project configuration release x64 87 build started project opencvperfcudastereo configuration release x64 59link fatal error lnk1181 cannot open input file 59done building project failed 88 build started project configuration release x64 89 build started project configuration release x64 79link fatal error lnk1181 cannot open input file 79done building project failed 78link fatal error lnk1181 cannot open input file 78done building project failed 90 build started project opencvperfcudalegacy configuration release x64 81link fatal error lnk1181 cannot open input file 81done building project failed 82link fatal error lnk1181 cannot open input file 82done building project failed 91 build started project configuration release x64 84link fatal error lnk1181 cannot open input file 84done building project failed 83link fatal error lnk1181 cannot open input file 83done building project failed 85link fatal error lnk1181 cannot open input file 85done building project opencvperfdnnvcxproj failed 92 build started project configuration release x64 93 build started project configuration release x64 86link fatal error lnk1181 cannot open input file 86done building project failed 87link fatal error lnk1181 cannot open input file 87done building project failed 94 build started project opencvperfcudacodec configuration release x64 89link fatal error lnk1181 cannot open input file 89done building project failed 95 build started project opencvperfcudabgsegm configuration release x64 80link fatal error lnk1181 cannot open input file 80done building project failed 96 build started project opencvperfcudaarithm configuration release x64 97 build started project opencvperfcore configuration release x64 90link fatal error lnk1181 cannot open input file 90done building project failed 98 build started project opencvperfcalib3d configuration release x64 99 build started project configuration release x64 100 build started project opencvperfaruco configuration release x64 91link fatal error lnk1181 cannot open input file 91done building project failed 92link fatal error lnk1181 cannot open input file 92done building project failed 93link fatal error lnk1181 cannot open input file 93done building project failed 94link fatal error lnk1181 cannot open input file 94done building project failed 95link fatal error lnk1181 cannot open input file 95done building project failed 96link fatal error lnk1181 cannot open input file 96done building project failed 100link fatal error lnk1181 cannot open input file 100done building project failed 99link fatal error lnk1181 cannot open input file 99done building project failed 98link fatal error lnk1181 cannot open input file 98done building project failed 97link fatal error lnk1181 cannot open input file 97done building project failed build 0 succeeded 100 failed 31 uptodate 0 skipped build started at 207 pm and took 04251 seconds steps to reproduce image image image issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nC++ version of OpenCV 4.8.0 returns wrong matrix size for ONNX model\nsystem information opencv 480 operating system centos compiler gcc11 windows 10 detailed description i am loading the same model with opencv python ok but get the wrong matrix size for the inference result in the compiled c version netron confirms the output nodes to be 1170 and 1179 with sizes 1x8400x5 and 1x8400x4 the python version of opencv does return this matrix size while the c version returns 8400 x 1 depth 5 channels 1 type 5 the compile machine is offline and i provided the correct version of ade by hand other dnn models load and work fine find the model here steps to reproduce compile opencv 48 offline using the following configuartion cmake3 dcmakebuildtypedebug verbose1 dcpubaselineavx2 dbuildtestsoff dbuildperftestsoff dbuildexamplesoff dbuildopencvappsoff ocvinitdownload opencv source tree is not fetched as git repository 3rdparty resources will be downloaded from githubcom by default detected processor x8664 python 275 looking for ccache not found cleaning internal cached variable zliblibrary cleaning internal cached variable zlibincludedir could not find zlib missing zliblibrary zlibincludedir required is at least version 123 cleaning internal cached variable jpeglibrary cleaning internal cached variable jpegincludedir could not find jpeg missing jpeglibrary jpegincludedir libjpegturbo version 213 build cleaning internal cached variable tifflibrary cleaning internal cached variable tiffincludedir could not find tiff missing tifflibrary tiffincludedir cleaning internal cached variable webplibrary cleaning internal cached variable webpincludedir could not find openjpeg minimal suitable version 20 recommended version 231 openjpeg will be built from sources openjpeg version 250 build openjpeg libraries will be built from sources libopenjp2 version 250 cleaning internal cached variable pnglibrary cleaning internal cached variable pngincludedir could not find png missing pnglibrary pngpngincludedir ippicv downloading from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message ippicv download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload downloadippicv include cmakeliststxt756 include could not find openblas include turning openblasfound off could not find openblas lib turning openblasfound off could not find atlas missing atlascblasincludedir atlascblaslibrary atlasblaslibrary atlaslapacklibrary could not find blas missing blaslibraries lapack requires blas a library with lapack api not found please specify library location could not find java missing javajarexecutable javajavacexecutable javajavahexecutable found version 180372 could not find jni missing javaincludepath javaincludepath2 javaawtincludepath vtk is not found please set dvtkdir in cmake to vtk build directory or to vtk install subdirectory with vtkconfigcmake file checking for module gtk30 no package gtk30 found checking for module gtk20 no package gtk20 found checking for module gthread20232 no package gthread20 found checking for modules no package libavcodec found no package libavformat found no package libavutil found no package libswscale found ffmpeg is disabled required libraries missing libraries checking for module gstreamerbase10 no package gstreamerbase10 found checking for module gstreamerapp10 no package gstreamerapp10 found checking for module gstreamerriff10 no package gstreamerriff10 found checking for module gstreamerpbutils10 no package gstreamerpbutils10 found checking for module gstreamervideo10 no package gstreamervideo10 found checking for module gstreameraudio10 no package gstreameraudio10 found checking for module libdc13942 no package libdc13942 found module opencvalphamat disabled because the following dependencies are not found eigen checking for module freetype2 no package freetype2 found checking for module harfbuzz no package harfbuzz found freetype2 no harfbuzz no could not find hdf5 missing hdf5libraries hdf5includedirs found version julia not found not compiling julia bindings module opencvovis disabled because ogre3d was not found no preference for use of exported gflags cmake configuration set and no hints for includelibrary directories provided defaulting to preferring an installedexported gflags cmake configuration if available failed to find installed gflags cmake configuration searching for gflags build directories exported with cmake failed to find gflags failed to find an installedexported cmake configuration for gflags will perform search for installed gflags components failed to find gflags could not find gflags include directory set gflagsincludedir to directory containing gflagsgflagsh failed to find glog could not find glog include directory set glogincludedir to directory containing glogloggingh module opencvsfm disabled because the following dependencies are not found eigen gloggflags checking for module tesseract no package tesseract found tesseract no allocator metrics storage type long long excluding from source files list excluding from source files list registering hook opencvdnn filter out cuda4dnn source code excluding from source files list excluding from source files list excluding from source files list excluding from source files list excluding from source files list imgcodecs openexr codec is disabled in runtime details highgui using builtin backend none rgbd eigen support is disabled eigen is required for posegraph optimization wechatqrcode downloading detectcaffemodel from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message wechatqrcode download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload cmake warning at message wechatqrcode cant get detect caffemodel file for wechat qrcode wechatqrcode downloading detectprototxt from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message wechatqrcode download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload cmake warning at message wechatqrcode cant get detect prototxt file for wechat qrcode wechatqrcode downloading srcaffemodel from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message wechatqrcode download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload cmake warning at message wechatqrcode cant get sr caffemodel file for wechat qrcode wechatqrcode downloading srprototxt from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message wechatqrcode download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload cmake warning at message wechatqrcode cant get sr prototxt file for wechat qrcode xfeatures2dboostdesc downloading boostdescbgmi from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message xfeatures2dboostdesc download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload xfeatures2dboostdesc downloading boostdescbgmbii from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message xfeatures2dboostdesc download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload xfeatures2dboostdesc downloading boostdescbgmhdi from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message xfeatures2dboostdesc download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload xfeatures2dboostdesc downloading from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message xfeatures2dboostdesc download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload xfeatures2dboostdesc downloading from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message xfeatures2dboostdesc download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload xfeatures2dboostdesc downloading from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message xfeatures2dboostdesc download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload xfeatures2dboostdesc downloading boostdesclbgmi from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message xfeatures2dboostdesc download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload xfeatures2dvgg downloading vgggenerated48i from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message xfeatures2dvgg download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload xfeatures2dvgg downloading vgggenerated64i from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message xfeatures2dvgg download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload xfeatures2dvgg downloading vgggenerated80i from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message xfeatures2dvgg download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload xfeatures2dvgg downloading vgggenerated120i from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message xfeatures2dvgg download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload cmake warning at message features2d boost descriptor implementation is not available due to missing data download failed cmake warning at message features2d vgg descriptor implementation is not available due to missing data download failed data downloading facelandmarkmodeldat from try 1 failed couldnt download files from the internet please check the internet access on this host cmake warning at message data download failed 6couldnt resolve host name for details please refer to the download log file call stack most recent call first ocvdownload cmake warning at message face cant get model file for face alignment found misc python modules from found matwrapperutils python modules from found gapi python modules from general configuration for opencv 480 version control unknown extra modules location extra version control extra unknown platform timestamp 20230712t115051z host linux 542481el7elrepox8664 x8664 cmake 3175 cmake generator unix makefiles cmake build tool usrbingmake configuration debug cpuhw features baseline sse sse2 sse3 ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 requested avx2 dispatched code generation avx512skx requested sse41 sse42 avx fp16 avx2 avx512skx avx512skx 5 files avx512f avx512common avx512skx cc built as dynamic libs yes c standard 11 c compiler ver 1130 c flags release fsignedchar w wall wreturntype wnonvirtualdtor waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wundef winitself wpointerarith wshadow wsignpromo wuninitialized wsuggestoverride wnocomment wnostrictoverflow wnolonglong pthread fnoomitframepointer ffunctionsections fdatasections msse msse2 msse3 mssse3 msse41 mpopcnt msse42 mf16c mfma mavx mavx2 fvisibilityhidden o2 dndebug dndebug c flags debug fsignedchar w wall wreturntype wnonvirtualdtor waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wundef winitself wpointerarith wshadow wsignpromo wuninitialized wsuggestoverride wnocomment wnostrictoverflow wnolonglong pthread fnoomitframepointer ffunctionsections fdatasections msse msse2 msse3 mssse3 msse41 mpopcnt msse42 mf16c mfma mavx mavx2 fvisibilityhidden g o0 ddebug ddebug c compiler c flags release fsignedchar w wall wreturntype waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wuninitialized wnocomment wnostrictoverflow wnolonglong pthread fnoomitframepointer ffunctionsections fdatasections msse msse2 msse3 mssse3 msse41 mpopcnt msse42 mf16c mfma mavx mavx2 fvisibilityhidden o2 dndebug dndebug c flags debug fsignedchar w wall wreturntype waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wuninitialized wnocomment wnostrictoverflow wnolonglong pthread fnoomitframepointer ffunctionsections fdatasections msse msse2 msse3 mssse3 msse41 mpopcnt msse42 mf16c mfma mavx mavx2 fvisibilityhidden g o0 ddebug ddebug linker flags release wlgcsections wlasneeded wlnoundefined linker flags debug wlgcsections wlasneeded wlnoundefined ccache no precompiled headers no extra dependencies dl m pthread rt 3rdparty dependencies opencv modules to be built aruco bgsegm bioinspired calib3d ccalib core datasets dnn dnnobjdetect dnnsuperres dpm face features2d flann fuzzy gapi hfs highgui imghash imgcodecs imgproc intensitytransform linedescriptor mcc ml objdetect optflow phaseunwrapping photo plot quality rapid reg rgbd saliency shape stereo stitching structuredlight superres surfacematching text tracking video videoio videostab wechatqrcode xfeatures2d ximgproc xobjdetect xphoto disabled world disabled by dependency unavailable alphamat cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev cvv freetype hdf java julia matlab ovis python2 python3 sfm ts viz applications documentation no nonfree algorithms no gui none gtk no vtk support no media io zlib zlib ver 1213 jpeg libjpegturbo ver 21362 webp build ver encoder 0x020f png build ver 1637 tiff build ver 42 420 jpeg 2000 build ver 250 openexr build ver 230 hdr yes sunraster yes pxm yes pfm yes video io dc1394 no ffmpeg no avcodec no avformat no avutil no swscale no avresample no gstreamer no v4lv4l2 yes linuxvideodev2h parallel framework pthreads trace yes with intel itt other thirdparty libraries va yes lapack no eigen no custom hal no protobuf build 3191 flatbuffers builtin3rdparty 2359 opencl yes intelva include path link libraries dynamic load python for build usrbinpython27 java ant no java no jni no java wrappers no java tests no install to configuring done generating done build files have been written to compile the test using the following configuration cmake3 dcmakebuildtypedebug verbose1 the code to load and execute the model stdstring modelpath load the network cvdnnnet net stdvector outs stdvector outputnames for int i 0 i outputnamessize i stdcout i stdendl netforwardouts stdcout outssize outssize stdendl for sizet i 0 i outssize i stdcout i outsisize depth outsidepth channels outsichannels type outsitype stdendl the output debug010440 global systemcpp2881 core restore fp mxcsr flags 0x00001fb0 debug310440 global systemcpp2881 core restore fp mxcsr flags 0x00001fb0 0 1170 1 1179 debug010492 global systemcpp2842 core update fp mxcsr flags 0x00009ff0 debug010492 global systemcpp2881 core restore fp mxcsr flags 0x00009ff0 outssize 2 0 8400 x 1 depth 5 channels 1 type 5 1 8400 x 1 depth 5 channels 1 type 5 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncmake: don't export external target twice\nfixup 23842 error message on dwithopenvinoon dbuildsharedlibsoff cmake error installexport opencvmodules includes target ocv3rdpartyopenvino more than once in the export set cmake error in cmakeliststxt given target ocv3rdpartyopenvino more than once"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfix: typing stubs overload presence check\nevery function has at least 1 overload the main one so before the fix always produced true as a coincide removes unnecessary import typing in several modules stubs eg pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTest_Torch_nets.FastNeuralStyle_accuracy/1 randomly fails with CUDA\nsystem information platform ubuntu cuda full test name where getparam cudacudafp16 detailed description run where getparam cudacudafp16 failure expected norminf linf actual 25654 vs 25 ref 255 failed where getparam cudacudafp16 1900 ms steps to reproduce issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPython type stubs does not handle cuda::GpuMat and cuda::Stream\nsystem information python 36 platform cuda detailed description failed to resolve cv2cudacodec namespace against cv2 errors failed to resolve function against cv2 errors 0 failed to resolve stream argument failed to resolve stream exposed as stream 1 failed to resolve stream argument failed to resolve stream exposed as stream failed to resolve cv2cudacodecencodeqp class against cv2 errors failed to resolve qpinterp property failed to resolve qpinterb property failed to resolve qpintra property failed to resolve class against cv2 errors failed to resolve targetquality property failed to resolve class against cv2 errors failed to resolve function against cv2 errors 0 failed to resolve frame argument failed to resolve one of gpumat none items errors failed to resolve gpumat exposed as gpumat 1 failed to resolve stream argument failed to resolve stream exposed as stream 2 failed to resolve return type failed to resolve one of tuplebool gpumat items errors failed to resolve gpumat exposed as gpumat failed to resolve function against cv2 errors 0 failed to resolve stream argument failed to resolve stream exposed as stream failed to resolve function against cv2 errors 0 failed to resolve frame argument failed to resolve one of gpumat none items errors failed to resolve gpumat exposed as gpumat 1 failed to resolve return type failed to resolve one of tuplebool gpumat items errors failed to resolve gpumat exposed as gpumat steps to reproduce cmake options that work cmake python38 python38 dwithcudaon dcudaarchbin61 opencvmaster cmake options that doe not cmake python38 python38 dwithcudaon dcudaarchbin61 opencvmaster cuda definitions for python issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDepthwise Convolution layer with 5x5 kernel much slower than 4.7.0\nsystem information macos m2 opencv 470 and 480 python detailed description mediapipe palm detection model from opencv zoo show the inference time is double than the 470 version reference model file layer by layer performance test results palm47txt palm48txt depth wise convolution inference time is 3 times than 470 version steps to reproduce just run benchmark in opencv zoo issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nVideoCapture MSMF plugin won't open using camera/device index.\nsystem information opencv version at least from 455 to master operating system platform windows 1011 compiler compiler version visual studio 2022 detailed description it looks like unnecessary nullptr check of optional argument below linked fragment with my comments by commenting out pointed filename check i was able to open camera on my local machine cpp static cvresult cvapicall const char filename int cameraindex int params unsigned nparams cvout cvplugincapture handle if handle return cverrorfail handle null if filename filename is optional see below return cverrorfail capturet cap 0 try parametersparams nparams cap new capturet bool res if filename if filename is true then we use res parameters else however if its nullptr res capopencameraindex parameters then we use index to search device if res handle cvplugincapturecap return cverrorok catch const stdexception e cvlogwarningnull msmf exception is raised ewhat catch cvlogwarningnull msmf unknown c exception is raised if cap delete cap return cverrorfail steps to reproduce open video capture from camera for example laptops builtin camera using msmf backend cvvideocapture vc0 cvcapmsmf built as a plugin its also very likely that its the same issue as issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpenCV solution for Visual Studio 2019 is not building opencv_core.lib when AVX2 is specified in (CPU_DISPATCH = SSE4_1;SSE4_2;AVX;FP16;AVX2) in x86 build\nsystem information opencv solution for visual studio 2019 is not building opencvcorelib when avx2 is specified in cpudispatch in x86 build opencv version 480 operating system platform windows 10 compiler compiler version visual studio 2019 detailed description by default x64 cmake configuration for visual studio 2019 uses cpubaseline sse3 cpudispatch and x86 configuration uses cpubaseline sse2 cpudispatch sse41sse42avxfp16 when i set the same flags in build for x86 as set in x64 build building opencvcore module ends with failure logs from building opencvcore module build started 1 build started project zerocheck configuration release win32 1checking build system 2 build started project ippiw configuration release win32 3 build started project ittnotify configuration release win32 4 build started project opencvcoresse41 configuration release win32 5 build started project opencvcoresse42 configuration release win32 6 build started project opencvcoreavx configuration release win32 7 build started project opencvcoreavx2 configuration release win32 8 build started project zlib configuration release win32 4building custom rule 2building custom rule 3building custom rule 7building custom rule 6building custom rule 8building custom rule 5building custom rule 2iwcorec 6mathfuncscoreavxcpp 4arithmsse41cpp 2iwimagec 3ittnotifystaticc 2iwimagefilterboxc 4matmulsse41cpp 3jitprofilingc 2iwimagefiltercannyc 5statsse42cpp 7statavx2cpp 8adler32c 8compressc 8crc32c 8deflatec 7arithmavx2cpp 7convertavx2cpp 8gzclosec 8gzlibc 8gzreadc 7convertscaleavx2cpp 7countnonzeroavx2cpp 7hasnonzeroavx2cpp 7matmulavx2cpp 8gzwritec 8inflatec 8infbackc 8inftreesc 2iwimagefiltersobelc 2iwimageopcopyc 2iwimageopcopymergec 2iwimageopcopysplitc 2iwimageopscalec 8inffastc 8treesc 8uncomprc 8zutilc error c3861 mm256extractepi64 identifier not found compiling source file message see reference to function template instantiation int64 m256i being compiled compiling source file message see reference to function template instantiation uint64 being compiled compiling source file 7meanavx2cpp 2iwimageopsetc 2iwownc error c3861 mm256extractepi64 identifier not found compiling source file message see reference to function template instantiation int64 m256i being compiled compiling source file message see reference to function template instantiation uint64 being compiled compiling source file 7mergeavx2cpp error c3861 mm256extractepi64 identifier not found compiling source file message see reference to function template instantiation int64 m256i being compiled compiling source file message see reference to function template instantiation uint64 being compiled compiling source file 7splitavx2cpp error c3861 mm256extractepi64 identifier not found compiling source file message see reference to function template instantiation int64 m256i being compiled compiling source file message see reference to function template instantiation uint64 being compiled compiling source file 7sumavx2cpp error c3861 mm256extractepi64 identifier not found compiling source file message see reference to function template instantiation int64 m256i being compiled compiling source file message see reference to function template instantiation uint64 being compiled compiling source file error c3861 mm256extractepi64 identifier not found compiling source file message see reference to function template instantiation int64 m256i being compiled compiling source file message see reference to function template instantiation uint64 being compiled compiling source file error c3861 mm256extractepi64 identifier not found compiling source file message see reference to function template instantiation int64 m256i being compiled compiling source file message see reference to function template instantiation uint64 being compiled compiling source file error c3861 mm256extractepi64 identifier not found compiling source file message see reference to function template instantiation int64 m256i being compiled compiling source file message see reference to function template instantiation uint64 being compiled compiling source file 3ittnotifyvcxproj 2ippiwvcxproj 8zlibvcxproj error c3861 mm256extractepi64 identifier not found compiling source file message see reference to function template instantiation int64 m256i being compiled compiling source file message see reference to function template instantiation uint64 being compiled compiling source file error c3861 mm256extractepi64 identifier not found compiling source file message see reference to function template instantiation int64 m256i being compiled compiling source file message see reference to function template instantiation uint64 being compiled compiling source file error c3861 mm256extractepi64 identifier not found compiling source file message see reference to function template instantiation int64 m256i being compiled compiling source file message see reference to function template instantiation uint64 being compiled compiling source file error c3861 mm256extractepi64 identifier not found compiling source file message see reference to function template instantiation int64 m256i being compiled compiling source file message see reference to function template instantiation uint64 being compiled compiling source file 7done building project failed 9 build started project opencvcore configuration release win32 9processing opencl kernels core 9 contains the same content 9building custom rule 9cmakepchcxx 9algorithmcpp 9arithmcpp 9arithmdispatchcpp 9arraycpp 9asynccpp 9batchdistancecpp 9bindingsutilscpp 9bufferareacpp 9channelscpp 9checkcpp 9convertdispatchcpp 9convertccpp 9copycpp 9cudagpumatcpp 9cudagpumatndcpp 9cudahostmemcpp 9cudainfocpp 9cudastreamcpp 9datastructscpp 9directxcpp 9downhillsimplexcpp 9dxtcpp 9glcore31cpp 9globcpp 9halinternalcpp 9kmeanscpp 9lapackcpp 9ldacpp 9loggercpp 9lpsolvercpp 9lutcpp 9mathfuncscpp 9matmuldispatchcpp 9matrixcpp 9matrixccpp 9matrixdecompcpp 9matrixiteratorcpp 9matrixoperationscpp 9matrixsparsecpp 9matrixtransformcpp 9matrixwrapcpp 9meandispatchcpp 9mergedispatchcpp 9minmaxcpp 9normcpp 9oclcpp 9openclclblascpp 9openclclfftcpp 9openclcorecpp 9openglcpp 9outcpp 9ovxcpp 9parallelopenmpcpp 9paralleltbbcpp 9parallelimplcpp 9pcacpp 9persistencecpp 9persistencejsoncpp 9persistencetypescpp 9persistencexmlcpp 9persistenceymlcpp 9randcpp 9softfloatcpp 9splitdispatchcpp 9statdispatchcpp 9statccpp 9stlcpp 9sumdispatchcpp 9systemcpp 9tablescpp 9tracecpp 9typescpp 9umatrixcpp 9datafilecpp 9filesystemcpp 9logtagmanagercpp 9samplescpp 9vaintelcpp 9alloccpp 9parallelcpp 9parallelcpp 9link fatal error lnk1181 cannot open input file 9done building project opencvcorevcxproj failed build 7 succeeded 2 failed 0 uptodate 0 skipped steps to reproduce 1 set cmake configuration to visual studio 2019 x86 2 set this flags cpubaseline sse3 cpudispatch buildsharedlibsoff 3 build visual studio 2019 solution 4 open solution and build opencvcore module cmakecachetxt issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPython type stubs: Class `cv2.error` is missing properties\nsystem information opencv python operating system platform 10019045 build 19045 python version 3913 detailed description class cv2error is currently typed as py class errorexception but should be something like py class errorexception code int err str file str func str line int msg str they are technically classvars but would be none as inspected with py import cv2 errordir dircv2error exceptiondir direxception x for x in errordir if x not in exceptiondir module weakref code err file func line msg try except cv2error as error printtypeerrorcode typeerrorerr typeerrorfile typeerrorfunc typeerrorline typeerrormsg steps to reproduce actual usage example image issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDetection of multiple ChArUco boards with different IDs in one image broken in 4.8.0\nsystem information opencv 480 ubuntu 2204 python 3106 detailed description in opencv 470 you could separately detect two charuco boards visible in a single image python dicttype arucodict6x6250 squares 5 7 squarelengthmm 200 markerlengthmm 100 arucodict board0 squarelengthmm markerlengthmm arucodict nparange17 there are 17 white squares provide 17 markers with ids 016 detector charucocorners charucoids markercorners markerids charucocorners charucoids 255 0 0 board1 squarelengthmm markerlengthmm arucodict nparange17 17 17 markers with ids 1733 detector charucocorners charucoids markercorners markerids charucocorners charucoids 0 255 0 screenshot from 20230702 140406 in opencv 480 the second detectboard does not return any charuco corners charucocornersand charucoids are both none the markers are still returned so it is not a detection issue sample code and sample image see below return under 470 running opencv 470 board0 charuco ids 023 24 marker ids 033 34 board1 charuco ids 023 24 marker ids 033 23 and same code under opencv 480 running opencv 480 board0 charuco ids 023 24 marker ids 033 34 board1 no charuco ids marker ids 033 23 steps to reproduce python import numpy as np import cv2 import cv2aruco as aruco if name main load image image cv2imreadimagepng generate aruco boards dicttype arucodict6x6250 squares 5 7 squarelengthmm 200 markerlengthmm 100 arucodict board0 squarelengthmm markerlengthmm arucodict nparange17 board1 squarelengthmm markerlengthmm arucodict nparange17 17 printfrunning opencv cv2version detector charucocorners charucoids markercorners markerids printboard0 if charucoids is none print no charuco ids else printf charuco ids lencharucoids charucocorners charucoids 255 0 0 printf marker ids lenmarkerids detector charucocorners charucoids markercorners markerids printboard1 if charucoids is none print no charuco ids else printf charuco ids lencharucoids charucocorners charucoids 0 255 0 printf marker ids lenmarkerids cv2imshowfcharuco ids with opencv cv2version image cv2waitkey0 cv2destroyallwindows image issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCUDA 12.2 fp16 dnn compilation error\nsystem information opencv version 480 os windows 11 compiler visual studio 2022 cuda 122 detailed description switching from cuda 121 to 122 results in several compilation like the one below when compiling the dnn module error c2666 operator overloaded functions have similar conversions failed nologo tp dcvapiexports dcvcuda4dnn1 dcvocl4dnn1 denableplugins dhaveflatbuffers1 dhaveprotobuf1 dusemathdefines dvariadicmax10 dwin32winnt0x0601 dopencvbuild1 dstdcconstantmacros dstdcformatmacros dstdclimitmacros externalicprogram filesnvidia gpu computing externalw0 dwin32 dwindows w4 gr d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise fs eha wd4127 wd4251 wd4324 wd4275 wd4512 wd4589 wd4819 wd4244 wd4267 wd4018 wd4355 wd4800 wd4251 wd4996 wd4146 wd4305 wd4127 wd4100 wd4512 wd4125 wd4389 wd4510 wd4610 wd4702 wd4456 wd4457 wd4065 wd4310 wd4661 wd4506 wd4125 wd4267 wd4127 wd4244 wd4512 wd4702 wd4456 wd4510 wd4610 wd4800 wd4701 wd4703 wd4505 wd4458 md o2 ob2 dndebug showincludes fdlibopencvdnn480pdb fs c error c2666 operator overloaded functions have similar conversions note could be bool cvoperator const cvfilenodeiterator const cvfilenodeiterator note or bool cvoperator const const note or bool cvoperator const cvmatconstiterator const cvmatconstiterator note or cvmatexpr cvoperator doubleconst cvmat note or cvmatexpr cvoperator const cvmat double note or cvmatexpr cvoperator const cvmat const cvmat note or bool cvoperator const cvumatdatamemoryflag const int note or bool cvoperator const cvinputarraykindflag const int note or bool cvoperator const cvaccessflag const int note or bool cvoperator const cvrange const cvrange note or const const note or const const note or const const note or const const note or const const note or const const note or const const note or const const note or const const note or const const cprogram filesnvidia gpu computing note or bool operator const half const half found using argumentdependent lookup cprogram filesnvidia gpu computing note or bool operator const half2 const half2 found using argumentdependent lookup cprogram filesnvidia gpu computing note or bool operator const nvbfloat16 const nvbfloat16 found using argumentdependent lookup cprogram filesnvidia gpu computing note or bool operator const nvbfloat162 const nvbfloat162 found using argumentdependent lookup note or builtin c operatorfloat double note or builtin c operatorsigned char double note or builtin c operatorunsigned char double note or builtin c operatorchar double note or builtin c operatorshort double note or builtin c operatorunsigned short double note or builtin c operatorint double note or builtin c operatorunsigned int double note or builtin c operatorlong double note or builtin c operatorunsigned long double note or builtin c operatorint64 double note or builtin c operatorunsigned int64 double note or builtin c operatorbool double note or bool cvoperator const cvmatiterator const cvmatiterator note bool cvoperator const cvmatiterator const cvmatiterator could not deduce template argument for const cvmatiterator from t with thalf note or bool cvoperator const cvmatconstiterator const cvmatconstiterator note bool cvoperator const cvmatconstiterator const cvmatconstiterator could not deduce template argument for const cvmatconstiterator from t with thalf note or cvmatexpr cvoperator const cvmatx const cvmat note cvmatexpr cvoperator const cvmatx const cvmat could not deduce template argument for const cvmatx from t with thalf note or cvmatexpr cvoperator const cvmat const cvmatx note cvmatexpr cvoperator const cvmat const cvmatx could not deduce template argument for const cvmatx from double note or bool cvoperator const cvscalar const cvscalar note bool cvoperator const cvscalar const cvscalar could not deduce template argument for const cvscalar from t with thalf note or bool cvoperator const cvrect const cvrect note bool cvoperator const cvrect const cvrect could not deduce template argument for const cvrect from t with thalf note or bool cvoperator const cvsize const cvsize note bool cvoperator const cvsize const cvsize could not deduce template argument for const cvsize from t with thalf note or bool cvoperator const cvpoint3 const cvpoint3 note bool cvoperator const cvpoint3 const cvpoint3 could not deduce template argument for const cvpoint3 from t with thalf note or bool cvoperator const cvpoint const cvpoint note bool cvoperator const cvpoint const cvpoint could not deduce template argument for const cvpoint from t with thalf note or bool cvoperator const cvcomplex const cvcomplex note bool cvoperator const cvcomplex const cvcomplex could not deduce template argument for const cvcomplex from t with thalf note or bool cvoperator const cvmatx const cvmatx note bool cvoperator const cvmatx const cvmatx could not deduce template argument for const cvmatx from t with thalf note while trying to match the argument list t double with thalf note while compiling class template member function void const note see reference to class template instantiation being compiled note see reference to function template instantiation cvptr const cvmat being compiled it looks like a result of the cuda math apis being reworked in this version of cuda specifically changes to the cprogram filesnvidia gpu computing file steps to reproduce cmakeexe bbuilddir hopencvdir gninja dbuildopencvworldoff dwithcudaon filesnvidia gpu computing toolkitcudav122 dcudaarchbin86 cmakeexe build builddir target opencvdnn issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n error: (-215:Assertion failed) inputs.size() in function 'cv::dnn::dnn4_v20230620::Layer::getMemoryShapes'\nsystem information general configuration for opencv 480pre version control 470505gc982be3924 extra modules location extra version control extra 47071g4f66f867 platform timestamp 20230605t094958z host windows 10022621 amd64 cmake 3261 cmake generator visual studio 17 2022 cmake build tool cprogram filesmicrosoft visual msvc 1935 configuration debug release cpuhw features baseline sse sse2 sse3 requested sse3 dispatched code generation sse41 sse42 fp16 avx avx2 avx512skx requested sse41 sse42 avx fp16 avx2 avx512skx sse41 18 files ssse3 sse41 sse42 2 files ssse3 sse41 popcnt sse42 fp16 1 files ssse3 sse41 popcnt sse42 fp16 avx avx 8 files ssse3 sse41 popcnt sse42 avx avx2 37 files ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 avx512skx 8 files ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 avx512f avx512common avx512skx cc built as dynamic libs yes c standard 11 c compiler cprogram filesmicrosoft visual ver 1935322150 c flags release dwin32 dwindows w4 gr d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise eha wd4127 wd4251 wd4324 wd4275 wd4512 wd4589 wd4819 mp md o2 ob2 dndebug c flags debug dwin32 dwindows w4 gr d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise eha wd4127 wd4251 wd4324 wd4275 wd4512 wd4589 wd4819 mp mdd zi ob0 od rtc1 c compiler cprogram filesmicrosoft visual c flags release dwin32 dwindows w3 d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise mp md o2 ob2 dndebug c flags debug dwin32 dwindows w3 d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise mp mdd zi ob0 od rtc1 linker flags release machinex64 incrementalno linker flags debug machinex64 debug incremental ccache no precompiled headers yes extra dependencies cudartstaticlib nppclib nppiallib nppicclib nppideilib nppiflib nppiglib nppimlib nppistlib nppisulib nppitclib nppslib cublaslib cudnnlib cufftlib libpathcprogram filesnvidia gpu computing 3rdparty dependencies opencv modules to be built alphamat aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnnobjdetect dnnsuperres dpm face features2d flann fuzzy gapi hfs highgui imghash imgcodecs imgproc intensitytransform java linedescriptor mcc ml objdetect optflow phaseunwrapping photo plot python3 quality rapid reg rgbd saliency sfm shape stereo stitching structuredlight superres surfacematching text tracking ts video videoio videostab viz wechatqrcode xfeatures2d ximgproc xobjdetect xphoto disabled world disabled by dependency unavailable cvv freetype hdf julia matlab ovis python2 applications tests perftests examples apps documentation doxygen python javadoc nonfree algorithms yes windows rt support no gui win32ui win32 ui yes opengl support yes opengl32 glu32 vtk support yes ver 925 media io zlib optimized debug ver 1213 jpeg buildlibjpegturbo ver 21362 simd support request yes simd support no webp build ver encoder 0x020f png optimized debug ver 1640 tiff build ver 42 420 jpeg 2000 build ver 250 openexr build ver 230 hdr yes sunraster yes pxm yes pfm yes video io dc1394 no ffmpeg yes prebuilt binaries avcodec yes 58134100 avformat yes 5876100 avutil yes 5670100 swscale yes 59100 avresample yes 400 gstreamer no directshow yes media foundation yes dxva yes parallel framework concurrency other thirdparty libraries intel ipp 20218 202180 at intel ipp iw sources 202180 at lapack yes cprogram files cprogram files cprogram files openvino yes 202230 eigen yes ver custom hal no protobuf build 3191 flatbuffers builtin3rdparty 2359 nvidia cuda yes ver 121 cufft cublas nvidia gpu arch 86 nvidia ptx archs cudnn yes ver 880 opencl yes nvd3d11 include path link libraries dynamic load python 3 interpreter cprogram ver 31010 libraries optimized cprogram debug cprogram ver 31010 numpy ver 1235 install path python for build cprogram java ant ver 11013 java no jni cprogram cprogram cprogram java wrappers yes ant java tests yes install to cinstallopencv detailed description i converted adabinskittypth to onnx using pytorch error is info00397 global onnximportercpp835 dnnonnx loading onnx v7 model produced by pytorch210 number of nodes 1838 initializers 468 inputs 1 outputs 2 info00398 global onnximportercpp728 dnnonnx onnx opset version 14 info01512 global onnximportercpp1006 dnnonnx processing node with 0 inputs and 1 outputs from domainaionnx info01512 global onnximportercpp1006 dnnonnx processing node with 0 inputs and 1 outputs from domainaionnx info01512 global onnximportercpp1006 dnnonnx processing node with 0 inputs and 1 outputs from domainaionnx info01513 global onnximportercpp1006 dnnonnx processing node with 0 inputs and 1 outputs from domainaionnx info01513 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01513 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01514 global onnximportercpp1006 dnnonnx processing node with 0 inputs and 1 outputs from domainaionnx info01514 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01514 global onnximportercpp1006 dnnonnx processing node with 0 inputs and 1 outputs from domainaionnx info01514 global onnximportercpp1006 dnnonnx processing node with 0 inputs and 1 outputs from domainaionnx info01515 global onnximportercpp1006 dnnonnx processing node with 0 inputs and 1 outputs from domainaionnx info01515 global onnximportercpp1006 dnnonnx processing node with 0 inputs and 1 outputs from domainaionnx info01515 global onnximportercpp1006 dnnonnx processing node with 5 inputs and 1 outputs from domainaionnx info01515 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01515 global onnximportercpp1006 dnnonnx processing node with 0 inputs and 1 outputs from domainaionnx info01516 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01516 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01516 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01516 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01516 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01516 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01516 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01516 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01517 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01517 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01517 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01517 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01517 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01517 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01517 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01517 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01517 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01518 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01518 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01518 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01518 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01518 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01518 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01519 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01519 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01519 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01519 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01519 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01519 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01519 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01519 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01519 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01520 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01520 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01520 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01520 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01520 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01520 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01520 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01520 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01520 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01521 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info01521 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01521 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01521 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01521 global onnximportercpp1006 dnnonnx processing node with 0 inputs and 1 outputs from domainaionnx info01521 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01521 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01521 global onnximportercpp1006 dnnonnx processing node with 0 inputs and 1 outputs from domainaionnx info01521 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01521 global onnximportercpp1006 dnnonnx processing node with 0 inputs and 1 outputs from domainaionnx info01522 global onnximportercpp1006 dnnonnx processing node with 2 inputs and 1 outputs from domainaionnx info01522 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01522 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info01522 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx opencv480pre error assertion failed inputssize in file line 255 error01522 global onnximportercpp1064 dnnonnx error during processing node with 1 inputs and 1 outputs from domainaionnx info01522 global onnximportercpp1068 input0 info01522 global onnximportercpp1072 output0 opencv480pre error unspecified error node parse error opencv480pre error 215assertion failed inputssize in function in file line 1083 opencv terminate handler is called the last opencv error is opencv480pre error unspecified error node parse error opencv480pre error 215assertion failed inputssize in function in file line 1083 studio process 5936 exited with code 3 stack trace is cvexception exc line 1283 c code const stdstring err const char func const char file int line line 1295 c line 1083 c external code opencvonnxnodeproto nodeproto line 1029 c line 919 c net const char onnxfile line 282 c char line 77 c char line 84 c stdstring onnxfile line 4076 c stdstring model const stdstring config const stdstring framework line 54 c steps to reproduce model is imported using adress given in import onnxscript import torch from models import unetadaptivebins import modelio import torchonnx opsetversion14 device torchdevicecpu model minval1e3 maxval10 dummyinput torchrand1 3 480 640 modeleval model model printexport model to onnx torchonnxexportmodel dummyinput adabinskittionnx verbosetrue inputnamesimagein outputnamesdepthout then i try to download model in opencv net net net issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMouse coordinates seem to be off if opencv versionhigher than 4.5\nsystem information opencv version 440 operating system platform windows 10 python version 3810 detailed description opencv version 440 seams to be still ok but somewhere for later versions mouse reading coordinates seems to be off is that true not sure what version it starts but latest 46 or 47 for sure it could be tested in code below it is a 2x2 image so with mouse increase the size of the window tt should print proper mouse coordinates but those latest versions show proper value only for top left quadrant for a pixel steps to reproduce import numpy as np import cv2 printfopencv version cv2version img npzeros223 npuint8 img0 0 0 0 255 img1 0 0 255 0 img0 1 255 0 0 def printxy cv2namedwindowimage cv2windownormal cv2windownormal mouseaction cv2imshowimage img cv2waitkey0"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndnn: fix overflow in sigmoid layer\nfixes 23850 pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMinGW-w64 Standalone Environment Error: 'pthread_self' was not declared in this scope\nsystem information opencv version 470 operating system windows 11 22h2 compiler version gccexe x8664win32sehrev1 built by mingwbuilds project 1310 mingww64 detailed description 27 building cxx object in function int cvgetthreadnum error pthreadself was not declared in this scope 800 return no zerobased indexing in the case of my machine ive had only define havepthreadspf enabled but the pthreadh header was not included for this case hence the error steps to reproduce cpp elif defined haveopenmp include elif defined havegcd include include elif defined winrt mscver 1900 include elif defined haveconcurrency include line 130 in elif defined havepthreadspf include endif line 131 in adding an elif defined havepthreadspf condition and a include snippet allowed cpp elif defined havepthreadspf return no zerobased indexing at line 800 to correctly find pthreadself and moves on correctly i wonder if this was somehow overlooked or was a design choice and that im just setting my cmake configs wrong issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nG-API: Fix incorrect OpaqueKind for Kernel outputs\npull request readiness checklist overview the pr is going to fix several problems 1 major gkernel doesnt hold kind for its outputs since gmodelbuilder traverse graph from outputs to inputs once it reaches any output of the operation it will use its kind to create data meta for all operation outputs since it essential for python to know gtypeinfo which is shape and kind it will be confused consider this operation intypescvgarrayint cvgarrayint class gsquaremean staticmethod def outmetadesc return cvemptygopaquedesc cvemptyarraydesc even though gopaque is float corresponding metadata might have int kind because it might be taken from cvgarrayint so it will be a problem if one of the outputs of these operation is graph output because python will cast it to the wrong type based on data meta 2 minor some of the openvino irs doesnt any layout information for input its usually true only for irv10 but since openvino 20 need this information to correctly configure resize we need to put default layout if there no such assigned in ovmodel see details at i agree to contribute to the project under apache 2 license to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfix: conditionally define generic NumPy NDArray alias\nthis patch introduces conditional alias definition fixes compatibility with numpy versions 120 and python 39 updates enums handling to utilise introduced generated cv2typinginitpy content after patch python import cv2matwrapper import numpy import sys import typing if 1200 and sysversioninfo 3 9 numpyarraygeneric else numpyarraygeneric numpyndarray if 1200 and sysversioninfo 3 9 numpyarrayfloat32 else numpyarrayfloat32 numpyndarray if 1200 and sysversioninfo 3 9 numpyarrayfloat64 else numpyarrayfloat64 numpyndarray matlike numpyarraygeneric matx33f numpyarrayfloat32 ndarrayshape3 3 dtypenumpyfloat32 matx33d numpyarrayfloat64 ndarrayshape3 3 dtypenumpyfloat64 matx44f numpyarrayfloat32 ndarrayshape4 4 dtypenumpyfloat32 matx44d numpyarrayfloat64 ndarrayshape4 4 dtypenumpyfloat64 resolves 23822 pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPython Typing module is incompatible with some Numpy versions\nsystem information os ubuntu 1804 python 380 from apt opencv 4x detailed description numpy 1243 importing issue python38 python 380 default dec 9 2021 175327 gcc 840 on linux type help copyright credits or license for more information import cv2 traceback most recent call last file line 1 in file line 181 in bootstrap file line 175 in bootstrap if submodule debug file line 28 in pymodule file line 127 in importmodule return package level file line 73 in matlike typeerror type subscription requires python 39 numpy 1202 python 380 default dec 9 2021 175327 gcc 840 on linux type help copyright credits or license for more information import cv2 traceback most recent call last file line 1 in file line 181 in bootstrap file line 175 in bootstrap if submodule debug file line 28 in pymodule file line 127 in importmodule return package level file line 73 in matlike typeerror numpydtypemeta object is not subscriptable steps to reproduce python38 import cv2 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nExport enums ALL_CAPS version to typing stub files\nexport allcaps versions alongside from normal names for enum constants since both versions are available in runtime change enum names entries comments to documentary strings before patch python rmataccessr int rmataccessw int rmataccess int one of r w after patch python rmataccessr int rmataccessr int rmataccessw int rmataccessw int rmataccess int one of rmataccessr rmataccessr rmataccessw rmataccessw resolves 23776 pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCAP_IMAGES: can't find starting number\nsystem information general configuration for opencv 470dev version control 470403g5d913f4d72 extra modules location extra version control extra 47054g8dfeed73 platform timestamp 20230605t094958z host windows 10022621 amd64 cmake 3261 cmake generator visual studio 17 2022 cmake build tool cprogram filesmicrosoft visual msvc 1935 configuration debug release cpuhw features baseline sse sse2 sse3 requested sse3 dispatched code generation sse41 sse42 fp16 avx avx2 avx512skx requested sse41 sse42 avx fp16 avx2 avx512skx sse41 18 files ssse3 sse41 sse42 2 files ssse3 sse41 popcnt sse42 fp16 1 files ssse3 sse41 popcnt sse42 fp16 avx avx 8 files ssse3 sse41 popcnt sse42 avx avx2 36 files ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 avx512skx 8 files ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 avx512f avx512common avx512skx cc built as dynamic libs yes c standard 11 c compiler cprogram filesmicrosoft visual ver 1935322150 c flags release dwin32 dwindows w4 gr d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise eha wd4127 wd4251 wd4324 wd4275 wd4512 wd4589 wd4819 mp md o2 ob2 dndebug c flags debug dwin32 dwindows w4 gr d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise eha wd4127 wd4251 wd4324 wd4275 wd4512 wd4589 wd4819 mp mdd zi ob0 od rtc1 c compiler cprogram filesmicrosoft visual c flags release dwin32 dwindows w3 d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise mp md o2 ob2 dndebug c flags debug dwin32 dwindows w3 d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise mp mdd zi ob0 od rtc1 linker flags release machinex64 incrementalno linker flags debug machinex64 debug incremental ccache no precompiled headers yes extra dependencies cudartstaticlib nppclib nppiallib nppicclib nppideilib nppiflib nppiglib nppimlib nppistlib nppisulib nppitclib nppslib cublaslib cudnnlib cufftlib libpathcprogram filesnvidia gpu computing 3rdparty dependencies opencv modules to be built alphamat aruco barcode bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnnobjdetect dnnsuperres dpm face features2d flann fuzzy gapi hfs highgui imghash imgcodecs imgproc intensitytransform java linedescriptor mcc ml objdetect optflow phaseunwrapping photo plot python3 quality rapid reg rgbd saliency sfm shape stereo stitching structuredlight superres surfacematching text tracking ts video videoio videostab viz wechatqrcode xfeatures2d ximgproc xobjdetect xphoto disabled world disabled by dependency unavailable cvv freetype hdf julia matlab ovis python2 applications tests perftests examples apps documentation doxygen python javadoc nonfree algorithms yes windows rt support no gui win32ui win32 ui yes opengl support yes opengl32 glu32 vtk support yes ver 925 media io zlib optimized debug ver 1213 jpeg buildlibjpegturbo ver 21362 simd support request yes simd support no webp build ver encoder 0x020f png optimized debug ver 1640 tiff build ver 42 420 jpeg 2000 build ver 250 openexr build ver 230 hdr yes sunraster yes pxm yes pfm yes video io dc1394 no ffmpeg yes prebuilt binaries avcodec yes 58134100 avformat yes 5876100 avutil yes 5670100 swscale yes 59100 avresample yes 400 gstreamer no directshow yes media foundation yes dxva yes parallel framework concurrency other thirdparty libraries intel ipp 20218 202180 at intel ipp iw sources 202180 at lapack yes cprogram files cprogram files cprogram files openvino yes 202230 eigen yes ver custom hal no protobuf build 3191 flatbuffers builtin3rdparty 2359 nvidia cuda yes ver 121 cufft cublas nvidia gpu arch 86 nvidia ptx archs cudnn yes ver 880 opencl yes nvd3d11 include path link libraries dynamic load python 3 interpreter cprogram ver 31010 libraries optimized cprogram debug cprogram ver 31010 numpy ver 1235 install path python for build cprogram java ant ver 11013 jni cprogram cprogram cprogram java wrappers yes java tests yes install to cinstallopencv detailed description this code gives no error import cv2 as cv imgread vid ret imgvid vidread printvideo open imgvid0 0 printimread imgread0 0 and results are not equal because ffmpeg uses its own jpeg decoder video open 127 137 224 imread 128 138 225 so i want to use imread i add apipreference import cv2 as cv vid cvcapimages and there is an exception exception warn00088 global samplescpp61 cvsamplesfindfile error00088 global capcpp166 cvvideocaptureopen videoiocvimages raised opencv exception opencv470dev error 5bad argument capimages cant find starting number in the name of file in function cvicvextractpattern warn00088 global capcpp206 cvvideocaptureopen videoiocvimages backend is generally available but cant be used to capture by name many example in dnn module uses videocaptureopen to read a file inference with videocaptureopen and imread do not give same results steps to reproduce same problem in c all codes is already given issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nType stubs: `cv2.typing` type aliases don't exist at runtime but are not marked as such\nsystem information opencv python operating system platform 10019045 build 19045 python version 3913 detailed description trying to use cv2typinganything at runtime will throw an attributeerror ie attributeerror module cv2typing has no attribute matlike the details of when thats the case will depend on the python version and its annotations parser this makes the cv2typing module dangerous to use because static type checkers will find its use acceptable the typingtypecheckonly decorator exists for those exact cases but unfortunately cant be used with type aliases theres a couple possible solutions for this heres some i can think of 1 make them exist at runtime this could be as simple as creating a cv2typinginitpy where all the values are assigned the type but without generic typing to support python 39 this has the added bonus of making them runtimecomparable using isinstance 2 use classes instead of type aliases that inherits from the aliased type those classes can now be marked as typecheckonly 3 use typesheds workaround of making them private not great imo but at least is serves as a reminder for users that these dont exist at runtime steps to reproduce heres a example that fails in python 39 an older version like 3637 would have more cases py from typing import cast import cv2typing lets pretend this came from a method that returns a matlike but isnt typed correctly foo object bar castcv2typingmatlike foo traceback most recent call last file cv2py line 6 in bar castcv2typingmatlike foo attributeerror module cv2typing has no attribute matlike issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nType stubs: Slicing a `cv2.mat_wrapper.Mat` or derived type results in partially unknown `ndarray`\nsystem information opencv python operating system platform 10019045 build 19045 python version 3913 detailed description pyright uses a special unknown type to represent well unknown type types that cant be inferred unspecified generic types etc it is semantically different than any which means literally any type is valid or used as an escape hatch this results in type errors when using strict typing mypy does not separate that concept and simply infers any when type information is loss or unspecified steps to reproduce py import cv2matwrapper import cv2typing using casts to simplify for static typing testing purposes matlike castcv2typingmatlike object mat castcv2matwrappermat object type of matlikesliced is partially unknown type of matlikesliced is ndarrayany unknown ndarrayany dtypegeneric matlikesliced matlike 3 type of matsliced is partially unknown type of matsliced is ndarrayany unknown matsliced mat 3 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nType stubs: `cv2.__init__.pyi` is missing module re-exports\nsystem information opencv python operating system platform 10019045 build 19045 python version 3913 detailed description cv2initpyi is missing module reexports which should look something like this py from cv2 import aruco as aruco from cv2 import cuda as cuda from cv2 import data as data from cv2 import detail as detail from cv2 import dnn as dnn from cv2 import error as error from cv2 import fisheye as fisheye from cv2 import flann as flann from cv2 import gapi as gapi from cv2 import ipp as ipp from cv2 import matwrapper as matwrapper from cv2 import misc as misc from cv2 import ml as ml from cv2 import ocl as ocl from cv2 import ogl as ogl from cv2 import parallel as parallel from cv2 import samples as samples from cv2 import segmentation as segmentation from cv2 import typing as typing from cv2 import utils as utils from cv2 import videoioregistry as videoioregistry steps to reproduce the following should be acceptable to static type checkers but is not py import cv2 argument type is unknown argument corresponds to parameter values in function cuda is not a known member of module function cuda unknown printcv2error py import cv2 cv2errorstsok 0 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nconverto value\nsystem information opencv version 470 operating system windows compiler compiler version gcc 12 simple function cv32f 10255 from input value 1420 give me 05566 but real value must be something like this float value 1420 2550 printf10fn value display 10 decimal places printf4fn value display 4 decimal places 05568627715 05569 0556863 detailed description not correct value from function steps to reproduce input value 142 cv32f 10255 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPython Scalar is different with C++\nhi i suspect the following code has different behavior in c and python py scalar a 10 for python the scalar a 10 code will only replace the first 00 to 10 do something like a0 10 for c it will do the scalar a scalar10 original link my code in python py paramtf2cedn cvdnndnnlayoutnhwc paramtf2cednddepth cvcv32f paramtf2cednmean 128 128 128 1 128 paramtf2cednsize 224 224 paramtf2cednswaprb false cvdnndnnpmodenull result is 00078125 10 10 10 in c cpp image2blobparams paramtf2cedn dnnlayoutnhwc paramtf2cednddepth cv32f paramtf2cednmean 128 128 128 1 128 paramtf2cednsize size224 224 paramtf2cednswaprb false dnnpmodenull cout endl result is 00078125 0 0 0 detailed description it is about opencvpython bing steps to reproduce install lastest opencvpython pip install py param parammean nparray02 03 04 02 03 04 00 then redefine it parammean 10 it is 10 03 04 00 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nG-API: OpenVINO Backend Hotfix\npull request readiness checklist see details at i agree to contribute to the project under apache 2 license to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nKeep inliers for linear remap with BORDER_TRANSPARENT\npull request readiness checklist resolves i do think that this is a bug because with intercubic bordertransparent the last column and row are preserved so same should be done for interlinear see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n imgproc/cvtColor: fixed invalid read in BGR2HLS\nrelated pr 22520 mhls3 is read outside of array intertmpm 3 elements it is not used anywhere replacing maxnlanes with vlanes for array size is still in question i think it should be ok it was not ok smiley"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFaceRecognizerSF.feature C++ throws vector subscript out of range\nsystem information opencv version 470 operating system platform windows 11 compiler compiler version clang 1501 detailed description the bug is on this line cvmat feature1 feature2 feature1 throws an exception vector subscript out of range feature1 feature1clone of this code include include include include include include define cosine 0363 define isl2similarnorm norm 1128 char const fdmodel char const frmodel double scale 12 static void visualizecvmat input cvmat faces int thickness 2 for int i 0 i facesrows i draw bounding box cvrectangleinput cvrect2iintfacesati 0 intfacesati 1 intfacesati 2 intfacesati 3 cvscalar0 255 0 thickness draw landmarks cvcircleinput cvpoint2iintfacesati 4 intfacesati 5 2 cvscalar255 0 0 thickness cvcircleinput cvpoint2iintfacesati 6 intfacesati 7 2 cvscalar0 0 255 thickness cvcircleinput cvpoint2iintfacesati 8 intfacesati 9 2 cvscalar0 255 0 thickness cvcircleinput cvpoint2iintfacesati 10 intfacesati 11 2 cvscalar255 0 255 thickness cvcircleinput cvpoint2iintfacesati 12 intfacesati 13 2 cvscalar0 255 255 thickness int main then set logging to silent cvvideocapture capture0 if captureisopened stdcerr fatal error cannot open capture devicen return exitfailure cvsize scale scale cvptr fd imgsize cvptr fr cvmat img1 img2 capimg1 capimg2 capturereadcapimg1 capturereadcapimg2 cvresizecapimg1 img1 imgsize cvresizecapimg2 img2 imgsize cvmat faces1 faces2 debug1 img1clone debug2 img2clone fddetectimg1 faces1 if faces1rows 1 stdcerr fatal error cannot find a face on owner imagen return exitfailure fddetectimg2 faces2 if faces1rows 1 stdcerr fatal error cannot find a face on webcamn return exitfailure visualizedebug1 faces1 visualizedebug2 faces2 cvimshowface1 debug1 cvimshowface2 debug2 cvwaitkey5000 cvmat alignedface1 alignedface2 fraligncropimg1 faces1row0 alignedface1 fraligncropimg2 faces2row0 alignedface2 stdcout aligned size alignedface1size alignedface2size n cvimshowaligned1 alignedface1 cvimshowaligned2 alignedface2 cvwaitkey3000 cvmat feature1 feature2 feature1 feature1 feature1clone feature2 feature2 feature2clone double cosscore frmatchfeature1 feature2 stdcout score cosscore is same n return exitsuccess steps to reproduce ive checked all your facerecognizersf related issues and i havent found any solution do i also need to provide some additional info issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nopencv.js: QR code test failure\nrelates 23264 │ qr code detect and decode │ died on test 1 cannot construct qrcodedetector due to unbound types │ fail │ │ │ at │ │ │ │ at object │ │ │ │ at modulecompile modulejs65330 │ │ │ │ at modulejs66410 │ │ │ │ at moduleload modulejs56632 │ │ │ │ at trymoduleload modulejs50612 │ │ │ │ at functionmoduleload modulejs4983"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nhow using open cv to maui net\nsystem information how using open cv to maui net detailed description how using open cv to maui net steps to reproduce how using open cv to maui net issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nopencv.js missing ArucoDetector, GridBoard, CharucoBoard\nsystem information opencvjs version 470 official build from detailed description the classes arucodetector gridboard and charucoboard are not available in the opencvjs despite being whitelisted in the opencvjsconfigpy config file tests for such classes are also missing thanks steps to reproduce using nodejs code correctly show build informations let detector new cvarucodetector generate runtime error of missing arucodetector constructor output general configuration for opencv 470 version control 470 platform timestamp 20221228t152023z host linux 515056generic x8664 target emscripten 1 x86 cmake 3102 cmake generator unix makefiles cmake build tool usrbinmake configuration release cpuhw features baseline cc built as dynamic libs no c standard 11 c compiler ver 1000 c flags release s usepthreads0 fsignedchar w wall wreturntype wnonvirtualdtor waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wsignpromo wuninitialized wnocomment qunusedarguments ffunctionsections fdatasections fvisibilityhidden dndebug o2 dndebug c flags debug s usepthreads0 fsignedchar w wall wreturntype wnonvirtualdtor waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wsignpromo wuninitialized wnocomment qunusedarguments ffunctionsections fdatasections fvisibilityhidden g o0 ddebug ddebug c compiler c flags release s usepthreads0 fsignedchar w wall wreturntype wnonvirtualdtor waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wsignpromo wuninitialized wnocomment qunusedarguments ffunctionsections fdatasections fvisibilityhidden dndebug o2 dndebug c flags debug s usepthreads0 fsignedchar w wall wreturntype wnonvirtualdtor waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wsignpromo wuninitialized wnocomment qunusedarguments ffunctionsections fdatasections fvisibilityhidden g o0 ddebug ddebug linker flags release wlgcsections wlnoundefined o2 linker flags debug wlgcsections wlnoundefined ccache no precompiled headers no extra dependencies 3rdparty dependencies zlib libprotobuf quirc opencv modules to be built calib3d core dnn features2d flann imgproc js objdetect photo video disabled highgui imgcodecs ml stitching videoio world disabled by dependency ts unavailable gapi java python2 python3 applications examples documentation js nonfree algorithms no gui media io zlib build ver 1213 jpeg 2000 build ver 240 hdr yes sunraster yes pxm yes pfm yes video io parallel framework none other thirdparty libraries va no custom hal no protobuf build 3191 python for build usrbinpython install to usrlocal runtimeerror aborttypeerror cvarucodetector is not a constructor issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGeneration of getter and setter for the DetectorParameters.cornerRefinementMethod property is skipped during Java wrapper generation.\nsystem information opencv version 470 operating system platform windows 10 22h2 compiler compiler version cmake 3243 detailed description the creation of the and int methods are skipped when the java wrapper is generated this problem has occurred since opencv 470 it appears that opencv460 and opencv470 have changed the type of the variable opencv460 opencv470 the following code is the java code generated for each of these versions opencv460 c int public int return c void public void opencv470 c cornerrefinemethod return type cornerrefinemethod is not supported skipping the function c void unknown type cornerrefinemethod i skipping the function steps to reproduce build with the flag on issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPython binding for cuda::GpuMat does not handle float16 properly when downloading to or uploading from a NumPy array\nsystem information opencv python version 47072 with opencv 87331ca built with cuda 118 operating system platform ubuntu 2204 python version 3108 detailed description trying to upload a float16 numpy array to a gpumat gives an arr data type 23 is not supported error while trying to download from a float16 gpumat gives a uint64 numpy array with garbage content the test case below shows that float16 cupy and gpumat interoperability appears to work fine heres the full output log to the code from steps to reproduce original cupy array and pointer 2 3 2 3 140353891991552 gpumat initialized and downloaded to numpy and pointer 140356343578624 94720260377824 1107312640 260 140353891991552 assert gpumat type is float16 true numpy dtype uint64 back to cupy from gpumat value and pointer 2 3 2 3 140353891991552 now try to upload a float16 numpy array to gpumat traceback most recent call last file tstcupytomatpy line 75 in cvauploadnpa cv2error opencv470 1 error 5bad argument in function upload overload resolution failed arr data type 23 is not supported expected ptr for argument arr expected ptr for argument arr cudagpumatupload missing required argument stream pos 2 cudagpumatupload missing required argument stream pos 2 cudagpumatupload missing required argument stream pos 2 steps to reproduce python import cupy as cp import numpy as np import cv2 def cv2cpmat cv2cudagpumat cpndarray class cudaarrayinterface def initself gpumat cv2cudagpumat w h gpumatsize typemap cv2cv8u u1 cv2cv8s i1 cv2cv16u u2 cv2cv16s i2 cv2cv32s i4 cv2cv32f f4 cv2cv64f f8 cv2cv16f f2 version 3 shape h w gpumatchannels if gpumatchannels 1 else h w typestr typemapgpumatdepth descr typemapgpumatdepth stream 1 strides gpumatstep gpumatelemsize gpumatelemsize1 if gpumatchannels 1 else gpumatstep gpumatelemsize data gpumatcudaptr false arr return arr def cp2cvarr cpndarray cv2cudagpumat assert lenarrshape in 2 3 cupy array must have 2 or 3 dimensions to be a valid gpumat typemap cpdtypeuint8 cv2cv8u cpdtypeint8 cv2cv8s cpdtypeuint16 cv2cv16u cpdtypeint16 cv2cv16s cpdtypeint32 cv2cv32s cpdtypefloat32 cv2cv32f cpdtypefloat64 cv2cv64f cpdtypefloat16 cv2cv16f depth typemapgetarrdtype assert depth is not none unsupported cupy array dtype channels 1 if lenarrshape 2 else arrshape2 mattype cv2cvmaketypedepth channels mat mattype return mat cpa cprandomrandint1 5 2 2astypenpfloat16 printoriginal cupy array and pointer printcpa print cva cp2cvcpa npa cvadownload print printgpumat initialized and downloaded to numpy and pointer printnpa cvacudaptr printfassert gpumat type is float16 cvatype cv2cv16fc1 printnumpy dtype npadtype print cpa2 cv2cpcva printback to cupy from gpumat value and pointer printcpa2 print printnow try to upload a float16 numpy array to gpumat npa nprandomrandint1 5 2 2astypenpfloat16 cva cv2cudagpumat cvauploadnpa issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDNN: fix potential bug, stride should not be set as 0.\npull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n No rule to make target 'cublas', needed by 'lib/libopencv_sfm.so.4.5.2'.\nsystem information i use ubuntu 2004 i have cuda 112 i have cudnn version 810 detailed description im trying to install opencv 452 with cuda 112 and cudnn 810 but im having a problem with that and its as follows aienv make j20 detected processor x8664 looking for ccache not found found zlib found suitable version 1211 minimum required is 123 cleaning internal cached variable webplibrary cleaning internal cached variable webpincludedir could not find openjpeg minimal suitable version 20 recommended version 231 openjpeg will be built from sources openjpeg version 240 build opencv452openjp2240 openjpeg libraries will be built from sources libopenjp2 version 240 found zlib found version 1211 found openexr found tbb cmake found intel ipp icv version 202000 202000 gold at found intel ipp integration wrappers sources 202000 at cuda detected 112 cuda using cudaarchbin86 cuda nvcc target flags lapackatlas lapacklibraries lapackatlas support is enabled could not find jni missing javaincludepath javaincludepath2 awt vtk is not found please set dvtkdir in cmake to vtk build directory or to vtk install subdirectory with vtkconfigcmake file opencv python during development append to pythonpath caffe no protobuf no glog yes freetype2 yes ver 23117 harfbuzz yes ver 264 hdf5 c compiler wrapper is unable to compile a minimal hdf5 program julia not found not compiling julia bindings module opencvovis disabled because ogre3d was not found found amd headers in found amd library found camd headers in found camd library found ccolamd headers in found ccolamd library found cholmod headers in found cholmod library found colamd headers in found colamd library found spqr headers in found spqr library found config headers in found config library found intel thread building blocks tbb library 20201 11101 include location assuming suitesparseqr was compiled with tbb adding librt to suitesparseconfig libraries required on linux unix not osx if suitesparse is compiled with timing could not find metis missing metisincludedir metislibrary tesseract yes ver 411 allocator metrics storage type long long hdf5 c compiler wrapper is unable to compile a minimal hdf5 program registering hook found amd headers in found amd library found camd headers in found camd library found ccolamd headers in found ccolamd library found cholmod headers in found cholmod library found colamd headers in found colamd library found spqr headers in found spqr library found config headers in found config library found intel thread building blocks tbb library 20201 11101 include location assuming suitesparseqr was compiled with tbb adding librt to suitesparseconfig libraries required on linux unix not osx if suitesparse is compiled with timing could not find metis missing metisincludedir metislibrary building with nvidia optical flow api 20 general configuration for opencv 452 version control unknown extra modules location extra version control extra unknown platform timestamp 20230521t122147z host linux 515072generic x8664 cmake 3260 cmake generator unix makefiles cmake build tool usrbinmake configuration release cpuhw features baseline sse sse2 sse3 requested sse3 dispatched code generation sse41 sse42 fp16 avx avx2 avx512skx requested sse41 sse42 avx fp16 avx2 avx512skx sse41 17 files ssse3 sse41 sse42 2 files ssse3 sse41 popcnt sse42 fp16 1 files ssse3 sse41 popcnt sse42 fp16 avx avx 5 files ssse3 sse41 popcnt sse42 avx avx2 31 files ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 avx512skx 7 files ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 avx512f avx512common avx512skx cc built as dynamic libs yes c standard 11 c compiler usrbinc ver 940 c flags release fsignedchar ffastmath w wall werrorreturntype werrornonvirtualdtor werroraddress werrorsequencepoint wformat werrorformatsecurity wmissingdeclarations wundef winitself wpointerarith wshadow wsignpromo wuninitialized wsuggestoverride wnocomment wnostrictoverflow wnolonglong pthread fomitframepointer ffunctionsections fdatasections msse msse2 msse3 fvisibilityhidden o3 dndebug dndebug c flags debug fsignedchar ffastmath w wall werrorreturntype werrornonvirtualdtor werroraddress werrorsequencepoint wformat werrorformatsecurity wmissingdeclarations wundef winitself wpointerarith wshadow wsignpromo wuninitialized wsuggestoverride wnocomment wnostrictoverflow wnolonglong pthread fomitframepointer ffunctionsections fdatasections msse msse2 msse3 fvisibilityhidden g o0 ddebug ddebug c compiler usrbincc c flags release fsignedchar ffastmath w wall werrorreturntype werroraddress werrorsequencepoint wformat werrorformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wuninitialized wnocomment wnostrictoverflow wnolonglong pthread fomitframepointer ffunctionsections fdatasections msse msse2 msse3 fvisibilityhidden o3 dndebug dndebug c flags debug fsignedchar ffastmath w wall werrorreturntype werroraddress werrorsequencepoint wformat werrorformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wuninitialized wnocomment wnostrictoverflow wnolonglong pthread fomitframepointer ffunctionsections fdatasections msse msse2 msse3 fvisibilityhidden g o0 ddebug ddebug linker flags release wlgcsections wlasneeded linker flags debug wlgcsections wlasneeded ccache no precompiled headers no extra dependencies m pthread cudartstatic dl rt nppc nppial nppicc nppidei nppif nppig nppim nppist nppisu nppitc npps cublas cudnn cufft lusrlibx8664linuxgnu 3rdparty dependencies opencv modules to be built alphamat aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnnobjdetect dnnsuperres dpm face features2d flann freetype fuzzy gapi hdf hfs highgui imghash imgcodecs imgproc intensitytransform linedescriptor mcc ml objdetect optflow phaseunwrapping photo plot python2 quality rapid reg rgbd saliency sfm shape stereo stitching structuredlight superres surfacematching text tracking ts video videoio videostab wechatqrcode xfeatures2d ximgproc xobjdetect xphoto disabled cudacodec world disabled by dependency unavailable cnn3dobj cvv java julia matlab ovis python3 viz applications tests perftests apps documentation no nonfree algorithms yes gui gtk yes ver 32420 gthread yes ver 2646 gtkglext no opengl support no vtk support no media io zlib ver 1211 jpeg ver 80 webp build ver encoder 0x020f png ver 1637 tiff ver 42 410 jpeg 2000 build ver 240 openexr ver 23 hdr yes sunraster yes pxm yes pfm yes video io dc1394 yes 225 ffmpeg yes avcodec yes 5854100 avformat yes 5829100 avutil yes 5631100 swscale yes 55100 avresample yes 400 gstreamer yes 1163 v4lv4l2 yes linuxvideodev2h parallel framework tbb ver 20201 interface 11101 trace yes with intel itt other thirdparty libraries intel ipp 202000 gold 202000 at intel ipp iw sources 202000 at va yes lapack yes eigen yes ver 337 custom hal no protobuf build 351 nvidia cuda yes ver 112 cufft cublas fastmath nvidia gpu arch 86 nvidia ptx archs cudnn yes ver 810 opencl yes intelva include path link libraries dynamic load python 2 interpreter usrbinpython27 ver 2718 libraries ver 2718 numpy ver 1165 install path python for build usrbinpython27 java ant no jni no java wrappers no java tests no install to usrlocal configuring done 32s generating done 09s build files have been written to 0 built target genpkgconfig 0 built target opencvvideoioplugins 0 built target ittnotify 0 built target quirc 0 built target 0 built target numeric 1 built target ippiw 2 built target libopenjp2 2 built target ade 3 built target opencvcudev 3 building cxx object 3 building cxx object 8 built target libwebp 11 built target libprotobuf 15 built target opencvcore 15 built target opencvhdf 15 built target opencvversion 15 built target opencvflann 15 built target 16 built target opencvml 18 built target opencvcudaarithm 22 built target opencvimgproc 22 built target opencvplot 22 built target 22 built target opencvfreetype 22 built target opencvquality 22 built target 22 built target opencvfuzzy 22 built target opencvimghash 22 built target opencvcudawarping 22 built target opencvalphamat 23 built target opencvhfs 24 built target opencvreg 26 built target opencvcudafilters 27 built target opencvimgcodecs 29 built target opencvfeatures2d 29 built target opencvlinedescriptor 29 built target opencvcudafeatures2d 29 built target opencvsaliency 29 built target opencvvideoio 30 built target opencvcudaimgproc 30 built target opencvhighgui 31 built target opencvannotation 31 built target opencvvisualisation 32 built target opencvphoto 33 built target opencvts 34 built target opencvbioinspired 35 built target opencvxphoto 35 built target 35 built target 36 built target 36 built target opencvtesthdf 36 built target opencvtestflann 37 built target opencvtestreg 37 built target opencvperfreg 37 built target opencvperfcudaarithm 39 built target opencvcalib3d 39 built target opencvtestquality 39 built target 39 built target 39 built target opencvtestcudaarithm 39 built target opencvperfimgcodecs 39 built target 40 built target opencvtestfuzzy 40 built target opencvperffeatures2d 41 built target opencvtestml 41 built target opencvtestimghash 42 built target 42 built target 42 built target 42 built target 43 built target opencvtestimgcodecs 43 built target opencvtestsaliency 43 built target opencvperfphoto 48 built target opencvdnn 48 built target opencvperfvideoio 49 built target opencvtestcudev 49 built target 49 built target opencvperfxphoto 49 built target 49 built target opencvtesthighgui 49 built target opencvrapid 49 built target opencvtestphoto 50 built target opencvtestfeatures2d 50 built target opencvperfcalib3d 50 built target opencvtestxphoto 50 built target 50 built target opencvtestvideoio 50 built target 50 built target opencvcudastereo 50 built target 50 built target opencvdnnobjdetect 50 built target 50 built target opencvaruco 52 built target opencvperfcore 52 built target opencvccalib 52 built target opencvshape 52 built target opencvobjdetect 52 built target opencvdnnsuperres 54 built target opencvperfimgproc 54 built target opencvperfcudastereo 54 built target opencvtestrapid 54 built target opencvtestcudastereo 55 built target opencvtext 55 built target 56 built target opencvperfdnn 57 built target 57 built target opencvtestaruco 57 built target 57 built target 57 built target opencvtestshape 57 built target opencvtestobjdetect 57 built target opencvperfobjdetect 57 built target opencvxobjdetect 58 built target opencvmcc 58 built target opencvtesttext 59 built target opencvdpm 60 built target opencvtestdnn 60 built target 60 built target opencvtestmcc 62 built target opencvtestcalib3d 64 built target opencvvideo 64 built target opencvrgbd 64 built target opencvface 64 built target opencvbgsegm 66 built target opencvwechatqrcode 66 built target opencvcudabgsegm 67 built target opencvperfrgbd 68 built target opencvdatasets 70 built target opencvtestcore 70 built target opencvtestbgsegm 70 built target 71 built target opencvtestrgbd 71 built target opencvtestface 73 built target opencvxfeatures2d 73 built target opencvtestvideo 74 built target opencvperfvideo 74 built target opencvperfcudabgsegm 74 built target opencvtestcudabgsegm 75 built target opencvcudalegacy 77 built target opencvtestimgproc 77 built target opencvcudaobjdetect 77 built target opencvperfcudalegacy 77 built target 77 built target 77 built target 78 built target 79 built target opencvstitching 80 built target opencvtestcudalegacy 81 built target opencvtracking 81 built target opencvperftracking 81 built target opencvstereo 81 built target opencvperfstitching 81 built target opencvtesttracking 81 built target opencvteststitching 81 built target opencvperfstereo 81 built target opencvteststereo 82 built target opencvximgproc 85 built target opencvgapi 87 built target opencvperfximgproc 87 built target opencvoptflow 87 built target opencvperfoptflow 88 built target opencvtestoptflow 89 built target opencvcudaoptflow 90 built target opencvtestximgproc 91 built target opencvperfgapi 91 built target 91 built target 91 linking cxx shared library 91 linking cxx shared library 94 built target opencvtestgapi 95 built target opencvsuperres 96 built target opencvvideostab 96 building cxx object 96 building cxx object 96 building cxx object 96 building cxx object 96 building cxx object 96 building cxx object 96 building cxx object 96 linking cxx executable 96 built target opencvtestsuperres 96 linking cxx executable 96 built target opencvtestvideostab 96 linking cxx executable 96 built target opencvperfsuperres 96 linking cxx static library liblibmultiviewa 96 built target multiview 96 built target correspondence 96 building cxx object 96 building cxx object 96 building cxx object 97 linking cxx static library 97 built target simplepipeline make2 no rule to make target cublas needed by liblibopencvsfmso452 stop make1 error 2 make makefile166 all error 2 thanks for the help in advance steps to reproduce none issue submission checklist i report the issue its not a question i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBuild fix for AVX 256\nzihaomu our ci environment started failing after you merged this commit in function void cvdnnpackdata8char float int int int const int int int int error convnr was not declared in this scope did you mean conv3d 448 vxstoreinpbufcfp32 kconvnr vxloadinptrinc k1 conv3d pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBuild issue: test_qrcode_encode.cpp and usage of std::random_shuffle\nsystem information c user building from source requires building all the tests and uses the function stdrandomshuffle to generate the input info however this function is no longer in std since c17 detailed description c user building from source requires building all the tests and uses the function stdrandomshuffle to generate the input info however this function is no longer in std since c17 my solution as for now is to just comment all the code however it should be able to build with all versions of c a solution would be replacing it with stdshuffle steps to reproduce build with c std 17 issue submission checklist x i report the issue its not a question i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd assert to check if layer input size is not empty\ncheck if tf model layer input is not empty pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFix even input dimensions for INTER_NEAREST_EXACT\npull request readiness checklist resolves related cc yosshi999 see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFixed mask handling in AffineFeature\naddress pull request readiness checklist see details at i agree to contribute to the project under apache 2 license to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFixes pixel info color font for dark Qt themes\nfor dark qt themes it is hard to read the pixel color information on the bottom left like the coordinates or rgb values this pr proposes a way on how the dynamically sets the font colors based on the systems theme original example original with patch image for windows nothing is changed tested on a windows 11 system because the font color is 000000 when using the default qt theme pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnused variable in frameprocessor.cpp\nsystem information opencv 4x detailed description in rejected is unused variable steps to reproduce read source code issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWrong version for OpenCV 4.7.0 in the releases website for iOS\nsystem information doesnt apply detailed description the downloaded version for ios ios pack in for the 470 seems to download the opencv version 3419 steps to reproduce download the 470 for ios issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpenCV 4.7.0 much slower than 4.6.0 for Java Apps\nsystem information performance comparisons are between opencv 470 slow and 460 faster 450 runs essentially same faster speed as 460 all runs use windows 10 hp elitebook laptop my test app the mre built with java compiler openjdk version 1705 20221018 openjdk runtime environment temurin17058 build 17058 openjdk 64bit server vm temurin17058 build 17058 mixed mode sharing essentially identical results running test on two java runtime versions java version 12 20190319 javatm se runtime environment build 1233 java hotspottm 64bit server vm build 1233 mixed mode sharing and openjdk version 1705 20221018 openjdk runtime environment temurin17058 build 17058 openjdk 64bit server vm temurin17058 build 17058 mixed mode sharing detailed description opencv 470 is much slower than 460 or 450 for the test run as shown using imread in the test mre for a variety of other methods in another app summarized below and for other java apps using opencv mre run times opencv 460 seconds 2000 imread elapsed time 3339 total cpu time 2984375 user cpu 20625 mre run times opencv 470 seconds 2000 imread elapsed time 6915 total cpu time 640625 user cpu 5640625 the mre test case scales correctly as expected 2000 iterations takes twice as long as 1000 iterations mre run times opencv 460 with imread commented out are nearly zero seconds 2000 imread elapsed time 0014 total cpu time 00 user cpu 0015625 instrumenting a complete app showed similar performance differences for most opencv java methods 450 and 460 as are essentially identical in performance versionmilliseconds 450 470 imread 69943 173004 convert 9054 324540 resize 2090 44447 blur 0 0 split 78 120 normalize 21 648 equalize 25 77 resize 14 22 adaptive threshold 14 64 steps to reproduce a mre app with the single method imread was written to demonstrate the slow performance it is attached and includes generating its own test file to read and it displays the opencv version build information for both versions which is included as comments in the file appjavatxt issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nThe `matchTemplate` function changes the data of the `mask`.\nsystem information opencv version 470 operating system platform windows 10 compiler compiler version visual studio 2019 detailed description when the matchtemplate function is used with a mask the data of the mask changes and it is no longer usable mask is an inputarray and should not change it should be read only steps to reproduce c mat src mat1 1 cv8uc1 scalar255 mat templ mat1 1 cv8uc1 scalar255 mat mask1 mat1 1 cv8uc1 scalar255 printfbefore dn mask1at0 0 mat res matchtemplatesrc templ res mask1 printfafter dn mask1at0 0 output before 255 after 1 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nLosing last mat row and column during `remap()` with `BORDER_TRANSPARENT`\nsystem information opencv python version 470 operating system platform windows 11 python revision 3108 detailed description edit unquoted relevant part of my question hi first off thanks for the great work you guys are doing ill try and break this down with the attached python snippet the docs say when it means that the pixels in the destination image that corresponds to the outliers in the source image are not modified by the function and sadly i cannot seem to find much more on this anywhere so i may be using it wrong in that case apologies for creating this issue but my understanding is that in the example code this should lead to pixels in the destination staying black when trying to map to a pixel in the source that doesnt exist eg 20 however in the example all pixels in the mapping mats exist in the source but still the last row and column in the destination always remain 0 when using bordertransparent it works as expected with borderconstant borderconstant grafik bordertransparent grafik steps to reproduce python bgimage npzeros8 12 1 dtypenpfloat32 source nparray01 02 03 05 06 07 09 10 09 3 1 imagesize bgimageshape1 bgimageshape0 map1 nparray0 1 2 0 1 2 0 1 2 dtypenpfloat32 map2 nparray0 0 0 1 1 1 2 2 2 dtypenpfloat32 destination npzeros3 3 1 dtypenpfloat32 cv2remapsource map1 map2 dstdestination result bgimagecopy result223 223 destination upscaledimage cv2resizeresult nparray1200 800 cv2imshowtest upscaledimage cv2waitkey0 cv2destroyallwindows issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSegfault at countNonZero8u on RISC-V with RVV 0.7.1\nsystem information opencv version operating system platform sipeed lichee rv dock allwinner d1 cpu compiler compiler version detailed description 0 0x0000003ff7d146ae in vsetvle64m1 a516770465071103 at 1 vmvvxu64m1 vl2225411534743296 a2199023256079104 at 2 a at 3 0x0000003ff7d15ae8 in src0x3ff65e8040 377 len2073600 at type for more q to quit c to continue without paging 4 0x0000003ff7d1655c in cvcountnonzero src at steps to reproduce build options bash driscvrvvscalableoff dcpubaselinervv build summary general configuration for opencv 470dev version control 470261g6dbc5e032f platform timestamp 20230428t073256z host linux x8664 target linux 1 riscv64 cmake 3242 cmake generator unix makefiles cmake build tool usrbinmake configuration debug cpuhw features baseline rvv cc built as dynamic libs yes c standard 11 c compiler ver 1020 c flags release marchrv64gc fsignedchar w wall wreturntype wnonvirtualdtor waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wundef winitself wpointerarith wshadow wsignpromo wuninitialized wsuggestoverride wnocomment wnostrictoverflow pthread fomitframepointer ffunctionsections fdatasections marchrv64gcv0p7 fvisibilityhidden o3 dndebug dndebug c flags debug marchrv64gc fsignedchar w wall wreturntype wnonvirtualdtor waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wundef winitself wpointerarith wshadow wsignpromo wuninitialized wsuggestoverride wnocomment wnostrictoverflow pthread fomitframepointer ffunctionsections fdatasections marchrv64gcv0p7 fvisibilityhidden g o0 ddebug ddebug c compiler c flags release marchrv64gc fsignedchar w wall wreturntype waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wuninitialized wnocomment wnostrictoverflow pthread fomitframepointer ffunctionsections fdatasections marchrv64gcv0p7 fvisibilityhidden o3 dndebug dndebug c flags debug marchrv64gc fsignedchar w wall wreturntype waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wuninitialized wnocomment wnostrictoverflow pthread fomitframepointer ffunctionsections fdatasections marchrv64gcv0p7 fvisibilityhidden g o0 ddebug ddebug linker flags release wlgcsections wlasneeded wlnoundefined linker flags debug wlgcsections wlasneeded wlnoundefined ccache yes precompiled headers no extra dependencies dl m pthread rt 3rdparty dependencies opencv modules to be built core dnn highgui imgcodecs imgproc ts videoio disabled world disabled by dependency calib3d features2d flann jsbindingsgenerator ml objdetect photo pythontests stitching video unavailable gapi java python2 python3 applications tests documentation no nonfree algorithms no gui none gtk no media io zlib zlib ver 1213 jpeg libjpegturbo ver 21362 png build ver 1637 jpeg 2000 build ver 240 hdr yes sunraster yes pxm yes pfm yes video io dc1394 no gstreamer no v4lv4l2 yes linuxvideodev2h parallel framework pthreads trace yes builtin other thirdparty libraries lapack no custom hal no protobuf build 3191 flatbuffers builtin3rdparty 23121 python for build usrbinpython27 install to cpp mat src01080 1920 cv8uc1 mat src11080 1920 cv8uc1 randusrc0 0 256 randusrc1 0 256 countnonzerosrc0 src1 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNary Elementwise Broadcast Failure Cases\ni wrote a brute force test to test elementwise which cases will be wrong here is the test report reportmd im not sure if i should put this brute force test into testlayercpp because it will test about 3844 times for each backend and it cant detect case which is fallback from gpu to cpu unless we add something to record this situation steps to reproduce 1 if you want to test on cuda modify file naryeltwiselayercpp change all return ptr to throw and it will be detected when fallback to cpu 2 build opencv with cuda and in release mode 3 use code here to generate this report cpp config stdvector backendtargetlist dnnbackendopencv dnntargetcpu dnnbackendcuda dnntargetcuda stdvector dimslist 1 2 3 4 5 struct util give n to generate all nd arrays with 0 or 1 static void getallarrstdvector arr int n int total 1 n arrassigntotal stdvectorn 1 forint i 0 i total i forint j 0 j n j arrij i n j 1 1 zero will replace all 0 one will replace all 1 static void replacestdvector arr int zero int one forint i 0 i arrsize i forint j 0 j arr0size j arrij arrij one zero test if the shape can be forwarded static int testbcastconst stdvector ashape const stdvector bshape const string op const stdpair backendtarget mat a matzerosint ashapesize ashapedata cv32fc1 mat b matonesint bshapesize bshapedata cv32fc1 net net layerparams lp lptype naryeltwise lpname testlayer lpsetoperation op int id lptype lp netconnect0 1 id 1 stdvector inpnames2 inpnames0 a inpnames1 b netsetinputa inpnames0 netsetinputb inpnames1 try mat re netforward auto ptrre float redata check if result is right forint i 0 i retotal i ifop sum ptrrei 1 return 2 sum result is wrong return 1 all right catchstdlogicerror e ifstdstring ewhat fallback return 3 fallback to cpu else return 1 other error catch return 1 runtime error static void printresultint type const stdvector shp1 const stdvector shp2 stdstring errorcontent switchtype case 1 return case 1 errorcontent runtime error break case 2 errorcontent result wrong break case 3 errorcontent fallback to cpu break default errorcontent break stdcout tostringshp1 op tostringshp2 fail reason is errorcontent stdendl stdvector dimshapelist stdvector subshapelist stdcout nary elementwise broadcast failure cases stdendl forauto backendtarget backendtargetlist stdcout backendid backendtargetfirst targetid backendtargetsecond stdendl for int dim dimslist stdcout dimension dim stdendl dimshapelistbegin dimshapelistend dim 1 3 same shape stdcout same shape stdendl for int i 0 i dimshapelistsize i for int j 0 j dimshapelistsize j dimshapelistj sum backendtarget dimshapelisti dimshapelistj diff shape stdcout different shape stdendl for const auto shp1 dimshapelist for const auto shp2 subshapelist shp2 sum backendtarget shp1 shp2 diff shape for const auto shp1 subshapelist for const auto shp2 dimshapelist shp2 sum backendtarget shp1 shp2 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrotatedRectangleIntersection does not return all intersection points as expected\nsystem information opencv python version 470 operating system platform windows 10 python version 31010 detailed description during some testing of a system that used and then contourarea to get the intersection area of 2 overlapping rectangles we got a size of 3500mm² instead of the expected 7000mm² it seems to be related to the fact that one edge of each rectangle are on the same line rectangle 1 28028737007069833 extent5650 1400 rectangle 2 27042527355719545 extent2750 500 this seems related to 21659 which should be fixed by 21677 but i havent tested that as it hasnt been released steps to reproduce py import cv2 as cv res points 8246421183672817 28028737007069833 5650 1400 17780506896972656 5673310438828003 27042527355719545 2750 500 9219493103027344 assert res 1 assert points is not none points pointsreshape1 2 area cvcontourareapoints printarea expected 7000 got 3500 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDNN/CUDA: make 'abcd op 1b11' broadcast eltwise operator support cuda\nthis pr will fix 23278 current implement is a temp impl i will try to make more eltwise broadcast cases support cuda the inference time of model is from 267651 ms to 178416 ms perftest result run this script to generate result shell binopencvperfdnnexe perfthreads1 use this script to generate summary shell python m min 1thxml 0thxml o markdown result name of test0th1th1th vs 0th xfactor fallback to cpu17936217 layer by layer data before being fixed shell 01515ms 00193ms 00145ms 00121ms resnet180preluneg0 00167ms 2071ms 00585ms 01643ms 00166ms 01179ms 00192ms 00114ms 00095ms 40522ms 00857ms 01803ms 0013ms 00533ms 00145ms 00116ms 00093ms 2346ms 00483ms 00748ms 01015ms 00135ms 00639ms 00161ms 00137ms 00133ms 00177ms 27318ms 00643ms 01083ms 00139ms 00496ms 00147ms 00115ms 00096ms 179ms 0045ms 00701ms 00776ms 0016ms 00479ms 00159ms 00135ms 00121ms 00173ms 21251ms 0043ms 00793ms 0012ms 00458ms 00133ms 00106ms 00091ms 17766ms 0043ms 00751ms 00758ms 00153ms 0048ms 00151ms 0013ms 0012ms 00176ms 21163ms 00396ms 00751ms 00121ms 00485ms 00158ms 0013ms 00121ms 20351ms 0037ms 0072ms 00142ms 00169ms 00014ms 00445ms 00165ms 00156ms embedding 0001ms after being fixed shell 0255ms 00309ms 00181ms 00147ms resnet180preluneg0 00539ms 00276ms 0018ms 01718ms 00215ms 01762ms 00201ms 00156ms 00142ms 00199ms 00478ms 01198ms 00139ms 02334ms 00244ms 00238ms 00196ms 00256ms 00204ms 01101ms 01641ms 00296ms 00867ms 00253ms 00223ms 00208ms 00337ms 00334ms 00306ms 01605ms 00266ms 00904ms 00712ms 00305ms 00237ms 00299ms 00257ms 01648ms 0147ms 00269ms 00805ms 00274ms 00214ms 00969ms 003ms 00272ms 00247ms 01316ms 00241ms 00792ms 00259ms 00213ms 00962ms 00633ms 00246ms 01131ms 01028ms 00273ms 00834ms 0031ms 01031ms 00858ms 0032ms 00333ms 00229ms 01609ms 00336ms 00869ms 00314ms 00235ms 00236ms 00368ms 00234ms 01913ms 00269ms 00234ms 00016ms 01472ms 00635ms 00692ms embedding 00019ms pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpenCV(4.5.5) Error: Gpu API call (CUDA_ERROR_FILE_NOT_FOUND [Code = 301]\nsystem information opencv455 opencvcontrib455 videocodecsdk1115 cmake 3231 win 10 detailed description hello i followed the online tutorial to compile opencv hard decoding i will first attempt to open a local mp4 file for hard decoding testing which can be run through when i switch to realtime video rtsprtmp the following issues will occur opencv455 error gpu api call code 301 in file line 66 steps to reproduce local mp4 video is ok stdstring fname stdcout gpu个数为 stdendl cvcudagpumat dframe error cvptr dreader issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSolve the \"Unrecognized selector\" issue in Objective-C/Swift binding\nsystem information opencv version 4x latest operating system platform macos any detailed description as originally reported in there is a frequently occurring problem when trying to use the mat touiimage method and other similar methods the unrecognized selector sent to instance error can be worked round by modifying the other linker flags but its a pain to always have to do this other functionality like debug quicklook also requires these flags to be set in order to work correctly and there is no hint in the ui to indicate that this is the case to solve the problem we need to move the functionality added to mat using categories in matconverters and matquicklook directly into the mat implemenation steps to reproduce refer to issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError in `generation_onnx_models.py` onnx test data generation script. \nsystem information hi running python generateonnxmodelspy inside to generate new test models and data results in error it seem that postprocessmodel function is not located in wrong place opencv python version 3810 operating system platform ubuntu 2004 focal python version 3810 detailed description python diagnostic run torchonnxexport version 200cpu verbose false log level levelerror 0 none 0 note 0 warning 0 error sliceopset11steps2d input has sizes torchsize6 6 sliceopset11steps2d output has sizes torchsize2 2 diagnostic run torchonnxexport version 200cpu verbose false log level levelerror 0 none 0 note 0 warning 0 error traceback most recent call last file generateonnxmodelspy line 530 in height width nameerror name postprocessmodel is not defined steps to reproduce running python generateonnxmodelspy inside to generate new test models and data results in error issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFix aruco module CORNER_REFINE_CONTOUR parameter gets skipped\npull request readiness checklist hi aleksandrpanov the aruco module is using the wrong variable to check whether it should perform corner refinement the previous buggy version of code since opencv 47 is using the candidates supplied in the function argument from user instead of the candidates returned from identifycandidates our current workaround is always to run the detectmarkers twice so the second time will use the ids returned from the first run however that workaround is not optimal and greatly hurt the performance could you please take a look and get this merged thanks see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDNN: support the split node of onnx opset >= 13\nmerge with test case the attribute of split in split layer has been moved from attribute to input related link the purpose of this pr is to support the split with input type pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "bug"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUsing the Java version of opencv, the camera encountered a memory overflow issue while iteratively fetching images \nsystem information opencv python version 48 operating system platform windows 11 java version 47 detailed description exception in thread main javalangexception stdexception bad allocation at method at at steps to reproduce when i loop through the code below from the camera there will be a memory overflow bug matofbyte mob new matofbyte imencodejpg mat mob byte array mobtoarray issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nERROR COMPILING OPENCV WITH CUDA at 99%, PLEASE HELP \nsystem information i put the following 2 commands to compile opencv with cuda wget o opencvzip wget o opencvcontribzip unzip opencvzip unzip opencvcontribzip mv opencvcontrib480 opencvcontrib cd opencv480build and cmake d d withcudaon d opencvdnncudaon d cudaarchbin75 d d d d buildopencvjavaoff d d withtbbon d enablefastmath1 d cudafastmath1 d withcublas1 d d withcudnnon d cudnnversion895 d withv4lon d withqton d withopenglon d withgstreameron d d d d d d d d installcexamplesoff d buildexamplesoff … and at 99 i had the next error error conversion from ‘cvcudastream’ to nonscalar type ‘cvptrcvcudastream’ requested 39041 ptrcvcudastream streamcudastreamnull my cuda version is 122 my ubuntu version is 2204 my cudnn is 875 and opencv is 48 thanks in advance for help detailed description i put the following 2 commands to compile opencv with cuda wget o opencvzip wget o opencvcontribzip unzip opencvzip unzip opencvcontribzip mv opencvcontrib480 opencvcontrib cd opencv480build and cmake d d withcudaon d opencvdnncudaon d cudaarchbin75 d d d d buildopencvjavaoff d d withtbbon d enablefastmath1 d cudafastmath1 d withcublas1 d d withcudnnon d cudnnversion895 d withv4lon d withqton d withopenglon d withgstreameron d d d d d d d d installcexamplesoff d buildexamplesoff … and at 99 i had the next error error conversion from ‘cvcudastream’ to nonscalar type ‘cvptrcvcudastream’ requested 39041 ptrcvcudastream streamcudastreamnull my cuda version is 122 my ubuntu version is 2204 my cudnn is 875 and opencv is 48 thanks in advance for help steps to reproduce i put the following 2 commands to compile opencv with cuda wget o opencvzip wget o opencvcontribzip unzip opencvzip unzip opencvcontribzip mv opencvcontrib480 opencvcontrib cd opencv480build and cmake d d withcudaon d opencvdnncudaon d cudaarchbin75 d d d d buildopencvjavaoff d d withtbbon d enablefastmath1 d cudafastmath1 d withcublas1 d d withcudnnon d cudnnversion895 d withv4lon d withqton d withopenglon d withgstreameron d d d d d d d d installcexamplesoff d buildexamplesoff … and at 99 i had the next error error conversion from ‘cvcudastream’ to nonscalar type ‘cvptrcvcudastream’ requested 39041 ptrcvcudastream streamcudastreamnull my cuda version is 122 my ubuntu version is 2204 my cudnn is 875 and opencv is 48 thanks in advance for help issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCan not set camera to 4k resolution \nsystem information opencv python version 480 operating system platform ubuntu 2004 python version 3817 camera model dell ultrasharp wb7022 detailed description i can not set the camera resolution to 4k with the normal method import cv2 cap cv2videocapture0 printcapisopened capset33840 capset42160 ret frame capread cv2imshowdisplay frame printframeshape if cv2waitkey0 0xff ordq exit0 this prints true 1080 1920 3 the same code works on windows and the cap is successfully set to 4k this is the output of v4l2ctl d0 listformatsext ioctl vidiocenumfmt type video capture 0 yuyv yuyv 422 size discrete 640x480 interval discrete 0033s 30000 fps size discrete 640x360 interval discrete 0033s 30000 fps size discrete 1280x720 interval discrete 0042s 24000 fps interval discrete 0033s 30000 fps size discrete 1920x1080 interval discrete 0042s 24000 fps interval discrete 0033s 30000 fps 1 mjpg motionjpeg compressed size discrete 640x480 interval discrete 0033s 30000 fps size discrete 1280x720 interval discrete 0042s 24000 fps interval discrete 0033s 30000 fps interval discrete 0017s 60000 fps size discrete 1920x1080 interval discrete 0042s 24000 fps interval discrete 0033s 30000 fps interval discrete 0017s 60000 fps size discrete 2560x1440 interval discrete 0042s 24000 fps interval discrete 0033s 30000 fps size discrete 3840x2160 interval discrete 0042s 24000 fps interval discrete 0033s 30000 fps 2 nv12 ycbcr 420 size discrete 640x480 interval discrete 0033s 30000 fps size discrete 640x360 interval discrete 0033s 30000 fps size discrete 1280x720 interval discrete 0033s 30000 fps size discrete 1920x1080 interval discrete 0033s 30000 fps i have tried this line cap cv2videocapture0 cv2capopencvmjpeg but i get this error warn00012 global capcpp342 open videoiocvmjpeg backend is generally available but cant be used to capture by index false traceback most recent call last file testopencamerapy line 14 in cv2imshowdisplay frame cv2error opencv480 io with software like webcamoid if i set the video format to mjpg then i can get 4k this is not the case with yuyv any help would be greatly appreciated steps to reproduce i dont know if it can be reproduced by other cameras issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCOLOR_RGB2Lab is not reliable for float32 values\nsystem information opencv python version 48074 operating system platform win11 python version 311 x64 detailed description the convert color function does not convert all rgbvalues to the correct corresponding labvalues if the rgb values are of type float32 steps to reproduce import numpy as np import cv2 as cv cvcolorrgb2lab printlabcolorcv output is 100 0 0 should be 6034288976 9817767091 6079175629 any value from 1 to 254 for the green value in rgb will lead to the wrong output of 100 0 0 while 2550255 and 255255255 are correct issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCross compiling ARM64 in Windows x86_64 fails\nsystem information opencv version 470 os windows 11 compiler version as reported by cmake building for visual studio 17 2022 the c compiler identification is msvc 1937328220 the cxx compiler identification is msvc 1937328220 detailed description im trying to crosscompile achieve arm64 binaries on a x64 windows 11 desktop i create the developer shell for windows visual c compilation and linking like this k cprogram filesmicrosoft visual archarm64 hostarchamd64 here is my bat script to run cmake and to compile link setting the cl env variable makes no difference set cldmarm641 set clarcharmv88 set cl echo echo extra vars for compiler cl echo set studio 17 2022 set dbuildtestsbooloff dbuilddocsbooloff dwithcudabooloff dbuildopencvjavaoff dbuildprotobufoff dbuildopencvdnnoff this is required to find the correct compiler set cmakearchitecturea arm64 cd opencv454 rmdir s build mkdir build cd build cmake cmakearchitecture cmakeoptions cmake cmakeoptions cd cmake build build config release i can see that cmake picks up the correct compiler allright check for working cxx compiler cprogram filesmicrosoft visual skipped finally i get tons of these cprogram filesmicrosoft visual fatal error c11 89 error this header is specific to x86 x64 arm64 and arm64ec targets compiling source file cusersvsriikonenopen j with emphasis on fatal error c1189 error this header is specific to x86 x64 arm64 and arm64ec targets which is stupid since we are indeed compiling for arm64 target origin of the problem is in the header files if definedmix86 definedmx64 definedmarm64 error this header is specific to x86 x64 arm64 and arm64ec targets endif so it seems that marm64 preprocessor directive is lost somewhere on the way indeed i cant find it in any of the cache files produced by cmake steps to reproduce see above issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDoes \"cv::VideoCapture\" have any thread lock?\nsystem information opencv python version 48076 operating system platform macos 14 windows 11 python version 3115 detailed description videocapture multithreading steps to reproduce when i using threadpool python import cv2 import time from concurrentfutures import threadpoolexecutor as poolexecutor def opencapturei capture cv2videocapture begintime timetime captureopen if captureisopened printfopen capture i timetimebegintimes if name main pool poolexecutor10 1 2 poolshutdown open capture 1 5037631034851074s open capture 2 626716685295105s open capture 1 14738409519195557s open capture 2 2794524908065796s open capture 1 13103349208831787s open capture 2 2629105806350708s when i using processpoolthey are opened almost at the same time python import cv2 import time from concurrentfutures import processpoolexecutor as poolexecutor def opencapturei capture cv2videocapture begintime timetime captureopen if captureisopened printfopen capture i timetimebegintimes if name main pool poolexecutor10 1 2 poolshutdown open capture 1 19312078952789307s open capture 2 1913451910018921s open capture 1 15760650634765625s open capture 2 15881609916687012s open capture 1 10843567848205566s open capture 2 1080475091934204s issue submission checklist i report the issue its not a question i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpencv includes not found after build\ndescribe the doc issue hello i built the opencv using cmake now i need to add opencv into my application and call its functions i could not find the includeversionhpp to include in my application header file your input is appreciated fix suggestion hello i have build the opencv using camke now i need to refer opencv in my c application i need to call the opencv functions from my application i could not find the includeversionhpp to include in my application appreciate your input"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCan cv2.VideoCapture  read 4 channel video?\ndescribe the doc issue i want to read 4 channel video using cv2videocapturepath while true ret frame videoread but i find the frame is 3 channel fix suggestion no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n faceRecognizerSF.feature(alingCrop, feature) Always return the same features for different faces\nsystem information opencv version 470 operating system platform win11 orgbytedeco opencv 470159 macosxx8664 windowsx8664 detailed description feature traverse different images to extract features and the returned dataaddr is always the same java mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue mat 1128cv32fc1 isconttrue issubmattrue steps to reproduce reproduction demo java package import import import orgopencvcoremat import orgopencvcorerect import orgopencvcoresize import import import import javaiofile import javautilmap import slf4j public class demo1 private static facedetectoryn facedetectorynimg private static facerecognizersf facerecognizersf private static map features new concurrenthashmap static facedetectorynimg new size320 240 float 09 float 03 5000 facerecognizersf public static void mainstring args initall private static void initall file fs for file file fs mat mat mat feature new mat detectmat feature if featureempty feature else logerrorfilegetname loginfo filegetname feature loginfoall filesfeaturessize fslength featuressize private static mat detectmat mat1 mat feature facerecognizersf mat face new mat mat alingcrop new mat mat maxface null double maxsize 0 try face for int i 0 i facerows i rect rect new rectint facegeti 00 int facegeti 10 int facegeti 20 int facegeti 30 if rectarea maxsize maxface facerowi maxsize rectarea if maxface null maxface alingcrop feature mat1release catch exception e eprintstacktrace finally alingcroprelease facerelease return feature issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nimshow not implemented\nsystem information opencv version 480 also occurs in version 470 operating system windows compiler microsoft visual c v193632535 x86 detailed description my code is in c im using the highgui module include and it seems to me that the imshow function is not implemented compiler error below why am i sure its a bug 1 the function is defined in highguihpp and the error says its unresolved but not undefined that means theres no issue with importing the prototypes 2 a namedwindow call from the same module compiles successfully yes thats after commenting out the imshow call that means theres no issue with importing the implementations heres the full error message error lnk2019 reference to unresolved external symbol void cdecl cvimshowclass stdbasicstringclass stdallocator const class const in function main this issue doesnt occur in opencv 2410 steps to reproduce cpp include include opencv2opencvhpp include using namespace cv int main videocapture capturecapany if captureisopened stdcout cannot open the video stream return 1 namedwindowcamera while true mat frame capture frame imshowcamera frame if waitkey30 0 return 0 this is my first program working with opencv it just shows a video stream from the builtin camera issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nRotate Parameter for putText() function\ndescribe the feature and motivation i am trying to rotate my puttext without rotating the whole frame but it seems like a hard thing to do is it possible to add a new rotate parameter to puttext function tia additional context no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to cite OpenCV?\ndescribe the doc issue i write a paper with opencv and i want to cite opencv in my paper so can i cite opencv in my paper fix suggestion no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOrdering of images in stitcher\ni was performing a 360 degree images stitch operation using sift for feature extraction and brute force matcher for matching i observed that the order of images which i provide does not matter as the output i get is in different order i used following program for stitching stitching detailed questions can i modify the order of images in matching stage so that i get a particular scene in the centre of my panorama do i need to reorder my feature vector before providing it to matcher example 360 degree image can i recenter the “river” to middle output1 additional context no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nerror: 'Mutex' in namespace 'cv' does not name a type AND  error: 'recursive_mutex' in namespace 'std' does not name a type\nsystem information opencv version 470dev host platform os ubuntu 2210 cross compiler used for compilation armnoneeabigcc version used cmakegui for configuring and generation not able to get the command line equivalent of the build command advise me how to get target platform arm cortexr5 cpu am273x high performance r5f cpu mcu from texas instruments trm here is my toolchaincmake file setcmakesystemname generic arm without that flag cmake is not able to pass test compilation check staticlibrary setcmakear setcmakeasmcompiler setcmakeccompiler setcmakecxxcompiler setcmakelinker setcmakeobjcopy cache internal setcmakeranlib cache internal setcmakesize cache internal setcmakestrip cache internal setcmakecflags mcpucortexr5 mthumb mfloatabihard mfpuvfpv3d16 fpic wnopsabi wnodev fshortenums fshortwchar fdatasections ffunctionsections wlgcsections cache internal setcmakecxxflags cmakecflags stdc11 fnopie fnopic wnodev fpermissive dcmakecrosscompiling cache internal specsnosysspecs setcmakecflagsdebug os g cache internal os dndebug cache internal cmakecflagsdebug cache internal cmakecflagsrelease cache internal never only only setcmakesystemname generic arm without that flag cmake is not able to pass test compilation check staticlibrary setcmakear setcmakeasmcompiler setcmakeccompiler setcmakecxxcompiler setcmakelinker setcmakeobjcopy cache internal setcmakeranlib cache internal setcmakesize cache internal setcmakestrip cache internal setcmakecflags mcpucortexr5 mthumb mfloatabihard mfpuvfpv3d16 fpic wnopsabi wnodev fshortenums fshortwchar fdatasections ffunctionsections wlgcsections cache internal setcmakecxxflags cmakecflags stdc11 fnopie fnopic wnodev fpermissive cache internal specsnosysspecs setcmakecflagsdebug os g cache internal os dndebug cache internal cmakecflagsdebug cache internal cmakecflagsrelease cache internal never only only include include setcmakesystemname generic armv7r setcmakeccompiler armnoneeabigcc setcmakecxxcompiler armnoneeabig setcmakeasmcompiler armnoneeabigcc never only only only define the toolchain variables settoolchainprefix setcmakear toolchainprefixar cache filepath archiver setcmakelinker toolchainprefixld cache filepath linker setcmakenm toolchainprefixnm cache filepath name tool setcmakeobjcopy cache filepath object copy tool setcmakeobjdump cache filepath object dump tool setcmakeranlib cache filepath ranlib detailed description once i have configured and generated my project heres my configuration log opencv systemspecific configuration file is not found generic detected processor arm cleaning internal cached variable zliblibrary cleaning internal cached variable zlibincludedir could not find zlib missing zliblibrary zlibincludedir required is at least version 123 could not find openjpeg minimal suitable version 20 recommended version 231 openjpeg will be built from sources openjpeg version 240 build openjpeg libraries will be built from sources libopenjp2 version 240 math lib libm not found floating point support disabled processing world modules module opencvcore module opencvimgproc module opencvfeatures2d module opencvimgcodecs processing world modules done excluding from source files list optimization is disabled excluding from source files list optimization is disabled excluding from source files list optimization is disabled excluding from source files list optimization is disabled excluding from source files list optimization is disabled excluding from source files list optimization is disabled excluding from source files list optimization is disabled excluding from source files list optimization is disabled general configuration for opencv 470dev version control 47098g0052d46b8e platform timestamp 20230530t140909z host linux 519021generic x8664 target generic arm cmake 3221 cmake generator unix makefiles cmake build tool usrbingmake configuration release cpuhw features baseline requested detect disabled vfpv3 neon cc built as dynamic libs no c standard 11 c compiler ver 1031 c flags release mcpucortexr5 mthumb mfloatabihard mfpuvfpv3d16 fpic wnopsabi wnodev fshortenums fshortwchar fdatasections ffunctionsections wlgcsections stdc11 fnopie fnopic wnodev fpermissive fsignedchar ffastmath w wreturntype wnonvirtualdtor waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wundef winitself wpointerarith wshadow wsignpromo wuninitialized wnopsabi wsuggestoverride wnocomment wnostrictoverflow fnoomitframepointer ffunctionsections fdatasections fvisibilityhidden os dndebug dndebug c flags debug mcpucortexr5 mthumb mfloatabihard mfpuvfpv3d16 fpic wnopsabi wnodev fshortenums fshortwchar fdatasections ffunctionsections wlgcsections stdc11 fnopie fnopic wnodev fpermissive fsignedchar ffastmath w wreturntype wnonvirtualdtor waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wundef winitself wpointerarith wshadow wsignpromo wuninitialized wnopsabi wsuggestoverride wnocomment wnostrictoverflow fnoomitframepointer ffunctionsections fdatasections fvisibilityhidden os g ddebug ddebug c compiler c flags release mcpucortexr5 mthumb mfloatabihard mfpuvfpv3d16 fpic wnopsabi wnodev fshortenums fshortwchar fdatasections ffunctionsections wlgcsections fsignedchar ffastmath w wreturntype waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wuninitialized wnopsabi wnocomment wnostrictoverflow fnoomitframepointer ffunctionsections fdatasections fvisibilityhidden os dndebug dndebug c flags debug mcpucortexr5 mthumb mfloatabihard mfpuvfpv3d16 fpic wnopsabi wnodev fshortenums fshortwchar fdatasections ffunctionsections wlgcsections fsignedchar ffastmath w wreturntype waddress wsequencepoint wformat wformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wuninitialized wnopsabi wnocomment wnostrictoverflow fnoomitframepointer ffunctionsections fdatasections fvisibilityhidden os g ddebug ddebug linker flags release wlgcsections linker flags debug wlgcsections ccache no precompiled headers no filesystem support is disabled extra dependencies 3rdparty dependencies libpng libopenjp2 zlib opencv modules to be built core features2d imgcodecs imgproc world disabled calib3d flann highgui jsbindingsgenerator ml objdetect photo pythontests stitching video videoio disabled by dependency unavailable dnn gapi java python2 python3 ts applications documentation no nonfree algorithms no gui media io zlib build ver 1213 png build ver 1637 jpeg 2000 build ver 240 hdr no sunraster no pxm no pfm no video io parallel framework none other thirdparty libraries custom hal no python for build usrbinpython27 install to configuring done generating done and when the make s j command is used to compile the source i am hit with the below error 0 building c object 0 building c object 1 building c object 1 building c object 1 building c object 2 building c object 2 building c object 3 building c object in function opjj2kdumptileinfo warning format x expects argument of type unsigned int but argument 3 has type opjuint32 aka long unsigned int wformat 11005 fprintfoutstream tt cstyxn ldefaulttilecsty unsigned int opjuint32 aka long unsigned int lx warning format d expects argument of type int but argument 3 has type opjuint32 aka long unsigned int wformat 11007 fprintfoutstream tt numlayersdn int opjuint32 aka long unsigned int ld warning format x expects argument of type unsigned int but argument 3 has type opjuint32 aka long unsigned int wformat 11008 fprintfoutstream tt mctxn ldefaulttilemct unsigned int opjuint32 aka long unsigned int lx warning format d expects argument of type int but argument 3 has type opjint32 aka long int wformat 11016 fprintfoutstream tt comp d n compno int opjint32 aka long int ld warning format x expects argument of type unsigned int but argument 3 has type opjuint32 aka long unsigned int wformat 11017 fprintfoutstream ttt cstyxn ltccpcsty opjuint32 aka long unsigned int unsigned int lx warning format d expects argument of type int but argument 3 has type opjuint32 aka long unsigned int wformat 11018 fprintfoutstream ttt numresolutionsdn ltccpnumresolutions int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 3 has type opjuint32 aka long unsigned int wformat 11019 fprintfoutstream ttt cblkw2dn ltccpcblkw int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 3 has type opjuint32 aka long unsigned int wformat 11020 fprintfoutstream ttt cblkh2dn ltccpcblkh int opjuint32 aka long unsigned int ld warning format x expects argument of type unsigned int but argument 3 has type opjuint32 aka long unsigned int wformat 11021 fprintfoutstream ttt cblkstyxn ltccpcblksty opjuint32 aka long unsigned int unsigned int lx warning format d expects argument of type int but argument 3 has type opjuint32 aka long unsigned int wformat 11022 fprintfoutstream ttt qmfbiddn ltccpqmfbid int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 3 has type opjuint32 aka long unsigned int wformat 11026 fprintfoutstream dd ltccpprcwresno ltccpprchresno int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 4 has type opjuint32 aka long unsigned int wformat 11026 fprintfoutstream dd ltccpprcwresno ltccpprchresno int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 3 has type opjuint32 aka long unsigned int wformat 11031 fprintfoutstream ttt qntstydn ltccpqntsty int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 3 has type opjuint32 aka long unsigned int wformat 11032 fprintfoutstream ttt numgbitsdn ltccpnumgbits int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 3 has type opjint32 aka long int wformat 11037 fprintfoutstream dd int opjint32 aka long int ld warning format d expects argument of type int but argument 4 has type opjint32 aka long int wformat 11037 fprintfoutstream dd int ld 11038 opjint32 aka long int warning format d expects argument of type int but argument 3 has type opjint32 aka long int wformat 11043 fprintfoutstream ttt roishiftdn ltccproishift int opjint32 aka long int ld in function opjj2kdumpmhindex warning format d expects argument of type int but argument 3 has type opjuint32 aka long unsigned int wformat 11141 fprintfoutstream tt nb of tilepart in tile ddn ittile int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 4 has type opjuint32 aka long unsigned int wformat 11141 fprintfoutstream tt nb of tilepart in tile ddn ittile int ld 11142 nboftilepart opjuint32 aka long unsigned int warning format d expects argument of type int but argument 3 has type opjuint32 aka long unsigned int wformat 11146 fprintfoutstream ttt tilepartd starpos prii64 endheader 11147 prii64 endpos prii64 n 11148 ittilepart opjuint32 aka long unsigned int in function opjj2kdumpmhinfo warning format d expects argument of type int but argument 3 has type opjuint32 aka long unsigned int wformat 11179 fprintfoutstream t tx0d ty0dn pj2kmcptx0 pj2kmcpty0 int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 4 has type opjuint32 aka long unsigned int wformat 11179 fprintfoutstream t tx0d ty0dn pj2kmcptx0 pj2kmcpty0 int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 3 has type opjuint32 aka long unsigned int wformat 11180 fprintfoutstream t tdxd tdydn pj2kmcptdx pj2kmcptdy int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 4 has type opjuint32 aka long unsigned int wformat 11180 fprintfoutstream t tdxd tdydn pj2kmcptdx pj2kmcptdy int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 3 has type opjuint32 aka long unsigned int wformat 11181 fprintfoutstream t twd thdn pj2kmcptw pj2kmcpth int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 4 has type opjuint32 aka long unsigned int wformat 11181 fprintfoutstream t twd thdn pj2kmcptw pj2kmcpth int opjuint32 aka long unsigned int ld in function j2kdumpimageheader warning format d expects argument of type int but argument 4 has type opjuint32 aka long unsigned int wformat 11201 fprintfoutstream s x0d y0dn tab imgheaderx0 imgheadery0 int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 5 has type opjuint32 aka long unsigned int wformat 11201 fprintfoutstream s x0d y0dn tab imgheaderx0 imgheadery0 int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 4 has type opjuint32 aka long unsigned int wformat 11202 fprintfoutstream s x1d y1dn tab imgheaderx1 int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 5 has type opjuint32 aka long unsigned int wformat 11202 fprintfoutstream s x1d y1dn tab imgheaderx1 int ld 11203 imgheadery1 opjuint32 aka long unsigned int warning format d expects argument of type int but argument 4 has type opjuint32 aka long unsigned int wformat 11204 fprintfoutstream s numcompsdn tab imgheadernumcomps int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 4 has type opjuint32 aka long unsigned int wformat 11209 fprintfoutstream st component d n tab compno int opjuint32 aka long unsigned int ld in function warning format d expects argument of type int but argument 4 has type opjuint32 aka long unsigned int wformat 11233 fprintfoutstream s dxd dydn tab compheaderdx compheaderdy int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 5 has type opjuint32 aka long unsigned int wformat 11233 fprintfoutstream s dxd dydn tab compheaderdx compheaderdy int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 4 has type opjuint32 aka long unsigned int wformat 11234 fprintfoutstream s precdn tab compheaderprec int opjuint32 aka long unsigned int ld warning format d expects argument of type int but argument 4 has type opjuint32 aka long unsigned int wformat 11235 fprintfoutstream s sgnddn tab compheadersgnd int opjuint32 aka long unsigned int ld at top level cc1 note unrecognized commandline option may have been intended to silence earlier diagnostics cc1 note unrecognized commandline option may have been intended to silence earlier diagnostics cc1 note unrecognized commandline option wnodev may have been intended to silence earlier diagnostics 3 building c object 3 building c object 4 building c object 4 building c object 5 building c object 5 building c object 5 building c object 6 building c object 6 building c object 6 building c object 7 building c object 7 building c object 8 building c object 8 linking c static library libliblibopenjp2a 8 built target libopenjp2 9 building c object 9 building c object 9 building c object 10 building c object 10 building c object 11 building c object 11 building c object 11 building c object 12 building c object 12 building c object 13 building c object 13 building c object 13 building c object 14 building c object 14 building c object 15 linking c static library liblibzliba 15 built target zlib 15 building c object 16 building c object 16 building c object 17 building c object 17 building c object 17 building c object 18 building c object 18 building c object 18 building c object 19 building c object 19 building c object 20 building c object 20 building c object 20 building c object 21 building c object 21 linking c static library libliblibpnga 21 built target libpng 21 processing opencl kernels imgproc contains the same content 22 processing opencl kernels core contains the same content 22 processing opencl kernels features2d contains the same content 23 building cxx object in file included from from error recursivemutex in namespace std does not name a type 718 typedef stdrecursivemutex mutex note stdrecursivemutex is defined in header did you forget to include 62 include stdmutex stdlockguard include 63 endif error mutex is not a member of cv 719 typedef stdlockguard autolock error mutex is not a member of cv error template argument 1 is invalid 719 typedef stdlockguard autolock in file included from error mutex in namespace cv does not name a type 369 cvmutex cc1plus note unrecognized commandline option may have been intended to silence earlier diagnostics cc1plus note unrecognized commandline option wnodev may have been intended to silence earlier diagnostics cc1plus note unrecognized commandline option wnodev may have been intended to silence earlier diagnostics make2 error 1 make1 error 2 make makefile166 all error 2 steps to reproduce 1 download the opencv source code 2 download the armnoneeabigcc compiler from this link 3 configure the opencv with cmakegui by using the module as stated in the first section ie core features2d imgproc imgcodecs build list 4 compile the build with make s and observe the same errors are received please note that the reason behind this error is know that the armnoneeabigcc compiler doesnt support the threads by default and when tried to run armnoneeabigcc v it gave the following output where it says thread model single instead of posix however i want to solve this error because i am trying to compile opencv for a embedded platform as stated before issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to compile OpenCV into a single static library file?\ndescribe the feature and motivation i compiled using dbuildopencvworldon dbuildsharedlibsoff which resulted in libopencvworlda in the lib directory and several a files in the libopencv3rdparty directory i would like to merge all the a files from the 3rdparty directory with the libopencvworlda file into one i have tried various methods including using the ar command for merging but the resulting static library throws various errors when used is there any way to compile all the modules or dependencies into a single static library additional context no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nImage Reshape  in c++\ninput image scalefactor cvsizewidth height false false this function return 1 x 3 x width x height but some model requested 1 x width x height x 3 in case difficult to reshape image how to convert 1 x 3 x width x height image size to 1 x width x height x 3 in c"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCreating an ROI on a live video\nsystem information jetson agx xavier jetpack 461 opencv 411 cmake 3231 detailed description i am trying to create an roi on a live video and for a while it seems to work but after some time the programme seems to think the roi has moved out of the image plane im not to sure on how this is happening and ive not found any potential fixes which have worked so far i have attached an image of the error i receive steps to reproduce int rx 450 int ry 200 int rw 300 int rh 100 videocapture cap0 while true cap img rect roirect roirect rectrxryrwrh mat roi imgroirect imshowframe img this is just a small snippet of the main code issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCannot load TensorFlow SavedModel created with Teachable Machine\nsystem information opencv version current branch 4x operating system windows 11 compiler visual studio 17 2022 win32 release build detailed description i built a simple model with teachable machine and downloaded it in the saved model format after unzipping i tried to load the model in opencv cpp this gave me a cvexception with the following message opencv470dev error 2unspecified error failed param failed to parse graphdef file in function steps to reproduce to reproduce it just head over to and train a model with two classes then export it to tensorflow savedmodel and try to load the model in opencv issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nThe parameter patternSize behaves unexpected in findCirclesGrid()\nsystem information opencv python version 47072 operating system platform macos 1331 python version 31010 detailed description according to the documentation patternsize should be pointsperrow pointspercolum however it seems that only when i set patternsize as pointspercolum pointsperrow can make the return value retval of findcirclesgrid become true steps to reproduce code python import cv2 img cv2imreadftestpng patternsize 7 10 retval centers patternsize printfpatternsize retval patternsize 10 7 retval centers patternsize printfpatternsize retval output patternsize7 10 retvalfalse patternsize10 7 retvaltrue test data test issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow about Edges?\ndescripe the feature and motivation they can be detected using edge detection algorithms like sobel canny or laplacian edges are useful for tasks like object detection image segmentation and feature matching additional context no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDoes DNN support intel N100 processor\nid like to buy a mini pc with intel n100 processor i am not sure if support the new processor i use the function to detect face in real time thanks in advance for your help"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to image process the on the original image like the of the given output.\nsystem information i have this image original image img1 and after processing it above we want the following output output image 3 detailed description i expecting this result is when i process on the original image the output image given above should come in the same result as this steps to reproduce code int main read image mat imgoffice imreadimg29jpg remove background using chroma keying mat imgnobg double threshold 5 adjust as necessary cvcvtcolorimgoffice imgoffice colorbgr2hsv convert to hsv color space cvinrangeimgoffice scalar200 200 200 scalar150 50 50 imgnobg detect green color range and set as the background cvinrangeimgoffice scalar0 0 0 scalar50 110 100 imgnobg imgnobg cvmorphclose cvsize250 10 fill small holes in the foreground imgnobg cvmorphclose cvsize150 20 imgnobg cvmorphclose cvsize255 20 display both images namedwindowimage windownormal namedwindowoutput windownormal imshowimage imgoffice imshowoutput imgnobg imgnobg imwriteo2jpg imgnobg waitkey0 destroyallwindows return 0 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpenCV no longer builds with Cuda 12.0.1\nsystem information opencv version 460 operating system platform gentoo linux compiler compiler version gcc 1221p20230121r1 detailed description fails to build due to missing symbols buildlog steps to reproduce bash emerge avudut backtrack30 verboseconflicts world this rebuilds anything needing an update and the command i used issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nColud we use USAC with PNP?\ndescripe the feature and motivation because using ransac with pnp shows bad effects additional context no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to compile 4.5.5 with ARM\nsystem information opencv version 455 operating system platform ubuntu 1804 compiler compiler version gcc 750 detailed description i tried to build opencv through the options of the command in steps to reproduce however i checked the following error message 97 building cxx object 97 building cxx object 97 building cxx object 97 building cxx object 98 building cxx object 98 building cxx object 98 building cxx object 98 building cxx object 98 building cxx object 98 building cxx object 98 building cxx object 98 building cxx object 98 building cxx object 98 building cxx object 98 linking cxx shared library liblibopencvworldso 98 built target opencvworld scanning dependencies of target opencvimghash scanning dependencies of target opencvannotation scanning dependencies of target opencvversion scanning dependencies of target scanning dependencies of target opencvvisualisation scanning dependencies of target 98 building cxx object 98 building cxx object 98 building cxx object 98 building cxx object 98 building cxx object 98 building cxx object 98 linking cxx executable 98 linking cxx executable binopencvversion 99 building cxx object 99 linking cxx executable binopencvannotation undefined reference to undefined reference to undefined reference to udevunref undefined reference to udevdeviceunref undefined reference to undefined reference to undefined reference to undefined reference to udevnew undefined reference to udevlistentrygetname undefined reference to udevlistentrygetnext undefined reference to undefined reference to udevdevicegetdevnode undefined reference to udevenumerateunref undefined reference to udevenumeratenew collect2 error ld returned 1 exit status recipe for target failed make2 error 1 recipe for target failed make1 error 2 make1 waiting for unfinished jobs 99 building cxx object undefined reference to undefined reference to undefined reference to udevunref undefined reference to udevdeviceunref undefined reference to undefined reference to undefined reference to undefined reference to udevnew undefined reference to udevlistentrygetname undefined reference to udevlistentrygetnext undefined reference to undefined reference to udevdevicegetdevnode undefined reference to udevenumerateunref undefined reference to udevenumeratenew collect2 error ld returned 1 exit status recipe for target binopencvversion failed make2 binopencvversion error 1 recipe for target failed make1 error 2 99 building cxx object 99 linking cxx executable undefined reference to undefined reference to undefined reference to udevunref undefined reference to udevdeviceunref undefined reference to undefined reference to undefined reference to undefined reference to udevnew undefined reference to udevlistentrygetname undefined reference to udevlistentrygetnext undefined reference to undefined reference to udevdevicegetdevnode undefined reference to udevenumerateunref undefined reference to udevenumeratenew collect2 error ld returned 1 exit status recipe for target binopencvannotation failed make2 binopencvannotation error 1 recipe for target failed make1 error 2 99 building cxx object 99 building cxx object undefined reference to undefined reference to undefined reference to udevunref undefined reference to udevdeviceunref undefined reference to undefined reference to undefined reference to undefined reference to udevnew undefined reference to udevlistentrygetname undefined reference to udevlistentrygetnext undefined reference to undefined reference to udevdevicegetdevnode undefined reference to udevenumerateunref undefined reference to udevenumeratenew collect2 error ld returned 1 exit status recipe for target failed make2 error 1 recipe for target failed make1 error 2 99 building cxx object 99 building cxx object 99 building cxx object 99 building cxx object 99 building cxx object 99 building cxx object 99 linking cxx shared library 99 built target opencvimghash 99 linking cxx executable undefined reference to undefined reference to undefined reference to udevunref undefined reference to udevdeviceunref undefined reference to undefined reference to undefined reference to undefined reference to udevnew undefined reference to udevlistentrygetname undefined reference to udevlistentrygetnext undefined reference to undefined reference to udevdevicegetdevnode undefined reference to udevenumerateunref undefined reference to udevenumeratenew collect2 error ld returned 1 exit status recipe for target failed make2 error 1 recipe for target failed make1 error 2 makefile162 recipe for target all failed make all error 2 i thought libudev was not installed on my system however it exists in the system pkgconfig cflags libs libudev ludev apt list installed grep libudev warning apt does not have a stable cli interface use with caution in scripts 2373ubuntu1056 arm64 installed 2373ubuntu1056 arm64 installed ll libaarch64linuxgnu grep libudev lrwxrwxrwx 1 root root 12 sep 6 0318 libudevso libudevso1 lrwxrwxrwx 1 root root 16 sep 6 0318 libudevso1 libudevso169 rwrr 1 root root 104504 sep 6 0318 libudevso169 steps to reproduce cmake d d d buildopencvpython3on d buildopencvworldon d withcudaon d cudaarchbin72 d cudaarchptx d withcudnnon d enablefastmathon d cudafastmathon d opencvdnncudaon d d d d d buildexamplesoff d withgphoto2off d buildtestsoff d withvtkoff d withgstreameroff d buildperftestsoff issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nputText() documentation is misleading about origin point\ndescripe the doc issue there is a mistake in puttext function documentation puttext point org bool bottomleftorigin false 1 org bottomleft corner of the text string in the image 2 bottomleftorigin when true the image data origin is at the bottomleft corner otherwise it is at the topleft corner by default so documentation about org argument is wrong fix suggestion i see two alternatives 1 if bottomleftorigin will be changed to true documentation is nearly ok but i think documentation of org argument should mention bottomleftorigin probably this is not an option because of backward compatibility concerns 2 update documentation like this param org topleft corner of the text string in the image if bottomleftorigin is false otherwise it is at the bottomleft corner param bottomleftorigin when false the image data origin is at the topleft corner otherwise it is at the bottomleft corner if this documentation update is ok i can create a pr if i miss something or there are a better way i will be glad to know"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to run the Simple RTSP program in docker\nopencv 47 operating system platform ubuntu 2004 compiler python i need to take and rtsp stream which is currently from vlc player rtsplocalhost8554 to the program running inside the docker and the docker container has to give the video output for that i did like this but everytime im getting the same error which is related qt and xcb please look into below details ind dockerfile and command kindly help me to resolve this issue hi im trying to dockerize this code code import cv2 import os rtspurl rtsp00008554 rtsptransportudp cap cv2capffmpeg if not capisopened printcannot open rtsp stream exit1 while true frame capread cv2imshowrtsp stream frame if cv2waitkey1 27 break caprelease cv2destroyallwindows code dockerfile below dockerfile from ubuntu2004 arg run mkdir app workdir app run chmod r 777 app run apt update run tzasiakolkata apt install y tzdata run apt install noinstallrecommends y python3pip run aptget install y libgl1mesadev run aptget install y libglib200 run pip install opencvpython workdir app copy cmd python3 u importcv2py end run command docker run it nethost device devvideo1 p 85548554 v tmpx11unixtmpx11unix abab670c544b error im getting is qtqpaplugin could not load the qt platform plugin xcb in appcv2qtplugins even though it was found this application failed to start because no qt platform plugin could be initialized reinstalling the application may fix this problem available platform plugins are xcb"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow disable MT default on MSVC?\ndescripe the doc issue got errors when link opencvlib with unreal engine 中 ue default using md but opencv default using mt how to enable md while still using static lib fix suggestion no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncv::setNumThreads does not work with Apple GCD\nsystem information opencv version 470 os macos 1301 on apple m1 compiler apple clang version 1400 clang1400029202 target arm64appledarwin2210 detailed description compile opencv with default configuration which results in using gcd for parallel framework in this case calling cvsetnumthreads always fails and cvgetnumthreads always returns 8 using 8 threads on apple m1 would result in worse performance since half of the cores are relatively weak one possible solution is using openmp instead on apple platform tried to build with option dwithopenmpon but got the following error when building fatal error omph file not found include my libomp is installed via homebrew steps to reproduce cpp include include accumulate include minelement include opencv2opencvhpp using namespace std using namespace cv int main const vector inputshape1 3 224 224 mat blob4 inputshapedata cv32fc1 randublob 0f 1f dnnnet net netsetinputblob set thread num int threadnum 4 stdcout threadnum getnumthreads stdendl warmup netforward benchmark tickmeter tm vector times for int i 0 i 10 i tmreset tmstart netforward tmstop double mean timesend 0f timessize double median times4 times5 2 double minimum timesend stdcout cvformatmean f median f min fn mean median minimum return 0 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAvoid using system zlib\ndescripe the feature and motivation how to forely using static build zlib rather than system one additional context how to forely using static build zlib rather than system one"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError trying to build OpenCV 4.5.5 with OpenVINO 2023.2\nsystem information opencv version 455 operating system platform windows 10 inference engine openvino version 20223 python version 396 detailed description hey guys so basically i was trying to build opencv 455 with openvino 20223 and cuda and got the following error error c2440 initializin g cannot convert from initializer list to ovdiscretetypeinfo message no constructor could take the source type or constructor overload resolution was ambiguous error c2131 expression did not evaluate to a constant ldvcxproj i have done this process multiple times and the only thing that i changed was the openvino version changed from 20214 to 20223 the cmake finds openvino new version 20223 correctly but when im building opencvworld cannot be generated because there are code errors does opencv 455 supports openvino 20223 is there any new procedure to build opencv with openvino like a new flag that you need to turn on or something if there is anything that i should try and if you can help i really appreciate note in the meantime im building openvino 20223 with the new released version of opencv 470 to check if the problem remains thanks césar steps to reproduce opencv flags used cmake dbuildopencvappsoff dbuildopencvarucooff dbuildopencvccalibon dbuildopencvcoreon dbuildopencvdnnon dbuildopencvdpmoff dbuildopencvfaceoff dbuildopencvflannon dbuildopencvfuzzyoff dbuildopencvgapioff dbuildopencvhfsoff dbuildopencvjsoff dbuildopencvmccoff dbuildopencvmlon dbuildopencvphotoon dbuildopencvploton dbuildopencvrapidoff dbuildopencvregoff dbuildopencvrgdboff dbuildopencvshapeoff dbuildopencvtextoff dbuildopencvtsoff dbuildopencvvideoon dbuildopencvworldon dbuildopencvxphotoon t v142 dwithffmpegon dwithinfengineon denablecxx11on dbuildjavaoff dwithmsmfoff dwithmsmfdxvaoff dbuildzlibon dbuildopencvhdfoff dwithcudaon denablefastmath1 dcudafastmath1 dwithcublas1 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to disable zlib?\nsystem information i using buildzliboff but it still calls some gzgets api from zlib and i found in code it hard coded img width510 altimage src am confused here how to disable zlib totally dont say features2d or some module need zlib i just want disable all of them i dont need zlib at all detailed description no steps to reproduce no issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpenCV contrib attribute not found - AttributeError: module 'cv2' has no attribute 'face'\nsystem information in case you get attributeerror module cv2 has no attribute face or any other module rgbd ximgproc bgsegm etc and you already have opencvcontribpython installed it might be that import cv2 is actually importing opencvpython library instead of opencvcontribpython my solution was to uninstall opencvpython pip install opencvcontribpython u force when running python script that uses cv2rgbd it crashes python depthpreviewpy file depthpreviewpy line 44 in depthcleaner 7 attributeerror module cv2 has no attribute rgbd uninstalling opencvpython made it work python mpip uninstall opencvpython detailed description opencvpython used instead of opencvcontribpython steps to reproduce opencvpython used instead of opencvcontribpython issue submission checklist x i report the issue its not a question i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAn nparray that uses an inconsistent save from cv2.imwrite\nsystem information example for python user opencv python version 4 operating system platform ubuntu 2004 python version 38 detailed description i ran the following code the outputs should be the same why are they different steps to reproduce import cv2 import numpy as np from pil import image a for i in range100 if i50 aii0 i aii1 i aii2 i else aii0 i aii1 i aii2 i printamax cv2imwrite1jpga img cv2imread1jpg printimgmax issue submission checklist x i report the issue its not a question i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGive it option to build opencv x86 static lib on a ARM M1 mac\ndescripe the feature and motivation give it option to build opencv x86 static lib on a arm m1 mac currently whenever enviroment set opencv always build arm static on a arm mac this is no problem but sometimes users need x86 lib on m1 mac for example build a thirdparty lib for ue5 additional context give it option to build opencv x86 static lib on a arm m1 mac currently whenever enviroment set opencv always build arm static on a arm mac this is no problem but sometimes users need x86 lib on m1 mac for example build a thirdparty lib for ue5"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nandroid jni VideoCapture can't open videofile\nsystem information opencv version 460 operating system platform android 12 compiler compiler version cmake 3102 detailed description ecverror opencv460 error requested object was not found could not open directory in globrec file line 279 alibc fatal signal 11 sigsegv code 2 segvaccerr fault addr 0x797302f480 in tid 19587 centyolov5ncnn pid 19587 centyolov5ncnn i use cvimread and cv2imwrite normalbut when i use videocapture open videoit will report the error even if i use 454it return the same error my code is simpleerror in line2 captureopen steps to reproduce read video cvvideocapture capture issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nProtobuf compatibility...\ndescripe the feature and motivation my env ubuntu 2204 gcc ubuntu 11301ubuntu12204 1130 protobuf 3203 opencv 460 building failed to build opencv dnn caffe with this version of protobuf console note candidate ‘void 318 void cleartoempty note candidate expects 0 arguments 2 provided in file included from in member function ‘void string’ error no matching function for call to string const string googleprotobufarena’ 36145 value getarena in file included from from note candidate ‘template void googleprotobufarena’ 266 void conststringref note template argument failed in file included from note mismatched types and ‘const string’ aka ‘const stdcxx11basicstring’ 36145 value getarena in file included from from note candidate ‘void googleprotobufarena’ 255 void setconststringparam value arena arena note candidate expects 2 arguments 3 provided note candidate ‘void googleprotobufarena’ 256 void setstdstring value arena arena note candidate expects 2 arguments 3 provided note candidate ‘void char googleprotobufarena’ 401 inline void char s arena arena note candidate expects 2 arguments 3 provided note candidate ‘void char sizet googleprotobufarena’ 405 inline void char s sizet n arena arena note no known conversion for argument 1 from ‘const string’ aka ‘const stdcxx11basicstring’ to ‘const char’ 405 inline void char s sizet n arena arena in file included from in member function ‘void error no matching function for call to string googleprotobufarena’ 36149 layerset 36150 stdmovevalue getarena in file included from from note candidate ‘template void googleprotobufarena’ 266 void conststringref note template argument failed in file included from note mismatched types and ‘const string’ aka ‘const stdcxx11basicstring’ 36149 layerset 36150 stdmovevalue getarena in file included from from note candidate ‘void googleprotobufarena’ 255 void setconststringparam value arena arena note candidate expects 2 arguments 3 provided note candidate ‘void googleprotobufarena’ 256 void setstdstring value arena arena note candidate expects 2 arguments 3 provided note candidate ‘void char googleprotobufarena’ 401 inline void char s arena arena note candidate expects 2 arguments 3 provided note candidate ‘void char sizet googleprotobufarena’ 405 inline void char s sizet n arena arena note no known conversion for argument 1 from ‘const string’ aka ‘const stdcxx11basicstring’ to ‘const char’ 405 inline void char s sizet n arena arena in file included from in member function ‘void char’ error no matching function for call to string stdstring googleprotobufarena’ 36156 stdstringvalue 36157 getarena in file included from from note candidate ‘template void googleprotobufarena’ 266 void conststringref note template argument failed in file included from note mismatched types and ‘const string’ aka ‘const stdcxx11basicstring’ 36156 stdstringvalue 36157 getarena in file included from from note candidate ‘void googleprotobufarena’ 255 void setconststringparam value arena arena note candidate expects 2 arguments 3 provided note candidate ‘void googleprotobufarena’ 256 void setstdstring value arena arena note candidate expects 2 arguments 3 provided note candidate ‘void char googleprotobufarena’ 401 inline void char s arena arena note candidate expects 2 arguments 3 provided note candidate ‘void char sizet googleprotobufarena’ 405 inline void char s sizet n arena arena note no known conversion for argument 1 from ‘const string’ aka ‘const stdcxx11basicstring’ to ‘const char’ 405 inline void char s sizet n arena arena in file included from in member function ‘void char sizet’ error no matching function for call to string stdstring googleprotobufarena’ 36163 stdstring 36164 reinterpretcastvalue size getarena in file included from from note candidate ‘template void googleprotobufarena’ 266 void conststringref note template argument failed in file included from note mismatched types and ‘const string’ aka ‘const stdcxx11basicstring’ 36163 stdstring 36164 reinterpretcastvalue size getarena in file included from from note candidate ‘void googleprotobufarena’ 255 void setconststringparam value arena arena note candidate expects 2 arguments 3 provided note candidate ‘void googleprotobufarena’ 256 void setstdstring value arena arena note candidate expects 2 arguments 3 provided note candidate ‘void char googleprotobufarena’ 401 inline void char s arena arena note candidate expects 2 arguments 3 provided note candidate ‘void char sizet googleprotobufarena’ 405 inline void char s sizet n arena arena note no known conversion for argument 1 from ‘const string’ aka ‘const stdcxx11basicstring’ to ‘const char’ 405 inline void char s sizet n arena arena in file included from in member function ‘stdstring error no matching function for call to string googleprotobufarena’ 36169 return getarena in file included from from note candidate ‘stdstring 275 stdstring mutablearena arena note candidate expects 1 argument 2 provided note candidate ‘stdstring googleprotobufarena’ 276 stdstring mutableconst lazystring defaultvalue arena arena note no known conversion for argument 1 from ‘const string’ aka ‘const stdcxx11basicstring’ to ‘const 276 stdstring mutableconst lazystring defaultvalue arena arena in file included from in member function ‘stdstring error ‘struct has no member named ‘releasenondefault’ did you mean ‘cleartodefault’ 36177 return getarena cleartodefault in member function ‘void error no matching function for call to string stdstring googleprotobufarena’ 36185 layer 36186 getarena in file included from from note candidate ‘void googleprotobufarena’ 309 void value arena arena note candidate expects 2 arguments 3 provided in file included from in member function ‘void error no matching function for call to string googleprotobufarena’ 36199 getarena in file included from from note candidate ‘void 318 void cleartoempty note candidate expects 0 arguments 2 provided in file included from in member function ‘void string’ error no matching function for call to string const string googleprotobufarena’ 36219 value getarena in file included from from note candidate ‘template void googleprotobufarena’ 266 void conststringref note template argument failed in file included from note mismatched types and ‘const string’ aka ‘const stdcxx11basicstring’ 36219 value getarena did anybody meet the same issue additional context no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nremap cv2\nsystem information opencv python version 4546 operating system platform ubuntu 2004 python version 381 detailed description remap function cut end of image i have xcoords and ycoord and use remap but output missing end of image image ori img original steps to reproduce here is code use remap xcoordstxt ycoordstxt import numpy as np import cv2 xcoords nploadtxtxcoordstxt ycoords nploadtxtycoordstxt remapped cv2remapori xcoords ycoordscv2intercubic none cv2borderreplicate cv2waitkey issue submission checklist x i report the issue its not a question i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to build C++ solution using OpenCV 4.5.5 with OpenVINO 2021.4.689\nsystem information opencv version 455 operating system platform ubuntu 1804 cuda version 112 cudnn version 810 detailed description hey so my ultimate goal is to build opencv 455 with support for cuda 112 and openvino 20214689 and install it so that i can further use it within my c solution opencv builds correctly with support for both cuda and openvino versions mencioned above but then when im compiling my c code i get the following error usrbinld warning needed by not found try using rpath or rpathlink undefined reference to vtable for undefined reference to vtable for undefined reference to const undefined reference to const undefined reference to const undefined reference to vtable for ngraphpassserialize undefined reference to const undefined reference to typeinfo for ngraphvariantwrapper undefined reference to undefined reference to stdostream stdmap stdallocator ngraphopset stdless stdallocator stdallocator stdallocator const ngraphopset undefined reference to const undefined reference to typeinfo for ngraphvariantwrapper undefined reference to typeinfo for ngraphvariantwrapper undefined reference to stdallocator const stdcxx11basicstring stdallocator const stdmap stdallocator ngraphopset stdless stdallocator stdallocator stdallocator const ngraphopset any other information that you need feel free to ask and thank you so much for the help steps to reproduce the opencv cmake flags that i used were the following ones cmake dbuildopencvappsoff dbuildopencvarucooff dbuildopencvccalibon dbuildopencvcoreon dbuildopencvdnnon dbuildopencvdpmoff dbuildopencvfaceoff dbuildopencvflannon dbuildopencvfuzzyoff dbuildopencvgapioff dbuildopencvhfsoff dbuildopencvjsoff dbuildopencvmccoff dbuildopencvmlon dbuildopencvphotoon dbuildopencvploton dbuildopencvrapidoff dbuildopencvregoff dbuildopencvrgdboff dbuildopencvshapeoff dbuildopencvtextoff dbuildopencvtsoff dbuildopencvvideoon dbuildopencvworldon dbuildopencvxphotoon dwithffmpegon dwithinfengineon denablecxx11on dbuildjavaoff dwithmsmfoff dwithmsmfdxvaoff dbuildzlibon dbuildopencvhdfoff dwithcudaon denablefastmath1 dcudafastmath1 dwithcublas1 dcudaarchbin75 the output of those cmake flags is the following cmakeoutputopencvtxt issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nThe ARM32 Linux platform uses opencv3.4.1\ndescripe the doc issue hello i use the arm32 linux platform and the operating system is ubuntu1604 after compiling opencv341 with the crosscompiler the following errors occurred when i generated an opencv program separately the above is my error information 图片"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to link statically to OpenCV 4.2\nsystem information opencv version 42 operating system platform ubuntu 2004 compiler compiler version gcc 940 detailed description i am trying to build a shared library that uses opencv i have opencv installed via aptget install libopencvdev in the docker image where i am building my library but i need my library to be used in a lean ubuntu 2004 machine ie no aptget install libopencvdev all required so need to be placed in a specific folder this means that i need to either 1 place all opencv so and their prerequisites as well in a specific folder or 2 statically link with opencv and its prerequisites since 1 seems very painful i was trying to follow 2 apparently it should be a matter of simply setting setopencvstatic on before doing findpackage opencv required on my librarys cmakeliststxt unfortunately this does not seem to work as opencv is still dynamically linked i saw numerous threads about statically linking with opencv but they all seem to build opencv from source instead of using the systeminstalled one is it not possible to statically link opencv without building from source steps to reproduce build a simple cmake project using opencv with setopencvstatic on and check that the produced library is dynamically linking opencv see snippet below for an example setopencvstatic on findpackage opencv required set library target shared include headers libraryname public opencvincludedirs public opencvlibs linkdirectories opencvlibdir issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nScan Image Coords issues\nsystem information we use opencv version 454 even the issue is there on the opencv version 342 also cvexception opencv454 error 215assertion failed ssizeempty in function resize when we try to scan the image coordinates and then crop the image we are getting this issue need urgent help on it we are blocked here for many days detailed description we use opencv version 454 even the issue is there on the opencv version 342 also cvexception opencv454 error 215assertion failed ssizeempty in function resize when we try to scan the image coordinates and then crop the image we are getting this issue need urgent help on it we are blocked here for many days steps to reproduce we use opencv version 454 even the issue is there on the opencv version 342 also cvexception opencv454 error 215assertion failed ssizeempty in function resize when we try to scan the image coordinates and then crop the image we are getting this issue need urgent help on it we are blocked here for many days issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to infer unet by opencv?\ndescripe the feature and motivation is there any example with cpp or py i can refer to unet inference？ so this can be used to unet inference please help me additional context no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhen compiling opencv4.5.5, I find that the objdetect module is not compiled.\nsystem information when compiling opencv455 i find that the objdetect module is not compiled the libopencvobjdetectso and files are not found in the lib directory in addition the objdetect module is included in opencv452 compilation why is that detailed description 31 building cxx object 32 building cxx object 32 building cxx object 32 building cxx object 32 building cxx object 32 building cxx object 32 building cxx object 33 building cxx object 33 building cxx object 33 building cxx object 33 building cxx object 33 building cxx object 34 building cxx object 34 building cxx object 34 building cxx object 34 building cxx object 34 building cxx object 34 building cxx object 35 building cxx object 35 building cxx object 35 building cxx object 35 building cxx object 35 building cxx object 36 building cxx object 36 building cxx object 36 building cxx object 36 building cxx object 36 building cxx object 36 building cxx object 37 building cxx object 37 building cxx object 37 building cxx object 37 building cxx object 37 building cxx object 38 building cxx object 38 building cxx object 38 building cxx object 38 building cxx object 38 building cxx object 38 building cxx object 39 building cxx object 39 building cxx object 39 building cxx object 39 building cxx object 39 building cxx object 40 building cxx object 40 building cxx object 40 building cxx object 40 building cxx object 40 building cxx object 40 building cxx object 41 building cxx object 41 building cxx object 41 building cxx object 41 building cxx object 41 building cxx object 42 building cxx object 42 building cxx object 42 building cxx object 42 building cxx object 42 building cxx object 42 building cxx object 43 building cxx object 43 building cxx object 43 building cxx object 43 building cxx object 43 building cxx object 44 building cxx object 44 building cxx object 44 building cxx object 44 building cxx object 44 building cxx object 44 building cxx object 45 building cxx object 45 building cxx object 45 building cxx object 45 building cxx object 45 building cxx object 45 building cxx object 46 building cxx object 46 building cxx object 46 building cxx object 46 building cxx object 46 building cxx object 47 building cxx object 47 building cxx object 47 building cxx object 47 linking cxx shared library liblibopencvcoreso 47 built target opencvcore 47 processing opencl kernels imgproc scanning dependencies of target opencvflann 47 building cxx object scanning dependencies of target opencvml 47 building cxx object 47 building cxx object 47 building cxx object 47 building cxx object 47 building cxx object 47 building cxx object scanning dependencies of target opencvimgproc 48 building cxx object 49 building cxx object 49 building cxx object 49 building cxx object 49 building cxx object 49 building cxx object 49 building cxx object 49 building cxx object 49 building cxx object 50 building cxx object 50 building cxx object 50 building cxx object 51 building cxx object 51 building cxx object 51 building cxx object 51 building cxx object 51 building cxx object 51 building cxx object 51 building cxx object 51 building cxx object 51 building cxx object 52 building cxx object 52 building cxx object 52 building cxx object 52 building cxx object 52 building cxx object 53 building cxx object 53 linking cxx shared library liblibopencvmlso 53 built target opencvml 53 building cxx object 53 building cxx object 53 building cxx object 53 building cxx object 53 building cxx object 54 building cxx object 54 building cxx object 54 building cxx object 54 building cxx object 54 building cxx object 55 building cxx object 55 building cxx object 55 building cxx object 55 building cxx object 55 building cxx object 55 building cxx object 55 linking cxx shared library liblibopencvflannso 55 built target opencvflann 56 building cxx object 56 building cxx object 56 building cxx object 56 building cxx object 56 building cxx object 57 building cxx object 57 building cxx object 57 building cxx object 57 building cxx object 57 building cxx object 57 building cxx object 58 building cxx object 58 building cxx object 58 building cxx object 58 building cxx object 58 building cxx object 59 building cxx object 59 building cxx object 59 building cxx object 59 building cxx object 59 building cxx object 59 building cxx object 60 building cxx object 60 building cxx object 60 building cxx object 60 building cxx object 60 building cxx object 60 building cxx object 61 building cxx object 61 building cxx object 61 building cxx object 61 building cxx object 61 building cxx object 62 building cxx object 62 building cxx object 62 building cxx object 62 building cxx object 62 building cxx object 62 building cxx object 63 building cxx object 63 building cxx object 63 building cxx object 63 building cxx object 63 building cxx object 64 building cxx object 64 building cxx object 64 building cxx object 64 building cxx object 64 building cxx object 64 building cxx object 65 building cxx object 65 building cxx object 65 building cxx object 65 building cxx object 65 building cxx object 66 linking cxx shared library 66 built target opencvimgproc 67 processing opencl kernels photo 67 processing opencl kernels features2d scanning dependencies of target opencvphoto 67 building cxx object 67 building cxx object 67 building cxx object 67 building cxx object 68 building cxx object 68 building cxx object scanning dependencies of target opencvimgcodecs 69 building cxx object scanning dependencies of target opencvfeatures2d 69 building cxx object 70 building cxx object 70 building cxx object 70 building cxx object 70 building cxx object 70 building cxx object 70 building cxx object 70 building cxx object 70 building cxx object 70 building cxx object 70 building cxx object 70 building cxx object 70 building cxx object 71 building cxx object 71 building cxx object 72 building cxx object 72 building cxx object 72 building cxx object 72 building cxx object 73 building cxx object 73 building cxx object 73 building cxx object 73 building cxx object 73 building cxx object 73 building cxx object 73 building cxx object 73 building cxx object 73 building cxx object 73 building cxx object 73 building cxx object 74 building cxx object 74 building cxx object 74 building cxx object 74 building cxx object 74 building cxx object 74 building cxx object 75 building cxx object 76 building cxx object 76 building cxx object 76 building cxx object 76 building cxx object 76 building cxx object 76 building cxx object 76 building cxx object 76 building cxx object 77 building cxx object 77 building cxx object 77 building cxx object 77 building cxx object 77 building cxx object 77 linking cxx shared library 77 built target opencvimgcodecs 77 building cxx object scanning dependencies of target opencvvideoio 77 linking cxx shared library liblibopencvphotoso 77 building cxx object 78 building cxx object 78 building cxx object 78 built target opencvphoto 78 building cxx object 79 building cxx object 79 building cxx object 79 building cxx object 79 building cxx object 79 building cxx object 79 building cxx object 79 building cxx object 79 building cxx object 79 building cxx object 80 building cxx object 80 building cxx object 81 building cxx object 81 building cxx object 81 linking cxx shared library 81 built target opencvvideoio scanning dependencies of target opencvhighgui 82 building cxx object 82 building cxx object 82 building cxx object 82 building cxx object 82 linking cxx shared library 82 built target opencvfeatures2d 82 processing opencl kernels calib3d scanning dependencies of target opencvcalib3d 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 83 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 building cxx object 84 linking cxx shared library 84 built target opencvhighgui 84 building cxx object 84 building cxx object 85 building cxx object 85 building cxx object 85 building cxx object 85 building cxx object 85 building cxx object 86 building cxx object 86 building cxx object 86 building cxx object 86 building cxx object 86 building cxx object 86 building cxx object 87 building cxx object 87 building cxx object 87 building cxx object 87 building cxx object 87 building cxx object 88 building cxx object 88 building cxx object 88 building cxx object 88 building cxx object 88 building cxx object 88 building cxx object 89 building cxx object 89 building cxx object 89 building cxx object 89 building cxx object 89 building cxx object 90 building cxx object 90 building cxx object 90 building cxx object 90 building cxx object 90 building cxx object 90 building cxx object 91 linking cxx shared library 91 built target opencvcalib3d 92 processing opencl kernels stitching 92 processing opencl kernels video scanning dependencies of target opencvstitching 92 building cxx object 92 building cxx object 92 building cxx object 92 building cxx object 93 building cxx object 93 building cxx object 93 building cxx object scanning dependencies of target opencvvideo 93 building cxx object 94 building cxx object 94 building cxx object 94 building cxx object 94 building cxx object 94 building cxx object 94 building cxx object 94 building cxx object 94 building cxx object 95 building cxx object 95 building cxx object 95 building cxx object 95 building cxx object 96 building cxx object 96 building cxx object 96 building cxx object 96 building cxx object 96 building cxx object 97 building cxx object 97 building cxx object 97 building cxx object 97 building cxx object 97 building cxx object 97 building cxx object 98 building cxx object 98 building cxx object 98 building cxx object 98 building cxx object 98 building cxx object 100 building cxx object 100 linking cxx shared library 100 built target opencvstitching 100 building cxx object 100 linking cxx shared library liblibopencvvideoso 100 built target opencvvideo steps to reproduce cmakeoption dwithprotobufoff dwithwebpoff dwithippoff dwithadeoff dbuildzlibon dbuildjpegon dbuildpngon dwithopenexroff dbuildtestsoff dbuildperftestsoff dbuildopencvappsoff dcmakeskiprpathtrue dwithffmpegoff dwithtiffon dbuildtiffon dwithjasperoff dbuildjasperoff dcvtraceoff issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGetting Bad argument (Can't read ONNX file: .\\\\yolov5s.onnx) When Trying to Load YOLOv5 ONNX Model.\nsystem information opencv version 460 operating system platform windows 11 pro 220001098 compiler compiler version microsoft visual c compiler msvc toolset v142 visual studio 2019 detailed description im trying to deploy my yolov5 model with opencv 460 using c however no matter what i try to do open cvs onnx importer throws the following runtime error text opencv460 error bad argument cant read onnx file yolov5sonnx in file line 255 this is the command im using to export the model in powershell text python yolov5exportpy data weights simplify include onnx i tried it with my own exported weights using exportpy and with the default weights and the result is still the same i have also switched between the master v70 and v701 branches and retrying the export i also tried exporting the model in protobuf pb format i even tried building open cv 460 from source all to no avail ive honestly fired all my bullets and couldnt find anything online related to the problem and error i cannot even know where the process is failing and if theres an error from my end heres my mainvoid function where i load the model i believe theres a problem with the opencv code that loads the onnx model below is the code that produces the said problem steps to reproduce c include include const float inputwidth 6400f const float inputheight 6400f const float scorethreshold 05f const float nmsthreshold 045f const float confidencethreshold 045f const float fontscale 07f const int fontface cvfonthersheysimplex const int thickness 1 cvscalar black cvscalar0 0 0 cvscalar blue cvscalar255 178 50 cvscalar yellow cvscalar0 255 255 cvscalar red cvscalar0 0 255 void drawlabel cvmat inputimage stdstring label int left int top int baseline 0 cvsize labelsize cvgettextsizelabel fontface fontscale thickness baseline top cvmaxtop labelsizeheight cvpoint topleftcorner cvpointleft top cvpoint bottomrightcorner cvpointleft labelsizewidth top labelsizeheight baseline topleftcorner bottomrightcorner black cvfilled cvputtext inputimage label cvpointleft top labelsizeheight fontface fontscale yellow thickness stdvector processinputcvmat inputimage cvdnnnet net cvmat blob cvdnnblobfromimage inputimage blob 1 255 cvsizeinputwidth inputheight cvscalar true false netsetinputblob stdvector outputs netforwardoutputs return outputs cvmat postprocess cvmat inputimage stdvector outputs const stdvector classname stdvector classids stdvector confidences stdvector boxes float xfactor inputimagecols inputwidth float yfactor inputimagerows inputheight float data floatoutputs0data const sizet dims 85 const sizet rows 25200 for sizet i 0 i rows i float confidence data4 if confidence confidencethreshold float classesscores data 5 cvmat scores 1 intclassnamesize cv32fc1 classesscores cvpoint classid double maxclassscore 00 cvminmaxlocscores 0 maxclassscore 0 classid if maxclassscore scorethreshold float centerx data0 float centery data1 float boxwidth data2 float boxheight data3 int left intcenterx 05 boxwidth xfactor int top intcentery 05 boxheight yfactor int width intboxwidth xfactor int height intboxheight yfactor top width height data 85 stdvector indices cvdnnnmsboxesboxes confidences scorethreshold nmsthreshold indices for sizet i 0 i indicessize i int idx indicesi cvrect box boxesidx int left boxx int top boxy int width boxwidth int height boxheight cvrectangle inputimage cvpointleft top cvpointleft width top height blue 3thickness stdstring label cvformat2f confidencesidx label classnameclassidsidx label drawlabelinputimage label left top return inputimage cvmat postprocess cvmat inputimage stdvector outputs const stdvector classname stdvector classids stdvector confidences stdvector boxes float xfactor inputimagecols inputwidth float yfactor inputimagerows inputheight float data floatoutputs0data const sizet dims 85 const sizet rows 25200 for sizet i 0 i rows i float confidence data4 if confidence confidencethreshold float classesscores data 5 cvmat scores 1 intclassnamesize cv32fc1 classesscores cvpoint classid double maxclassscore 00 cvminmaxlocscores 0 maxclassscore 0 classid if maxclassscore scorethreshold float centerx data0 float centery data1 float boxwidth data2 float boxheight data3 int left intcenterx 05 boxwidth xfactor int top intcentery 05 boxheight yfactor int width intboxwidth xfactor int height intboxheight yfactor top width height data 85 stdvector indices cvdnnnmsboxesboxes confidences scorethreshold nmsthreshold indices for sizet i 0 i indicessize i int idx indicesi cvrect box boxesidx int left boxx int top boxy int width boxwidth int height boxheight cvrectangle inputimage cvpointleft top cvpointleft width top height blue 3 thickness stdstring label cvformat2f confidencesidx label classnameclassidsidx label drawlabelinputimage label left top return inputimage int mainvoid try stdvector classlist bus car truck cvmat frame cvdnnnet net the line that throws the runtime error stdvector layerstimes stdvector detections processinputframe net cvmat img detections classlist double freq cvgettickfrequency 1000 double timetaken freq stdstring label cvformatinference timet4f ms timetaken cvputtextimg label cvpoint20 40 fontface fontscale red cvimshowoutput img cvwaitkey0 return 0 catch cvexception e stdcout stdendl ewhat stdendl return 1 issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n'haarcascade_fontalface_default.xml' in read mode\ndescripe the doc issue im very new to opencv and was just running my first program ever in the terminal when i get the phrase error00012 global 505 open cant open file in read mode does anyone know what this means here is my code for reference import cv2 trainedfacedata img cv2imreadrdpng cv2imshowclever programmer face detector img cv2waitkey printcode completed fix suggestion no response"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncv::VideoCapture will affect GPU performance?\nmy model takes 6ms when testing a single frame of image but it takes 8ms when using cvvideocapture to get video frame and after dozens of inferences the timeconsuming increases to 12ms win10 opencv version 46"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpenCV iOS use in 2022\nhello i am just getting into opencv and want to understand the following 1 as i understand opencv doesnt support metal so as a result there is no way for opencv to use gpu on ios devices is that correct 2 is my understanding correct that it only makes sense to use opencv on ios devices where opencv performance on cpu is good for app use cases"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhy is the image merge area white\nsavedscreen1212 i dont know why two pictures merged the overlapping area is white i hope the teacher can give me a solution this my scripts： private void warptrianglemat img1 mat img2 list tri1 list tri2 point2f points2f list inputpoints list keypoints thisinitpoints2f for int i 0 i inputpointscount i 遍历每个点 tri1 keypointsi 一个点就是一个三角形像素 tri2 inputpointsi opencvsharprect r1 cv2boundingrecttri1 opencvsharprect r2 cv2boundingrecttri2 list tri1cropped new list tri2cropped new list list tri2croppedint new list for int ii 0 ii 3 ii tri1croppedaddnew point2ftri1iix r1x tri1iiy r1y tri2croppedaddnew point2ftri2iix r2x tri2iiy r2y fillconvexpoly needs a vector of point and not point2f tri2croppedintaddnew r2x mathffloortri2iiy r2y mat img1cropped new mat img1cropped r1center mat warpmat tri2cropped mat img2cropped matzerossize size img1croppedtype img2cropped warpmat img2croppedsize mat mask matzerossize size mattypecv32fc3 tri2croppedint new scalar10 10 10 linetypesantialias 0 mask img2cropped mat matout matzerosnew sizesize size img1type cv2addmatout img2cropped matout float tx tri2minx xx float ty tri2miny yy float warpvalues 10f 00f tx 00f 10f ty 图片偏移 mat translationmatrix new mat2 3 mattypecv32f warpvalues img2cropped translationmatrix new sizesize size new scalar10 10 10 mask img2cropped cv2addimg2 img2cropped img2 float tx tri2minx xx float ty tri2miny yy create the translation matrix using tx and ty float warpvalues 10f 00f tx 00f 10f ty 图片偏移 mat translationmatrix new mat2 3 mattypecv32f warpvalues cv2warpaffinematout matout translationmatrix new sizesize size cv2addimg2 matout img2 cv2flipimg2 img2 flipmodex 图片翻转 cv2imshowoutput img2 img2converttoimg2 mattypecv8uc3 2550 texture2d tex byte bytes texencodetopng bytes debuglog输出图像"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBug (Javascript) mean/meanStdDev broken for 8UC3 images\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library system information version example opencv 42 operating system platform windows 64 bit compiler visual studio 2017 opencv 460 operating system platform macos 130 detailed description javascript functions mean and meanstddev and probably others cause an uncaught exception when applied with masks on 3channel images img width895 altimage src steps to reproduce let src let dst1 cvmatzerossrccols srcrows cvcv8uc1 let mask1 cvmatzerossrccols srcrows dst1type let dst3 cvmatzerossrccols srcrows cvcv8uc3 let mask3 cvmatzerossrccols srcrows dst3type const meanval cvmeandst1 mask1 works const meanval cvmeandst3 mask3 causes uncaught exception error"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIn file included from /home/xxx/opencv/modules/python/src2/cv2.cpp:11:0: /home/xxx/opencv/build/modules/python_bindings_generator/pyopencv_generated_include.h:19:10: fatal error: opencv2/hdf/hdf5.hpp: no file or directory  #include \"opencv2/hdf/hdf5.hpp\"           ^~~~~~~~~~~~~~~~~~~~~~\nim building opencvcudait happens at the end"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to build for FreeBSD 13.1 ? \nsystem information version opencv 460 operating system platform freebsd 131 compiler clangllvm and gcc 11 kde5 plasma has anyone able to compile opencv 460 successfully for freebsd 131 if so what was used to compile opencv and also what commands was used thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nhow opencv load .dylibs under macos\nim working on python3912 macox125 i import cv2 as cv and i find the some dylib under cv2dylibs are loaded but i cant find out where the code loads them i need help"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nFailed to install opencv 4.6.0 on ubuntu\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library system information version example opencv 460 operating system platform linux 64 bit compiler gnu compilers opencv greyquestion operating system platform greyquestion compiler greyquestion detailed description hi i am a newbie on installing opencv from scratch i am trying to install opencv460 on ubuntu followed the instruction the first step is successful without any error cmake d however in the second step “cmake build ” i met the following errors note in expansion of macro ‘iwinline’ 72 static iwinline iwibordersize iwisizetobordersize in file included from from error expected ‘’ ‘’ ‘’ ‘asm’ or ‘attribute’ before 72 static iwinline iwibordersize iwisizetobordersize in file included from from error unknown type name ‘inline’ 79 define iwinline inline note in expansion of macro ‘iwinline’ 85 static iwinline iwibordersize in file included from from error expected ‘’ ‘’ ‘’ ‘asm’ or ‘attribute’ before 85 static iwinline iwibordersize error expected ‘’ before ‘void’ 98 static iwinline void iwishiftptr does anyone can help how to correct it thanks steps to reproduce to add code example fence it with triple backticks and optional file extension cpp c code example or attach as txt or zip file issue submission checklist x i report the issue its not a question opencv team works with forumopencvorg stack overflow and other communities to discuss problems tickets with questions without a real issue statement will be closed x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution places to check opencv documentation faq page opencv forum opencv issue tracker stack overflow branch i updated to the latest opencv version and the issue is still there master branch for opencv 4x and 34 branch for opencv 3x releases opencv team supports only the latest release for each branch the ticket is closed if the problem is not reproduced with the modern version there is reproducer code and related data files videos images onnx etc the best reproducer test case for opencv that we can add to the library recommendations for media files and binary files try to reproduce the issue with images and videos in opencvextra repository to reduce attachment size use png for images if you report some cv related bug but not image reader issue attach the image as an archive to the ticket if you report some reader issue image hosting services compress images and it breaks the repro code provide onnx file for some public model or onnx file with random weights if you report onnx parsing or handling issue architecture details diagram from netron tool can be very useful too see"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfatal error\ncloningdemocpp2310 fatal error opencv2photohpp no such file or directory 23 include opencv2photohpp compilation terminated"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to quickly convert RGB to YUV422\nhello ，i am using cvtcolor will rgb to yuv422 but this funciton param mode dont have bgr2yuv422 i use the indown method to transform void rgb cvmat yuv cvmat yuv444rgbrows rgbcols cv8uc3 cvcvtcolorrgb yuv444 cvbgr2yuv chroma subsampling yuv444 yuv422 for int row 0 row yuv444rows row for int col 0 col yuv444cols col2 cvvec3b p0in yuv444atrow col cvvec3b p1in yuv444atrow col1 cvvec2b p0out p1out p0outval0 p0inval0 p0outval1 p0inval1 p1outval0 p1inval0 p1outval1 p0inval2 yuvatrow col p0out yuvatrow col1 p1out but this approach takes a long time how to use the parallel computing method for transformation or how to make opencv support yuv422 conversion please provide me with reference"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncan OpenCV 3.4.16 using cuda 11.6?\ncan opencv 3416 using cuda 116"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to automatically obtain the input image size from the ONNX model？\nis there a function in opencv dnn that automatically gets the input image size from the only onnx model？ thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nerror: 'off64_t' undeclared here (not in a function); did you mean 'off_t'?\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library system information version example opencv 42 operating system platform windows 64 bit compiler visual studio 2017 opencv 460 operating system platform ubuntu 1804 compiler gcc detailed description i want to build opencv 460 via these options cmake d d d python3 d d python3 d python2 d c from distutilssysconfig import getpythoninc printgetpythoninc d c from distutilssysconfig import getpythonlib printgetpythonlib d d d buildpngon d buildtiffon d buildtbbon d buildjpegon d buildjasperon d buildzlibon d buildexampleson d buildtestson d buildopencvjavaon d buildopencvpython2on d buildopencvpython3on d d d withopenclon d withippon d witheigenon d buildperftestson d d withffmpegon d withv4lon d withgstreameron d withgstreamer010on d withgtkon d enablefastmathon d withvtkon d withtbbon d withqton d withopenglon d d installcexampleson d installtestson d enableneonon d withlibv4loff but after building these errors occurred so configuring incomplete cmakeerrorlog content error ‘off64t’ undeclared here not in a function did you mean ‘offt’ error ‘int8’ undeclared here not in a function did you mean ‘int8c’ error ‘int16’ undeclared here not in a function did you mean ‘int16c’ error ‘int32’ undeclared here not in a function did you mean ‘int32c’ how could i resolve these errors steps to reproduce to add code example fence it with triple backticks and optional file extension cpp c code example or attach as txt or zip file issue submission checklist i report the issue its not a question opencv team works with forumopencvorg stack overflow and other communities to discuss problems tickets with questions without a real issue statement will be closed i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution places to check opencv documentation faq page opencv forum opencv issue tracker stack overflow branch master branch for opencv 4x and 34 branch for opencv 3x releases opencv team supports only the latest release for each branch the ticket is closed if the problem is not reproduced with the modern version the best reproducer test case for opencv that we can add to the library recommendations for media files and binary files try to reproduce the issue with images and videos in opencvextra repository to reduce attachment size use png for images if you report some cv related bug but not image reader issue attach the image as an archive to the ticket if you report some reader issue image hosting services compress images and it breaks the repro code provide onnx file for some public model or onnx file with random weights if you report onnx parsing or handling issue architecture details diagram from netron tool can be very useful too see"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nimshow() for .png transparent images with RGBA 4 channels\nlooks like imshow cannot show transparency correctly i prefer not to show rgb some times with alpha mask how can i make the transparency displayed i can load i can save but with imshow i cannot display correctly"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nConvcert cvMat to pcd file\nhi i would like to convert a cvmat to pcl format have you an idea thanks"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGetting cv2.error\nscreenshot 289 above picture is the code and i am getting this error message which is shown below could anyone help me fix this issue screenshot 290"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nVideoCapture: read() use video orientation\nif the video orientation is available if should be used by default with reading frames opencv 4x operating system platform linux x64 compiler gcc detailed description by default imread for images use the exif orientation information if possible videocaptureread should use the orientation information if available by default too steps to reproduce happens on portrait videos taken by smartphones if needed i can provide one issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAbout debug\ni debug opencv in one step but i couldnt find the function entry of the matrix plus method"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSyntaxError: invalid syntax   --->frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\nwhen i tried to use lucaskanade on optical flow i couldnt figure out why theres always invalid syntax when i use frame cv2circleframe inta intb 5 coloritolist 1 heres the code guys please help me import numpy as np import cv2 cap featureparams dict maxcorners 100 qualitylevel 03 mindistance 7 lkparams dict winsize 1515 maxlevel 2 color ret oldframe capread oldgray cv2cvtcoloroldframe cv2colorbgr2gray p0 mask none featureparams mask npzeroslikeoldframe whiletrue retframe capread framegray p1 st err framegray p0 none lkparams goodnew p1st1 goodold p0st1 for i newold in ab newravel cd oldravel mask frame cv2circleframe inta intb 5 coloritolist 1 the problem is here image cv2circleimage centercoordinates radius color thickness img cv2addframemask cv2imshowframeimg k cv2waitkey150 0xff if k 27 break oldgray framegraycopy p0 goodnewreshape112 cv2destroyallwindows caprelease"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to properly use opencl acceleration applied to 360 surround view\n360 surround view multithreaded processing of pictures from different cameras opencv 455 for image correction and perspective transformation remap the cpu usage is very high so use opencl 10 to accelerate but with the increase of the number of threads the processing time of a single thread increases several times and the gpu occupancy rate is also high how to optimize 1 use opencl 20 2 picture copy umat has no data pointer cannot use hardware rga acceleration can only use copyto which is timeconsuming 3 it feels that in multithreading the operation of opencl is blocked and queued and the use of mutex has almost no effect on the time consumption"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncv2.drawFrameAxes broken\nusing python 39 macos 1221 opencv 455 i am not getting the correct axes displayed the axes are defined as ox is drawn in red oy in green and oz in blue in the reference docs using the code below zero rotation has the zaxis blue right and yaxis green down wrong orientation 90 deg around zaxis rotates instead around the xaxis red 60 deg around yaxis seems to work 60 deg around xaxis rotates instead around the zaxis blue python def drawaxesrvecs tvecs nparray000 width 400 im npzeroswidthwidth3 cx cy width2 width2 f width k nparrayf 0 cx0 f cy0 0 1 dtypefloat dist nparray00 00 00 00 00 dtypefloat set the axes size as a function of the markers square size and project onto image space s 4 axis npfloat32s00 0s0 00sreshape13 imgpts jac cv2projectpoints axis rvecs tvecs k dist cv2drawframeaxes im k dist rvecs tvecs length2 thickness3 return im pltfigurefigsize1010 pltsubplot221 plttitlexyz 000 pltsubplot222 plttitlexyz 0090 pltsubplot223 plttitlexyz 0600 pltsubplot224 plttitlexyz 6000 download"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nORB FeatureDetector has different result between C++ and Python\ni use orb featuredetector to extract feature using python and c code sees below but the output results is different completely i am sure my input is same and opencv version all is 346 i am confuse i need some help"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncv2.imread() fails when filenames have multiple dots (.)\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library system information version example opencv 42 operating system platform windows 64 bit compiler visual studio 2017 opencv 45564 operating system platform windows compiler pycharm community edition 202011 detailed description when the cv2imread method encounters a filename with multiple dots a nonetype is returned i think this might be because the file extension is assumed to be everything after the first dot and not the last but it could be something completely different example steps to reproduce to add code example fence it with triple backticks and optional file extension cpp c code example running the following code with two images in the same directory py import cv2 im project – mainpy 18052022 154450png im2 16052022 234007png printim printim2 gives the result py warn00221 global 239 cvfinddecoder project – mainpy 18052022 154450png cant openread file check file pathintegrity none 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 153 139 140 152 139 139 151 139 138 148 136 135 150 138 138 151 140 139 which shows that the first image one dot loaded successfully but the second one with the multiple dots failed issue submission checklist x i report the issue its not a question opencv team works with forumopencvorg stack overflow and other communities to discuss problems tickets with questions without a real issue statement will be closed x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution places to check opencv documentation faq page opencv forum opencv issue tracker stack overflow branch x i updated to the latest opencv version and the issue is still there master branch for opencv 4x and 34 branch for opencv 3x releases opencv team supports only the latest release for each branch the ticket is closed if the problem is not reproduced with the modern version x there is reproducer code and related data files videos images onnx etc the best reproducer test case for opencv that we can add to the library recommendations for media files and binary files try to reproduce the issue with images and videos in opencvextra repository to reduce attachment size use png for images if you report some cv related bug but not image reader issue attach the image as an archive to the ticket if you report some reader issue image hosting services compress images and it breaks the repro code provide onnx file for some public model or onnx file with random weights if you report onnx parsing or handling issue architecture details diagram from netron tool can be very useful too see"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSystemError: <built-in function writeTextGraph> returned NULL without setting an error when using cv2.dnn.writeTextGraph\nopencv 412 operating system platform windows 64 bit compiler google colab so i recently created a machine learning model with keras and saved it using the savemodel function into a pb file i want to use this model with opencv and therefore have been trying to obtain a pbtxt file to use alongside the dnn module of opencv net yet for some reason i keep getting the error in the title systemerror returned null without setting an error what ive done ive been saving the model on google colab so ive tried restarting the runtime a couple of times ive made sure my file path was correct im not sure how to check if the pb file is corrupted but i dont imagine it is since i directly downloaded it from keras this is the code below loadedmodel this is the genereated folder from the save function of keras import cv2 graphpbtxt"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nError While Installing openCV 4.5.1 on Ubuntu 18.04 ( jetson nano production module).\nsystem information version example opencv 42 operating system platform windows 64 bit compiler visual studio 2017 opencv greyquestion operating system platform ubuntu 1804 compiler gcc ubuntulinaro 7503ubuntu11804 750 detailed description hello im using a jetson production module running on ubuntu 1804 and i cant install open cv 451 i have already done and sudo aptget update and sudo aptget upgrade steps im running this script binbash set e echo installing opencv 451 on your jetson nano echo it will take 2 hours reveal the cuda location cd sudo sh c echo usrlocalcudalib64 sudo ldconfig install the dependencies sudo aptget install y buildessential cmake git unzip pkgconfig sudo aptget install y libjpegdev libpngdev libtiffdev sudo aptget install y libavcodecdev libavformatdev libswscaledev sudo aptget install y libgtk20dev libcanberragtk sudo aptget install y python3dev python3numpy python3pip sudo aptget install y libxvidcoredev libx264dev libgtk3dev sudo aptget install y libtbb2 libtbbdev libdc139422dev sudo aptget install y gstreamer10tools libv4ldev v4lutils sudo aptget install y libgstreamer10dev sudo aptget install y libavresampledev libvorbisdev libxine2dev sudo aptget install y libfaacdev libmp3lamedev libtheoradev sudo aptget install y libopencoreamrnbdev libopencoreamrwbdev sudo aptget install y libopenblasdev libatlasbasedev libblasdev sudo aptget install y liblapackdev libeigen3dev gfortran sudo aptget install y libhdf5dev protobufcompiler sudo aptget install y libprotobufdev libgoogleglogdev libgflagsdev remove old versions or previous builds cd sudo rm rf opencv download the latest version wget o opencvzip wget o opencvcontribzip unpack unzip opencvzip unzip opencvcontribzip some administration to make live easier later on mv opencv451 opencv mv opencvcontrib451 opencvcontrib clean up the zip files rm opencvzip rm opencvcontribzip set install dir cd opencv mkdir build cd build run cmake cmake d d d d d withopencloff d withcudaon d cudaarchbin53 d cudaarchptx d withcudnnon d withcublason d enablefastmathon d cudafastmathon d opencvdnncudaon d enableneonon d withqtoff d withopenmpon d buildtiffon d withffmpegon d withgstreameron d withtbbon d buildtbbon d buildtestsoff d witheigenon d withv4lon d withlibv4lon d d installcexamplesoff d d d d d buildexamplesoff run make freememfree m awk swap print 2 use j 4 only swap space is larger than 35gb if freemem gt 3500 then nojob4 else echo due to limited swap make only uses 1 core nojob1 fi make j nojob sudo rm r sudo make install sudo ldconfig cleaning frees 300 mb make clean sudo aptget update echo congratulations echo youve successfully installed opencv 451 on your jetson nano output found pythoninterp usrbinpython27 found suitable version 2717 minimum required is 27 could not find pythonlibs missing pythonlibraries pythonincludedirs required is exact version 2717 traceback most recent call last file line 1 in importerror no module named numpydistutils found pythoninterp usrbinpython3 found suitable version 369 minimum required is 32 found pythonlibs found suitable exact version 369 looking for ccache not found performing test havecxxfsignedchar performing test havecxxfsignedchar success performing test havecfsignedchar performing test havecfsignedchar success performing test havecxxffastmath performing test havecxxffastmath success performing test havecffastmath performing test havecffastmath success performing test havecxxw performing test havecxxw success performing test havecw performing test havecw success performing test havecxxwall performing test havecxxwall success performing test havecwall performing test havecwall success performing test performing test success performing test performing test success performing test performing test success performing test performing test failed performing test havecxxwerroraddress performing test havecxxwerroraddress success performing test havecwerroraddress performing test havecwerroraddress success performing test performing test success performing test performing test success performing test havecxxwformat performing test havecxxwformat success performing test havecwformat performing test havecwformat success performing test performing test success performing test performing test success performing test performing test success performing test performing test success performing test performing test failed performing test performing test success performing test performing test failed performing test performing test success performing test havecxxwundef performing test havecxxwundef success performing test havecwundef performing test havecwundef success performing test havecxxwinitself performing test havecxxwinitself success performing test havecwinitself performing test havecwinitself success performing test havecxxwpointerarith performing test havecxxwpointerarith success performing test havecwpointerarith performing test havecwpointerarith success performing test havecxxwshadow performing test havecxxwshadow success performing test havecwshadow performing test havecwshadow success performing test havecxxwsignpromo performing test havecxxwsignpromo success performing test havecwsignpromo performing test havecwsignpromo failed performing test performing test success performing test havecwuninitialized performing test havecwuninitialized success performing test performing test success performing test performing test failed performing test performing test success performing test performing test failed performing test performing test failed performing test performing test failed performing test havecxxwnocomment performing test havecxxwnocomment success performing test havecwnocomment performing test havecwnocomment success performing test performing test success performing test performing test success performing test performing test success performing test performing test success performing test performing test success performing test performing test success performing test havecxxpthread performing test havecxxpthread success performing test havecpthread performing test havecpthread success performing test performing test success performing test performing test success performing test performing test success performing test performing test success performing test havecxxfdatasections performing test havecxxfdatasections success performing test havecfdatasections performing test havecfdatasections success performing test havecpuneonsupport check file performing test havecpuneonsupport success performing test havecpufp16support check file performing test havecpufp16support success performing test havecpubaselineflags performing test havecpubaselineflags success performing test performing test success performing test performing test success performing test performing test success performing test performing test failed performing test havelinkasneeded performing test havelinkasneeded success looking for pthreadh looking for pthreadh found looking for posixmemalign looking for posixmemalign found looking for malloch looking for malloch found looking for memalign looking for memalign found check if the system is big endian searching 16 bit integer looking for systypesh looking for systypesh found looking for stdinth looking for stdinth found looking for stddefh looking for stddefh found check size of unsigned short check size of unsigned short done using unsigned short check if the system is big endian little endian found openmpc fopenmp found version 45 found openmpcxx fopenmp found version 45 found openmp true found version 45 found zlib found suitable version 1211 minimum required is 123 found jpeg looking for asserth looking for asserth found looking for dlfcnh looking for dlfcnh found looking for fcntlh looking for fcntlh found looking for inttypesh looking for inttypesh found looking for ioh looking for ioh not found looking for limitsh looking for limitsh found looking for memoryh looking for memoryh found looking for searchh looking for searchh found looking for stringh looking for stringh found looking for stringsh looking for stringsh found looking for systimeh looking for systimeh found looking for unistdh looking for unistdh found performing test chasinline performing test chasinline success check size of signed short check size of signed short done check size of unsigned short check size of unsigned short done check size of signed int check size of signed int done check size of unsigned int check size of unsigned int done check size of signed long check size of signed long done check size of unsigned long check size of unsigned long done check size of signed long long check size of signed long long done check size of unsigned long long check size of unsigned long long done check size of unsigned char check size of unsigned char done check size of sizet check size of sizet done check size of ptrdifft check size of ptrdifft done check size of int8 check size of int8 failed check size of int16 check size of int16 failed check size of int32 check size of int32 failed looking for floor looking for floor found looking for pow looking for pow found looking for sqrt looking for sqrt found looking for isascii looking for isascii found looking for memset looking for memset found looking for mmap looking for mmap found looking for getopt looking for getopt found looking for memmove looking for memmove found looking for setmode looking for setmode not found looking for strcasecmp looking for strcasecmp found looking for strchr looking for strchr found looking for strrchr looking for strrchr found looking for strstr looking for strstr found looking for strtol looking for strtol found looking for strtol looking for strtol found looking for strtoull looking for strtoull found looking for lfind looking for lfind found performing test havesnprintf performing test havesnprintf success check if the system is big endian searching 16 bit integer using unsigned short check if the system is big endian little endian performing test performing test success performing test performing test success performing test performing test success performing test havecwnoundef performing test havecwnoundef success performing test havecwnounused performing test havecwnounused success performing test havecwnosigncompare performing test havecwnosigncompare success performing test havecwnocastalign performing test havecwnocastalign success performing test havecwnoshadow performing test havecwnoshadow success performing test performing test success performing test performing test success performing test performing test success performing test performing test success performing test performing test success performing test performing test success performing test performing test success performing test performing test success performing test performing test failed performing test havecxxwnoundef performing test havecxxwnoundef success performing test havecstdc99 performing test havecstdc99 success performing test performing test success performing test performing test success could not find openjpeg minimal suitable version 20 recommended version 231 openjpeg will be built from sources performing test performing test failed openjpeg version 231 build opencv451openjp2231 check if the system is big endian searching 16 bit integer using unsigned short check if the system is big endian little endian looking for stdlibh looking for stdlibh found looking for stdioh looking for stdioh found looking for mathh looking for mathh found looking for floath looking for floath found looking for timeh looking for timeh found looking for stdargh looking for stdargh found looking for ctypeh looking for ctypeh found looking for stdinth looking for stdinth found looking for inttypesh looking for inttypesh found looking for sysstath looking for sysstath found looking for include file malloch looking for include file malloch found looking for alignedmalloc looking for alignedmalloc not found looking for posixmemalign looking for posixmemalign found looking for memalign looking for memalign found performing test performing test success performing test performing test failed openjpeg libraries will be built from sources libopenjp2 version 231 found zlib found version 1211 found png found version 1634 looking for usrincludelibpngpngh looking for usrincludelibpngpngh found looking for semaphoreh looking for semaphoreh found performing test havecxxwnoshadow performing test havecxxwnoshadow success performing test havecxxwnounused performing test havecxxwnounused success performing test performing test success performing test performing test success performing test havecxxwnoswitch performing test havecxxwnoswitch success performing test performing test success performing test performing test success performing test havecxxwnoextra performing test havecxxwnoextra success performing test performing test success performing test performing test success performing test havecxxwnodeprecated performing test havecxxwnodeprecated success performing test performing test success performing test performing test failed performing test performing test success performing test performing test success performing test havecxxwnoreorder performing test havecxxwnoreorder success performing test performing test success performing test performing test failed checking for module gtk30 found gtk30 version 32230 checking for module gthread20 found gthread20 version 2564 tbb download v20202targz performing test performing test failed cmake warning at message opencv is not able to findconfigure cuda sdk required by withcuda cuda support will be disabled in opencv build to eliminate this warning remove withcudaon cmake configuration option call stack most recent call first cmakeliststxt700 include could not find openblas include turning openblasfound off could not find openblas lib turning openblasfound off could not find atlas missing looking for sgemm looking for sgemm found found threads true a library with blas api found looking for cheev looking for cheev found a library with lapack api found performing test performing test success performing test havecxxwnosignpromo performing test havecxxwnosignpromo success performing test performing test failed performing test performing test success performing test performing test success performing test performing test success performing test performing test failed performing test performing test success performing test performing test failed could not find jni missing javaawtlibrary javajvmlibrary javaincludepath javaincludepath2 javaawtincludepath vtk is not found please set dvtkdir in cmake to vtk build directory or to vtk install subdirectory with vtkconfigcmake file looking for dlerror in dl looking for dlerror in dl found ade download v011fzip opencv python during development append to pythonpath checking for modules found libavcodec version 57107100 found libavformat version 5783100 found libavutil version 5578100 found libswscale version 48100 checking for module libavresample found libavresample version 370 checking for module gstreamerbase10 found gstreamerbase10 version 1145 checking for module gstreamerapp10 found gstreamerapp10 version 1145 checking for module gstreamerriff10 found gstreamerriff10 version 1145 checking for module gstreamerpbutils10 found gstreamerpbutils10 version 1145 checking for module libdc13942 found libdc13942 version 225 caffe no protobuf no glog yes checking for module freetype2 found freetype2 version 21015 checking for module harfbuzz found harfbuzz version 172 freetype2 yes ver 21015 harfbuzz yes ver 172 hdf5 using hdf5 compiler wrapper to determine c configuration found hdf5 found version 11001 julia not found not compiling julia bindings module opencvovis disabled because ogre3d was not found checking sfm gloggflags deps true ceres support is disabled ceres solver for reconstruction api is required checking for module tesseract no package tesseract found tesseract no allocator metrics storage type int hdf5 using hdf5 compiler wrapper to determine c configuration excluding from source files list excluding from source files list excluding from source files list excluding from source files list excluding from source files list cmake error at message dnn cuda backend requires cuda toolkit please resolve dependency or disable opencvdnncudaoff registering hook opencvdnn filter out ocl4dnn source code opencvdnn filter out cuda4dnn source code excluding from source files list excluding from source files list excluding from source files list excluding from source files list performing test performing test success rgbd ceres support is disabled ceres solver is required for posegraph optimization xfeatures2dboostdesc download boostdescbgmi xfeatures2dboostdesc download boostdescbgmbii xfeatures2dboostdesc download boostdescbgmhdi xfeatures2dboostdesc download xfeatures2dboostdesc download xfeatures2dboostdesc download xfeatures2dboostdesc download boostdesclbgmi xfeatures2dvgg download vgggenerated48i xfeatures2dvgg download vgggenerated64i xfeatures2dvgg download vgggenerated80i xfeatures2dvgg download vgggenerated120i data download facelandmarkmodeldat ceres support is disabled ceres solver for reconstruction api is required performing test performing test success performing test performing test failed general configuration for opencv 451 version control unknown extra modules location extra version control extra unknown platform timestamp 20220509t080701z host linux 49201tegra aarch64 cmake 3102 cmake generator unix makefiles cmake build tool usrbinmake configuration release cpuhw features baseline neon fp16 required neon cc built as dynamic libs yes c standard 11 c compiler usrbinc ver 750 c flags release fsignedchar ffastmath w wall werrorreturntype werrornonvirtualdtor werroraddress werrorsequencepoint wformat werrorformatsecurity wmissingdeclarations wundef winitself wpointerarith wshadow wsignpromo wuninitialized wsuggestoverride wnocomment wnostrictoverflow pthread fomitframepointer ffunctionsections fdatasections fvisibilityhidden fopenmp o3 dndebug dndebug c flags debug fsignedchar ffastmath w wall werrorreturntype werrornonvirtualdtor werroraddress werrorsequencepoint wformat werrorformatsecurity wmissingdeclarations wundef winitself wpointerarith wshadow wsignpromo wuninitialized wsuggestoverride wnocomment wnostrictoverflow pthread fomitframepointer ffunctionsections fdatasections fvisibilityhidden fopenmp g o0 ddebug ddebug c compiler usrbincc c flags release fsignedchar ffastmath w wall werrorreturntype werroraddress werrorsequencepoint wformat werrorformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wuninitialized wnocomment wnostrictoverflow pthread fomitframepointer ffunctionsections fdatasections fvisibilityhidden fopenmp o3 dndebug dndebug c flags debug fsignedchar ffastmath w wall werrorreturntype werroraddress werrorsequencepoint wformat werrorformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wuninitialized wnocomment wnostrictoverflow pthread fomitframepointer ffunctionsections fdatasections fvisibilityhidden fopenmp g o0 ddebug ddebug linker flags release wlgcsections wlasneeded linker flags debug wlgcsections wlasneeded ccache no precompiled headers no extra dependencies dl m pthread rt 3rdparty dependencies opencv modules to be built alphamat aruco bgsegm bioinspired calib3d ccalib core datasets dnn dnnobjdetect dnnsuperres dpm face features2d flann freetype fuzzy gapi hdf hfs highgui imghash imgcodecs imgproc intensitytransform linedescriptor mcc ml objdetect optflow phaseunwrapping photo plot python3 quality rapid reg rgbd saliency sfm shape stereo stitching structuredlight superres surfacematching text tracking ts video videoio videostab xfeatures2d ximgproc xobjdetect xphoto disabled world disabled by dependency unavailable cnn3dobj cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev cvv java julia matlab ovis python2 viz applications perftests apps documentation no nonfree algorithms yes gui gtk yes ver 32230 gthread yes ver 2564 gtkglext no vtk support no media io zlib ver 1211 jpeg ver 80 webp build ver encoder 0x020f png ver 1634 tiff build ver 42 4010 jpeg 2000 build ver 231 openexr build ver 230 hdr yes sunraster yes pxm yes pfm yes video io dc1394 yes 225 ffmpeg yes avcodec yes 57107100 avformat yes 5783100 avutil yes 5578100 swscale yes 48100 avresample yes 370 gstreamer yes 1145 v4lv4l2 yes linuxvideodev2h parallel framework tbb ver 20202 interface 11102 trace yes with intel itt other thirdparty libraries lapack no eigen yes ver 334 custom hal yes carotene ver 001 protobuf build 351 nvidia cuda no cudnn no python 3 interpreter usrbinpython3 ver 369 libraries ver 369 numpy ver 1133 install path python for build usrbinpython27 java ant no jni no java wrappers no java tests no install to usr configuring incomplete errors occurred see also see also"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nJS version cannot find the undistortpoints function 。how to compute distorted image points position in opencv.js？\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library system information version example opencv 42 operating system platform windows 64 bit compiler visual studio 2017 opencv greyquestion operating system platform greyquestion compiler greyquestion detailed description steps to reproduce to add code example fence it with triple backticks and optional file extension cpp c code example or attach as txt or zip file issue submission checklist i report the issue its not a question opencv team works with forumopencvorg stack overflow and other communities to discuss problems tickets with questions without a real issue statement will be closed i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution places to check opencv documentation faq page opencv forum opencv issue tracker stack overflow branch i updated to the latest opencv version and the issue is still there master branch for opencv 4x and 34 branch for opencv 3x releases opencv team supports only the latest release for each branch the ticket is closed if the problem is not reproduced with the modern version there is reproducer code and related data files videos images onnx etc the best reproducer test case for opencv that we can add to the library recommendations for media files and binary files try to reproduce the issue with images and videos in opencvextra repository to reduce attachment size use png for images if you report some cv related bug but not image reader issue attach the image as an archive to the ticket if you report some reader issue image hosting services compress images and it breaks the repro code provide onnx file for some public model or onnx file with random weights if you report onnx parsing or handling issue architecture details diagram from netron tool can be very useful too see"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncommon.hpp\nsystem information opencv 455 operating system platform windows 64 bit compiler visual studio 2022 hi i just installing opencv and i trying this code but i have an error vs2022 can not found commonhpp someone know how to resolve this i need to replace it with another lib thanks a lot d"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n Iplimage has not been declared\nifndef mm3dh define mm3dh include include 3dmmglobalh include pf注释的找不到这个文件 include include include pf注释的找不到这个文件 include pf注释的找不到这个文件 include pf注释的找不到这个文件 using namespace std using namespace cv define inf 1e20 class mm3d public 3dmm and reference frame mapping void cartesian2refdouble vertex double tri double texture int width int height int nver int ntri double ref double refco double triind void zbufferdouble vertex double tri double texture int nver int ntri double srcimg int width int height int nchannels double img double triind void zbuffertridouble vertex double tri double texturetri int nver int ntri double srcimg int width int height int nchannels double img double triind void getcovertridouble vertex double tri double r double p int nver int ntri double covertri void visiblesurfdouble vertex double tri double r int nver int ntri double visbin bool pointintrimat point mat pt1 mat pt2 mat pt3 void dt double im int width int height void dtfloat d float f int n void lightingdouble vertex double tri double tex int nv int nt illumpara para iplimage img void drawmodalfloat shape unsigned int triangle float color int nt int nv illumpara para unsigned char face int widthstep void normdirectionfloat vertex unsigned int tri int nt int nv float norm void meshmapdouble vertex double tri int nver int ntri double meshmap int width int height void occlusionquerydouble vertex double tri int ntri int nver int width int height double visibility double threshold opengl related hglrc hrc hdc hdc byte data hbitmap bitmap for face int width int height bool preparegl bool releasegl double xmin double xmax double ymin double ymax double zmin double zmax endif 1 my opencv version is 455 i use matlab mex compile opencv but i got a bug i have no idea"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDifference in predictions when running on GPU vs CPU\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library system information version example opencv 450 operating system platform ubuntu 20043 compiler visual studio 2017 opencv 450 operating system platform ubuntu 20043 lts python 3810 cuda driver version runtime version 1150 1140 cuda capability majorminor version number 86 detailed description hi there at the moment im trying to use my gpu nvidia rtx 3060ti for inference of some darknet models using opencv dnn module however ive run into something that i cant quite explain when running on cpu i get better results in terms of prediction accuracy compared to when running on gpu outcomes xposition yposition width height confidence using cpu 16601124 13718239 6899952 9705516 075609446 using gpu 16611267 13738803 70430055 10015738 04337875 the big difference here is the confidence scores which seem to be off this happens when running on the outofthebox yolov3 model weights and config but also when running custom models steps to reproduce uncomment lines stating setpreferablebackend and setpreferabletarget to enable gpu usage also did a quick check on the output of cv2dnnblobfromimage this returns the exact same image when running with cpu or gpu enabled import cv2 import numpy as np if name main net cv2dnnreadnet rnetworkweights rnetworkcfg img blob scalefactor000392 size1056 1056 mean0 0 0 swaprbtrue cropfalse outputlayers netsetinputblob outputs detections nparraydetection for output in outputs for detection in output scores detections 5 data detections 4 classids npargmaxscores axis1 mainscores classids keep only detections which have score higher than conf suffscores mainscores 03 class id and score classids classidssuffscores confs mainscoressuffscores data datasuffscores w data 2 1920 h data 3 1080 centerx data 0 1920 centery data 1 1080 printa b c d e for a b c d e in zipcenterx centery w h confs thanks in advance"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMissing libraries in OpenCV 3.3.1\ni tried installing opencv331 using the exe at however it seems to be missing some libraries that i need to run my application how can i obtain the complete set of libraries image"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWhy are there 3 compiled dynamic libraries? What's the difference between them?\nimg width200 src"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n`cv.imdecode` can't open the dib(bmp) images from clipboard\nsystem information version opencv opencvpython 355 operating system platform win10 compiler precompiled detailed description cvimdecode cant open the dibbmp images from clipboard but can from file steps to reproduce work py with openuntitledbmprb as f src fread dtypenpuint8 cvimreadcolor cant work py take a screenshoot or anything src or win32concfdibv5 dtypenpuint8 cvimreadcolor the imdecode return null is it able to support this kind of format of bmpaka dib for opencv issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPython and Java don't decode JPG in the same way\nsystem information version opencv 453 operating system platform linuxdebian compiler system default detailed description jpg images read from python or java arent exactly equal i would expect that they get decoded to exactly the same uint8 values below an example steps to reproduce python img1 cvimread2jpg img1maxaxis01 result array194 188 190 dtypeuint8 java string imgfile 2jpg mat img list channels new arraylist coresplitimg channels channelsforeachch result 1890 1840 1890 ive attached the input file 2jpg issue submission checklist x i report the issue its not a question opencv team works with forumopencvorg stack overflow and other communities to discuss problems tickets with questions without a real issue statement will be closed x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution places to check opencv documentation faq page opencv forum opencv issue tracker stack overflow branch x i updated to the latest opencv version and the issue is still there master branch for opencv 4x and 34 branch for opencv 3x releases opencv team supports only the latest release for each branch the ticket is closed if the problem is not reproduced with the modern version x there is reproducer code and related data files videos images onnx etc the best reproducer test case for opencv that we can add to the library recommendations for media files and binary files try to reproduce the issue with images and videos in opencvextra repository to reduce attachment size use png for images if you report some cv related bug but not image reader issue attach the image as an archive to the ticket if you report some reader issue image hosting services compress images and it breaks the repro code provide onnx file for some public model or onnx file with random weights if you report onnx parsing or handling issue architecture details diagram from netron tool can be very useful too see 2"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUndefined symbols for architecture arm64:   \"std::__1::basic_istream, (built on m1 mac)\ni followed that instructions on 21571 and successfully built an xcframework when i tried to import it the follow error show undefined symbols for architecture arm64 std1basicistream bool referenced from platform macbook pro with m1 pro chip swiftdriver version 1452 apple swift version 56 swiftlang56032362 clang13160208 target arm64applemacosx120 apple clang version 1316 clang13160212"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsome issue with cmake and opencv \nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library detailed description recently i am working on my first project which is using intel d455 to track skeleton i am planning use opencv to complete i had read some articles and one of them is from intel this site lead me to i follow the description down below and find out an error which i cant solved ↓ after clicking configure and this occurred ↓error description honestly i had no idea what happened to my cmake and what i done so far seem to be unrelated to my current project i am confused can someone point out the problem in my cmake and how can i do to solve steps to reproduce to add code example fence it with triple backticks and optional file extension cpp c code example or attach as txt or zip file issue submission checklist i report the issue its not a question opencv team works with forumopencvorg stack overflow and other communities to discuss problems tickets with questions without a real issue statement will be closed i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution places to check opencv documentation faq page opencv forum opencv issue tracker stack overflow branch i updated to the latest opencv version and the issue is still there master branch for opencv 4x and 34 branch for opencv 3x releases opencv team supports only the latest release for each branch the ticket is closed if the problem is not reproduced with the modern version there is reproducer code and related data files videos images onnx etc the best reproducer test case for opencv that we can add to the library recommendations for media files and binary files try to reproduce the issue with images and videos in opencvextra repository to reduce attachment size use png for images if you report some cv related bug but not image reader issue attach the image as an archive to the ticket if you report some reader issue image hosting services compress images and it breaks the repro code provide onnx file for some public model or onnx file with random weights if you report onnx parsing or handling issue architecture details diagram from netron tool can be very useful too see"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n  OpenCV: Include directory doesn't exist:   '/usr/local/stow/absl/include/opencv4'.  OpenCV installation may be broken.\nsystem information version opencv 455 operating system linux ubuntu 2004 cmakemakeinstall cmake d d d d witheigenon d withqton d d installcexamplesoff d d d d buildexamplesoff make j8 sudo make install pkgconfig modversion opencv4 455 pkgconfig libs opencv4 lusrlocallib lopencvgapi lopencvstitching lopencvalphamat lopencvaruco lopencvbarcode lopencvbgsegm lopencvbioinspired lopencvccalib lopencvcvv lopencvdnnobjdetect lopencvdnnsuperres lopencvdpm lopencvface lopencvfreetype lopencvfuzzy lopencvhdf lopencvhfs lopencvimghash lopencvmcc lopencvquality lopencvrapid lopencvreg lopencvrgbd lopencvsaliency lopencvsfm lopencvstereo lopencvsuperres lopencvoptflow lopencvtracking lopencvhighgui lopencvdatasets lopencvtext lopencvplot lopencvvideostab lopencvvideoio lopencvviz lopencvwechatqrcode lopencvxfeatures2d lopencvshape lopencvml lopencvximgproc lopencvvideo lopencvxobjdetect lopencvobjdetect lopencvcalib3d lopencvimgcodecs lopencvfeatures2d lopencvdnn lopencvflann lopencvxphoto lopencvphoto lopencvimgproc lopencvcore cmakelisttxt 35 languages cxx findpackageopencv required findpackage opencv required maincpp opencvlibs error cmake warning at message opencv include directory doesnt exist opencv installation may be broken skip call stack most recent call first cmakeliststxt5 findpackage"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nreadNetFromTensorflow don't work\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library system information version example opencv 42 operating system platform windows 64 bit compiler visual studio 2017 opencv 45564 operating system platform windows 11 64 bit compiler python 3102 detailed description when i want to load my savedmodelpb which is on the same directory with i got this error cv2error opencv455 error 2unspecified error failed param failed to parse graphdef file savedmodelpb in function i saw everyone use already trained model and nobody train its own model for use it in opencv i dont see anything related with my error on internet or to load a custom model in opencv steps to reproduce model 3 paddingsame activationrelu 3 paddingsame activationrelu tfkeraslayersflatten activationrelu tfkeraslayersdense2 metricsaccuracy modelfit trainds validationdatavalds epochs10 modelsave model to add code example fence it with triple backticks and optional file extension cpp c code example or attach as txt or zip file issue submission checklist x i report the issue its not a question opencv team works with forumopencvorg stack overflow and other communities to discuss problems tickets with questions without a real issue statement will be closed x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution places to check opencv documentation faq page opencv forum opencv issue tracker stack overflow branch x i updated to the latest opencv version and the issue is still there master branch for opencv 4x and 34 branch for opencv 3x releases opencv team supports only the latest release for each branch the ticket is closed if the problem is not reproduced with the modern version x there is reproducer code and related data files videos images onnx etc the best reproducer test case for opencv that we can add to the library recommendations for media files and binary files try to reproduce the issue with images and videos in opencvextra repository to reduce attachment size use png for images if you report some cv related bug but not image reader issue attach the image as an archive to the ticket if you report some reader issue image hosting services compress images and it breaks the repro code provide onnx file for some public model or onnx file with random weights if you report onnx parsing or handling issue architecture details diagram from netron tool can be very useful too see"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nconfused about the principle of cvFindExtrinsicCameraParams2() interface ?\ncould tell me about the principle of following code in interface any theory or paper initialize extrinsic parameters if w2w1 1e3 a planar structure case all ms lie in the same plane double tt3 h9 h1norm h2norm cvmat rtransform matv cvmat ttransform cvmat 3 1 cv64f tt cvmat math cvmat 3 3 cv64f h cvmat h1 h2 h3 if v2v2 v5v5 1e10 cvsetidentity rtransform if cvdetrtransform 0 cvscale rtransform rtransform 1 cvgemm rtransform mc 1 0 0 ttransform cvgemmbt for i 0 i count i const double rp rtransformdatadb const double tp ttransformdatadb const double src matmdatadb i3 double dst mxydatadb i2 dst0 rp0src0 rp1src1 rp2src2 tp0 dst1 rp3src0 rp4src1 rp5src2 tp1 cvfindhomography mxy mn math if cvcheckarrmath cvcheckquiet cvgetcol math h1 0 h2 h1 h2datadb h3 h2 h3datadb h1norm stdsqrth0h0 h3h3 h6h6 h2norm stdsqrth1h1 h4h4 h7h7 cvscale h1 h1 1maxh1norm dblepsilon cvscale h2 h2 1maxh2norm dblepsilon cvscale h3 t 2maxh1norm h2norm dblepsilon cvcrossproduct h1 h2 h3 cvrodrigues2 math r cvrodrigues2 r math cvmatmuladd math ttransform t t cvmatmul math rtransform matr else cvsetidentity matr cvzero t cvrodrigues2 matr r"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncv::cudacodec::VideoReader throw_no_cuda\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library system information version example opencv 42 operating system platform windows 64 bit compiler visual studio 2017 opencv 450 operating system platform windows 10 64bit compiler visual studio 2019 cuda 112 gpu gtx 3070 detailed description this is my source code： to add code example fence it with triple backticks and optional file extension cpp c code example or attach as txt or zip file cpp include include opencv2opencvhpp include opencv2cudacodechpp using namespace std using namespace cv int main const string videoname cvcudagpumat dframe cvptr dreader while true if break cvwaitkey1 return 0 when i run the cvptr dreader an error occurred in the program： opencv terminate handler is called the last opencv error is opencv450 error the functionfeature is not implemented the called functionality is disabled for current build or platform in thrownocuda file line 112 the information of cmake is as follows： selecting windows sdk version 100190410 to target windows 10019042 detected processor amd64 libjpegturbo version 205 build could not find openjpeg minimal suitable version 20 recommended version 231 openjpeg will be built from sources openjpeg version 231 build opencv450openjp2231 openjpeg libraries will be built from sources libopenjp2 version 231 found intel ipp icv version 202000 202000 gold at found intel ipp integration wrappers sources 202000 at cuda detected 112 cuda using cudaarchbin86 cuda nvcc target flags cuda msvs generator is detected disabling cmake rerun checks you need to run cmake manually if updates are required could not find openblas include turning openblasfound off could not find openblas lib turning openblasfound off could not find blas missing blaslibraries could not find lapack missing lapacklibraries reason given by package lapack could not be found because dependency blas could not be found vtk is not found please set dvtkdir in cmake to vtk build directory or to vtk install subdirectory with vtkconfigcmake file opencv python during development append to pythonpath module opencvalphamat disabled because the following dependencies are not found eigen caffe no protobuf no glog no freetype2 no harfbuzz no julia not found not compiling julia bindings module opencvovis disabled because ogre3d was not found no preference for use of exported gflags cmake configuration set and no hints for includelibrary directories provided defaulting to preferring an installedexported gflags cmake configuration if available failed to find installed gflags cmake configuration searching for gflags build directories exported with cmake failed to find gflags failed to find an installedexported cmake configuration for gflags will perform search for installed gflags components failed to find gflags could not find gflags include directory set gflagsincludedir to directory containing gflagsgflagsh failed to find glog could not find glog include directory set glogincludedir to directory containing glogloggingh module opencvsfm disabled because the following dependencies are not found eigen gloggflags tesseract no processing world modules module opencvcudev module opencvcore allocator metrics storage type long long module opencvcudaarithm module opencvflann module opencvimgproc module module opencvml module module opencvplot module opencvquality module opencvreg module module opencvcudafilters module opencvcudaimgproc module opencvcudawarping module opencvdnn registering hook module opencvdnnsuperres module opencvfeatures2d module opencvfuzzy module opencvhfs module opencvimgcodecs module opencvlinedescriptor module opencvphoto module opencvsaliency module opencvtext module opencvvideoio module opencvxphoto module opencvcalib3d module opencvcudacodec module opencvcudafeatures2d module opencvcudastereo module opencvdatasets module opencvhighgui module opencvmcc module opencvobjdetect module opencvrapid module opencvrgbd module opencvshape module module opencvvideo module opencvxfeatures2d module opencvximgproc module opencvxobjdetect module opencvaruco module opencvbgsegm module opencvbioinspired module opencvccalib module opencvcudabgsegm module opencvcudalegacy module opencvcudaobjdetect module opencvdnnobjdetect module opencvdpm module opencvface module opencvgapi module opencvoptflow module opencvstitching module opencvtracking module opencvcudaoptflow module opencvstereo module opencvsuperres module opencvvideostab processing world modules done cmake warning at message configuration is not supported validate setupvars script in install directory call stack most recent call first cmakeliststxt976 include general configuration for opencv 450 version control unknown extra modules location extra version control extra unknown platform timestamp 20220304t080333z host windows 10019042 amd64 cmake 3193 cmake generator visual studio 16 2019 cmake build tool cprogram files x86microsoft visual msvc 1929 cpuhw features baseline sse sse2 sse3 requested sse3 dispatched code generation sse41 sse42 fp16 avx avx2 avx512skx requested sse41 sse42 avx fp16 avx2 avx512skx sse41 17 files ssse3 sse41 sse42 2 files ssse3 sse41 popcnt sse42 fp16 1 files ssse3 sse41 popcnt sse42 fp16 avx avx 5 files ssse3 sse41 popcnt sse42 avx avx2 31 files ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 avx512skx 7 files ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 avx512f avx512common avx512skx cc built as dynamic libs yes c standard 11 c compiler cprogram files x86microsoft visual ver 1929300381 c flags release dwin32 dwindows w4 gr d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpfast eha wd4127 wd4251 wd4324 wd4275 wd4512 wd4589 mp md o2 ob2 dndebug c flags debug dwin32 dwindows w4 gr d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpfast eha wd4127 wd4251 wd4324 wd4275 wd4512 wd4589 mp mdd zi ob0 od rtc1 c compiler cprogram files x86microsoft visual c flags release dwin32 dwindows w3 d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpfast mp md o2 ob2 dndebug c flags debug dwin32 dwindows w3 d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpfast mp mdd zi ob0 od rtc1 linker flags release machinex64 incrementalno linker flags debug machinex64 debug incremental ccache no precompiled headers no extra dependencies opengl32 glu32 cudartstaticlib nppclib nppiallib nppicclib nppideilib nppiflib nppiglib nppimlib nppistlib nppisulib nppitclib nppslib cublaslib cudnnlib cufftlib libpathcprogram filesnvidia gpu computing 3rdparty dependencies opencv modules to be built aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnnobjdetect dnnsuperres dpm face features2d flann fuzzy gapi hfs highgui imghash imgcodecs imgproc intensitytransform linedescriptor mcc ml objdetect optflow phaseunwrapping photo plot quality rapid reg rgbd saliency shape stereo stitching structuredlight superres surfacematching text tracking ts video videoio videostab world xfeatures2d ximgproc xobjdetect xphoto disabled python3 pythontests disabled by dependency unavailable alphamat cnn3dobj cvv freetype hdf java js julia matlab ovis python2 python2 sfm viz applications tests perftests apps documentation no nonfree algorithms yes windows rt support no gui win32 ui yes opengl support yes opengl32 glu32 vtk support no media io zlib build ver 1211 jpeg buildlibjpegturbo ver 20562 webp build ver encoder 0x020f png build ver 1637 tiff build ver 42 4010 jpeg 2000 build ver 231 openexr build ver 230 hdr yes sunraster yes pxm yes pfm yes video io dc1394 no ffmpeg yes prebuilt binaries avcodec yes 5891100 avformat yes 5845100 avutil yes 5651100 swscale yes 57100 avresample yes 400 gstreamer no directshow yes media foundation yes dxva yes parallel framework concurrency trace yes with intel itt other thirdparty libraries intel ipp 202000 gold 202000 at intel ipp iw sources 202000 at lapack no eigen no custom hal no protobuf build 351 nvidia cuda yes ver 112 cufft cublas nvcuvid fastmath nvidia gpu arch 86 nvidia ptx archs cudnn yes ver 821 opencl yes nvd3d11 include path link libraries dynamic load python for build dpython39pythonexe java ant no jni djavainclude djavaincludewin32 djavainclude java wrappers no java tests no install to configuring done generating done why it does not run successfully with “nvcuvid” displayed？i am very confused please help me？"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nundefined reference to `cv::Mat::Mat(int, int, int, cv::Scalar_<double> const&)'\nwhen i ran this code it went wrong detailed description cvmat system information version opencv 453code in question pulled from here ubuntu 2004 opencv 453 ubuntu 2004 it reported undefined reference to cvmatmatint int int cvscalar const undefined reference to issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nInconsistant conversion from BGRA to BGR on png image\nsystem information version opencv 455 operating system platform ubuntu 2004 compiler g detailed description usually in opencv the conversion from bgra to bgr via imreadcolor or cvtcolor set the transparent background as black however for this image it seem to generate an inconsistant background steps to reproduce python3 import cv2 img cv2imreadpath cv2imreadcolor cv2imshowwindow img cv2waitkey0 original image imgrgba output image outrgba issue submission checklist x i report the issue its not a question opencv team works with forumopencvorg stack overflow and other communities to discuss problems tickets with questions without a real issue statement will be closed x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution places to check opencv documentation faq page opencv forum opencv issue tracker stack overflow branch x i updated to the latest opencv version and the issue is still there master branch for opencv 4x and 34 branch for opencv 3x releases opencv team supports only the latest release for each branch the ticket is closed if the problem is not reproduced with the modern version x there is reproducer code and related data files videos images onnx etc the best reproducer test case for opencv that we can add to the library recommendations for media files and binary files try to reproduce the issue with images and videos in opencvextra repository to reduce attachment size use png for images if you report some cv related bug but not image reader issue attach the image as an archive to the ticket if you report some reader issue image hosting services compress images and it breaks the repro code provide onnx file for some public model or onnx file with random weights if you report onnx parsing or handling issue architecture details diagram from netron tool can be very useful too see"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to launch app with brew version OpenCV 4.5.5 linked\nsystem information version opencv 455 operating system platform macos 1164 apple m1 compiler apple clang version 1300 c detailed description when i write cmakefilestxt to link opencv 455 installed by brew the built program will not be able to run the os kills my program i think errors of loading dylibs occur when the application is launched reproduction is very easy here is a simple code am i doing something wrong steps to reproduce 1 c source code maincpp anything is ok maincpp int mainint argc char argv 2 cmakeliststxt just link this code above with the opencv library cmake 3211 1 for verbose mode run like verbose1 make j8 projectcvlink addexecutablecvlink targetsourcescvlink private maincpp findpackageopencv required opencvlibs 3 build build normally in the manner of cmake zsh brew install opencv if not yet mkdir build cd build cmake make 4 run but fails zsh cvlink zsh killed cvlink 5 i would like to confirm my opencv version zsh opencvversion 455 which opencvversion i think it is an issue with the brew version of opencv here is the build log of my reproduction code mymac 184209 build make checkbuildsystem 0 e cmakeprogressstart f cmakefilesmakefile2 all f cd e cmakedepends unix makefiles usersmynametmpcvlink usersmynametmpcvlink color f 50 building cxx object isystem arch arm64 isysroot mmacosxversionmin116 stdgnu11 md mt mf o c 100 linking cxx executable cvlink e cmakelinkscript verbose1 arch arm64 isysroot mmacosxversionmin116 wlsearchpathsfirst lopthomebrewlib o cvlink 100 built target cvlink e cmakeprogressstart 0 mymac 184210 build because there were too many dylibs included in the build i tried to link and launch only one library to isolate the problem for all of the libraries i found that out of 56 libraries the following 10 libraries failed to launch if i linked even one of each of them the other 46 can be linked all at once without any problem i dont know but is there any common characteristics of these bad bad bad bad bad bad bad bad bad bad issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCMake detects a non-existent external dependency\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library system information version example opencv 455 operating system platform ubuntu 2008 compiler gcc 930 cmake 3163 opencv 455 operating system platform ubuntu 2004 compiler gcc 930 cmake 3163 cuda 116 cudnn 821 nvidia driver 5104703 detailed description cmake detects nonexistent library lib i am trying to compile opencv with cuda support when i run cmake it detects the following external dependencies extra dependencies m pthread cudartstatic dl rt nppc nppial nppicc nppidei nppif nppig nppim nppist nppisu nppitc npps cublas lib cufft lusrlibx8664linuxgnu the problem is that lib is not a valid library this leads to failures during linking steps to reproduce i used the following cmake command cmake d d d withcudaon d enablefastmath1 d cudafastmath1 d withcublas1 d d d d d d pythonlibrarylibrary d buildexampleson dbuildopencvdpmoff dbuildopencvfaceoff dbuildopencvcvvoff dbuildjavaoff dhaveopencvpython3on dwithopengloff dwithvtkoff dforcevtkoff dwithtbbon dwithgdalon dcudafastmathon dwithcublason dwithmklon dmklusemultithreadon dwithcudaon perthread dwithnvcuvidoff dmklwithtbbon dwithffmpegon dmklwithopenmpon dwithxineon issue submission checklist x i report the issue its not a question opencv team works with forumopencvorg stack overflow and other communities to discuss problems tickets with questions without a real issue statement will be closed x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution places to check opencv documentation faq page opencv forum opencv issue tracker stack overflow branch x i updated to the latest opencv version and the issue is still there master branch for opencv 4x and 34 branch for opencv 3x releases opencv team supports only the latest release for each branch the ticket is closed if the problem is not reproduced with the modern version x there is reproducer code and related data files videos images onnx etc the best reproducer test case for opencv that we can add to the library recommendations for media files and binary files try to reproduce the issue with images and videos in opencvextra repository to reduce attachment size use png for images if you report some cv related bug but not image reader issue attach the image as an archive to the ticket if you report some reader issue image hosting services compress images and it breaks the repro code provide onnx file for some public model or onnx file with random weights if you report onnx parsing or handling issue architecture details diagram from netron tool can be very useful too see"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nundefined reference to `google::protobuf::internal::InitSCCImpl(google::protobuf::internal::SCCInfoBase*)'\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library system information version example opencv 42 operating system platform windows 64 bit compiler visual studio 2017 opencv 455 operating system platform ubuntu 20043 64 bit compiler gccg 1031 detailed description just use cmake to build current opencv 4x with opencvcontrib 4x console git show commit head 4x upstreammaster upstreamhead upstream4x origin4x merge 2efcaa9e8e 33f219dfe6 author alexander alekhin date tue feb 22 192332 2022 0000 merge pull request 21613 from yusukekamedapatch1 steps to reproduce configure buildprotobuf off protobufupdatefiles on buildopencvdatasets on buildopencvdnn on on on buildopencvdpm on opencvdnncuda on opencvdnnopencl off opencvdnnopenvino off opencvdnnperfcaffe off opencvdnnperfclcaffe off error messages after make j16 console 29 linking cxx shared library liblibopencvcvvso cd usrlocalbincmake e cmakelinkscript verbose1 usrlocalbinc fpic fsignedchar ffastmath w wall wreturntype wnonvirtualdtor waddress wsequencepoint wformat wformatsecurity wundef winitself wpointerarith wsignpromo wuninitialized wsuggestoverride wnocomment wnostrictoverflow wnolonglong pthread fnoomitframepointer pg g msse msse2 msse3 fvisibilityhidden fopenmp wnoshadow o3 dndebug dndebug wlasneeded wlnoundefined shared o liblibopencvcvvso455 lusrlocalcudalib64 ldl lm lpthread lrt lcudartstatic ldl lrt lnppc lnppial lnppicc lnppidei lnppif lnppig lnppim lnppist lnppisu lnppitc lnpps lcublas lcudnn lcufft lusrlocalcudalib64 lusrlibx8664linuxgnu lcudartstatic ldl lrt lnppc lnppial lnppicc lnppidei lnppif lnppig lnppim lnppist lnppisu lnppitc lnpps lm lpthread lcublas lcudnn lcufft make2 leaving directory opencvbuild 29 built target in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld more undefined references to follow usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld more undefined references to const unsigned long const follow usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld in function const int undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld more undefined references to const int follow usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld more undefined references to follow usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function const int undefined reference to const int usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const int undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld in function void stdallocator bool undefined reference to long void void usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function void bool undefined reference to long void void usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function const int undefined reference to const int usrbinld in function undefined reference to const make2 leaving directory opencvbuild usrbinld 29 built target in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld more undefined references to follow usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const int undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld more undefined references to const int follow usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld more undefined references to follow usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const int undefined reference to const int usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const int undefined reference to const int usrbinld undefined reference to const int usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function const int undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld more undefined references to follow usrbinld in function undefined reference to const buildfile usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld more undefined references to follow usrbinld in function const int undefined reference to const int usrbinld undefined reference to const int usrbinld in function stdallocator const char const undefined reference to char const usrbinld in function const int undefined reference to const int usrbinld in function stdallocator const char const undefined reference to char const usrbinld in function void undefined reference to void void usrbinld in function void stdallocator stdcxx11basicstring stdallocator undefined reference to void void usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function void stdallocator const void stdless stdallocator stdallocator const const void bool undefined reference to long void void usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function void stdallocator const void stdless stdallocator stdallocator const const void bool undefined reference to long void void usrbinld undefined reference to long void void usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function void stdintegralconstant undefined reference to void void usrbinld in function undefined reference to const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function void stdallocator const void stdless stdallocator stdallocator const const void bool undefined reference to long void void usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function void bool undefined reference to long void void usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function void stdallocator const void stdless stdallocator stdallocator const const void bool undefined reference to long void void usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function const int undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld more undefined references to follow usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function stdallocator const char const undefined reference to char const usrbinld undefined reference to char const usrbinld in function const int undefined reference to const int usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function stdallocator const char const undefined reference to char const usrbinld in function const int undefined reference to const int usrbinld in function stdallocator const char const undefined reference to char const usrbinld undefined reference to char const usrbinld undefined reference to char const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const int undefined reference to const int usrbinld undefined reference to const int usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function void stdallocator const void stdless stdallocator stdallocator const const void bool undefined reference to long void void usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function void stdintegralconstant undefined reference to void void usrbinld in function undefined reference to const usrbinld in function const int undefined reference to const int usrbinld in function void bool undefined reference to long void void usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function const int undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function void stdallocator const void stdless stdallocator stdallocator const const void bool undefined reference to long void void usrbinld in function const unsigned long const undefined reference to const unsigned long const make2 leaving directory opencvbuild 29 built target usrbinld make2 leaving directory opencvbuild 29 built target in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const int undefined reference to const int usrbinld in function stdallocator const char const undefined reference to char const usrbinld undefined reference to char const usrbinld undefined reference to char const usrbinld undefined reference to char const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld in function const int undefined reference to const int usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function void stdallocator const void stdless stdallocator stdallocator const const void bool undefined reference to long void void usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function void stdintegralconstant undefined reference to void void usrbinld in function globalsubigraphpbcc undefined reference to const usrbinld in function const int undefined reference to const int usrbinld in function void bool undefined reference to long void void usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function const int undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld undefined reference to const int usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function void stdallocator const void stdless stdallocator stdallocator const const void bool undefined reference to long void void usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld more undefined references to follow usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const int undefined reference to const int usrbinld in function stdallocator const char const undefined reference to char const usrbinld undefined reference to char const usrbinld undefined reference to char const usrbinld undefined reference to char const usrbinld undefined reference to char const usrbinld in function const int undefined reference to const int usrbinld in function stdallocator const char const undefined reference to char const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld more undefined references to follow usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const int undefined reference to const int usrbinld in function stdallocator const char const undefined reference to char const usrbinld undefined reference to char const usrbinld undefined reference to char const usrbinld in function const int undefined reference to const int usrbinld in function stdallocator const char const undefined reference to char const usrbinld undefined reference to char const usrbinld undefined reference to char const usrbinld in function const int undefined reference to const int usrbinld in function globalsubiopdefpbcc undefined reference to const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld in function const int undefined reference to const int usrbinld in function globalsubitensorpbcc undefined reference to const usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function const int undefined reference to const int usrbinld in function stdallocator const char const undefined reference to char const usrbinld in function const int undefined reference to const int usrbinld in function undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld undefined reference to usrbinld more undefined references to follow usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function undefined reference to usrbinld in function undefined reference to const usrbinld in function undefined reference to usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld in function const int undefined reference to const int usrbinld in function undefined reference to usrbinld in function undefined reference to const make2 leaving directory opencvbuild 29 built target jar make2 leaving directory opencvbuild javac compiling 280 source files to 29 built target make2 leaving directory opencvbuild make2 leaving directory opencvbuild 29 built target 29 built target make2 leaving directory opencvbuild 29 built target usrbinld in function const unsigned long const undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld undefined reference to const unsigned long const usrbinld more undefined references to const unsigned long const follow usrbinld in function globalsubitypespbcc undefined reference to const cd usrlocalbincmake e cmakesymlinklibrary liblibopencvcvvso455 liblibopencvcvvso405 liblibopencvcvvso make2 leaving directory opencvbuild 32 built target opencvcvv make f make2 entering directory opencvbuild cd opencvbuild usrlocalbincmake e cmakedepends unix makefiles opencv opencvbuild color make2 leaving directory opencvbuild make f make2 entering directory opencvbuild cheers"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCannot write files in ProRes codecs\ni am attempting to write a video file using opencv in the prores 4444 codec i have tried other codecs such as xvid and the code works perfectly however no prores codec of any kind seems to be working relavent code above code specifies clipname which increments for each clip created in the loop below subclip 24 size adds frames to subclip f 0 cliprange contains new frames every time this code is run while f lencliprange f 1 printclip created subcliprelease when i run this code i get a runtime error for every attempted filewrite prores 0x7fb8e4986600 specified pixel format yuv420p is invalid or not supported error0 global 2774 open could not open codec prores error unspecified error error0 global 2791 open videoioffmpeg failed to initialize videowriter im guessing that by default opencv or ffmpeg are using the format yuv420p when trying to write these files upon checking the file path listed is invalid in fact the folder privatevarfolders has no directory named 24 and the file capffmpegimplhpp does not appear to be anywhere on my computer do i need to download this format or update some software or possibly change some settings to enable it or even update some setting to have prores encoded with a different pixel format settings opencv 453 macos 1152 on intel not apple silicon python 388 ffmpeg 422 built with clang version 401 tagsrelease401final configuration disabledoc enableavresample enablegmp enablelibfreetype enablelibvpx enablepthreads enablelibopus enablepostproc enablepic enablepthreads enableshared enablestatic enableversion3 enablezlib enablelibmp3lame disablenonfree enablegpl enablegnutls disableopenssl enablelibopenh264 enablelibx264 libavutil 56 31100 56 31100 libavcodec 58 54100 58 54100 libavformat 58 29100 58 29100 libavdevice 58 8100 58 8100 libavfilter 7 57100 7 57100 libavresample 4 0 0 4 0 0 libswscale 5 5100 5 5100 libswresample 3 5100 3 5100 libpostproc 55 5100 55 5100"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpencv error with GPU backend\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue that can be processed as quickly as possible this is the bug reporting section for the opencv library system information version opencv 455dev operating system platform ubuntu 20 compiler gcc detailed description i cannot run anymore my cv2dnn on gpu i tried to run the code in cpu and its workings i also tested with the older version of opencv and is working i think the new commit merged in february changed the dnn output is an nparray and is not compatible with 455 release version could you please give an example of how to use the new output steps to reproduce python with cuda enabled net netsetinputimage results netforward issue submission checklist i report the issue its not a question opencv team works with forumopencvorg stack overflow and other communities to discuss problems tickets with questions without a real issue statement will be closed x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution places to check opencv documentation faq page opencv forum opencv issue tracker stack overflow branch x i updated to the latest opencv version and the issue is still there master branch for opencv 4x and 34 branch for opencv 3x releases opencv team supports only the latest release for each branch the ticket is closed if the problem is not reproduced with the modern version there is reproducer code and related data files videos images onnx etc the best reproducer test case for opencv that we can add to the library recommendations for media files and binary files try to reproduce the issue with images and videos in opencvextra repository to reduce attachment size use png for images if you report some cv related bug but not image reader issue attach the image as an archive to the ticket if you report some reader issue image hosting services compress images and it breaks the repro code provide onnx file for some public model or onnx file with random weights if you report onnx parsing or handling issue architecture details diagram from netron tool can be very useful too see"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWarning: libmediandk.so, needed by ../../lib/arm64-v8a/libopencv_videoio.so, not found (try using -rpath or -rpath-link)\nhi i was trying to cross compile opencv for android my ndk version is 19 and api level is 28 the make is crashing stating warning libmediandkso was not found any guidance on rectifying the issue will be useful image i used the instructions here for the same the cmake command i used is cmake dbuildjavaoff dandroidstlcshared dbuildsharedlibson dandroidabiarm64v8a dcmakecxxflagsllog"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to Compile GAPI Code returning contours from cv::gapi::findContours\nsystem information version opencv 455 operating system platform windows 10 64 bit compiler visual studio 2017 c14 2022 c141720 detailed description i have compiled version 455 on windows with visual studio i am unable to compile code dealing with gapi that calls findcontours and returns the contours in my example i have a conditional compilation that returns a gmat instead of contours the code compiles compiler error from vs error list window error c2338 type not found testgapi 37 compiler warning from vs output window error c2338 type not found message see reference to class template instantiation being compiled 1 with 1 1 targetint 1 message see reference to class template instantiation being compiled 1 with 1 1 targetint 1 message see reference to class template instantiation being compiled 1 with 1 1 targetint 1 message see reference to class template instantiation being compiled 1 with 1 1 targetint 1 message see reference to class template instantiation being compiled 1 with 1 1 targetint 1 message see reference to class template instantiation being compiled 1 with 1 1 targetint 1 message see reference to class template instantiation cvutiltypelistindex being compiled message see reference to function template instantiation being compiled 1 with 1 1 tyint 1 tint 1 message see reference to function template instantiation being compiled 1 with 1 1 tyint 1 tint 1 message see reference to function template instantiation cvgprotoargs being compiled message see reference to function template instantiation cvgprotoinputargs cvgincvgmat int int being compiled 1done building project testgapivcxproj failed steps to reproduce include include include include include define doesnotcompile 1 comment this line to compile successfully cvgcomputation mgcomputation cvgmat in ifdef doesnotcompile int numdilation int numerosions else int numdilation3 int numerosions3 endif cvgmat cvsize11 11 00 mask cvgapierode3x3mask numerosions mask cvgapidilate3x3mask numdilation ifdef doesnotcompile cvgarray contours return cvgoutcontours else return cvgcomputationin mask endif const cvscalar whitecvscalar255 int mainint argc char argv int ndilation3 nerosions3 rw60 rh40 ofs50 lw1 int xofs yofsi cvmat inputcvmatzeros640 480 cv8uc1 for i 0 i 3 i cvrectangleinput cvrectx y rw rh white lw cvfilled x rw ofs y rh ofs ifdef doesnotcompile stdvector contours else cvmat output endif ifdef doesnotcompile if contoursempty stdcout no contours found stdendl else stdcout found contourssize contours stdendl endif return 0"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHow to confirm the version of the OpenCV 3rdParty libs\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library system information version opencv 452 operating system platform linux compiler gcc version 485 detailed description i need to obtain each software version in the 3rdparty directory in the source code of opencv 452 to analyze whether opencv 452 has dependency vulnerabilitiesbut the thirdparty software version is not found in the code repository or in the documentfor example the versions of opensource software such as carotene cpufeatures ippicv and ittnotify cannot be confirmed image steps to reproduce issue submission checklist x i report the issue its not a question opencv team works with forumopencvorg stack overflow and other communities to discuss problems tickets with questions without a real issue statement will be closed x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution places to check opencv documentation faq page opencv forum opencv issue tracker stack overflow branch x i updated to the latest opencv version and the issue is still there master branch for opencv 4x and 34 branch for opencv 3x releases opencv team supports only the latest release for each branch the ticket is closed if the problem is not reproduced with the modern version there is reproducer code and related data files videos images onnx etc the best reproducer test case for opencv that we can add to the library recommendations for media files and binary files try to reproduce the issue with images and videos in opencvextra repository to reduce attachment size use png for images if you report some cv related bug but not image reader issue attach the image as an archive to the ticket if you report some reader issue image hosting services compress images and it breaks the repro code provide onnx file for some public model or onnx file with random weights if you report onnx parsing or handling issue architecture details diagram from netron tool can be very useful too see"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrelocation R_X86_64_PC32 against symbol `ff_pw_9' can not be used when making a shared object; recompile with -fPIC\nsystem information version detected processor x8664 could not find pythoninterp missing pythonexecutable required is at least version 27 looking for ccache not found found zlib found suitable version 1211 minimum required is 123 could not find openjpeg minimal suitable version 20 recommended version 231 could not find jasper missing jasperlibraries jasperincludedir found zlib found version 1211 checking for module gtk30 no package gtk30 found cuda detected 114 cuda using cuda nvcc target flags could not find openblas include turning openblasfound off could not find openblas lib turning openblasfound off could not find atlas missing a library with lapack api found vtk is not found please set dvtkdir in cmake to vtk build directory or to vtk install subdirectory with vtkconfigcmake file opencv python during development append to pythonpath checking for module libavresample no package libavresample found checking for module gstreamerbase10 no package gstreamerbase10 found checking for module gstreamerapp10 no package gstreamerapp10 found checking for module gstreamerriff10 no package gstreamerriff10 found checking for module gstreamerpbutils10 no package gstreamerpbutils10 found checking for module libdc13942 no package libdc13942 found caffe no protobuf no glog no freetype2 yes ver 23117 harfbuzz yes ver 264 could not find hdf5 missing hdf5libraries hdf5includedirs found version julia not found not compiling julia bindings module opencvovis disabled because ogre3d was not found no preference for use of exported gflags cmake configuration set and no hints for includelibrary directories provided defaulting to preferring an installedexported gflags cmake configuration if available failed to find installed gflags cmake configuration searching for gflags build directories exported with cmake failed to find gflags failed to find an installedexported cmake configuration for gflags will perform search for installed gflags components failed to find gflags could not find gflags include directory set gflagsincludedir to directory containing gflagsgflagsh failed to find glog could not find glog include directory set glogincludedir to directory containing glogloggingh module opencvsfm disabled because the following dependencies are not found gloggflags checking for module tesseract no package tesseract found tesseract no allocator metrics storage type long long registering hook general configuration for opencv 440 version control unknown extra modules location extra version control extra unknown platform timestamp 20220117t071453z host linux 511046generic x8664 cmake 3163 cmake generator unix makefiles cmake build tool usrbinmake configuration release cpuhw features baseline sse sse2 sse3 requested sse3 dispatched code generation sse41 sse42 fp16 avx avx2 avx512skx requested sse41 sse42 avx fp16 avx2 avx512skx sse41 14 files ssse3 sse41 sse42 1 files ssse3 sse41 popcnt sse42 fp16 0 files ssse3 sse41 popcnt sse42 fp16 avx avx 4 files ssse3 sse41 popcnt sse42 avx avx2 28 files ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 avx512skx 4 files ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 avx512f avx512common avx512skx cc built as dynamic libs yes c standard 11 c compiler usrbinc ver 930 c flags release fsignedchar w wall werrorreturntype werrornonvirtualdtor werroraddress werrorsequencepoint wformat werrorformatsecurity wmissingdeclarations wundef winitself wpointerarith wshadow wsignpromo wuninitialized winitself wsuggestoverride wnocomment wnostrictoverflow wnolonglong pthread fomitframepointer ffunctionsections fdatasections msse msse2 msse3 fvisibilityhidden o3 dndebug dndebug c flags debug fsignedchar w wall werrorreturntype werrornonvirtualdtor werroraddress werrorsequencepoint wformat werrorformatsecurity wmissingdeclarations wundef winitself wpointerarith wshadow wsignpromo wuninitialized winitself wsuggestoverride wnocomment wnostrictoverflow wnolonglong pthread fomitframepointer ffunctionsections fdatasections msse msse2 msse3 fvisibilityhidden g o0 ddebug ddebug c compiler usrbincc c flags release fsignedchar w wall werrorreturntype werroraddress werrorsequencepoint wformat werrorformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wuninitialized winitself wnocomment wnostrictoverflow wnolonglong pthread fomitframepointer ffunctionsections fdatasections msse msse2 msse3 fvisibilityhidden o3 dndebug dndebug c flags debug fsignedchar w wall werrorreturntype werroraddress werrorsequencepoint wformat werrorformatsecurity wmissingdeclarations wmissingprototypes wstrictprototypes wundef winitself wpointerarith wshadow wuninitialized winitself wnocomment wnostrictoverflow wnolonglong pthread fomitframepointer ffunctionsections fdatasections msse msse2 msse3 fvisibilityhidden g o0 ddebug ddebug linker flags release wlgcsections wlasneeded linker flags debug wlgcsections wlasneeded ccache no precompiled headers no extra dependencies dl m pthread rt cudart nppc nppial nppicc nppidei nppif nppig nppim nppist nppisu nppitc npps cublas cudnn cufft lusrlocalcudalib64 3rdparty dependencies opencv modules to be built alphamat aruco bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnnobjdetect dnnsuperres dpm features2d flann freetype fuzzy hfs highgui imghash imgcodecs imgproc intensitytransform linedescriptor ml objdetect optflow phaseunwrapping photo plot quality rapid reg rgbd saliency shape stereo stitching structuredlight superres surfacematching text tracking ts video videoio videostab xfeatures2d ximgproc xobjdetect xphoto disabled face pythontests world disabled by dependency unavailable cnn3dobj cvv gapi hdf java js julia matlab ovis python2 python3 sfm viz applications apps documentation no nonfree algorithms yes gui gtk yes ver 22432 gthread yes ver 2646 gtkglext no vtk support no media io zlib ver 1211 jpeg ver 80 webp build ver encoder 0x020f png ver 1637 tiff build ver 42 4010 jpeg 2000 build jasper ver 19001 openexr build ver 230 hdr yes sunraster yes pxm yes pfm yes video io dc1394 no ffmpeg yes avcodec yes 58134100 avformat yes 5876100 avutil yes 5670100 swscale yes 59100 avresample no gstreamer no v4lv4l2 yes linuxvideodev2h parallel framework pthreads trace yes with intel itt other thirdparty libraries lapack no eigen yes ver 337 custom hal no protobuf build 351 nvidia cuda yes ver 114 cufft cublas nvidia gpu arch 35 37 50 52 60 61 70 75 80 nvidia ptx archs cudnn yes ver 824 opencl yes no extra features include path link libraries dynamic load python for build usrbinpython3 install to usrlocal configuring done detailed description usrbinld relocation rx8664pc32 against symbol ffpw9 can not be used when making a shared object recompile with fpic usrbinld 最后的链结失败 bad value collect2 error ld returned 1 exit status make2 错误 1 make1 错误 2 make1 正在等待未完成的任务 i dont know whether this error is caused by ffmpeg or opencv steps to reproduce enable to system information version issue submission checklist i report the issue its not a question opencv team works with forumopencvorg stack overflow and other communities to discuss problems tickets with question without real issue statement will be closed x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found solution places to check opencv documentation faq page opencv forum opencv issue tracker stack overflow branch i updated to latest opencv version and the issue is still there master branch for opencv 4x and 34 branch for opencv 3x releases opencv team supports only latest release for each branch the ticket is closed if the problem is not reproduced with modern version there is reproducer code and related data files videos images onnx etc the best reproducer test case for opencv that we can add to the library recommendations for media files and binary files try to reproduce the issue with images and videos in opencvextra repository to reduce attachment size use png for images if you report some cv related bug but not image reader issue attach the image as archive to the ticket if you report some reader issue image hosting services compress images and it breaks the repro code provide onnx file for some public model or onnx file with with random weights if you report onnx parsing or handling issue architecture details diagram from netron tool can be very useful too see"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncompile opencv with inference-engine\nhello when i use cmake to compile opencv with inferenceengine i get problem next image how to solve it"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAndroid NDK 23b LTS Compile Error \nhey please advise changes required i can pr fixes following error for arm64x86x8664 when targeting ndk 23b error at message android cmakeandroidarmmode is set but is valid only for armeabi all is working with ndk target 21b in all architectures with the following build script system information version opencv 455 operating system platform macos arm 64 bit m1 compiler clang detailed description androidconfigure cmake config ndkvesionmajor 23 ndkplatform android21 androidndkhome sysroot toolchain ar cmake error at message android cmakeandroidarmmode is set but is valid only for armeabi architectures call stack most recent call first include cmakeliststxt113 enablelanguage cmake error cmake was unable to find a build program corresponding to unix makefiles cmakemakeprogram is not set you probably need to select a different build tool configuring incomplete errors occurred received error compilation successful in ndk 23b armv7a armv7 failures in x86 x8664 armv8a arm64 steps to reproduce cmake compile rm rf buildfolder mkdir buildfolder cd buildfolder if abi armeabiv7a then export elif abi arm64v8a then export elif abi x8664 then export elif abi x86 then export fi androidndkndkroot export echo androidndk pwd cmake dcmakeccompilercc dcmakecxxcompilercxx stdliblibc o3 fpic stdliblibc o3 fpic armmode d dandroidabiabi d d d buildopencvvideooff d d d buildopencvflannoff d buildopencvhighguion d buildopencvmlon d buildopencvphotooff d buildopencvpythonoff d buildopencvshapeoff d d d buildopencvtsoff d d withmatlaboff d withcudaoff dbuildsharedlibsoff dbuilddocsoff dbuildexamplesoff dbuildfatjavaliboff dbuildjasperoff dbuildpackageoff dbuildopencvjavaoff dbuildopencvappsoff dbuildjpegoff dbuildpngoff dwithcaroteneoff dwithcpufeaturesoff dwithtiffoff dwithopenexroff dwith1394off dwithjpegoff dwithpngoff dwithffmpegoff dwithopencloff dwithgigeapioff dwithcudaoff dwithcufftoff dwithjasperoff dwithimageiooff dwithippoff dwithopennioff dwithqtoff dwithv4loff dwithpvapioff dwitheigenoff dbuildtestsoff dandroidndkndkroot dandroidabiabi dandroidstlcstatic dbuildperftestsoff make jparallelmake make install issue submission checklist x i report the issue its not a question opencv team works with forumopencvorg stack overflow and other communities to discuss problems tickets with question without real issue statement will be closed x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found solution places to check opencv documentation faq page opencv forum opencv issue tracker stack overflow branch x i updated to latest opencv version and the issue is still there master branch for opencv 4x and 34 branch for opencv 3x releases opencv team supports only latest release for each branch the ticket is closed if the problem is not reproduced with modern version x there is reproducer code and related data files videos images onnx etc the best reproducer test case for opencv that we can add to the library recommendations for media files and binary files try to reproduce the issue with images and videos in opencvextra repository to reduce attachment size use png for images if you report some cv related bug but not image reader issue attach the image as archive to the ticket if you report some reader issue image hosting services compress images and it breaks the repro code provide onnx file for some public model or onnx file with with random weights if you report onnx parsing or handling issue architecture details diagram from netron tool can be very useful too see"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nhaarcascade_frontalcatface muslim women detection\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library system information version example opencv 42 operating system platform windows 64 bit compiler visual studio 2017 opencv greyquestion operating system platform greyquestion compiler greyquestion detailed description the cant detect faces of mulsim women who wear hijab also it didnt work in detecting far faces some children faces although it is clear like this image steps to reproduce to add code example fence it with triple backticks and optional file extension cpp c code example or attach as txt or zip file issue submission checklist i report the issue its not a question opencv team works with forumopencvorg stack overflow and other communities to discuss problems tickets with question without real issue statement will be closed i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found solution places to check opencv documentation faq page opencv forum opencv issue tracker stack overflow branch i updated to latest opencv version and the issue is still there master branch for opencv 4x and 34 branch for opencv 3x releases opencv team supports only latest release for each branch the ticket is closed if the problem is not reproduced with modern version there is reproducer code and related data files videos images onnx etc the best reproducer test case for opencv that we can add to the library recommendations for media files and binary files try to reproduce the issue with images and videos in opencvextra repository to reduce attachment size use png for images if you report some cv related bug but not image reader issue attach the image as archive to the ticket if you report some reader issue image hosting services compress images and it breaks the repro code provide onnx file for some public model or onnx file with with random weights if you report onnx parsing or handling issue architecture details diagram from netron tool can be very useful too see"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[ONNX] inference different result between Python and C++\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library system information opencv 44 operating system platform macos compiler gcc11 detailed description with same modelsame imageonnx inference diffrent result between python and c model download link image download link steps to reproduce with python code below python import cv2 import numpy as np img cv2imreaddatatestjpg img img npfloat32img net blobimage 117 123falsefalse outnames netsetinputblobimage outs netforwardoutnames locconf outs boxes loc0tolist scores conf0tolist loc 45279x4 conf 45279x2 with openpyoutcsv w as f for i in rangelenboxes if scoresi1099 continue printscoresi1 line fwriteline i get 83 locsscore099and this is python eval result top 7 lines pyoutcsv 83 lines in total while c code only get 29 locsscore099 c include include include include include using namespace std using namespace cv int main string modelpath string imagepath datatestjpg mat clr mat imageblobconfloc resizeclr image size 25 25 interlinear blob 10 sizeimagecols imagerows scalar1040 1170 1230 false false auto net netsetinputblob stdvector outlayernames stdvector outs netforwardouts outlayernames matouts0size1 outs0size2 cv32f outs0datacopytoloc matouts1size1 outs1size2 cv32f outs1datacopytoconf ofstream ofsoutcsv for int i 0 i confrows i if confati 1 0999 ofs i 0 i 1 i 2 i 3 i 1 endl ofsclose and this is c eval result top 7 lines csv outcsv 29 lines in total"}, {"role": "assistant", "content": "question"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nadd Intel® oneAPI DPC++/C++ Compiler (icx)\nintelregistered c compiler classic icc is deprecated and will be removed in a oneapi release in the second half of 2023 deprecation notice this commit is intended to add support for the nextgeneration compiler intelregistered oneapi dpcc compiler icx the documentation for the compiler is available on the link pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCUDA compilation is not using ccache\nsystem information opencv version 480 operating system platform ubuntu 20046 lts compiler compiler version gcc 940 cuda 114 detailed description using ccache 377 ubuntu version or latest version 482 ccache is found by opencvs cmake but used only to compile cc steps to reproduce cd opencv mkdir build cd build cmake dwithcudaon dcudaarchbin72 verbose1 make opencvcore verbose1 make opencvcudaimgproc we could see that ccache is used for c files 22 building cxx object cd usrbinccache usrbinc dcvapiexports long dopencvwithitt1 dusemathdefines dopencvbuild1 dstdcconstantmacros dstdcformatmacros dstdclimitmacros dhavemalloch1 dhavememalign1 dhaveposixmemalign1 isystem fsignedchar w wall wreturntype wnonvirtualdtor waddress wsequencepoint wformat wformatsecurity wmissingdeclarations winitself wpointerarith wsignpromo wuninitialized wsuggestoverride wnocomment wnostrictoverflow wnolonglong pthread fomitframepointer ffunctionsections fdatasections msse msse2 msse3 fvisibilityhidden wnoundef wnoenumcompare wnounusedfunction wnoshadow o3 dndebug dndebug stdc11 fpic md mt mf o c but cuda files are not cached 14 building nvcc device object cd e makedirectory cd d verbosebool1 d d d p removing e rm f generating dependency file m dcudacc o ccbin usrbincc m64 dusemathdefines dstdcconstantmacros dstdclimitmacros dstdcformatmacros dopencvwithitt1 long dopencvbuild1 xcompiler gencode dforceinlines xcompiler dcvapiexports xcompiler fpic stdc14 dnvcc generating temporary cmake readable file d d d verbose1 p copy if different to e copyifdifferent removing and e rm f generating c o ccbin usrbincc m64 dusemathdefines dstdcconstantmacros dstdclimitmacros dstdcformatmacros dopencvwithitt1 long dopencvbuild1 xcompiler gencode dforceinlines xcompiler dcvapiexports xcompiler fpic stdc14 dnvcc i would expect the last line to use ccache issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nConvert BGR to RGB NOW!!!\ndescribe the feature and motivation the reason why the early developers at opencv chose bgr color format is probably that back then bgr color format was popular among camera manufacturers and software providers eg in windows when specifying color value using colorref they use the bgr format 0x00bbggrr bgr was a choice made for historical reasons and now we have to live with it in other words bgr is the horse’s ass in opencv rgb revolution give a like if you support the cause additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nG-API: Support DirectML Execution Provider for ONNXRT Backend\npull request readiness checklist see details at i agree to contribute to the project under apache 2 license to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nGoogle Summer of Code Support ONNX operator gather elements\npull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake this is a draft pull request for gsoc review purposes edits need to be made"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfeat: update NumPy type to Mat type fail message\noutput string representation of numpy array type if it is not convertible to opencv mat type example output from the test cv2error opencv480dev 1 error 5bad argument in function dumpinputarray overload resolution failed argument data type object is not supported expected ptr for argument argument resolves 23106 pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nExpose list of VideoCapture devices\ndescribe the feature and motivation there is no way currently within opencv to list existing devices to let the user select them this means that they must be obtained in a different manner either by reimplementing manually or using a thirdparty library which may not match opencvs indexes and may not work on all platforms there is a workaround to try every indexes individually but this has 4 main issues 1 some videocapture devices will freeze if opened and closed quickly or if it was already in use the popular sd capture card gvusb2 confirmed myself ive had reports that an avermedia capture card is affected as well 2 some devices take a long time to boot making this technique quite slow like my logitech c920 webcam 3 the total amount of devices is unknown and usable devices may not be sequential so we have to guess how many devices maximum the user may have trying to balance between time spent or risking missing some 4 even if you get all the ids after this you dont have access to the names to present to the user see 23537 additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd single image support to VideoCapture\npull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdded Aruco-based QR code detection method to python sample\npull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nWeird behaviour when I use Image2BlobParams\ndescribe the feature and motivation full post is my code in python paramtf2cedn cvdnndnnlayoutnhwc paramtf2cednddepth cvcv32f paramtf2cednmean 128 128 128 1 128 paramtf2cednsize 224 224 paramtf2cednswaprb false cvdnndnnpmodenull result is 00078125 10 10 10 in c image2blobparams paramtf2cedn dnnlayoutnhwc paramtf2cednddepth cv32f paramtf2cednmean 128 128 128 1 128 paramtf2cednsize size224 224 paramtf2cednswaprb false dnnpmodenull cout endl result is 00078125 0 0 0 difference is in constructor thanks to zihaomu i think something must be write in doc or constructor change additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpenCV(4.7.0-dev) Error: Assertion failed (interp_mode != \"tf_half_pixel_for_nn\") \nsystem information general configuration for opencv 470dev version control 470389g9fa014edcd extra modules location extra version control extra 47054g8dfeed73 platform timestamp 20230605t094958z host windows 10022621 amd64 cmake 3261 cmake generator visual studio 17 2022 cmake build tool cprogram filesmicrosoft visual msvc 1935 configuration debug release cpuhw features baseline sse sse2 sse3 requested sse3 dispatched code generation sse41 sse42 fp16 avx avx2 avx512skx requested sse41 sse42 avx fp16 avx2 avx512skx sse41 18 files ssse3 sse41 sse42 2 files ssse3 sse41 popcnt sse42 fp16 1 files ssse3 sse41 popcnt sse42 fp16 avx avx 8 files ssse3 sse41 popcnt sse42 avx avx2 36 files ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 avx512skx 8 files ssse3 sse41 popcnt sse42 fp16 fma3 avx avx2 avx512f avx512common avx512skx cc built as dynamic libs yes c standard 11 c compiler cprogram filesmicrosoft visual ver 1935322150 c flags release dwin32 dwindows w4 gr d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise eha wd4127 wd4251 wd4324 wd4275 wd4512 wd4589 wd4819 mp md o2 ob2 dndebug c flags debug dwin32 dwindows w4 gr d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise eha wd4127 wd4251 wd4324 wd4275 wd4512 wd4589 wd4819 mp mdd zi ob0 od rtc1 c compiler cprogram filesmicrosoft visual c flags release dwin32 dwindows w3 d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise mp md o2 ob2 dndebug c flags debug dwin32 dwindows w3 d crtsecurenodeprecate d d sclsecurenowarnings gy bigobj oi fpprecise mp mdd zi ob0 od rtc1 linker flags release machinex64 incrementalno linker flags debug machinex64 debug incremental ccache no precompiled headers yes extra dependencies cudartstaticlib nppclib nppiallib nppicclib nppideilib nppiflib nppiglib nppimlib nppistlib nppisulib nppitclib nppslib cublaslib cudnnlib cufftlib libpathcprogram filesnvidia gpu computing 3rdparty dependencies opencv modules to be built alphamat aruco barcode bgsegm bioinspired calib3d ccalib core cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev datasets dnn dnnobjdetect dnnsuperres dpm face features2d flann fuzzy gapi hfs highgui imghash imgcodecs imgproc intensitytransform java linedescriptor mcc ml objdetect optflow phaseunwrapping photo plot python3 quality rapid reg rgbd saliency sfm shape stereo stitching structuredlight superres surfacematching text tracking ts video videoio videostab viz wechatqrcode xfeatures2d ximgproc xobjdetect xphoto disabled world disabled by dependency unavailable cvv freetype hdf julia matlab ovis python2 applications tests perftests examples apps documentation doxygen python javadoc nonfree algorithms yes windows rt support no gui win32ui win32 ui yes opengl support yes opengl32 glu32 vtk support yes ver 925 media io zlib optimized debug ver 1213 jpeg buildlibjpegturbo ver 21362 simd support request yes simd support no webp build ver encoder 0x020f png optimized debug ver 1640 tiff build ver 42 420 jpeg 2000 build ver 250 openexr build ver 230 hdr yes sunraster yes pxm yes pfm yes video io dc1394 no ffmpeg yes prebuilt binaries avcodec yes 58134100 avformat yes 5876100 avutil yes 5670100 swscale yes 59100 avresample yes 400 gstreamer no directshow yes media foundation yes dxva yes parallel framework concurrency other thirdparty libraries intel ipp 20218 202180 at intel ipp iw sources 202180 at lapack yes cprogram files cprogram files cprogram files openvino yes 202230 eigen yes ver custom hal no protobuf build 3191 flatbuffers builtin3rdparty 2359 nvidia cuda yes ver 121 cufft cublas nvidia gpu arch 86 nvidia ptx archs cudnn yes ver 880 opencl yes nvd3d11 include path link libraries dynamic load python 3 interpreter cprogram ver 31010 libraries optimized cprogram debug cprogram ver 31010 numpy ver 1235 install path python for build cprogram java ant ver 11013 jni cprogram cprogram cprogram java wrappers yes java tests yes install to cinstallopencv detailed description i train my own cedn network using tensorflow 2120 i used this script to freeze and convert pb to onnx freeze model import tensorflow as tf from tensorflow import keras from import import numpy as np from tensorflowpythonutil import compat from tf2onnx import tfloader from tf2onnxtfonnx import processtfgraph from tf2onnxoptimizer import optimizegraph from tf2onnx import utils constants from tf2onnxhandler import tfop class def initself superinit def callselfyvraiypred mse1 0 1 2 mse2 tfreducesumyvrai tfsquareyvraiypred 0 1 2 return 10mse2mse1 monmodele compilefalse infer f frozenfunc graphdef outputnames outname for out in frozenfuncoutputs inputnames inpname for inp in frozenfuncinputs extraopset 1 with tfgraphasdefault as tfgraph name with g inputnamesinputnames extraopsetextraopset onnxgraph optimizegraphg modelproto modelproto printconversion onnx complete i tried too python m tf2onnxconvert savedmodel ctmplogdirtocdcednpb output ctmpcednonnx opset 11 but results does not change opset must be 11 my c code is dnnnet mynet mynet i run program and i ve got an execption debug011168 global systemcpp2842 core update fp mxcsr flags 0x00009fe0 debug011172 global onnximportercpp269 dnnonnx processing onnx model from file ctmpcednmodel2bonnx info011687 global onnximportercpp835 dnnonnx loading onnx v8 model produced by tf2onnx1140 8f8d49 number of nodes 54 initializers 45 inputs 1 outputs 1 debug011689 global onnximportercpp723 dnnonnx using nonstandard onnx opset1 domainaionnxml version2 debug011689 global onnximportercpp723 dnnonnx using nonstandard onnx opset2 domainaionnxcontrib version1 info011689 global onnximportercpp728 dnnonnx onnx opset version 15 info011690 global onnximportercpp743 dnnonnx unknown domainaionnxcontrib version15 no dispatch map you may need to register custom layers info011690 global onnximportercpp743 dnnonnx unknown domainaionnxml version15 no dispatch map you may need to register custom layers debug011700 global onnximportercpp842 dnnonnx graph simplified to 54 nodes global onnximportercpp365 dnnonnx initializer0 as scales146 shape 4 datatype1 global onnximportercpp365 dnnonnx initializer1 as roi133 shape 0 datatype1 global onnximportercpp365 dnnonnx initializer2 as newshape187 shape 4 datatype7 global onnximportercpp365 dnnonnx initializer3 as shape 256 128 3 3 datatype1 global onnximportercpp365 dnnonnx initializer4 as shape 128 datatype1 global onnximportercpp365 dnnonnx initializer5 as shape 128 128 3 3 datatype1 global onnximportercpp365 dnnonnx initializer6 as shape 128 datatype1 global onnximportercpp365 dnnonnx initializer7 as shape 128 64 3 3 datatype1 global onnximportercpp365 dnnonnx initializer8 as shape 64 datatype1 global onnximportercpp365 dnnonnx initializer9 as shape 1 datatype1 global onnximportercpp365 dnnonnx initializer10 as shape 1 32 5 5 datatype1 global onnximportercpp365 dnnonnx initializer11 as shape 32 datatype1 global onnximportercpp365 dnnonnx initializer12 as shape 64 64 3 3 datatype1 global onnximportercpp365 dnnonnx initializer13 as shape 32 64 5 5 datatype1 global onnximportercpp365 dnnonnx initializer14 as shape 64 datatype1 global onnximportercpp365 dnnonnx initializer15 as shape 64 128 5 5 datatype1 global onnximportercpp365 dnnonnx initializer16 as shape 128 datatype1 global onnximportercpp365 dnnonnx initializer17 as shape 128 256 5 5 datatype1 global onnximportercpp365 dnnonnx initializer18 as shape 256 datatype1 global onnximportercpp365 dnnonnx initializer19 as shape 256 512 5 5 datatype1 global onnximportercpp365 dnnonnx initializer20 as shape 512 datatype1 global onnximportercpp365 dnnonnx initializer21 as shape 512 512 5 5 datatype1 global onnximportercpp365 dnnonnx initializer22 as shape 512 datatype1 global onnximportercpp365 dnnonnx initializer23 as shape 64 datatype1 global onnximportercpp365 dnnonnx initializer24 as shape 512 4096 1 1 datatype1 global onnximportercpp365 dnnonnx initializer25 as shape 4096 datatype1 global onnximportercpp365 dnnonnx initializer26 as shape 4096 512 3 3 datatype1 global onnximportercpp365 dnnonnx initializer27 as shape 512 datatype1 global onnximportercpp365 dnnonnx initializer28 as shape 512 512 3 3 datatype1 global onnximportercpp365 dnnonnx initializer29 as shape 512 datatype1 global onnximportercpp365 dnnonnx initializer30 as shape 512 512 3 3 datatype1 global onnximportercpp365 dnnonnx initializer31 as shape 512 datatype1 global onnximportercpp365 dnnonnx initializer32 as shape 512 512 3 3 datatype1 global onnximportercpp365 dnnonnx initializer33 as shape 512 datatype1 global onnximportercpp365 dnnonnx initializer34 as shape 64 3 3 3 datatype1 global onnximportercpp365 dnnonnx initializer35 as shape 512 512 3 3 datatype1 global onnximportercpp365 dnnonnx initializer36 as shape 512 datatype1 global onnximportercpp365 dnnonnx initializer37 as shape 512 512 3 3 datatype1 global onnximportercpp365 dnnonnx initializer38 as shape 512 datatype1 global onnximportercpp365 dnnonnx initializer39 as shape 512 256 3 3 datatype1 global onnximportercpp365 dnnonnx initializer40 as shape 256 datatype1 global onnximportercpp365 dnnonnx initializer41 as shape 256 256 3 3 datatype1 global onnximportercpp365 dnnonnx initializer42 as shape 256 datatype1 global onnximportercpp365 dnnonnx initializer43 as shape 256 256 3 3 datatype1 global onnximportercpp365 dnnonnx initializer44 as shape 256 datatype1 debug011770 global onnximportercpp867 dnnonnx input0 dim0 dynamic debug011770 global onnximportercpp882 dnnonnx input0 as args00 shape 0 224 224 3 debug011773 global onnximportercpp340 dnnonnx output0 dim0 dynamic debug011773 global onnximportercpp349 dnnonnx output0 as identity0 shape 0 224 224 1 info011773 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011779 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011785 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011789 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011789 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011789 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011792 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011792 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011792 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011792 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011793 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011793 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011793 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011793 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011793 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011793 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011793 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011793 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011794 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011794 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011794 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011794 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011794 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011794 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011794 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011794 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011795 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011795 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011795 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011795 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011795 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011795 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011795 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011795 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011796 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx info011796 global onnximportercpp1006 dnnonnx processing node with 1 inputs and 1 outputs from domainaionnx info011796 global onnximportercpp1006 dnnonnx processing node with 3 inputs and 1 outputs from domainaionnx opencv470dev error assertion failed interpmode tfhalfpixelfornn in file line 2772 error011802 global onnximportercpp1064 dnnonnx error during processing node with 3 inputs and 1 outputs from domainaionnx info011802 global onnximportercpp1068 input0 info011802 global onnximportercpp1068 input1 roi133 info011802 global onnximportercpp1068 input2 scales146 info011802 global onnximportercpp1072 output0 resize1370 opencv470dev error unspecified error node parse error opencv470dev error 215assertion failed interpmode tfhalfpixelfornn in function in file line 1083 steps to reproduce all data can be downloaded tf2 model onnx model issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBuild Java without ANT\npull request readiness checklist enables a path of building java bindings without ant able to build opencv jar and docs without ant java ant no jni java wrappers yes java tests no possible to build opencv jar without ant but tests still require ant merge with notes use opencvjavaignoreant1 to force java flow for building java bindings java tests still require apache ant jar doesnt include java source code files see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMoved barcode from opencv_contrib\nmerge with todo x documentation bib x tutorial references x sample app refactored x java test passes x python test passes x build without dnn forcebuilderscustom"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nExposing CV_MAKETYPE(depth, cn) and CV_8UC(n), CV_8SC(n) etc., macros to the Python binding for arbitrary channel number handling in cv2.cuda.GpuMat\ndescribe the feature and motivation it would be great to expose the following macros to the python binding c define cvmaketypedepth cn cvmatdepthdepth cn1 cvcnshift define cv8ucn cvmaketypecv8un define cv8scn cvmaketypecv8sn define cv16ucn cvmaketypecv16un define cv16scn cvmaketypecv16sn define cv32scn cvmaketypecv32sn define cv32fcn cvmaketypecv32fn define cv64fcn cvmaketypecv64fn while they arent of much use for the general python interface which uses numpy arrays with shape and dtype attributes readily available they can be useful for cuda gpumat handling consider the following code to initialize a gpumat from cuda memory from a cupy array it uses from 23371 python import cv2 import cupy as cp def cpndarray cv2cudagpumat assert lenarrshape in 2 3 cupy array must have 2 or 3 dimensions to be a valid gpumat typemap cpdtypeuint8 cv2cv8u cpdtypeint8 cv2cv8s cpdtypeuint16 cv2cv16u cpdtypeint16 cv2cv16s cpdtypeint32 cv2cv32s cpdtypefloat32 cv2cv32f cpdtypefloat64 cv2cv64f depth typemapgetarrdtype assert depth is not none unsupported cupy array dtype channels 1 if lenarrshape 2 else arrshape2 equivalent to unexposed opencv c macro depth7 channels 1 3 mattype depth channels 1 3 mat mattype return mat the mattype line would be more readable with cvmaketype available eg python mattype cv2cvmaketypedepth channels thanks in advance additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nvideoio/FFmpeg: increased packet read attempt limit, allow configuring it\nresolves 9455 related 3225 use different counters for wrong packets recieved by demuxer and errors from decoder allow modifying these counters via environment variables added logging when reading breaks at one of error limits notes ive been able to reproduce original issue with a video file with 14 total streams video audio subtitles at some point in the video only packets from the last stream are being sent by the demuxer thus exceeding our limit for my specific video total number of packets from wrong stream was about 2700 ive chosen 4096 as default value default limit of decoding attempts is quite low because im not sure in which cases it can be exceeded network stream i tried to read 8k video from the disk but it did not cause break at decode point"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd AVIF support through libavif.\nthis is to fix extra pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd int64, uint64, bool, uint data type.\nsince we only have three bits for the data type this pr wants to expand the number of bits of the data type to 4 bits at present there are many aspects of this pr that have not been considered any suggestions are welcome pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUnable to call LMSolver in python.\ndescripe the feature and motivation i want to solve a levenbergmarquardt problem with lmsolver or cvlevmarq in opencv but i find i cant call lmsolver or cvlevmarq with python are these two interfaces not available in python additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nMeta's Segment Anything with dnn\ndescripe the feature and motivation a novel model with published trained weights x export model to onnx need to export carefully see below for details x model can be imported with dnn requires a fix for expand to support broadcast axis 1 x model can be inferred compare accuracy with pytorch create a sample additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNewton PNP Solver\nnewtonpnp realtime visual navigation for autonomous toydrones ibrahim jubran fares fares yuval alfassi firas ayoub dan feldman link for the article with information and proof of working the perspectivenpoint problem aims to estimate the relative pose between a calibrated monocular camera and a known 3d model by aligning pairs of 2d captured image points to their corresponding 3d points in the model we suggest an algorithm that runs on weak iot devices in realtime but still provides provable theoretical guarantees for both running time and correctness existing solvers provide only one of these requirements our main motivation was to turn the popular djis tello drone 90gr 100 into an autonomous drone that navigates in an indoor environment with no external humanlaptopsensor by simply attaching a raspberry pi zero 9gr 25 to it this tiny microprocessor takes as input a realtime video from a tiny rgb camera and runs our pnp solver onboard extensive experimental results open source code and a demonstration video are included pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nrequest emplace_back() in class Mat defined in mat.hpp\ndescripe the feature and motivation c11 introduce emplaceback into stl which can inplace constructe that can improve performance i am trying to working on it add a similar one to mat but i am new to this project and i dont think i can do it very well so i issued this issue if anyone want to work on this i may help something additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd  ScrollWheel in Cocoa \npull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nimshow速度太慢，如何能加快imshow\ndescripe the feature and motivation additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpenCV cannot import ONNX model: Inconsistent shape for ConcatLayer in function 'cv::dnn::ConcatLayerImpl::getMemoryShapes'\nsystem information opencv python operating system platform windows 10 64 bit python 3104 detailed description i converted the modnetmobilenetv2 model from paddleseg to onnx opencv cannot load the model i do not get any errors or warnings from netron find the offending model here error00123 global onnximportercpp1055 dnnonnx error during processing node with 2 inputs and 1 outputs from domainaionnx traceback most recent call last file line 99 in model cv2error opencv470dev error 2unspecified error in function node parse error opencv470dev error 201incorrect size of input array inconsistent shape for concatlayer in function steps to reproduce load model with the following code python model issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndnn(tflite): add 3rdparty flatbuffers with pre-generated schema\nrelates 23161 apache 20 todo x fix build issues 32bit and static libraries x fix tests x readme and licensing information winlinux avx2linux buildsharedcustomoff buildsharedcustom winoff xbuildsharedlinux avx2off"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nvideoio: add support for Orbbec Femto Mega RGB-D camera\nvideoio add support for orbbec femto mega rgbd camera about femto mega new feature be able to open the depth and color stream of the orbbec femto mega camera bug fix obsensor：fix the problem that takes too long to turn off the stream on windows platform x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch os compiler camera result windows11 vs2022msvc173 femto mega pass ubuntu2204 gcc112 femto mega pass"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfeat: named arguments handling in Python interface\nnamed arguments handling backport from pr 19156 to 4x branch different arguments and code generation logic is used for easier integration with pr 14590 named arguments mimic normal arguments and reveal their nature only during function call interopt pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpenCV 4.7.0 Huawei CANN support error: CANN graph check failed in function ‘compileCannGraph’ \nsystem information opencv version 470 operating system platform ubuntu 1804 compiler compiler version gcc 750 detailed description i’m testing huawei ascend cann hardware the example code is as in huawei cann backend · opencvopencv wiki · github but the sample code result in error error00822 global netcanncpp286 compilecanngraph cann graph check failed ret 4294967295 terminate called after throwing an instance of ‘cvexception’ what opencv470 error 2unspecified error cann graph check failed in function ‘compilecanngraph’ error01427 global netcanncpp286 compilecanngraph cann graph check failed ret 4294967295 terminate called after throwing an instance of ‘cvexception’ what opencv470 error 2unspecified error cann graph check failed in function ‘compilecanngraph’ error01959 global opcanncpp258 loadtodevice cann check failed ret 100000 terminate called after throwing an instance of ‘cvexception’ what opencv470 error 2unspecified error cann check failed in function ‘loadtodevice’ aborted core dumped i checked opencv 47 and cann installation seems fine canns own sample code could run as well steps to reproduce include include include opencv2opencvhpp void preprocessconst cvmat src cvmat dst srcconverttodst cv32fc3 cvcvtcolordst dst cvcolorbgr2rgb center crop cvresizedst dst cvsize256 256 cvrect roi16 16 224 224 dst dstroi dst 102550 cvsize cvscalar0485 0456 0406 cvdividedst cvscalar0229 0224 0225 dst void softmaxconst cvmat src cvmat dst int axis1 using namespace cvdnn layerparams lp net netsoftmax softmax lp cvmat out netsoftmaxforward outcopytodst int mainint argc char argv using namespace cv mat image imreadpathtoimage replace with the path to your image mat inputblob preprocessimage inputblob dnnnet net replace with the path to the model netsetinputinputblob mat out mat prob softmaxout prob 1 double minval maxval point minloc maxloc minmaxlocprob minval maxval minloc maxloc stdcout cvformatcls d score 4fn maxlocx maxval return 0 the onnx model is as link issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCancel prints in roiSelector.cpp\ndescripe the feature and motivation hello is it possible to add a boolean argument to the cv2roiselector method to prevent the method to print the following messages select a roi and then press space or enter button cancel the selection process by pressing c button thanks additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTFLite models importer\npull request readiness checklist merge with resolves how to build tested on ubuntu 2004 git clone b v23121 cmake s flatbuffers b fbsbuild cmake build fbsbuild j4 cmake install fbsbuild prefix fbsinstall export cmake dwithflatbufferson s opencv b opencvbuild how to build for opencvjs emcmake python3 buildwasm buildwasm see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake forcebuilderslinux opencllinux avx2 buildworkerlinux opencllinux1"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpenCV cannot import ONNX model: Can't create layer \"...\" of type \"Exp\"\nsystem information opencv python opencvpython 451 operating system platform windows 10 64 bit python 3711 detailed description i have a darknet yolov4 model that i can use with i converted the model to an onnx file using this codebase i load the onnx file with cvdnnreadnetfromonnx and ran my application but got the following error error0 global 1878 dnnonnx error during processing node with 1 inputs and 1 outputs exp365 traceback most recent call last file runpy line 16 in aiasrunprojconfig runtimeerror opencv451 error 2unspecified error in function node exp365 parse error opencv451 error 2unspecified error cant create layer 365 of type exp in function issue submission checklist i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nThe Einsum Layer will be supported in the future\ndescripe the feature and motivation error02968 global onnximportercpp1054 dnnonnx error during processing node with 2 inputs and 1 outputs from domainaionnx additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSupport GraphCutSeamFinder in stitching_detailed.py\ndescripe the feature and motivation with the release of opencv 47 this pr becomes available so we can add to previously it was removed since python bindings were corrupt thanks to chinery for fixing this additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nA redundant logic in `distanceTransform`.\nversion opencv 470 issue c if needlabels …… masksize cvdistmask5 the masksize is set to cvdistmask5 if needlabels meaning the followup code c if disttype cvdistc disttype cvdistl1 masksize needlabels cvdistmask3 cvdistmask5 else if disttype cvdistl2 needlabels masksize cvdistmask5 does the same as c ifdisttype cvdistc disttype cvdistl1 needlabels masksize cvdistmask3 the redundant code should be removed the masksize being set to cvdistmask5 if needlabels no matter what masksize is provided is undocumented behavior and should be properly documented"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReplace all instances of CUDA texture references with texture objects\nsee and cuda texture references have now been completley removed in the latest sdk cuda 120 if is merged this code block which is causing builds to fail against cuda 120 will become redundant pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nVCPKG feature for Intel's Inference Engine\ndescripe the feature and motivation hi i think actually there is no feature to build opencv with intels inference engine support openvino i guess i dont know if is it there any fast solution from compile opencv from source code with the dwithopenvinoon flag and that stuff so im requesting if it is possible to have a “feature” like the others for cuda support dnn modules contrib etc but for the intels inference engine thank you so much additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nvideoio: add Orbbec Gemini 2 and Astra 2 camera support\npull request readiness checklist x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x the feature is well documented and sample code can be built with the project cmake test result os compiler camera result windows11 vs2022msvc173orbbec gemini 2pass windows11 vs2022msvc173orbbec astra 2pass gemini 2pass astra 2pass"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncore(logger): strip opencv's modules base path\nstrip path from logger keep file name only reverted cverror changes"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndnn: support ONNX Slice with negative steps by adding and using cv::flipND\nfixes merge with current workaround for negative steps is computing the forward indexing range for slice and flip at axis with negative step x of shape 5 10 x501 1013 npflipx151 2103 aixs0 1 we can also extend range to support backward indexing and steps like python list which needs more effort to do so i think pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nUse QR code alignment markers\nmerge with added detect qr code alignment marker 1 marker for 26 versions 6 markers for 740 versions alignment marker uses to find the correct position of the fourth corner to check the correctness a benchmark was launched qrpytxt 2 total decode 5 against detected qr codes 04 pixels total accuracy for corner detect logging from benchmark no decode regression now pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDepth Encoding FFMPEG 16bit file support\ndescripe the feature and motivation depth images typically come as type uint16 ive been looking online and there is pretty lackluster support for depth video compression which i think is an extremely important problem for example i am a part of a group collecting a large robot dataset and we need to compress our depth data some existing approaches include using 1 ffv1 but opencv ffmpeg doesnt support 16bit datatypes as of now 2 converting depth images to color and then encoding normally it would be super helpful if cv2 could provide some built in functionality for this additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nNow there is no way to control GStreamer drop timeout when ip-camera drops\ndescripe the feature and motivation im using opencv with gstreamer and sometimes my camera can disconnect and when its happened i just have program freezing for 20 s and maybe i didnt find there is no way to change that timeout similar thing is for ffmpeg but it didnt work for gstreamer additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nBatched NMSBoxes\ndescripe the feature and motivation batched nms is especially useful for modern generic object detection postprocessing generic object detection has multiple classes and it is important to perform nms on each class to give correct results however the existing api for nms in dnn module nmsboxes does not support multiple classes we can use the same strategy from to implement batched nms 1 get the maximum coordinate from boxes 2 calculate the offset based on the maximum coordinate and class ids 3 add offsets to boxes 4 run nmsboxes with boxes with offsets scores and thresholds although this is quite simple to implement for experienced developers it would still be better if we put it in the dnn module as a new api lets call it batchednmsboxes and it can be done by calling a single api instead of wasting time implementing every time we need it additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDNN: make MatMul support 3D or 4D with broadcast\nmerge with extra this pr follows the the main purpose of this pr is making matmul support the broadcast that the second input has less dimention than the first one and let the operation support simd and multithread beacuse it doesnt support 1d mat only support matmul like 2x3x4 mul 4x5 2x3x5 2x3x4x5 mul 3x5x6 2x3x4x6 2 const inputs create a virtual layer for the first input 1 const input with cpu whether or not using broadcast use the simd and multithread flow which for innerproduct 1 const input with cuda broadcast inputs will fallback to cpu inputs with the same shape will use the cuda pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpenCV cannot import ONNX model: (bool)layer in function 'cv::dnn::dnn4_v20220524::runLayer'\nsystem information opencv python opencvpythonrolling 46020221022 operating system platform windows 10 64 bit python 3104 detailed description i converted the decoupledseg from paddleseg to onnx the onnx file opens fine in netron this fails to load in opencv 46 prerelease error00667 global 1050 dnnonnx error during processing node with 2 inputs and 1 outputs tileonnxnodep2otile0 from domainaionnx traceback most recent call last file line 123 in model cv2error opencv460dev error 2unspecified error in function node parse error opencv460dev error 215assertion failed boollayer in function steps to reproduce model find the model here issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncore: support CV_Check*() macros with 'bool' parameters\nadded support for cvcheckeqnebool bool msg ltgeetc variants doesnt makes sense with bool and should not be used msg msg also eliminates related build warning forcebuilderslinux32 buildimagecustom winmsvs2019"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsupport Nanotrack in video module\nteset data in opencvextra nanotrack is an extremely lightweight and fast objecttracking model the total size is 11 mb and the fps on m1 chip is 150 on raspberry pi 4 is about 30 float32 cpu only with this model many users can run object tracking on the edge device the author of nanotrack is honglinchu the original repo is pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd support for CAP_PROP_ORIENTATION_AUTO to AVFoundation backend\nthis is an extension to 15499 i pulled some of the code up so now it would be somewhat easier to add support for orientation metadata into the other backends as well pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpenCV cannot import ONNX model: Can't create layer \"...\" of type \"Tile\"\nsystem information opencv python opencvpythonrolling 46020221022 operating system platform windows 10 64 bit python 3104 detailed description i converted the danets from paddleseg to onnx this fails to load in opencv 46 prerelease error00494 global 1050 dnnonnx error during processing node with 2 inputs and 1 outputs tileonnxnodep2otile0 from domainaionnx traceback most recent call last file line 123 in model cv2error opencv460dev error 2unspecified error in function node parse error opencv460dev error 2unspecified error cant create layer onnxnodep2otile0 of type tile in function steps to reproduce model find one of the models here issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCreate _InputArray/_OutputArray from fixed size array\ndescripe the feature and motivation i think we could add an extra constructor to so that it can convert directly from a c fixed size array like this c template inputarrayconst tp vecnm traditionally we need to explicitly convert it to a combination of pointer size like c auto arr inputarrayvec stdsizevec it would be more convenient to have something like c auto arr inputarrayvec additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncv.LUT is missing in openCv 4.6.0\ndescripe the feature and motivation hi thankyou for this awesome js library there was a use case which involved useing cvlut however it is not available as of now this function is available in opencv c and python versions requesting you to please add this function in opencv js library with a proper documentation which will help developers like me kind regards aditya additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nstitching_detailed.py: It can not be spliced well , Request help\ndescripe the feature and motivation stitchingdetailedpy it can not be spliced well request help direction transverse 1jpg 4500 16000 2jpg 4500 16000 3jpg 4500 16000 i need to splice but i cant complete the requirements very well i need help pictures can be sent to email additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nPass the AVDictionary generated from OPENCV_FFMPEG_CAPTURE_OPTIONS and OPENCV_FFMPEG_WRITER_OPTIONS to avformat_find_stream_info as well to gain access to more ffmpeg options\ndescribe the feature and motivation while working on i realized that the environment variables and can only configure a very small subset of the ffmpeg options the options listed in that prevented me from passing all necessary options to fully specify the stream anyway i suggest passing the avdictionary not just to avformatopeninput but to as well and maybe even to avcodecopen2 additional context no response"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nprint a debug message if the environment variables OPENCV_FFMPEG_CAPTURE_OPTIONS and OPENCV_FFMPEG_WRITER_OPTIONS are set\ndescripe the feature and motivation the environment variables and potentially have great impact on the internals of the ffmpeg video backend but when they are used the log files dont show it id like to print a debug message containing the value of those variables in case they are set additional context this issue contains examples of how those variables can be used"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDNN: let Quant and Dequant of ONNX_importer support the Constant input.\nmerge with extra opencvextra1014 for zeropoint and scale can be 1d tensor only exists in quant deaunt and weight of qlinearconv we have supported 1d tensor case in qlinearconv for quant and deaunt we can support the constant input case which is very common situation in perchannel qdq quantized format model examples can be found at pr of extra pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDNN: More stable DB text detection API\nmerge with extra the followings are the purpose of the pr 1 let blobfromimage support scalar scale to feed the requirement of standard deviation value 2 more stable db text detection api the old postprocessing will get assert errors when length 0 the related code part 3 output the correct confidence or score instead of always being 1 4 support ppocrv2 and ppocrv3 db models the original inference code can be found here related regression test model pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nadd cvGetPropVisible_COCOA\nnaive fix for the 22595 issue tested not visible behaviour via cvwaitkey12345 and minimising the window during that wait pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd bindings to CUDA photo denoising functions\npython bindings were missing from the cuda photo denoising functions the function signatures have been updated and python test added to verify their existence are these supposed to be in the main repository pull request readiness checklist see details at i agree to contribute to the project under apache 2 license to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDNN: supports Scatter and ScatterND from ONNX\nfixes 22528 merge with checklist x scatter impl x scatter impl for negative indices x test data for scatter x scatternd impl x scatternd impl for negative indices x test data for scatternd x disable the perf test to save ci server resources before merge onnx operator doc benchmark benchmark was done on m1 macbook air 16g mem time is in milliseconds shapes of input indices updates are all 8 256 128 100 version operation mean median min intial scatter 22353 22344 22077 initial scatteradd 24119 24186 23811 passingmat scatter 22851 22836 22645 passingmat scatteradd 24908 24920 24754 current impl optm pm scatter 15462 15380 15338 current impl optm pm scatteradd 16939 16963 16820 shapes of input indices updates are 8 256 128 100 8 256 128 100 4 8 256 128 100 respectively version operation mean median min intial scatternd 46592 46525 46478 initial scatterndadd 47501 47386 47313 passingmat scatternd 46459 46440 46413 passingmat scatterndadd 47380 47024 46580 pm ng index scatternd 51117 50844 50773 pm ng index scatterndadd 51891 51856 51094 optm1 pm ng index scatternd 22704 22629 22521 optm1 pm ng index scatterndadd 21858 21837 21726 current impl optm2 optm1 pm ng index scatternd 13287 13294 13209 current impl optm2 optm1 pm ng index scatterndadd 13517 13505 13393 potential issue scatternd should support duplicate indices if reduction is not none also scatternd permits negative indices see here for more details notice current impl does not check for duplicate indices if reduction is none pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nColor conversion: RGB => NV12 / NV21\nadd color conversion for rgb rgba bgr bgra to nv12 nv21 system information version opencv 4x operating system platform all detailed description there are conversions from nv12 nv21 to rgb rgba bgr bgra gray but not the reverse this can be useful if we need to pass the an image to a video encoder that expect that steps to reproduce issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd H264 / H265 writter support for Android\npull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nG-API Expose all core operations to python\npull request readiness checklist see details at i agree to contribute to the project under apache 2 license to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake motivation python bindings are available since a long time but only a few operations operationon wrappers were exposed there was a great plan to implement feature in python parser that could automatically detect gapi operation via gapitypedkernel macro or so and expose it into python but this functionality is more about giving an opportunity to user to implement python kernels for already existing in gapi operations this pr is going to expose just operationon wrappers to python in order to give user everything that is available from c because now for developers who dont build from source and change the code only available a small amount of functionality since a lot of developers use opencv from pip lets expose it once and forever great example of gapi usage todo list x expose core expose imgproc expose video expose stereo other stuff eg constant initialization for gtypes some compiler args"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd support for V4L2_PIX_FMT_Y16_BE\nopencv currently only has support for v4l2pixfmty16 but not for the big endian version of this format v4l2pixfmty16be would it be possible to add it to capv4lcpp the handling should be a lot similar to the little endian version of the format but can opencv handle big endian data or are there any functions to swap the endianess"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n4-bit_palette_color\npull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDNN: support silu activation in darknet\nrelated issue 22409 pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nadd multiview calibration [GSOC 2022]\npull request readiness checklist x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake the usage tutorial is on google docs following this link"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\n[GSoC] Add more universal intrinsic implementations for RVV.\nthis is a patch of my gsoc project that the goal is to make the existing universal intrinsic compatible with scalable variablelength backends in 22179 we have already introduce a new framework of universal intrinsic for riscv vector backend and few implementations and test cases are also added in this patch we are going to add more universal intrinsic implementations for rvv tested with qemu for rvv backend in various vlen qemuriscv64 cpu rv64xvtruevlen128 binopencvtestcore gtestfilterhal qemuriscv64 cpu rv64xvtruevlen512 binopencvtestcore gtestfilterhal also tested for avx and sse backend on linux pull request readiness checklist see details at i agree to contribute to the project under apache 2 license to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDNN: Add qgemm and squeeze op13 supported on ONNXImporter\nsqueeze node of onnx has moved the axes from attribute to input test data pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nVideoCapture FFMpeg RTSP low fps fixes\nwhen using videocapture with the ffmpeg backend to stream from an rtsp source at a low frame rate on a machine with a large number of cpu cores videocapturereadgrab can fail due to the interrupt timer exceeding timeoutafterms to try and fix this this pr adds the cappropnthreads which can be set on open to reduce the number of threads in this case this is related to but i cannot tell if it fixes the issue as i am unable to recreate it on a machine with reading from a file with only 20 cpu cores in addition to this videocaptureopen can get stuck and therefore interupted on the call to err null when streaming from an rtsp source at a low frame rate regardless of the number of cpu cores the call to open still succeeds and the frame can be read but because the flag has been set in open the call to grabread fails to fix this the flag is reset on entry to grabread pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nV4L2: Add multi-planar capture support\ndevices which only support multiplanar capture cannot be processed as singleplanar add multiplanar support to v4l driver pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDNN: Reduce Layer (add dynamic batch and ReduceSum support) \nrelated reducesum issue 22195 related dynamic batch of reduce layer issue 22086 in this pr we supported two input of reducesum layer and dynamic batch size in reduce layer of onnximportercpp regression test the pervious pr on dynamic batch of reduce layer has been closed pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nvideoio: add support for obsensor (Orbbec RGB-D Camera )\nvideocapture for obsensor obsensor is orbbecs new generation rgbd camera brand based on uvc protocol the purpose is to let opencv read rgb and depth data from orbbec rgbd camera via uvc protocol rather than relying on the 3rdparty library like openni this will greatly facilitate users to directly read use and process the depth camera in opencv supported orbbec device orbbec astra detail depth stream 640x480x30 fps cv16uc1 rgb stream 640x480x30fps bgr orbbec femto detail depth stream 640x480x30 fps cv16uc1 rgb stream 640x480x30fps bgr orbbec future device supported os windows and linux macox will be supported in near future supported hw x86 x64 arm since the new orbbec devices rely on uvc while old devices still rely on openni this will cause obsensor doesnt support some old orbbec cameras and the following is a list of specific unsupported devices orbbec astra orbbec astra pro for these unspported devices we still need the support of openni please refer to the detailed tutorial of using orbbec astra 3d cameras in opencv pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x the feature is well documented and sample code can be built with the project cmake x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nCUDA: add support for Orin GPU\npull request readiness checklist reference see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd zoom factor to interactive calibration tool\ncan be useful when the screen is smaller than the image from camera pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nHOGDescriptor\nresolves pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nhighgui Wayland xdg_shell\nenable using dwithwaylandon adapted from using stable protocol overrides haveqt if havewayland and withwayland are set signedoffby joel winarske pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake pfpacket"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nSave Frames option for interactive calibration tool\nthe option to save all frames that contribute to final calibration result useful for dataset collection and further offline tuning pull request readiness checklist see details at i agree to contribute to the project under apache 2 license to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nimgcodecs: jpeg: add IMWRITE_JPEG_SAMPLING_FACTOR parameter\nfix this merge request contains sample and test program pull request readiness checklist see details at i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake forcebuilderscustom"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nConsider video meta on GStreamer video capture\nsome gstreamer elements may produce buffers with very non standard strides offsets andor even transport each plane in different noncontiguous pointers this nonstandard layout is communicated via gstvideometa structures attached to the buffers given this when a gstvideometa is available one should parse the layout from it instead of generating a generic one from the caps the gstvideoframe utility does precisely this if the buffer contains a video meta it uses that to fill the format and memory layout if there is no meta available the layout is inferred from the caps pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nOpenCV fails to import ONNX model\nsystem information version opencv 455 operating system platform windows 10 64 bit compiler python 3104 installed packages numpy 1223 opencvcontribpython 45564 pip 2204 setuptools 5810 detailed description when running the demopy for opencvzoo the models fails to import all the other models i tried to import did work well i wrote a python script in a different venv to check the model with onnx and infer with the model with onnxruntime the model imports and executes fine this is not a problem with the models but with the importer error message error00223 global nnxonnximportercpp 909 dn nonnx error during processing node with 3 inputs and 1 outputs clip317 f rom domainaionnx traceback most recent call last file li ne 41 in v2 labelpathargslabel backendidargsbackend targetidargstarget file py line 11 in init selfmodel cv2error opencv455 error 2unspecified error in function cvdnn node clipaionnx317 parse error opencv455 daopencvpythonopencv error 2unspecifi ed error in function void cdecl clipclass const class opencvonnxnodep roto expected nodeprotoinputsize 1 where nodeprotoinputsize is 3 must be equal to 1 is 1 steps to reproduce reproducible yes enforceable yes run the provided demopy in opencvzoo issue submission checklist x i report the issue its not a question x i checked the problem with documentation faq open issues forumopencvorg stack overflow etc and have not found any solution x i updated to the latest opencv version and the issue is still there x there is reproducer code and related data files videos images onnx etc"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nsupport use memory buffer as input to read multi-page image\npull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nadded blob contours to blob detector\nthis pr adds an option to collect blob contours during blob detection simpleblobdetector pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReimplementation of Element-wise layers with broadcasting support\nthis version supports elementwise nary operations on kdimensional tensors with broadcastcompatible shapes update by fengyuentau onnx operators that needs broadcasting benchmarks on apple m1 input tensor a of shape 8 256 128 100 input tensor b of shape 8 256 128 100 operation eltwise layers ms this pr ms add not supported 560 and not supported div 830 555 equal not supported 558 greater not supported 550 less not supported 545 max 830 564 nary mean not supported 544 nary min 830 560 nary mul 859 569 or not supported pow not supported 21338 sub not supported 570 sum 834 556 nary xor not supported end of updates benchmarks sum of two tensors with shape8256128100 eltwise layer takes 24ms this implementation takes 49ms note smallvector doesnt speed up anything right now so itll probably get removed pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nDNN: Add sign, shrink and reciprocal for onnx_impoter\nadd sign shrink and reciprocal for onnximportercpp implemented with opencv cuda and opencl backend pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\npython binding for matches and inliers_mask attributes of cv2.detail_MatchesInfo class\nin respect to the issue 21364 the pull request makes matches and inliersmask attributes of the cv2detailmatchesinfo class accessible from python interface by this way developers could be able to make changes on the computed matches pull request readiness checklist yes i agree to contribute to the project under apache 2 license yes to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv yes the pr is proposed to the proper branch yes there is a reference to the original bug report and related work"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nvideoio: initial FFmpeg 5.0 support\nresolves 20147 closes 21766 ffmpegn50 debug sh configure enableshared disablestatic enablepic enablegpl enablenonfree enablelibxvid enablelibx264 enableswresample enabledebug3 disablestripping extracflagsgstabs og g fnoinline fnoomitframepointer disableoptimizations todo x check hw acceleration support va x check and fix compatibility with older ffmpeg versions up to 20 releases backport to opencv 34 buildcontribcustom winoff buildsharedcustomoff buildimagelinux avx2ubuntu2004 winlinux avx2 testopenclcustomon buildimagecustom winffmpeg xbuildimagecustom winffmpegplugin buildworkercustom winwindows2 testmodulescustom winvideoio testopenclcustom winon"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nadd Gather implementation\nmerge with extra should resolve 20439 resolve 19957 pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd n-dimensional transpose to core\npull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nTIFFDecoder does not support 12 bits (integer)\nopencv 45 as of opencv 45 the tiffdecoder does not support 12 bits integer it looks like a deliberate choice since decoding 8 and 16 are supported with optimized icv conversion functions would it be accepted to add a slow unpacking step for nonstandard bit depths there are at least two problems it would be logical to automatically scale the resulting cvmat here by 11612 but the caller would not be aware that such a conversion was done tiff is so complex that its hard to ensure that all and every packing scheme is supported"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nG-API: VPP preprocessing GIEBackend integration\nintegration of vpp preprocessing into giebackend this pr had done in term of pr inferroi is supported only pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake build configuration wincustom mac x64ade011f x64 debugade011f xbuildimagecustom winopenvino202120 buildimagecustom macopenvino202120 testmodulescustom testmodulescustom testopenclcustomoff testbigdatacustom1 testfiltercustom buildimagecustom wingapionevpl202160 buildworkercustom winwindows3 buildcontribcustom winoff"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nG-API: Added reshape() functionality to CPU backend\nsummary added reshape functionality to cpu backend fixed fluid heterogeneous reshape pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake build configuration wincustom mac x64ade011f x64 debugade011f buildimagecustom winopenvino202141 buildimagecustom macopenvino202141 testmodulescustom testmodulescustom disabled due high memory usage testopenclcustomon testopenclcustomoff testbigdatacustom1 testfiltercustom"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdded NEON support in builds for Windows on ARM\nsince visual studio 1611 visual studio 2022 170 the data types eg int32x4t used by arm neon instructions are now defined so the blocking of neon support in builds for windows on arm has been resolved preprocessor arm64 vector intrinsics typedefs float32x4t and int32x4t to the same type visual studio feedback 16027 todo x alalek fix buildsampleson mode findpackageopencl founds opencl from cuda sdk which cant work with arm64 crosscompialtion added dwithopencloff x alalek configure msvs 2022 build image pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake forcebuilderscustom win xbuildimagecustom winmsvs2019arm64 buildimagecustom winmsvs2022arm64 buildworkercustom winwindows1 buildcontribcustom winoff xbuildexamplescustom winoff"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nIssues 21537\nthe patch will try to use 15 bits channel to generate 16 bits channel panoramas example of input files 1 2 example of the panorama using the 420 from standard linuxmint packages panorama8bitref example of the panorama using the branch 4x with the patch panorama8bit example of the panorama using the branch 4x with the patch with the images converted to 16 bits channel cv16uc3 and multiply by 256 panorama16bit somehow the result seems to keep more details when the images was converted to 16 bits channel see the attached crops original input image panorama using 420 8 bits channel panorama using the patch and 8 bits channel panorama using the patch and 16 bits channel 1zoom panorama8bitrefzoom panorama8bitzoom panorama16bitzoom pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncv::va_intel::convertFromVASurface always fails on AMD devices using mesa\nif you have a question rather than reporting a bug please go to where you get much faster responses if you need further assistance please read how to contribute this is a template helping you to create an issue which can be processed as quickly as possible this is the bug reporting section for the opencv library system information version opencv 455 operating system platform slackwarecurrent detailed description always fails on amd devices using mesa steps to reproduce i am trying to convert a vaapi image from ffmpeg in an avframe to a umat so my code is like this bool avframe frame bool video check if the incoming frame is vaapi if video frameformat avpixfmtvaapi framehwframesctx avhwframescontext hwframes avhwframescontext framehwframesctxdata avhwdevicecontext devicectx hwframesdevicectx avvaapidevicecontext hwctx if devicectxtype avhwdevicetypevaapi lerrorvaapi frame does not have vaapi device return false hwctx cvumat tmp const vasurfaceid surf try surf cvsizeframewidth frameheight tmp catch cvexception e lwarnerror converting image from vaapi to opencv emsg return false digging into it calls vaderiveimage which if using mesa calls vlvaderiveimage but per the comment in mesa that always fails on amd devices unless your program name is vlc h264encode or hevcencode this function is used by some programs to test for hardware decoding but on amd devices the buffers default to interlaced which causes this function to fail some programs expect this function to fail while others assume this means hardware acceleration is not available and give up without trying the fallback vacreateimage vaputimage the solution then is should have the vacreateimage vaputimage fallback that mesa requires"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ndnn: apply hint to ignore denormals processing\nreworks 17295 continues 21506 resolves 21046"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\ncore: FP denormals support\nrelates 21046 support x86 sse ftzdaz flags info forcebuilderscustom"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nfeature: submodule or a class scope for exported classes\nall classes are registered in the scope that corresponds to c namespace or exported class example cvmlboost is exported as cvmlboost is exported as for backward compatibility all classes are registered in the global module with their mangling name containing scope information example cvmlboost has cvmlboost alias to cvmlboost type closes 14730 backport for 4x is required to handle gapi aliases in the right way python cvgapiwipdrawrect cvgapiwipdrawrect cvgapiwipdrawtext cvgapiwipdrawtext cvgapiwipdrawcircle cvgapiwipdrawcircle cvgapiwipdrawline cvgapiwipdrawline cvgapiwipdrawmosaic cvgapiwipdrawmosaic cvgapiwipdrawimage cvgapiwipdrawimage cvgapiwipdrawpoly cvgapiwipdrawpoly cv pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or another license that is incompatible with opencv x the pr is proposed to the proper branch x there is a reference to the original bug report and related work x there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name x the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nReading BigTiff images\nmerge with extra resolves 18717 pull request readiness checklist see details at i agree to contribute to the project under apache 2 license to the best of my knowledge the proposed patch is not based on a code under gpl or other license that is incompatible with opencv the pr is proposed to proper branch there is reference to original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdd general broadcasting layer\nperformance detailsbroadcasting 1x1 to 16x2048x2048 mat of cv32fc1 260mb ocl copyto for dims 3 there is that runs in 1ms and can work on strided data but higher dimensions are not supported ocl memcpy 22ms cpu copyto 36ms cpu memcpy 20ms cuda memcpy 11ms tests this doesnt enable any of the conformance tests since the only two we could use addbcast and subbcast use 1d inputs and we convert them to 2d inserting 1 in the wrong spot rendering the shape layouts noncompatible other tests with broadcastingandorxor less equal greater and such require bool output pull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or other license that is incompatible with opencv x the pr is proposed to proper branch there is reference to original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake win buildimagecustom winopenvino202142 buildworkercustom winwindows3 testbigdatacustom win1 testfiltercustom win testmodulescustom testopenclcustom winon buildcontribcustom winoff"}, {"role": "assistant", "content": "feature"}]}
{"messages": [{"role": "system", "content": "GitHub Pull Request Classifier"}, {"role": "user", "content": "Classify, IN ONLY 1 WORD, the following GitHub pull request as 'feature', 'bug', or 'question' based on its title and body:\nAdapt remote inference to operate with NV12 blobs\npull request readiness checklist see details at x i agree to contribute to the project under apache 2 license x to the best of my knowledge the proposed patch is not based on a code under gpl or other license that is incompatible with opencv x the pr is proposed to proper branch there is reference to original bug report and related work there is accuracy test performance test and test data in opencvextra repository if applicable patch to opencvextra has the same branch name the feature is well documented and sample code can be built with the project cmake wincustom mac x64ade011f x64 debugade011f buildimagecustom winopenvino202141 buildimagecustom macopenvino202141 testmodulescustom testmodulescustom disabled due high memory usage testopenclcustomon testopenclcustomoff testbigdatacustom1 testfiltercustom"}, {"role": "assistant", "content": "feature"}]}
